[
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "Preface\nTo Everyone\nWelcome to this book! We hope you\u2019ll enjoy reading it as much as we enjoyed\nwriting it. The book is calledOperating Systems: Three Easy Pieces(available\nat http://www.ostep.org), and the title is obviously an homage to one of the\ngreatest sets of lecture notes ever created, by one Richard Feynman on the topic of\nPhysics [F96]. While this book will undoubtedly fall short of the high standard set\nby that famous physicist, perhaps it will be good enough for you in your quest to\nunderstand what operating systems (and more generally, systems) are all about.\nThe three easy pieces refer to the three major thematic elementsthe book is\norganized around: virtualization, concurrency,a n dpersistence. In discussing\nthese concepts, we\u2019ll end up discussing most of the important things an operating\nsystem does; hopefully, you\u2019ll also have some fun along the way. Learning new\nthings is fun, right? At least, it should be.\nEach major concept is divided into a set of chapters, most of which present a\nparticular problem and then show how to solve it. The chaptersare short, and try\n(as best as possible) to reference the source material where the ideas really came\nfrom. One of our goals in writing this book is to make the paths of history as clear\nas possible, as we think that helps a student understand what is,w h a tw a s ,a n d\nwhat will be more clearly. In this case, seeing how the sausage was made is nearly\nas important as understanding what the sausage is good for1.\nThere are a couple devices we use throughout the book which are probably\nworth introducing here. The \ufb01rst is thecrux of the problem. Anytime we are\ntrying to solve a problem, we \ufb01rst try to state what the most important issue is;\nsuch acrux of the problemis explicitly called out in the text, and hopefully solved\nvia the techniques, algorithms, and ideas presented in the rest of the text.\nIn many places, we\u2019ll explain how a system works by showing its behavior\nover time. Thesetimelines are at the essence of understanding; if you know what\nhappens, for example, when a process page faults, you are on your way to truly\nunderstanding how virtual memory operates. If you comprehend whatt a k e sp l a c e\nwhen a journaling \ufb01le system writes a block to disk, you have taken the \ufb01rst steps\ntowards mastery of storage systems.\nThere are also numerousasides and tips throughout the text, adding a little\ncolor to the mainline presentation. Asides tend to discuss something relevant (but\nperhaps not essential) to the main text; tips tend to be generallessons that can be\n1Hint: eating! Or if you\u2019re a vegetarian, running away from.\niii",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "greatest sets of lecture notes ever created, by one Richard Feynman on the topic of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "greatest",
          "sets",
          "lecture",
          "notes",
          "ever",
          "created",
          "richard",
          "feynman"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand what operating systems (and more generally, systems) are all about.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "operating",
          "systems",
          "generally",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "these concepts, we\u2019ll end up discussing most of the important things an operating",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concepts",
          "discussing",
          "important",
          "things",
          "operating"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "system does; hopefully, you\u2019ll also have some fun along the way. Learning new",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "hopefully",
          "also",
          "along",
          "learning"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Each major concept is divided into a set of chapters, most of which present a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "major",
          "concept",
          "divided",
          "chapters",
          "present"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "particular problem and then show how to solve it. The chaptersare short, and try",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "particular",
          "problem",
          "show",
          "solve",
          "chaptersare",
          "short"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "from. One of our goals in writing this book is to make the paths of history as clear",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goals",
          "writing",
          "book",
          "make",
          "paths",
          "history",
          "clear"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "as possible, as we think that helps a student understand what is,w h a tw a s ,a n d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "possible",
          "think",
          "helps",
          "student",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "as important as understanding what the sausage is good for1.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "understanding",
          "sausage",
          "good"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "trying to solve a problem, we \ufb01rst try to state what the most important issue is;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trying",
          "solve",
          "problem",
          "state",
          "important",
          "issue"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand at http: //www.ostep.org), and the title is obviously an homage to one of the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "at http",
          "ostep",
          "title",
          "obviously",
          "homage"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "iv\napplied to systems you build. An index at the end of the book listsall of these tips\nand asides (as well as cruces, the odd plural of crux) for your convenience.\nWe use one of the oldest didactic methods, thedialogue, throughout the book,\nas a way of presenting some of the material in a different light.These are used to\nintroduce the major thematic concepts (in a peachy way, as we wills e e ) ,a sw e l la s\nto review material every now and then. They are also a chance towrite in a more\nhumorous style. Whether you \ufb01nd them useful, or humorous, well, that\u2019sa n o t h e r\nmatter entirely.\nAt the beginning of each major section, we\u2019ll \ufb01rst present anabstraction that an\noperating system provides, and then work in subsequent chapters on the mecha-\nnisms, policies, and other support needed to provide the abstraction. Abstractions\nare fundamental to all aspects of Computer Science, so it is perhaps no surprise\nthat they are also essential in operating systems.\nThroughout the chapters, we try to usereal code(not pseudocode)w h e r ep o s -\nsible, so for virtually all examples, you should be able to type them up yourself and\nrun them. Running real code on real systems is the best way to learnabout operat-\ning systems, so we encourage you to do so when you can. We are alsomaking code\navailable athttps://github.com/remzi-arpacidusseau/ostep-code for\nyour viewing pleasure.\nIn various parts of the text, we have sprinkled in a fewhomeworks to ensure\nthat you are understanding what is going on. Many of these homeworks are little\nsimulations of pieces of the operating system; you should download the home-\nworks, and run them to quiz yourself. The homework simulators have the follow-\ning feature: by giving them a different random seed, you can generate a virtually\nin\ufb01nite set of problems; the simulators can also be told to solvethe problems for\nyou. Thus, you can test and re-test yourself until you have achieved a good level\nof understanding.\nThe most important addendum to this book is a set ofprojects in which you\nlearn about how real systems work by designing, implementing, and testing your\nown code. All projects (as well as the code examples, mentioned above) are in\nthe Cp r o g r a m m i n gl a n g u a g e[KR88]; C is a simple and powerful language that\nunderlies most operating systems, and thus worth adding to your tool-chest of\nlanguages. Two types of projects are available (see the onlinea p p e n d i xf o ri d e a s ) .\nThe \ufb01rst aresystems programmingprojects; these projects are great for those who\nare new to C and UNIX and want to learn how to do low-level C programming.\nThe second type are based on a real operating system kernel developed at MIT\ncalled xv6 [CK+08]; these projects are great for students thatalready have some C\nand want to get their hands dirty inside the OS. At Wisconsin, we\u2019ve run the course\nin three different ways: either all systems programming, all xv6programming, or\na mix of both.\nWe are slowly making project descriptions, and a testing framework, avail-\nable. See https://github.com/remzi-arpacidusseau/ostep-projects\nfor more information. If not part of a class, this will give you achance to do these\nprojects on your own, to better learn the material. Unfortunately, you don\u2019t have\na TA to bug when you get stuck, but not everything in life can be free (but books\ncan be!).\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "We use one of the oldest didactic methods, thedialogue, throughout the book,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "oldest",
          "didactic",
          "methods",
          "thedialogue",
          "throughout",
          "book"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "introduce the major thematic concepts (in a peachy way, as we wills e e ) ,a sw e l la s",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "introduce",
          "major",
          "thematic",
          "concepts",
          "peachy",
          "wills"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "are fundamental to all aspects of Computer Science, so it is perhaps no surprise",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "aspects",
          "computer",
          "science",
          "perhaps",
          "surprise"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "that they are also essential in operating systems.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "essential",
          "operating",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "sible, so for virtually all examples, you should be able to type them up yourself and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sible",
          "virtually",
          "examples",
          "able",
          "type"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "run them. Running real code on real systems is the best way to learnabout operat-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "running",
          "real",
          "code",
          "real",
          "systems",
          "best",
          "learnabout",
          "operat"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "that you are understanding what is going on. Many of these homeworks are little",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "going",
          "many",
          "homeworks",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "in\ufb01nite set of problems; the simulators can also be told to solvethe problems for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problems",
          "simulators",
          "also",
          "told",
          "solvethe",
          "problems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "of understanding.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "The most important addendum to this book is a set ofprojects in which you",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "addendum",
          "book",
          "ofprojects"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand ing feature: by giving them a different random seed, you can generate a virtually",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ing feature",
          "giving",
          "different",
          "random",
          "seed",
          "generate",
          "virtually"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand See https: //github.com/remzi-arpacidusseau/ostep-projects",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "see https",
          "github",
          "remzi",
          "arpacidusseau",
          "ostep",
          "projects"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "v\nTo Educators\nIf you are an instructor or professor who wishes to use this book,p l e a s ef e e l\nfree to do so. As you may have noticed, they are free and availableo n - l i n ef r o m\nthe following web page:\nhttp://www.ostep.org\nYou can also purchase a printed copy fromlulu.com.L o o kf o ri to nt h ew e b\npage above.\nThe (current) proper citation for the book is as follows:\nOperating Systems: Three Easy Pieces\nRemzi H. Arpaci-Dusseau and Andrea C. Arpaci-Dusseau\nArpaci-Dusseau Books\nAugust, 2018 (Version 1.00)\nhttp://www.ostep.org\nThe course divides fairly well across a 15-week semester, in which you can\ncover most of the topics within at a reasonable level of depth.Cramming the\ncourse into a 10-week quarter probably requires dropping some detail from each\nof the pieces. There are also a few chapters on virtual machine monitors, which we\nusually squeeze in sometime during the semester, either right at endof the large\nsection on virtualization, or near the end as an aside.\nOne slightly unusual aspect of the book is that concurrency, a topic at the front\nof many OS books, is pushed off herein until the student has built anunderstand-\ning of virtualization of the CPU and of memory. In our experience inteaching\nthis course for nearly 20 years, students have a hard time understanding how the\nconcurrency problem arises, or why they are trying to solve it, if they don\u2019t yet un-\nderstand what an address space is, what a process is, or why context switches can\noccur at arbitrary points in time. Once they do understand theseconcepts, how-\never, introducing the notion of threads and the problems that arise due to them\nbecomes rather easy, or at least, easier.\nAs much as is possible, we use a chalkboard (or whiteboard) to deliver a lec-\nture. On these more conceptual days, we come to class with a few majori d e a s\nand examples in mind and use the board to present them. Handouts are useful\nto give the students concrete problems to solve based on the material. On more\npractical days, we simply plug a laptop into the projector and show real code; this\nstyle works particularly well for concurrency lectures as wellas for any discus-\nsion sections where you show students code that is relevant fort h e i rp r o j e c t s .W e\ndon\u2019t generally use slides to present material, but have now madeas e ta v a i l a b l e\nfor those who prefer that style of presentation.\nIf you\u2019d like a copy of any of these materials, please drop us an email. We\nhave already shared them with many others around the world, andothers have\ncontributed their materials as well.\nOne last request: if you use the free online chapters, please just link to them,\ninstead of making a local copy. This helps us track usage (over 1 million chapters\ndownloaded in the past few years!) and also ensures students gett h el a t e s t( a n d\ngreatest?) version.\nc\u20dd 2008\u201318, A RPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "of many OS books, is pushed off herein until the student has built anunderstand-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "books",
          "pushed",
          "herein",
          "student",
          "built",
          "anunderstand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "this course for nearly 20 years, students have a hard time understanding how the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "nearly",
          "years",
          "students",
          "hard",
          "time",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "concurrency problem arises, or why they are trying to solve it, if they don\u2019t yet un-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concurrency",
          "problem",
          "arises",
          "trying",
          "solve"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "occur at arbitrary points in time. Once they do understand theseconcepts, how-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "occur",
          "arbitrary",
          "points",
          "time",
          "understand",
          "theseconcepts"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ture. On these more conceptual days, we come to class with a few majori d e a s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ture",
          "conceptual",
          "days",
          "come",
          "class",
          "majori"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "to give the students concrete problems to solve based on the material. On more",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "give",
          "students",
          "concrete",
          "problems",
          "solve",
          "based",
          "material"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand One last request: if you use the free online chapters, please just link to them,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last request",
          "free",
          "online",
          "chapters",
          "please",
          "link"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "vi\nTo Students\nIf you are a student reading this book, thank you! It is an honor for us to\nprovide some material to help you in your pursuit of knowledge aboutoperating\nsystems. We both think back fondly towards some textbooks of our undergraduate\ndays (e.g., Hennessy and Patterson [HP90], the classic bookon computer architec-\nture) and hope this book will become one of those positive memories for you.\nYou may have noticed this book is free and available online2. There is one major\nreason for this: textbooks are generally too expensive. This book, we hope, is the\n\ufb01rst of a new wave of free materials to help those in pursuit of their education,\nregardless of which part of the world they come from or how much they are willing\nto spend for a book. Failing that, it is one free book, which isbetter than none.\nWe also hope, where possible, to point you to the original sources of much\nof the material in the book: the great papers and persons who have shaped the\n\ufb01eld of operating systems over the years. Ideas are not pulled out of the air; they\ncome from smart and hard-working people (including numerous Turing-award\nwinners3), and thus we should strive to celebrate those ideas and peoplewhere\npossible. In doing so, we hopefully can better understand the revolutions that\nhave taken place, instead of writing texts as if those thoughtshave always been\npresent [K62]. Further, perhaps such references will encouragey o ut od i gd e e p e r\non your own; reading the famous papers of our \ufb01eld is certainly oneof the best\nways to learn.\n2A digression here: \u201cfree\u201d in the way we use it here does not mean opensource, and it\ndoes not mean the book is not copyrighted with the usual protections \u2013 it is! What it means is\nthat you can download the chapters and use them to learn about operatingsystems. Why not\nan open-source book, just like Linux is an open-source kernel? Well, we believe it is important\nfor a book to have a single voice throughout, and have worked hard to provide such a voice.\nWhen you\u2019re reading it, the book should kind of feel like a dialogue with the person explaining\nsomething to you. Hence, our approach.\n3The Turing Award is the highest award in Computer Science; it is like the Nobel Prize,\nexcept that you have never heard of it.\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "provide some material to help you in your pursuit of knowledge aboutoperating",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "provide",
          "material",
          "help",
          "pursuit",
          "knowledge",
          "aboutoperating"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "possible. In doing so, we hopefully can better understand the revolutions that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "possible",
          "hopefully",
          "better",
          "understand",
          "revolutions"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ways to learn.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ways",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "that you can download the chapters and use them to learn about operatingsystems. Why not",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "download",
          "chapters",
          "learn",
          "operatingsystems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "an open-source book, just like Linux is an open-source kernel? Well, we believe it is important",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "open",
          "source",
          "book",
          "like",
          "linux",
          "open",
          "source",
          "kernel"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "When you\u2019re reading it, the book should kind of feel like a dialogue with the person explaining",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "book",
          "kind",
          "feel",
          "like",
          "dialogue",
          "person",
          "explaining"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "something to you. Hence, our approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "something",
          "hence",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 2A digression here: \u201cfree\u201d in the way we use it here does not mean opensource, and it",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2a digression here",
          "free",
          "mean",
          "opensource"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "vii\nAcknowledgments\nThis section will contain thanks to those who helped us put the book together.\nThe important thing for now:your name could go here!But, you have to help. So\nsend us some feedback and help debug this book. And you could be famous!O r ,\nat least, have your name in some book.\nThe people who have helped so far include:Aaron Gember (Colgate), Aashrith\nH Govindraj (USF), Abhinav Mehra, Abhirami Senthilkumaran*, Adam Drescher* (WUSTL),\nAdam Eggum, Aditya Venkataraman, Adriana Iamnitchi and class (USF), Ahmad Jarara, Ahmed\nFikri*, Ajaykrishna Raghavan, Akiel Khan, Alex Curtis, Alex Wyler, Alex Zhao (U. Colorado at\nColorado Springs), Ali Razeen (Duke), Alistair Martin, AmirBehzadEslami, Anand Mundada,\nAndrew Mahler, Andrew Valencik (Saint Mary\u2019s), Angela Demke Brown (Toronto), Antonella\nBernobich (UoPeople)*, Arek Bulski, B. Brahmananda Reddy (Minnesota), Bala Subrahmanyam\nKambala, Bart Miller, Ben Kushigian (U. Mass), Benita Bose, Biswajit Mazumder (Clemson),\nBobby Jack, Bj\u00a8orn Lindberg, Brandon Harshe (U. Minn), Brennan Payne, Brian Gorman, Brian\nKroth, Caleb Sumner (Southern Adventist), Cara Lauritzen, Charlotte Kissinger, Cheng Su,\nChien-Chung Shen (Delaware)*, Christian Stober, Christoph Jaeger, C.J.Stanbridge (Memorial\nU. of Newfoundland), Cody Hanson, Constantinos Georgiades, Dakota Crane (U. Washington-\nTacoma), Dan Soendergaard (U. Aarhus), Dan Tsafrir (Technion), Danilo Bruschi (Universita\nDegli Studi Di Milano), Darby Asher Noam Haller, David Hanle (Grinnell), David Hartman,\nDeepika Muthukumar, Demir Delic, Dennis Zhou, Dheeraj Shetty (North Carolina State), Do-\nrian Arnold (New Mexico), Dustin Metzler, Dustin Passofaro, EduardoStelmaszczyk, Emad\nSadeghi, Emil Hessman, Emily Jacobson, Emmett Witchel (Texas), Eric Freudenthal (UTEP),\nEric Johansson, Erik Turk, Ernst Biersack (France), Fangjun Kuang (U. Stuttgart), Feng Zhang\n(IBM), Finn Kuusisto*, Giovanni Lagorio (DIBRIS), Glenn Bruns (CSU Monterey Bay), Glen\nGranzow (College of Idaho), Guilherme Baptista, Hamid Reza Ghasemi, Hao Chen, Henry\nAbbey, Hilmar G\u00b4ustafsson (Aalborg University), Hrishikesh Amur, Huanchen Zhang*, Huseyin\nSular, Hugo Diaz, Ilya Oblomkov, Itai Hass (Toronto), Jackson \u201cJake\u201d Haenchen (Texas), Ja-\ngannathan Eachambadi, Jake Gillberg, Jakob Olandt, James Earley, JamesPerry (U. Michigan-\nDearborn)*, Jan Reineke (Universit\u00a8at des Saarlandes), Jason MacLafferty (Southern Adven-\ntist), Jason Waterman (Vassar), Jay Lim, Jerod Weinman (Grinnell), Jhih-ChengLuo, Jiao Dong\n(Rutgers), Jia-Shen Boon, Jiawen Bao, Jingxin Li, Joe Jean (NYU), Joel Kuntz (Saint Mary\u2019s),\nJoel Sommers (Colgate), John Brady (Grinnell), John Komenda, Jonathan Perry (MIT), Joshua\nCarpenter (NCSU), Jun He, Karl Wallinger, Kartik Singhal, Katherine Dudenas, Katie Coyle\n(Georgia Tech), Kaushik Kannan, Kemal B\u0131c \u00b8akc\u0131, Kevin Liu*, Lanyue Lu,Laura Xu, Lei Tian\n(U. Nebraska-Lincoln), Leonardo Medici (U. Milan), Leslie Schultz, Liang Yin,Lihao Wang,\nLooserof, Manav Batra (IIIT-Delhi), Manu Awasthi (Samsung), Marcel van der Holst, Marco\nGuazzone (U. Piemonte Orientale), Mart Oskamp, Martha Ferris, Masashi Kishikawa (Sony),\nMatt Reichoff, Mattia Monga (U. Milan), Matty Williams, Meng Huang, Michael Machtel\n(Hochschule Konstanz), Michael Wal\ufb01sh (NYU), Michael Wu (UCLA), Mike Griepentrog, Ming\nChen (Stonybrook), Mohammed Alali (Delaware), Mohamed Omran (GUST), Murugan Kan-\ndaswamy, Nadeem Shaikh, Natasha Eilbert, Natasha Stopa, Nathan Dipiazza, Nathan Sulli-\nvan, Neeraj Badlani (N.C. State), Neil Perry, Nelson Gomez, Nghia Huynh (Texas), Nicholas\nMandal, Nick Weinandt, Patel Pratyush Ashesh (BITS-Pilani), Patricio Jara, Pavle Kostovic,\nPerry Kivolowitz, Peter Peterson (Minnesota), Pieter Kockx, Radford Smith, Riccardo Mut-\nschlechner, Ripudaman Singh, Robert Ord\u00b4o\u02dcnez and class (Southern Adventist), Roger Watten-\nhofer (ETH), Rohan Das (Toronto)*, Rohan Pasalkar (Minnesota), Rohan Puri, RossAiken, Rus-\nlan Kiselev, Ryland Herrick, Sam Kelly, Sam Noh (UNIST), Samer Al-Kiswany, Sandeep Um-\nmadi (Minnesota), Sankaralingam Panneerselvam, Satish Chebrolu (NetApp), Satyanarayana\nc\u20dd 2008\u201318, A RPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Acknowledgments",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "acknowledgments"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The important thing for now:your name could go here!But, you have to help. So",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "thing",
          "name",
          "could",
          "help"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "viii\nShanmugam*, Scott Catlin, Scott Lee (UCLA), Seth Pollen, Sharad Punuganti, Shreevatsa R.,\nSimon Pratt (Waterloo), Sivaraman Sivaraman*, Song Jiang (Wayne State), Spencer Harston\n(Weber State), Srinivasan Thirunarayanan*, Stefan Dekanski, Stephen Bye, Suriyhaprakhas\nBalaram Sankari, Sy Jin Cheah, Teri Zhao (EMC), Thanumalayan S. Pillai, Thomas Griebel,\nThomas Scrace, Tianxia Bai, Tong He, Tongxin Zheng, Tony Adkins, Torin Rudeen (Princeton),\nTuo Wang, Tyler Couto, Varun Vats, Vikas Goel, Waciuma Wanjohi, William Royle (Grinnell),\nXiang Peng, Xu Di, Yifan Hao, Yuanyuan Chen, Yubin Ruan, Yudong Sun, Yue Zhuo (Texas\nA&M), Yufui Ren, Zef RosnBrick, Zeyuan Hu (Texas), ZiHan Zheng (USTC), ZuyuZhang.\nSpecial thanks to those marked with an asterisk above, who haveg o n ea b o v ea n d\nbeyond in their suggestions for improvement.\nIn addition, a hearty thanks to Professor Joe Meehean (Lynchburg) for his de-\ntailed notes on each chapter, to Professor Jerod Weinman (Grinnell) and his entire\nclass for their incredible booklets, to Professor Chien-Chung Shen (Delaware) for\nhis invaluable and detailed reading and comments, to Adam Drescher (WUSTL)\nfor his careful reading and suggestions, to Glen Granzow (College of Idaho) for his\nincredibly detailed comments and tips, Michael Wal\ufb01sh (NYU) for his enthusiasm\nand detailed suggestions for improvement, Peter Peterson (UMD)for his many\nbits of useful feedback and commentary, Mark Kampe (Pomona) for detailed crit-\nicism (we only wish we could \ufb01x all suggestions!), and Youjip Won(Hanyang) for\nhis translation work into Korean(!) and numerous insightful suggestions. All have\nhelped these authors immeasurably in the re\ufb01nement of the materialsh e r e i n .\nAlso, many thanks to the hundreds of students who have taken 537 over the\nyears. In particular, the Fall \u201908 class who encouraged the \ufb01rstw r i t t e nf o r mo f\nthese notes (they were sick of not having any kind of textbook to read \u2014 pushy\nstudents!), and then praised them enough for us to keep going (including one hi-\nlarious \u201cZOMG! You should totally write a textbook!\u201d comment in ourcourse\nevaluations that year).\nAg r e a td e b to ft h a n k si sa l s oo w e dt ot h eb r a v ef e ww h ot o o kt h exv6 project\nlab course, much of which is now incorporated into the main 537 course. From\nSpring \u201909: Justin Cherniak, Patrick Deline, Matt Czech, TonyG r e g e r s o n ,M i c h a e l\nGriepentrog, Tyler Harter, Ryan Kroiss, Eric Radzikowski,Wesley Reardan, Rajiv\nVaidyanathan, and Christopher Waclawik. From Fall \u201909: Nick Bearson, Aaron\nBrown, Alex Bird, David Capel, Keith Gould, Tom Grim, Jeffrey Hugo, Brandon\nJohnson, John Kjell, Boyan Li, James Loethen, Will McCardell,R y a nS z a r o l e t t a ,S i -\nmon Tso, and Ben Yule. From Spring \u201910: Patrick Blesi, Aidan Dennis-Oehling,\nParas Doshi, Jake Friedman, Benjamin Frisch, Evan Hanson, Pikkili Hemanth,\nMichael Jeung, Alex Langenfeld, Scott Rick, Mike Treffert, Garret Staus, Brennan\nWall, Hans Werner, Soo-Young Yang, and Carlos Grif\ufb01n (almost).\nAlthough they do not directly help with the book, our graduate students have\ntaught us much of what we know about systems. We talk with them regularly\nwhile they are at Wisconsin, but they do all the real work \u2014 and by telling us about\nwhat they are doing, we learn new things every week. This listincludes the follow-\ning collection of current and former students and post-docs withw h o mw eh a v e\npublished papers; an asterisk marks those who received a Ph.D.under our guid-\nance: Abhishek Rajimwale, Aishwarya Ganesan, Andrew Krioukov, AoMa, Brian\nForney, Chris Dragga, Deepak Ramamurthi, Dennis Zhou, Edward Oakes, Flo-\nrentina Popovici*, Hariharan Gopalakrishnan, Haryadi S. Gunawi*, James Nugent,\nJoe Meehean*, John Bent*, Jun He, Kevin Houck, Lanyue Lu*, LakshmiBairava-\nsundaram*, Laxman Visampalli, Leo Arulraj*, Leon Yang, Meenali Rungta, Muthian\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "taught us much of what we know about systems. We talk with them regularly",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "taught",
          "much",
          "know",
          "systems",
          "talk",
          "regularly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "what they are doing, we learn new things every week. This listincludes the follow-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "things",
          "every",
          "week",
          "listincludes",
          "follow"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 09: Justin Cherniak, Patrick Deline, Matt Czech, TonyG r e g e r s o n ,M i c h a e l",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "09",
          "justin",
          "cherniak",
          "patrick",
          "deline",
          "matt",
          "czech",
          "tonyg"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 10: Patrick Blesi, Aidan Dennis-Oehling,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "10",
          "patrick",
          "blesi",
          "aidan",
          "dennis",
          "oehling"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand ance: Abhishek Rajimwale, Aishwarya Ganesan, Andrew Krioukov, AoMa, Brian",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ance",
          "abhishek",
          "rajimwale",
          "aishwarya",
          "ganesan",
          "andrew",
          "krioukov",
          "aoma",
          "brian"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ix\nSivathanu*, Nathan Burnett*, Nitin Agrawal*, Ram Alagappan, Samer Al-Kiswany,\nScott Hendrickson, Sriram Subramanian*, Stephen Todd Jones*, Stephen Sturde-\nvant, Sudarsun Kannan, Suli Yang*, Swaminathan Sundararaman*, Swetha Krish-\nnan, Thanh Do*, Thanumalayan S. Pillai*, Timothy Denehy*, TylerH a r t e r * ,V e n k a t\nVenkataramani, Vijay Chidambaram*, Vijayan Prabhakaran*, Yiying Zhang*, Yupu\nZhang*, Yuvraj Patel, Zev Weiss*.\nOur graduate students have largely been funded by the National Science Foun-\ndation (NSF), the Department of Energy Of\ufb01ce of Science (DOE),and by industry\ngrants. We are especially grateful to the NSF for their supportover many years, as\nour research has shaped the content of many chapters herein.\nWe thank Thomas Griebel, who demanded a better cover for the book. Al-\nthough we didn\u2019t take his speci\ufb01c suggestion (a dinosaur, can youb e l i e v ei t ? ) ,t h e\nbeautiful picture of Halley\u2019s comet would not be found on the cover without him.\nA \ufb01nal debt of gratitude is also owed to Aaron Brown, who \ufb01rst took this course\nmany years ago (Spring \u201909), then took the xv6 lab course (Fall \u201909), and \ufb01nally was\na graduate teaching assistant for the course for two years or so(Fall \u201910 through\nSpring \u201912). His tireless work has vastly improved the state oft h ep r o j e c t s( p a r -\nticularly those in xv6 land) and thus has helped better the learning experience for\ncountless undergraduates and graduates here at Wisconsin. As Aaron would say\n(in his usual succinct manner): \u201cThx.\u201d\nc\u20dd 2008\u201318, A RPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ticularly those in xv6 land) and thus has helped better the learning experience for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ticularly",
          "land",
          "thus",
          "helped",
          "better",
          "learning",
          "experience"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "x\nFinal Words\nYeats famously said \u201cEducation is not the \ufb01lling of a pail but the lighting of a\n\ufb01re.\u201d He was right but wrong at the same time4.Y o ud oh a v et o\u201c \ufb01 l lt h ep a i l \u201dab i t ,\nand these notes are certainly here to help with that part of your education; after all,\nwhen you go to interview at Google, and they ask you a trick question about how\nto use semaphores, it might be good to actually know what a semaphorei s ,r i g h t ?\nBut Yeats\u2019s larger point is obviously on the mark: the real pointof education\nis to get you interested in something, to learn something more about the subject\nmatter on your own and not just what you have to digest to get a goodgrade in\nsome class. As one of our fathers (Remzi\u2019s dad, Vedat Arpaci) used tosay, \u201cLearn\nbeyond the classroom\u201d.\nWe created these notes to spark your interest in operating systems, to read more\nabout the topic on your own, to talk to your professor about all theexciting re-\nsearch that is going on in the \ufb01eld, and even to get involved with that research. It\nis a great \ufb01eld(!), full of exciting and wonderful ideas that have shaped computing\nhistory in profound and important ways. And while we understand this \ufb01re won\u2019t\nlight for all of you, we hope it does for many, or even a few. Becauseo n c et h a t\ufb01 r e\nis lit, well, that is when you truly become capable of doing something great. And\nthus the real point of the educational process: to go forth, to study many new and\nfascinating topics, to learn, to mature, and most importantly, to \ufb01nd something\nthat lights a \ufb01re for you.\nAndrea and Remzi\nMarried couple\nProfessors of Computer Science at the University of Wisconsin\nChief Lighters of Fires, hopefully5\n4If he actually said this; as with many famous quotes, the history of thisg e mi sm u r k y .\n5If this sounds like we are admitting some past history as arsonists,y o ua r ep r o b a b l y\nmissing the point. Probably. If this sounds cheesy, well, that\u2019s because it is, but you\u2019ll just have\nto forgive us for that.\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to use semaphores, it might be good to actually know what a semaphorei s ,r i g h t ?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "semaphores",
          "might",
          "good",
          "actually",
          "know",
          "semaphorei"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "is to get you interested in something, to learn something more about the subject",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interested",
          "something",
          "learn",
          "something",
          "subject"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "some class. As one of our fathers (Remzi\u2019s dad, Vedat Arpaci) used tosay, \u201cLearn",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "class",
          "fathers",
          "remzi",
          "vedat",
          "arpaci",
          "used",
          "tosay",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "We created these notes to spark your interest in operating systems, to read more",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "notes",
          "spark",
          "interest",
          "operating",
          "systems",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "history in profound and important ways. And while we understand this \ufb01re won\u2019t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "history",
          "profound",
          "important",
          "ways",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "fascinating topics, to learn, to mature, and most importantly, to \ufb01nd something",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fascinating",
          "topics",
          "learn",
          "mature",
          "importantly",
          "something"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xi\nReferences\n[CK+08] \u201cThe xv6 Operating System\u201d by Russ Cox, Frans Kaashoek, Robert Morris, Nickolai\nZeldovich. From: http://pdos.csail.mit.edu/6.828/2008/index.html. xv6 was\ndeveloped as a port of the originalUNIX version 6 and represents a beautiful, clean, and simple way to\nunderstand a modern operating system.\n[F96] \u201cSix Easy Pieces: Essentials Of Physics Explained By Its Most Brilliant Teacher\u201d by\nRichard P . Feynman. Basic Books, 1996.This book reprints the six easiest chapters of Feynman\u2019s\nLectures on Physics, from 1963. If you like Physics, it is a fantastic read.\n[HP90] \u201cComputer Architecture a Quantitative Approach\u201d (1st ed.) by David A. Patterson and\nJohn L. Hennessy . Morgan-Kaufman, 1990.A book that encouraged each of us at our undergraduate\ninstitutions to pursue graduate studies; we later both had the pleasure of workingwith Patterson, who\ngreatly shaped the foundations of our research careers.\n[KR88] \u201cThe C Programming Language\u201d by Brian Kernighan and Dennis Ritchie.Prentice-\nHall, April 1988.The C programming reference that everyone should have, by the people who invented\nthe language.\n[K62] \u201cThe Structure of Scienti\ufb01c Revolutions\u201d by Thomas S. Kuhn. University of Chicago\nPress, 1962. A great and famous read about the fundamentals of the scienti\ufb01c process. Mop-up work,\nanomaly, crisis, and revolution. We are mostly destined to do mop-up work, alas.\nc\u20dd 2008\u201318, A RPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "developed as a port of the originalUNIX version 6 and represents a beautiful, clean, and simple way to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developed",
          "port",
          "originalunix",
          "version",
          "represents",
          "beautiful",
          "clean",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand a modern operating system.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "modern",
          "operating",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[F96] \u201cSix Easy Pieces: Essentials Of Physics Explained By Its Most Brilliant Teacher\u201d by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "easy",
          "pieces",
          "essentials",
          "physics",
          "explained",
          "brilliant",
          "teacher"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[HP90] \u201cComputer Architecture a Quantitative Approach\u201d (1st ed.) by David A. Patterson and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "computer",
          "architecture",
          "quantitative",
          "approach",
          "david",
          "patterson"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Press, 1962. A great and famous read about the fundamentals of the scienti\ufb01c process. Mop-up work,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "press",
          "great",
          "famous",
          "read",
          "fundamentals",
          "process",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand From: http://pdos.csail.mit.edu/6.828/2008/index.html. xv6 was",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "from",
          "http",
          "pdos",
          "csail",
          "index",
          "html"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "Contents\nTo Everyone . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii\nTo Educators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v\nTo Students . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nFinal Words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\n1A D i a l o g u e o n t h e B o o k 1\n2I n t r o d u c t i o n t o O p e r a t i n g S y s t e m s 3\n2.1 Virtualizing The CPU . . . . . . . . . . . . . . . . . . . . . 5\n2.2 Virtualizing Memory . . . . . . . . . . . . . . . . . . . . . . 7\n2.3 Concurrency . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.4 Persistence . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.5 Design Goals . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.6 Some History . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\nHomework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nIV i r t u a l i z a t i o n 21\n3A D i a l o g u e o n V i r t u a l i z a t i o n 2 3\n4T h e A b s t r a c t i o n : T h e P r o c e s s 2 5\n4.1 The Abstraction: A Process . . . . . . . . . . . . . . . . . . 26\n4.2 Process API . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.3 Process Creation: A Little More Detail . . . . . . . . . . . . 28\n4.4 Process States . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.5 Data Structures . . . . . . . . . . . . . . . . . . . . . . . . . 31\n4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nxiii",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . vii",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "acknowledgments"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Design Goals . . . . . . . . . . . . . . . . . . . . . . . . . . 13",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "goals"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1 The Abstraction: A Process . . . . . . . . . . . . . . . . . . 26",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 the abstraction",
          "process"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 3 Process Creation: A Little More Detail . . . . . . . . . . . . 28",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 process creation",
          "little",
          "detail"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand virtualizing the cpu . . . . . . . . . . . . . . . . . . . . . 5",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand virtualizing memory . . . . . . . . . . . . . . . . . . . . . . 7",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing",
          "memory"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand concurrency . . . . . . . . . . . . . . . . . . . . . . . . . . 8",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrency"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand persistence . . . . . . . . . . . . . . . . . . . . . . . . . . . 11",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "persistence"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand design goals . . . . . . . . . . . . . . . . . . . . . . . . . . 13",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "goals"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand some history . . . . . . . . . . . . . . . . . . . . . . . . . . 14",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "history"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xiv CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xiv CONTENTS\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 35\n5I n t e r l u d e : P r o c e s s A P I 37\n5.1 The fork() System Call . . . . . . . . . . . . . . . . . . . 37\n5.2 The wait() System Call . . . . . . . . . . . . . . . . . . . 39\n5.3 Finally, The exec() System Call . . . . . . . . . . . . . . . 40\n5.4 Why? Motivating The API . . . . . . . . . . . . . . . . . . . 41\n5.5 Process Control And Users . . . . . . . . . . . . . . . . . . 44\n5.6 Useful Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n5.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n6M e c h a n i s m : L i m i t e d D i r e c t E x e c u t i o n 4 9\n6.1 Basic Technique: Limited Direct Execution . . . . . . . . . 49\n6.2 Problem #1: Restricted Operations . . . . . . . . . . . . . . 50\n6.3 Problem #2: Switching Between Processes . . . . . . . . . . 55\n6.4 Worried About Concurrency? . . . . . . . . . . . . . . . . . 59\n6.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nHomework (Measurement) . . . . . . . . . . . . . . . . . . . . . . 63\n7S c h e d u l i n g : I n t r o d u c t i o n 65\n7.1 Workload Assumptions . . . . . . . . . . . . . . . . . . . . 65\n7.2 Scheduling Metrics . . . . . . . . . . . . . . . . . . . . . . . 66\n7.3 First In, First Out (FIFO) . . . . . . . . . . . . . . . . . . . . 66\n7.4 Shortest Job First (SJF) . . . . . . . . . . . . . . . . . . . . . 68\n7.5 Shortest Time-to-Completion First (STCF) . . . . . . . . . . 69\n7.6 A New Metric: Response Time . . . . . . . . . . . . . . . . 70\n7.7 Round Robin . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n7.8 Incorporating I/O . . . . . . . . . . . . . . . . . . . . . . . 73\n7.9 No More Oracle . . . . . . . . . . . . . . . . . . . . . . . . . 74\n7.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 76\n8S c h e d u l i n g :\nThe Multi-Level Feedback Queue 77\n8.1 MLFQ: Basic Rules . . . . . . . . . . . . . . . . . . . . . . . 78\n8.2 Attempt #1: How To Change Priority . . . . . . . . . . . . 79\n8.3 Attempt #2: The Priority Boost . . . . . . . . . . . . . . . . 83\n8.4 Attempt #3: Better Accounting . . . . . . . . . . . . . . . . 84\n8.5 Tuning MLFQ And Other Issues . . . . . . . . . . . . . . . 84\n8.6 MLFQ: Summary . . . . . . . . . . . . . . . . . . . . . . . . 86\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 88\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Basic Technique: Limited Direct Execution . . . . . . . . . 49",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "technique",
          "limited",
          "direct",
          "execution"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 1 Basic Technique: Limited Direct Execution . . . . . . . . . 49",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 basic technique",
          "limited",
          "direct",
          "execution"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 1: Restricted Operations . . . . . . . . . . . . . . 50",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "restricted",
          "operations"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 2: Switching Between Processes . . . . . . . . . . 55",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "switching",
          "processes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 6 A New Metric: Response Time . . . . . . . . . . . . . . . . 70",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 a new metric",
          "response",
          "time"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand 1 MLFQ: Basic Rules . . . . . . . . . . . . . . . . . . . . . . . 78",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 mlfq",
          "basic",
          "rules"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand 1: How To Change Priority . . . . . . . . . . . . 79",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "change",
          "priority"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand 2: The Priority Boost . . . . . . . . . . . . . . . . 83",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "priority",
          "boost"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand 3: Better Accounting . . . . . . . . . . . . . . . . 84",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "better",
          "accounting"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the fork() system call . . . . . . . . . . . . . . . . . . . 37",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fork",
          "system",
          "call"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand the wait() system call . . . . . . . . . . . . . . . . . . . 39",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "system",
          "call"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand finally, the exec() system call . . . . . . . . . . . . . . . 40",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "exec",
          "system",
          "call"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand why? motivating the api . . . . . . . . . . . . . . . . . . . 41",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "motivating"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand process control and users . . . . . . . . . . . . . . . . . . 44",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "control",
          "users"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand useful tools . . . . . . . . . . . . . . . . . . . . . . . . . . . 45",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "useful",
          "tools"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CONTENTS xv",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CONTENTS xv\n9S c h e d u l i n g : P r o p o r t i o n a l S h a r e 8 9\n9.1 Basic Concept: Tickets Represent Your Share . . . . . . . . 89\n9.2 Ticket Mechanisms . . . . . . . . . . . . . . . . . . . . . . . 91\n9.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 92\n9.4 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n9.5 How To Assign Tickets? . . . . . . . . . . . . . . . . . . . . 94\n9.6 Why Not Deterministic? . . . . . . . . . . . . . . . . . . . . 94\n9.7 The Linux Completely Fair Scheduler (CFS) . . . . . . . . . 95\n9.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 102\n10 Multiprocessor Scheduling (Advanced) 103\n10.1 Background: Multiprocessor Architecture . . . . . . . . . . 104\n10.2 Don\u2019t Forget Synchronization . . . . . . . . . . . . . . . . . 106\n10.3 One Final Issue: Cache Af\ufb01nity . . . . . . . . . . . . . . . . 107\n10.4 Single-Queue Scheduling . . . . . . . . . . . . . . . . . . . 107\n10.5 Multi-Queue Scheduling . . . . . . . . . . . . . . . . . . . . 109\n10.6 Linux Multiprocessor Schedulers . . . . . . . . . . . . . . . 112\n10.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 114\n11 Summary Dialogue on CPU Virtualization 117\n12 A Dialogue on Memory Virtualization 119\n13 The Abstraction: Address Spaces 121\n13.1 Early Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n13.2 Multiprogramming and Time Sharing . . . . . . . . . . . . 122\n13.3 The Address Space . . . . . . . . . . . . . . . . . . . . . . . 123\n13.4 Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n13.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\n14 Interlude: Memory API 131\n14.1 Types of Memory . . . . . . . . . . . . . . . . . . . . . . . . 131\n14.2 The malloc() Call . . . . . . . . . . . . . . . . . . . . . . 132\n14.3 The free() Call . . . . . . . . . . . . . . . . . . . . . . . . 134\n14.4 Common Errors . . . . . . . . . . . . . . . . . . . . . . . . 134\n14.5 Underlying OS Support . . . . . . . . . . . . . . . . . . . . 137\n14.6 Other Calls . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n14.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\nc\u20dd 2008\u201318, ARPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Basic Concept: Tickets Represent Your Share . . . . . . . . 89",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "concept",
          "tickets",
          "represent",
          "share"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 92",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goals"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1 Basic Concept: Tickets Represent Your Share . . . . . . . . 89",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 basic concept",
          "tickets",
          "represent",
          "share"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 1 Background: Multiprocessor Architecture . . . . . . . . . . 104",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 background",
          "multiprocessor",
          "architecture"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 3 One Final Issue: Cache Af\ufb01nity . . . . . . . . . . . . . . . . 107",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 one final issue",
          "cache"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand ticket mechanisms . . . . . . . . . . . . . . . . . . . . . . . 91",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ticket",
          "mechanisms"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand implementation . . . . . . . . . . . . . . . . . . . . . . . . . 92",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "implementation"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand an example . . . . . . . . . . . . . . . . . . . . . . . . . . . 93",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand how to assign tickets? . . . . . . . . . . . . . . . . . . . . 94",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assign",
          "tickets"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand why not deterministic? . . . . . . . . . . . . . . . . . . . . 94",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "deterministic"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xvi CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xvi CONTENTS\n15 Mechanism: Address Translation 141\n15.1 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n15.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n15.3 Dynamic (Hardware-based) Relocation . . . . . . . . . . . 145\n15.4 Hardware Support: A Summary . . . . . . . . . . . . . . . 148\n15.5 Operating System Issues . . . . . . . . . . . . . . . . . . . . 149\n15.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 154\n16 Segmentation 155\n16.1 Segmentation: Generalized Base/Bounds . . . . . . . . . . 155\n16.2 Which Segment Are We Referring To? . . . . . . . . . . . . 158\n16.3 What About The Stack? . . . . . . . . . . . . . . . . . . . . 159\n16.4 Support for Sharing . . . . . . . . . . . . . . . . . . . . . . 160\n16.5 Fine-grained vs. Coarse-grained Segmentation . . . . . . . 161\n16.6 OS Support . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\n16.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 165\n17 Free-Space Management 167\n17.1 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . 168\n17.2 Low-level Mechanisms . . . . . . . . . . . . . . . . . . . . 169\n17.3 Basic Strategies . . . . . . . . . . . . . . . . . . . . . . . . . 177\n17.4 Other Approaches . . . . . . . . . . . . . . . . . . . . . . . 179\n17.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 183\n18 Paging: Introduction 185\n18.1 A Simple Example And Overview . . . . . . . . . . . . . . 185\n18.2 Where Are Page Tables Stored? . . . . . . . . . . . . . . . . 189\n18.3 What\u2019s Actually In The Page Table? . . . . . . . . . . . . . 190\n18.4 Paging: Also Too Slow . . . . . . . . . . . . . . . . . . . . . 191\n18.5 A Memory Trace . . . . . . . . . . . . . . . . . . . . . . . . 192\n18.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 197\n19 Paging: Faster Translations (TLBs) 199\n19.1 TLB Basic Algorithm . . . . . . . . . . . . . . . . . . . . . . 199\n19.2 Example: Accessing An Array . . . . . . . . . . . . . . . . 201\n19.3 Who Handles The TLB Miss? . . . . . . . . . . . . . . . . . 203\n19.4 TLB Contents: What\u2019s In There? . . . . . . . . . . . . . . . 205\n19.5 TLB Issue: Context Switches . . . . . . . . . . . . . . . . . 206\n19.6 Issue: Replacement Policy . . . . . . . . . . . . . . . . . . . 208\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Other Approaches . . . . . . . . . . . . . . . . . . . . . . . 179",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "TLB Basic Algorithm . . . . . . . . . . . . . . . . . . . . . . 199",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand xvi CONTENTS\n15 Mechanism: Address Translation 141",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "xvi contents\n15 mechanism",
          "address",
          "translation"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 4 Hardware Support: A Summary . . . . . . . . . . . . . . . 148",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 hardware support",
          "summary"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 1 Segmentation: Generalized Base/Bounds . . . . . . . . . . 155",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 segmentation",
          "generalized",
          "base",
          "bounds"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 4 Paging: Also Too Slow . . . . . . . . . . . . . . . . . . . . . 191",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 paging",
          "also",
          "slow"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 197\n19 Paging: Faster Translations (TLBs) 199",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "197\n19 paging",
          "faster",
          "translations",
          "tlbs"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 2 Example: Accessing An Array . . . . . . . . . . . . . . . . 201",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 example",
          "accessing",
          "array"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 4 TLB Contents: What\u2019s In There? . . . . . . . . . . . . . . . 205",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 tlb contents"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand 5 TLB Issue: Context Switches . . . . . . . . . . . . . . . . . 206",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 tlb issue",
          "context",
          "switches"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . 142",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assumptions"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand an example . . . . . . . . . . . . . . . . . . . . . . . . . . . 142",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand dynamic (hardware-based) relocation . . . . . . . . . . . 145",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "dynamic",
          "hardware",
          "based",
          "relocation"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand operating system issues . . . . . . . . . . . . . . . . . . . . 149",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "system",
          "issues"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CONTENTS xvii",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CONTENTS xvii\n19.7 A Real TLB Entry . . . . . . . . . . . . . . . . . . . . . . . . 209\n19.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\nHomework (Measurement) . . . . . . . . . . . . . . . . . . . . . . 212\n20 Paging: Smaller Tables 215\n20.1 Simple Solution: Bigger Pages . . . . . . . . . . . . . . . . 215\n20.2 Hybrid Approach: Paging and Segments . . . . . . . . . . 216\n20.3 Multi-level Page Tables . . . . . . . . . . . . . . . . . . . . 219\n20.4 Inverted Page Tables . . . . . . . . . . . . . . . . . . . . . . 226\n20.5 Swapping the Page Tables to Disk . . . . . . . . . . . . . . 227\n20.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 229\n21 Beyond Physical Memory: Mechanisms 231\n21.1 Swap Space . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n21.2 The Present Bit . . . . . . . . . . . . . . . . . . . . . . . . . 233\n21.3 The Page Fault . . . . . . . . . . . . . . . . . . . . . . . . . 234\n21.4 What If Memory Is Full? . . . . . . . . . . . . . . . . . . . . 235\n21.5 Page Fault Control Flow . . . . . . . . . . . . . . . . . . . . 236\n21.6 When Replacements Really Occur . . . . . . . . . . . . . . 237\n21.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239\nHomework (Measurement) . . . . . . . . . . . . . . . . . . . . . . 240\n22 Beyond Physical Memory: Policies 243\n22.1 Cache Management . . . . . . . . . . . . . . . . . . . . . . 243\n22.2 The Optimal Replacement Policy . . . . . . . . . . . . . . . 244\n22.3 A Simple Policy: FIFO . . . . . . . . . . . . . . . . . . . . . 246\n22.4 Another Simple Policy: Random . . . . . . . . . . . . . . . 248\n22.5 Using History: LRU . . . . . . . . . . . . . . . . . . . . . . 249\n22.6 Workload Examples . . . . . . . . . . . . . . . . . . . . . . 250\n22.7 Implementing Historical Algorithms . . . . . . . . . . . . . 253\n22.8 Approximating LRU . . . . . . . . . . . . . . . . . . . . . . 254\n22.9 Considering Dirty Pages . . . . . . . . . . . . . . . . . . . . 255\n22.10 Other VM Policies . . . . . . . . . . . . . . . . . . . . . . . 256\n22.11 Thrashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\n22.12 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 259\n23 Complete Virtual Memory Systems 261\n23.1 VAX/VMS Virtual Memory . . . . . . . . . . . . . . . . . . 262\n23.2 The Linux Virtual Memory System . . . . . . . . . . . . . . 268\n23.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\nc\u20dd 2008\u201318, ARPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Hybrid Approach: Paging and Segments . . . . . . . . . . 216",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hybrid",
          "approach",
          "paging",
          "segments"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Implementing Historical Algorithms . . . . . . . . . . . . . 253",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "historical",
          "algorithms"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1 Simple Solution: Bigger Pages . . . . . . . . . . . . . . . . 215",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 simple solution",
          "bigger",
          "pages"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2 Hybrid Approach: Paging and Segments . . . . . . . . . . 216",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 hybrid approach",
          "paging",
          "segments"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 3 A Simple Policy: FIFO . . . . . . . . . . . . . . . . . . . . . 246",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 a simple policy",
          "fifo"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 4 Another Simple Policy: Random . . . . . . . . . . . . . . . 248",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 another simple policy",
          "random"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 5 Using History: LRU . . . . . . . . . . . . . . . . . . . . . . 249",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 using history"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a real tlb entry . . . . . . . . . . . . . . . . . . . . . . . . 209",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "real",
          "entry"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand multi-level page tables . . . . . . . . . . . . . . . . . . . . 219",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "multi",
          "level",
          "page",
          "tables"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand inverted page tables . . . . . . . . . . . . . . . . . . . . . . 226",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "inverted",
          "page",
          "tables"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xviii CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xviii CONTENTS\n24 Summary Dialogue on Memory Virtualization 279\nII Concurrency 283\n25 A Dialogue on Concurrency 285\n26 Concurrency: An Introduction 287\n26.1 Why Use Threads? . . . . . . . . . . . . . . . . . . . . . . . 288\n26.2 An Example: Thread Creation . . . . . . . . . . . . . . . . 289\n26.3 Why It Gets Worse: Shared Data . . . . . . . . . . . . . . . 292\n26.4 The Heart Of The Problem: Uncontrolled Scheduling . . . 294\n26.5 The Wish For Atomicity . . . . . . . . . . . . . . . . . . . . 296\n26.6 One More Problem: Waiting For Another . . . . . . . . . . 298\n26.7 Summary: Why in OS Class? . . . . . . . . . . . . . . . . . 298\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 301\n27 Interlude: Thread API 303\n27.1 Thread Creation . . . . . . . . . . . . . . . . . . . . . . . . 303\n27.2 Thread Completion . . . . . . . . . . . . . . . . . . . . . . . 304\n27.3 Locks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n27.4 Condition Variables . . . . . . . . . . . . . . . . . . . . . . 309\n27.5 Compiling and Running . . . . . . . . . . . . . . . . . . . . 311\n27.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\n28 Locks 315\n28.1 Locks: The Basic Idea . . . . . . . . . . . . . . . . . . . . . 315\n28.2 Pthread Locks . . . . . . . . . . . . . . . . . . . . . . . . . . 316\n28.3 Building A Lock . . . . . . . . . . . . . . . . . . . . . . . . 317\n28.4 Evaluating Locks . . . . . . . . . . . . . . . . . . . . . . . . 317\n28.5 Controlling Interrupts . . . . . . . . . . . . . . . . . . . . . 318\n28.6 A Failed Attempt: Just Using Loads/Stores . . . . . . . . . 319\n28.7 Building Working Spin Locks with Test-And-Set . . . . . . 320\n28.8 Evaluating Spin Locks . . . . . . . . . . . . . . . . . . . . . 322\n28.9 Compare-And-Swap . . . . . . . . . . . . . . . . . . . . . . 323\n28.10 Load-Linked and Store-Conditional . . . . . . . . . . . . . 324\n28.11 Fetch-And-Add . . . . . . . . . . . . . . . . . . . . . . . . . 326\n28.12 Too Much Spinning: What Now? . . . . . . . . . . . . . . . 327\n28.13 A Simple Approach: Just Yield, Baby . . . . . . . . . . . . . 328\n28.14 Using Queues: Sleeping Instead Of Spinning . . . . . . . . 329\n28.15 Different OS, Different Support . . . . . . . . . . . . . . . . 332\n28.16 Two-Phase Locks . . . . . . . . . . . . . . . . . . . . . . . . 332\n28.17 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Compare-And-Swap . . . . . . . . . . . . . . . . . . . . . . 323",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A Simple Approach: Just Yield, Baby . . . . . . . . . . . . . 328",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "approach",
          "yield",
          "baby"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 2 An Example: Thread Creation . . . . . . . . . . . . . . . . 289",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 an example",
          "thread",
          "creation"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 6 One More Problem: Waiting For Another . . . . . . . . . . 298",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 one more problem",
          "waiting",
          "another"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 7 Summary: Why in OS Class? . . . . . . . . . . . . . . . . . 298",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7 summary",
          "class"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 1 Locks: The Basic Idea . . . . . . . . . . . . . . . . . . . . . 315",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 locks",
          "basic",
          "idea"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand 6 A Failed Attempt: Just Using Loads/Stores . . . . . . . . . 319",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 a failed attempt",
          "using",
          "loads",
          "stores"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand 12 Too Much Spinning: What Now? . . . . . . . . . . . . . . . 327",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "12 too much spinning"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand 13 A Simple Approach: Just Yield, Baby . . . . . . . . . . . . . 328",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "13 a simple approach",
          "yield",
          "baby"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand 14 Using Queues: Sleeping Instead Of Spinning . . . . . . . . 329",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "14 using queues",
          "sleeping",
          "instead",
          "spinning"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand why use threads? . . . . . . . . . . . . . . . . . . . . . . . 288",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "threads"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand why it gets worse: shared data . . . . . . . . . . . . . . . 292",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "gets",
          "worse",
          "shared",
          "data"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand the heart of the problem: uncontrolled scheduling . . . 294",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "heart",
          "problem",
          "uncontrolled",
          "scheduling"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand the wish for atomicity . . . . . . . . . . . . . . . . . . . . 296",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "wish",
          "atomicity"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CONTENTS xix",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CONTENTS xix\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 336\n29 Lock-based Concurrent Data Structures 337\n29.1 Concurrent Counters . . . . . . . . . . . . . . . . . . . . . . 337\n29.2 Concurrent Linked Lists . . . . . . . . . . . . . . . . . . . . 342\n29.3 Concurrent Queues . . . . . . . . . . . . . . . . . . . . . . . 345\n29.4 Concurrent Hash Table . . . . . . . . . . . . . . . . . . . . 346\n29.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\n30 Condition Variables 351\n30.1 De\ufb01nition and Routines . . . . . . . . . . . . . . . . . . . . 352\n30.2 The Producer/Consumer (Bounded Buffer) Problem . . . . 355\n30.3 Covering Conditions . . . . . . . . . . . . . . . . . . . . . . 363\n30.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\n31 Semaphores 367\n31.1 Semaphores: A De\ufb01nition . . . . . . . . . . . . . . . . . . . 367\n31.2 Binary Semaphores (Locks) . . . . . . . . . . . . . . . . . . 369\n31.3 Semaphores For Ordering . . . . . . . . . . . . . . . . . . . 370\n31.4 The Producer/Consumer (Bounded Buffer) Problem . . . . 372\n31.5 Reader-Writer Locks . . . . . . . . . . . . . . . . . . . . . . 376\n31.6 The Dining Philosophers . . . . . . . . . . . . . . . . . . . 378\n31.7 How To Implement Semaphores . . . . . . . . . . . . . . . 381\n31.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\n32 Common Concurrency Problems 385\n32.1 What Types Of Bugs Exist? . . . . . . . . . . . . . . . . . . 385\n32.2 Non-Deadlock Bugs . . . . . . . . . . . . . . . . . . . . . . 386\n32.3 Deadlock Bugs . . . . . . . . . . . . . . . . . . . . . . . . . 389\n32.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 400\n33 Event-based Concurrency (Advanced) 401\n33.1 The Basic Idea: An Event Loop . . . . . . . . . . . . . . . . 401\n33.2 An Important API:select() (or poll())......... 4 0 2\n33.3 Using select() ........................ 4 0 3\n33.4 Why Simpler? No Locks Needed . . . . . . . . . . . . . . . 404\n33.5 A Problem: Blocking System Calls . . . . . . . . . . . . . . 405\n33.6 A Solution: Asynchronous I/O . . . . . . . . . . . . . . . . 405\n33.7 Another Problem: State Management . . . . . . . . . . . . 408\nc\u20dd 2008\u201318, ARPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "How To Implement Semaphores . . . . . . . . . . . . . . . 381",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "semaphores"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "An Important API:select() (or poll())......... 4 0 2",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "select",
          "poll"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1 Semaphores: A De\ufb01nition . . . . . . . . . . . . . . . . . . . 367",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 semaphores"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 1 The Basic Idea: An Event Loop . . . . . . . . . . . . . . . . 401",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 the basic idea",
          "event",
          "loop"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2 An Important API: select() (or poll())......... 4 0 2",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 an important api",
          "select",
          "poll"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 5 A Problem: Blocking System Calls . . . . . . . . . . . . . . 405",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 a problem",
          "blocking",
          "system",
          "calls"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 6 A Solution: Asynchronous I/O . . . . . . . . . . . . . . . . 405",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 a solution",
          "asynchronous"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 7 Another Problem: State Management . . . . . . . . . . . . 408",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7 another problem",
          "state",
          "management"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrent counters . . . . . . . . . . . . . . . . . . . . . . 337",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "counters"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand concurrent linked lists . . . . . . . . . . . . . . . . . . . . 342",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "linked",
          "lists"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand concurrent queues . . . . . . . . . . . . . . . . . . . . . . . 345",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "queues"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand concurrent hash table . . . . . . . . . . . . . . . . . . . . 346",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "hash",
          "table"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand de\ufb01nition and routines . . . . . . . . . . . . . . . . . . . . 352",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "routines"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xx CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xx CONTENTS\n33.8 What Is Still Dif\ufb01cult With Events . . . . . . . . . . . . . . 409\n33.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 411\n34 Summary Dialogue on Concurrency 413\nIII Persistence 415\n35 A Dialogue on Persistence 417\n36 I/O Devices 419\n36.1 System Architecture . . . . . . . . . . . . . . . . . . . . . . 419\n36.2 A Canonical Device . . . . . . . . . . . . . . . . . . . . . . 421\n36.3 The Canonical Protocol . . . . . . . . . . . . . . . . . . . . 422\n36.4 Lowering CPU Overhead With Interrupts . . . . . . . . . . 423\n36.5 More Ef\ufb01cient Data Movement With DMA . . . . . . . . . 424\n36.6 Methods Of Device Interaction . . . . . . . . . . . . . . . . 425\n36.7 Fitting Into The OS: The Device Driver . . . . . . . . . . . . 426\n36.8 Case Study: A Simple IDE Disk Driver . . . . . . . . . . . . 427\n36.9 Historical Notes . . . . . . . . . . . . . . . . . . . . . . . . 430\n36.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431\n37 Hard Disk Drives 433\n37.1 The Interface . . . . . . . . . . . . . . . . . . . . . . . . . . 433\n37.2 Basic Geometry . . . . . . . . . . . . . . . . . . . . . . . . . 434\n37.3 A Simple Disk Drive . . . . . . . . . . . . . . . . . . . . . . 435\n37.4 I/O Time: Doing The Math . . . . . . . . . . . . . . . . . . 438\n37.5 Disk Scheduling . . . . . . . . . . . . . . . . . . . . . . . . 442\n37.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 448\n38 Redundant Arrays of Inexpensive Disks (RAIDs) 449\n38.1 Interface And RAID Internals . . . . . . . . . . . . . . . . . 450\n38.2 Fault Model . . . . . . . . . . . . . . . . . . . . . . . . . . . 451\n38.3 How To Evaluate A RAID . . . . . . . . . . . . . . . . . . . 451\n38.4 RAID Level 0: Striping . . . . . . . . . . . . . . . . . . . . . 452\n38.5 RAID Level 1: Mirroring . . . . . . . . . . . . . . . . . . . . 455\n38.6 RAID Level 4: Saving Space With Parity . . . . . . . . . . . 458\n38.7 RAID Level 5: Rotating Parity . . . . . . . . . . . . . . . . 462\n38.8 RAID Comparison: A Summary . . . . . . . . . . . . . . . 463\n38.9 Other Interesting RAID Issues . . . . . . . . . . . . . . . . 464\n38.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 464\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Methods Of Device Interaction . . . . . . . . . . . . . . . . 425",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "methods",
          "device",
          "interaction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "How To Evaluate A RAID . . . . . . . . . . . . . . . . . . . 451",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "evaluate",
          "raid"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 8 Case Study: A Simple IDE Disk Driver . . . . . . . . . . . . 427",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8 case study",
          "simple",
          "disk",
          "driver"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand O Time: Doing The Math . . . . . . . . . . . . . . . . . . 438",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "o time",
          "math"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 4 RAID Level 0: Striping . . . . . . . . . . . . . . . . . . . . . 452",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 raid level 0",
          "striping"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 5 RAID Level 1: Mirroring . . . . . . . . . . . . . . . . . . . . 455",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 raid level 1",
          "mirroring"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 6 RAID Level 4: Saving Space With Parity . . . . . . . . . . . 458",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 raid level 4",
          "saving",
          "space",
          "parity"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 7 RAID Level 5: Rotating Parity . . . . . . . . . . . . . . . . 462",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7 raid level 5",
          "rotating",
          "parity"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 8 RAID Comparison: A Summary . . . . . . . . . . . . . . . 463",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8 raid comparison",
          "summary"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand what is still dif\ufb01cult with events . . . . . . . . . . . . . . 409",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "still",
          "events"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand system architecture . . . . . . . . . . . . . . . . . . . . . . 419",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "architecture"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand a canonical device . . . . . . . . . . . . . . . . . . . . . . 421",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "canonical",
          "device"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand the canonical protocol . . . . . . . . . . . . . . . . . . . . 422",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "canonical",
          "protocol"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand lowering cpu overhead with interrupts . . . . . . . . . . 423",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "lowering",
          "overhead",
          "interrupts"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CONTENTS xxi",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CONTENTS xxi\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 466\n39 Interlude: Files and Directories 467\n39.1 Files And Directories . . . . . . . . . . . . . . . . . . . . . . 467\n39.2 The File System Interface . . . . . . . . . . . . . . . . . . . 469\n39.3 Creating Files . . . . . . . . . . . . . . . . . . . . . . . . . . 469\n39.4 Reading And Writing Files . . . . . . . . . . . . . . . . . . 470\n39.5 Reading And Writing, But Not Sequentially . . . . . . . . . 472\n39.6 Shared File Table Entries:fork() And dup() ....... 4 7 5\n39.7 Writing Immediately Withfsync() ............. 4 7 7\n39.8 Renaming Files . . . . . . . . . . . . . . . . . . . . . . . . . 478\n39.9 Getting Information About Files . . . . . . . . . . . . . . . 479\n39.10 Removing Files . . . . . . . . . . . . . . . . . . . . . . . . . 480\n39.11 Making Directories . . . . . . . . . . . . . . . . . . . . . . . 480\n39.12 Reading Directories . . . . . . . . . . . . . . . . . . . . . . 481\n39.13 Deleting Directories . . . . . . . . . . . . . . . . . . . . . . 482\n39.14 Hard Links . . . . . . . . . . . . . . . . . . . . . . . . . . . 482\n39.15 Symbolic Links . . . . . . . . . . . . . . . . . . . . . . . . . 484\n39.16 Permission Bits And Access Control Lists . . . . . . . . . . 485\n39.17 Making And Mounting A File System . . . . . . . . . . . . 488\n39.18 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 490\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 491\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n40 File System Implementation 493\n40.1 The Way To Think . . . . . . . . . . . . . . . . . . . . . . . 493\n40.2 Overall Organization . . . . . . . . . . . . . . . . . . . . . . 494\n40.3 File Organization: The Inode . . . . . . . . . . . . . . . . . 496\n40.4 Directory Organization . . . . . . . . . . . . . . . . . . . . 501\n40.5 Free Space Management . . . . . . . . . . . . . . . . . . . . 501\n40.6 Access Paths: Reading and Writing . . . . . . . . . . . . . . 502\n40.7 Caching and Buffering . . . . . . . . . . . . . . . . . . . . . 506\n40.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 510\n41 Locality and The Fast File System 511\n41.1 The Problem: Poor Performance . . . . . . . . . . . . . . . 511\n41.2 FFS: Disk Awareness Is The Solution . . . . . . . . . . . . . 513\n41.3 Organizing Structure: The Cylinder Group . . . . . . . . . 513\n41.4 Policies: How To Allocate Files and Directories . . . . . . . 515\n41.5 Measuring File Locality . . . . . . . . . . . . . . . . . . . . 517\n41.6 The Large-File Exception . . . . . . . . . . . . . . . . . . . 518\n41.7 A Few Other Things About FFS . . . . . . . . . . . . . . . . 520\n41.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 522\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 524\nc\u20dd 2008\u201318, ARPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "File System Implementation 493",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "file",
          "system",
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 466\n39 Interlude: Files and Directories 467",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "466\n39 interlude",
          "files",
          "directories"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 3 File Organization: The Inode . . . . . . . . . . . . . . . . . 496",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 file organization",
          "inode"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 6 Access Paths: Reading and Writing . . . . . . . . . . . . . . 502",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 access paths",
          "reading",
          "writing"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 1 The Problem: Poor Performance . . . . . . . . . . . . . . . 511",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 the problem",
          "poor",
          "performance"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 2 FFS: Disk Awareness Is The Solution . . . . . . . . . . . . . 513",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 ffs",
          "disk",
          "awareness",
          "solution"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 3 Organizing Structure: The Cylinder Group . . . . . . . . . 513",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 organizing structure",
          "cylinder",
          "group"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 4 Policies: How To Allocate Files and Directories . . . . . . . 515",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 policies",
          "allocate",
          "files",
          "directories"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand files and directories . . . . . . . . . . . . . . . . . . . . . . 467",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "files",
          "directories"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand the file system interface . . . . . . . . . . . . . . . . . . . 469",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "system",
          "interface"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand creating files . . . . . . . . . . . . . . . . . . . . . . . . . . 469",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "creating",
          "files"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand reading and writing files . . . . . . . . . . . . . . . . . . 470",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "writing",
          "files"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand reading and writing, but not sequentially . . . . . . . . . 472",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "writing",
          "sequentially"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand shared file table entries:fork() and dup() ....... 4 7 5",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shared",
          "file",
          "table",
          "entries",
          "fork"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xxii CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xxii CONTENTS\n42 Crash Consistency: FSCK and Journaling 525\n42.1 A Detailed Example . . . . . . . . . . . . . . . . . . . . . . 526\n42.2 Solution #1: The File System Checker . . . . . . . . . . . . 529\n42.3 Solution #2: Journaling (or Write-Ahead Logging) . . . . . 531\n42.4 Solution #3: Other Approaches . . . . . . . . . . . . . . . . 541\n42.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 545\n43 Log-structured File Systems 547\n43.1 Writing To Disk Sequentially . . . . . . . . . . . . . . . . . 548\n43.2 Writing Sequentially And Effectively . . . . . . . . . . . . . 549\n43.3 How Much To Buffer? . . . . . . . . . . . . . . . . . . . . . 550\n43.4 Problem: Finding Inodes . . . . . . . . . . . . . . . . . . . 551\n43.5 Solution Through Indirection: The Inode Map . . . . . . . 551\n43.6 Completing The Solution: The Checkpoint Region . . . . . 553\n43.7 Reading A File From Disk: A Recap . . . . . . . . . . . . . 553\n43.8 What About Directories? . . . . . . . . . . . . . . . . . . . 554\n43.9 A New Problem: Garbage Collection . . . . . . . . . . . . . 555\n43.10 Determining Block Liveness . . . . . . . . . . . . . . . . . . 556\n43.11 A Policy Question: Which Blocks To Clean, And When? . . 557\n43.12 Crash Recovery And The Log . . . . . . . . . . . . . . . . . 558\n43.13 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 558\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 560\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 561\n44 Flash-based SSDs 563\n44.1 Storing a Single Bit . . . . . . . . . . . . . . . . . . . . . . . 563\n44.2 From Bits to Banks/Planes . . . . . . . . . . . . . . . . . . 564\n44.3 Basic Flash Operations . . . . . . . . . . . . . . . . . . . . . 565\n44.4 Flash Performance And Reliability . . . . . . . . . . . . . . 567\n44.5 From Raw Flash to Flash-Based SSDs . . . . . . . . . . . . 568\n44.6 FTL Organization: A Bad Approach . . . . . . . . . . . . . 569\n44.7 A Log-Structured FTL . . . . . . . . . . . . . . . . . . . . . 570\n44.8 Garbage Collection . . . . . . . . . . . . . . . . . . . . . . . 572\n44.9 Mapping Table Size . . . . . . . . . . . . . . . . . . . . . . 574\n44.10 Wear Leveling . . . . . . . . . . . . . . . . . . . . . . . . . 579\n44.11 SSD Performance And Cost . . . . . . . . . . . . . . . . . . 579\n44.12 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 583\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 585\n45 Data Integrity and Protection 587\n45.1 Disk Failure Modes . . . . . . . . . . . . . . . . . . . . . . . 587\n45.2 Handling Latent Sector Errors . . . . . . . . . . . . . . . . 589\n45.3 Detecting Corruption: The Checksum . . . . . . . . . . . . 590\n45.4 Using Checksums . . . . . . . . . . . . . . . . . . . . . . . 593\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Solution #3: Other Approaches . . . . . . . . . . . . . . . . 541",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "FTL Organization: A Bad Approach . . . . . . . . . . . . . 569",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "organization",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1: The File System Checker . . . . . . . . . . . . 529",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "file",
          "system",
          "checker"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2: Journaling (or Write-Ahead Logging) . . . . . 531",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "journaling",
          "write",
          "ahead",
          "logging"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 3: Other Approaches . . . . . . . . . . . . . . . . 541",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "approaches"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 4 Problem: Finding Inodes . . . . . . . . . . . . . . . . . . . 551",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 problem",
          "finding",
          "inodes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 5 Solution Through Indirection: The Inode Map . . . . . . . 551",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 solution through indirection",
          "inode"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 6 Completing The Solution: The Checkpoint Region . . . . . 553",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 completing the solution",
          "checkpoint",
          "region"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand 9 A New Problem: Garbage Collection . . . . . . . . . . . . . 555",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "9 a new problem",
          "garbage",
          "collection"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand 11 A Policy Question: Which Blocks To Clean, And When? . . 557",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "11 a policy question",
          "blocks",
          "clean"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a detailed example . . . . . . . . . . . . . . . . . . . . . . 526",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "detailed",
          "example"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand writing to disk sequentially . . . . . . . . . . . . . . . . . 548",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "writing",
          "disk",
          "sequentially"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CONTENTS xxiii",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CONTENTS xxiii\n45.5 A New Problem: Misdirected Writes . . . . . . . . . . . . . 594\n45.6 One Last Problem: Lost Writes . . . . . . . . . . . . . . . . 595\n45.7 Scrubbing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595\n45.8 Overheads Of Checksumming . . . . . . . . . . . . . . . . 596\n45.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 598\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 599\n46 Summary Dialogue on Persistence 601\n47 A Dialogue on Distribution 603\n48 Distributed Systems 605\n48.1 Communication Basics . . . . . . . . . . . . . . . . . . . . . 606\n48.2 Unreliable Communication Layers . . . . . . . . . . . . . . 607\n48.3 Reliable Communication Layers . . . . . . . . . . . . . . . 609\n48.4 Communication Abstractions . . . . . . . . . . . . . . . . . 611\n48.5 Remote Procedure Call (RPC) . . . . . . . . . . . . . . . . . 613\n48.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 618\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 619\nHomework (Code) . . . . . . . . . . . . . . . . . . . . . . . . . . . 620\n49 Sun\u2019s Network File System (NFS) 621\n49.1 A Basic Distributed File System . . . . . . . . . . . . . . . . 622\n49.2 On To NFS . . . . . . . . . . . . . . . . . . . . . . . . . . . . 623\n49.3 Focus: Simple And Fast Server Crash Recovery . . . . . . . 623\n49.4 Key To Fast Crash Recovery: Statelessness . . . . . . . . . 624\n49.5 The NFSv2 Protocol . . . . . . . . . . . . . . . . . . . . . . 625\n49.6 From Protocol To Distributed File System . . . . . . . . . . 627\n49.7 Handling Server Failure With Idempotent Operations . . . 629\n49.8 Improving Performance: Client-side Caching . . . . . . . . 631\n49.9 The Cache Consistency Problem . . . . . . . . . . . . . . . 631\n49.10 Assessing NFS Cache Consistency . . . . . . . . . . . . . . 633\n49.11 Implications On Server-Side Write Buffering . . . . . . . . 633\n49.12 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 635\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 637\nHomework (Measurement) . . . . . . . . . . . . . . . . . . . . . . 638\n50 The Andrew File System (AFS) 639\n50.1 AFS Version 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 639\n50.2 Problems with Version 1 . . . . . . . . . . . . . . . . . . . . 641\n50.3 Improving the Protocol . . . . . . . . . . . . . . . . . . . . 642\n50.4 AFS Version 2 . . . . . . . . . . . . . . . . . . . . . . . . . . 642\n50.5 Cache Consistency . . . . . . . . . . . . . . . . . . . . . . . 644\n50.6 Crash Recovery . . . . . . . . . . . . . . . . . . . . . . . . . 646\n50.7 Scale And Performance Of AFSv2 . . . . . . . . . . . . . . 646\nc\u20dd 2008\u201318, ARPACI -DUSSEAU\nTHREE\nEASY\nPIECES",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 5 A New Problem: Misdirected Writes . . . . . . . . . . . . . 594",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 a new problem",
          "misdirected",
          "writes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 6 One Last Problem: Lost Writes . . . . . . . . . . . . . . . . 595",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 one last problem",
          "lost",
          "writes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 3 Focus: Simple And Fast Server Crash Recovery . . . . . . . 623",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 focus",
          "simple",
          "fast",
          "server",
          "crash",
          "recovery"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 8 Improving Performance: Client-side Caching . . . . . . . . 631",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8 improving performance",
          "client",
          "side",
          "caching"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_3",
        "text": "understand scrubbing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "scrubbing"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand overheads of checksumming . . . . . . . . . . . . . . . . 596",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "overheads",
          "checksumming"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand communication basics . . . . . . . . . . . . . . . . . . . . . 606",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "communication",
          "basics"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "xxiv CONTENTS",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "xxiv CONTENTS\n50.8 AFS: Other Improvements . . . . . . . . . . . . . . . . . . . 649\n50.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651\nHomework (Simulation) . . . . . . . . . . . . . . . . . . . . . . . 652\n51 Summary Dialogue on Distribution 653\nGeneral Index 655\nAsides 667\nTips 671\nCruces 675\nOPERATING\nSYSTEMS\n[VERSION 1.00] WWW.OSTEP .ORG",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 8 AFS: Other Improvements . . . . . . . . . . . . . . . . . . . 649",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8 afs",
          "improvements"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "1\nA Dialogue on the Book\nProfessor: Welcome to this book! It\u2019s called Operating Systems in Three Easy\nPieces, and I am here to teach you the things you need to know about oper ating\nsystems. I am called \u201cProfessor\u201d; who are you?\nStudent: Hi Professor! I am called \u201cStudent\u201d, as you might have guessed. An d\nI am here and ready to learn!\nProfessor: Sounds good. Any questions?\nStudent: Sure! Why is it called \u201cThree Easy Pieces\u201d?\nProfessor: That\u2019s an easy one. Well, you see, there are these great lectures on\nPhysics by Richard Feynman...\nStudent: Oh! The guy who wrote \u201cSurely Y ou\u2019re Joking, Mr . Feynman\u201d, right?\nGreat book! Is this going to be hilarious like that book was?\nProfessor: Um... well, no. That book was great, and I\u2019m glad you\u2019ve read it.\nHopefully this book is more like his notes on Physics. Some of the basics w ere\nsummed up in a book called \u201cSix Easy Pieces\u201d. He was talking about Phys ics;\nwe\u2019re going to do Three Easy Pieces on the \ufb01ne topic of Operating Syst ems. This\nis appropriate, as Operating Systems are about half as hard as Phy sics.\nStudent: Well, I liked physics, so that is probably good. What are those pieces?\nProfessor: They are the three key ideas we\u2019re going to learn about: virtualiza-\ntion, concurrency, and persistence. In learning about these ideas, we\u2019ll learn\nall about how an operating system works, including how it decides wha t program\nto run next on a CPU, how it handles memory overload in a virtual memo ry sys-\ntem, how virtual machine monitors work, how to manage information o n disks,\nand even a little about how to build a distributed system that works wh en parts\nhave failed. That sort of stuff.\nStudent: I have no idea what you\u2019re talking about, really.\nProfessor: Good! That means you are in the right class.\nStudent: I have another question: what\u2019s the best way to learn this stuff?\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pieces, and I am here to teach you the things you need to know about oper ating",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pieces",
          "teach",
          "things",
          "need",
          "know",
          "oper",
          "ating"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "I am here and ready to learn!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ready",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Professor: They are the three key ideas we\u2019re going to learn about: virtualiza-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "three",
          "ideas",
          "going",
          "learn",
          "virtualiza"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "tion, concurrency, and persistence. In learning about these ideas, we\u2019ll learn",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "concurrency",
          "persistence",
          "learning",
          "ideas",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Student: I have another question: what\u2019s the best way to learn this stuff?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "another",
          "question",
          "best",
          "learn",
          "stuff"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand That: you are in the right class.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "that",
          "right",
          "class"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Hi Professor! I am called \u201cStudent\u201d, as you might have guessed. An d",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "professor",
          "called",
          "student",
          "might",
          "guessed"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Sounds good. Any questions?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "sounds",
          "good",
          "questions"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Sure! Why is it called \u201cThree Easy Pieces\u201d?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sure",
          "called",
          "three",
          "easy",
          "pieces"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: That\u2019s an easy one. Well, you see, there are these great lectures on",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "easy",
          "well",
          "great",
          "lectures"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: Oh! The guy who wrote \u201cSurely Y ou\u2019re Joking, Mr . Feynman\u201d, right?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "wrote",
          "surely",
          "joking",
          "feynman",
          "right"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Um... well, no. That book was great, and I\u2019m glad you\u2019ve read it.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "book",
          "great",
          "glad",
          "read"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Student: Well, I liked physics, so that is probably good. What are those pieces?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "liked",
          "physics",
          "probably",
          "good",
          "pieces"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand it called \u201cThree Easy Pieces\u201d",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "called",
          "three",
          "easy",
          "pieces"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 A D I A L O G U E O N T H EBO O K",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 A D I A L O G U E O N T H EBO O K\nProfessor: Excellent query! Well, each person needs to \ufb01gure this out on their\nown, of course, but here is what I would do: go to class, to hear the professor\nintroduce the material. Then, at the end of every week, read thes e notes, to help\nthe ideas sink into your head a bit better . Of course, some time later (hint: before\nthe exam!), read the notes again to \ufb01rm up your knowledge. Of cour se, your pro-\nfessor will no doubt assign some homeworks and projects, so you sho uld do those;\nin particular , doing projects where you write real code to solve real problems is\nthe best way to put the ideas within these notes into action. As Confu cius said...\nStudent: Oh, I know! \u2019I hear and I forget. I see and I remember . I do and I\nunderstand.\u2019 Or something like that.\nProfessor: (surprised) How did you know what I was going to say?!\nStudent: It seemed to follow. Also, I am a big fan of Confucius, and an even\nbigger fan of Xunzi, who actually is a better source for this quote 1 .\nProfessor: (stunned) Well, I think we are going to get along just \ufb01ne! Just \ufb01ne\nindeed.\nStudent: Professor \u2013 just one more question, if I may. What are these dialogue s\nfor? I mean, isn\u2019t this just supposed to be a book? Why not present t he material\ndirectly?\nProfessor: Ah, good question, good question! Well, I think it is sometimes\nuseful to pull yourself outside of a narrative and think a bit; these d ialogues are\nthose times. So you and I are going to work together to make sense of all of these\npretty complex ideas. Are you up for it?\nStudent: So we have to think? Well, I\u2019m up for that. I mean, what else do I have\nto do anyhow? It\u2019s not like I have much of a life outside of this book.\nProfessor: Me neither , sadly. So let\u2019s get to work!\n1 According to http://www.barrypopik.com (on, December 19, 2012, entitled \u201cT ell\nme and I forget; teach me and I may remember; involve me and I will lear n\u201d) Confucian\nphilosopher Xunzi said \u201cNot having heard something is not as good as having heard it; having\nheard it is not as good as having seen it; having seen it is not as good as knowing it; knowing\nit is not as good as putting it into practice.\u201d Later on, the wisdom got attached to Confucius\nfor some reason. Thanks to Jiao Dong (Rutgers) for telling us!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the exam!), read the notes again to \ufb01rm up your knowledge. Of cour se, your pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "exam",
          "read",
          "notes",
          "knowledge",
          "cour"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in particular , doing projects where you write real code to solve real problems is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "particular",
          "projects",
          "write",
          "real",
          "code",
          "solve",
          "real",
          "problems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Student: Oh, I know! \u2019I hear and I forget. I see and I remember . I do and I",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "know",
          "hear",
          "forget",
          "remember"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "understand.\u2019 Or something like that.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "something",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Professor: (surprised) How did you know what I was going to say?!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "surprised",
          "know",
          "going"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "heard it is not as good as having seen it; having seen it is not as good as knowing it; knowing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "heard",
          "good",
          "seen",
          "seen",
          "good",
          "knowing",
          "knowing"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_6",
        "text": "understand Student: It seemed to follow. Also, I am a big fan of Confucius, and an even",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "seemed",
          "follow",
          "also",
          "confucius",
          "even"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Professor: (stunned) Well, I think we are going to get along just \ufb01ne! Just \ufb01ne",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "stunned",
          "well",
          "think",
          "going",
          "along"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Student: Professor \u2013 just one more question, if I may. What are these dialogue s",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "professor",
          "question",
          "dialogue"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Professor: Ah, good question, good question! Well, I think it is sometimes",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good",
          "question",
          "good",
          "question",
          "well",
          "think",
          "sometimes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Student: So we have to think? Well, I\u2019m up for that. I mean, what else do I have",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "think",
          "well",
          "mean",
          "else"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Professor: Me neither , sadly. So let\u2019s get to work!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "neither",
          "sadly",
          "work"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2\nIntroduction to Operating Systems\nIf you are taking an undergraduate operating systems course, you should\nalready have some idea of what a computer program does when it runs.\nIf not, this book (and the corresponding course) is going to be dif\ufb01cu lt\n\u2014 so you should probably stop reading this book, or run to the near-\nest bookstore and quickly consume the necessary background mater ial\nbefore continuing (both Patt & Patel [PP03] and Bryant & O\u2019Hallar on\n[BOH10] are pretty great books).\nSo what happens when a program runs?\nW ell, a running program does one very simple thing: it executes i n-\nstructions. Many millions (and these days, even billions) of tim es ev-\nery second, the processor fetches an instruction from memory , decodes\nit (i.e., \ufb01gures out which instruction this is), and executes it (i.e., it does\nthe thing that it is supposed to do, like add two numbers together , access\nmemory , check a condition, jump to a function, and so forth). After it is\ndone with this instruction, the processor moves on to the next instr uction,\nand so on, and so on, until the program \ufb01nally completes 1 .\nThus, we have just described the basics of the V on Neumann model of\ncomputing2 . Sounds simple, right? But in this class, we will be learning\nthat while a program runs, a lot of other wild things are going on with\nthe primary goal of making the system easy to use .\nThere is a body of software, in fact, that is responsible for making it\neasy to run programs (even allowing you to seemingly run many at t he\nsame time), allowing programs to share memory , enabling program s to\ninteract with devices, and other fun stuff like that. That body of software\n1 Of course, modern processors do many bizarre and frightening things under neath the\nhood to make programs run faster , e.g., executing multiple instru ctions at once, and even issu-\ning and completing them out of order! But that is not our concern here; we ar e just concerned\nwith the simple model most programs assume: that instructions see mingly execute one at a\ntime, in an orderly and sequential fashion.\n2 V on Neumann was one of the early pioneers of computing systems. He al so did pioneer-\ning work on game theory and atomic bombs, and played in the NBA for six years. OK, one of\nthose things isn\u2019t true.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus, we have just described the basics of the V on Neumann model of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "described",
          "basics",
          "neumann",
          "model"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "computing2 . Sounds simple, right? But in this class, we will be learning",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sounds",
          "simple",
          "right",
          "class",
          "learning"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the primary goal of making the system easy to use .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "primary",
          "goal",
          "making",
          "system",
          "easy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ing work on game theory and atomic bombs, and played in the NBA for six years. OK, one of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "work",
          "game",
          "theory",
          "atomic",
          "bombs",
          "played",
          "years"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 I N T R O D U C T I O N TO OP E R AT I N G SY S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nTH E CR U X O F T H E PR O B L E M :\nHO W TO VI RT U A L I Z E RE S O U R C E S\nOne central question we will answer in this book is quite simple: how\ndoes the operating system virtualize resources? This is the cru x of our\nproblem. Why the OS does this is not the main question, as the answer\nshould be obvious: it makes the system easier to use. Thus, we focu s on\nthe how: what mechanisms and policies are implemented by the OS to\nattain virtualization? How does the OS do so ef\ufb01ciently? What ha rdware\nsupport is needed?\nW e will use the \u201ccrux of the problem\u201d, in shaded boxes such as this one,\nas a way to call out speci\ufb01c problems we are trying to solve in buil ding\nan operating system. Thus, within a note on a particular topic, you may\n\ufb01nd one or more cruces (yes, this is the proper plural) which highlight the\nproblem. The details within the chapter , of course, present the solution,\nor at least the basic parameters of a solution.\nis called the operating system (OS)3 , as it is in charge of making sure the\nsystem operates correctly and ef\ufb01ciently in an easy-to-use man ner .\nThe primary way the OS does this is through a general technique t hat\nwe call virtualization. That is, the OS takes a physical resource (such as\nthe processor , or memory , or a disk) and transforms it into a more gen-\neral, powerful, and easy-to-use virtual form of itself. Thus, we sometimes\nrefer to the operating system as a virtual machine .\nOf course, in order to allow users to tell the OS what to do and thus\nmake use of the features of the virtual machine (such as running a pro-\ngram, or allocating memory , or accessing a \ufb01le), the OS also provid es\nsome interfaces (APIs) that you can call. A typical OS, in fact, e xports\na few hundred system calls that are available to applications. Because\nthe OS provides these calls to run programs, access memory and de vices,\nand other related actions, we also sometimes say that the OS provi des a\nstandard library to applications.\nFinally , because virtualization allows many programs to run (t hus shar-\ning the CPU), and many programs to concurrently access their own in-\nstructions and data (thus sharing memory), and many programs to access\ndevices (thus sharing disks and so forth), the OS is sometimes k nown as\na resource manager . Each of the CPU, memory , and disk is a resource\nof the system; it is thus the operating system\u2019s role to manage those re-\nsources, doing so ef\ufb01ciently or fairly or indeed with many other pos sible\ngoals in mind. T o understand the role of the OS a little bit better , let\u2019s take\na look at some examples.\n3 Another early name for the OS was the supervisor or even the master control program .\nApparently , the latter sounded a little overzealous (see the movi e T ron for details) and thus,\nthankfully , \u201coperating system\u201d caught on instead.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the how: what mechanisms and policies are implemented by the OS to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "mechanisms",
          "policies",
          "implemented"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "as a way to call out speci\ufb01c problems we are trying to solve in buil ding",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "problems",
          "trying",
          "solve",
          "buil",
          "ding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The primary way the OS does this is through a general technique t hat",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "primary",
          "general",
          "technique"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "a few hundred system calls that are available to applications. Because",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hundred",
          "system",
          "calls",
          "available",
          "applications"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "goals in mind. T o understand the role of the OS a little bit better , let\u2019s take",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goals",
          "mind",
          "understand",
          "role",
          "little",
          "better",
          "take"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the operating system virtualize resources",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "system",
          "virtualize",
          "resources"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the OS do so ef\ufb01ciently",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "1 Virtualizing The CPU",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "2.1 Virtualizing The CPU\nFigure 2.1 depicts our \ufb01rst program. It doesn\u2019t do much. In fact, a ll\nit does is call Spin(), a function that repeatedly checks the time and\nreturns once it has run for a second. Then, it prints out the string that the\nuser passed in on the command line, and repeats, forever .\nLet\u2019s say we save this \ufb01le as cpu.c and decide to compile and run it\non a system with a single processor (or CPU as we will sometimes call it).\nHere is what we will see:\nprompt> gcc -o cpu cpu.c -Wall\nprompt> ./cpu \"A\"\nA\nA\nA\nA\n\u02c6C\nprompt>\nNot too interesting of a run \u2014 the system begins running the progra m,\nwhich repeatedly checks the time until a second has elapsed. O nce a sec-\nond has passed, the code prints the input string passed in by the user (in\nthis example, the letter \u201cA \u201d), and continues. Note the program w ill run\nforever; by pressing \u201cControl-c\u201d (which on U N I X-based systems will ter-\nminate the program running in the foreground) we can halt the prog ram.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand virtualizing the cpu",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 I N T R O D U C T I O N TO OP E R AT I N G SY S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nprompt> ./cpu A & ./cpu B & ./cpu C & ./cpu D &\n[1] 7353\n[2] 7354\n[3] 7355\n[4] 7356\nA\nB\nD\nC\nA\nB\nD\nC\nA\n...\nFigure 2.2: Running Many Programs At Once\nNow , let\u2019s do the same thing, but this time, let\u2019s run many differ ent in-\nstances of this same program. Figure 2.2 shows the results of this slightly\nmore complicated example.\nW ell, now things are getting a little more interesting. Even th ough we\nhave only one processor , somehow all four of these programs seem to be\nrunning at the same time! How does this magic happen? 4\nIt turns out that the operating system, with some help from the har d-\nware, is in charge of this illusion, i.e., the illusion that the system has a\nvery large number of virtual CPUs. T urning a single CPU (or smal l set of\nthem) into a seemingly in\ufb01nite number of CPUs and thus allowing many\nprograms to seemingly run at once is what we call virtualizing the CPU ,\nthe focus of the \ufb01rst major part of this book.\nOf course, to run programs, and stop them, and otherwise tell the O S\nwhich programs to run, there need to be some interfaces (APIs) t hat you\ncan use to communicate your desires to the OS. W e\u2019ll talk about thes e\nAPIs throughout this book; indeed, they are the major way in which m ost\nusers interact with operating systems.\nY ou might also notice that the ability to run multiple programs a t once\nraises all sorts of new questions. For example, if two programs wan t to\nrun at a particular time, which should run? This question is answered by\na policy of the OS; policies are used in many different places within an\nOS to answer these types of questions, and thus we will study the m as\nwe learn about the basic mechanisms that operating systems implement\n(such as the ability to run multiple programs at once). Hence th e role of\nthe OS as a resource manager .\n4 Note how we ran four processes at the same time, by using the & symbol. Doing so runs a\njob in the background in the zsh shell, which means that the user is able to immediately issue\ntheir next command, which in this case is another program to run. If you\u2019re using a different\nshell (e.g., tcsh), it works slightly differently; read documentation online for detai ls.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "we learn about the basic mechanisms that operating systems implement",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "learn",
          "basic",
          "mechanisms",
          "operating",
          "systems",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "job in the background in the zsh shell, which means that the user is able to immediately issue",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "background",
          "shell",
          "means",
          "user",
          "able",
          "immediately",
          "issue"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand which: that the user is able to immediately issue",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which",
          "user",
          "able",
          "immediately",
          "issue"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 2: Running Many Programs At Once",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "running",
          "many",
          "programs"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand this magic happen",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "magic",
          "happen"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "2 Virtualizing Memory",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "2.2 Virtualizing Memory\nNow let\u2019s consider memory . The model of physical memory pre-\nsented by modern machines is very simple. Memory is just an arra y of\nbytes; to read memory , one must specify an address to be able to access\nthe data stored there; to write (or update) memory , one must also specify\nthe data to be written to the given address.\nMemory is accessed all the time when a program is running. A pro-\ngram keeps all of its data structures in memory , and accesses th em through\nvarious instructions, like loads and stores or other explicit inst ructions\nthat access memory in doing their work. Don\u2019t forget that each instr uc-\ntion of the program is in memory too; thus memory is accessed on each\ninstruction fetch.\nLet\u2019s take a look at a program (in Figure 2.3) that allocates some mem -\nory by calling malloc(). The output of this program can be found here:\nprompt> ./mem\n(2134) address pointed to by p: 0x200000\n(2134) p: 1\n(2134) p: 2\n(2134) p: 3\n(2134) p: 4\n(2134) p: 5\n\u02c6C\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "bytes; to read memory , one must specify an address to be able to access",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bytes",
          "read",
          "memory",
          "must",
          "specify",
          "address",
          "able",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand virtualizing memory",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing",
          "memory"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 I N T R O D U C T I O N TO OP E R AT I N G SY S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nprompt> ./mem &; ./mem &\n[1] 24113\n[2] 24114\n(24113) address pointed to by p: 0x200000\n(24114) address pointed to by p: 0x200000\n(24113) p: 1\n(24114) p: 1\n(24114) p: 2\n(24113) p: 2\n(24113) p: 3\n(24114) p: 3\n(24113) p: 4\n(24114) p: 4\n...\nFigure 2.4: Running The Memory Program Multiple Times\nThe program does a couple of things. First, it allocates some memory\n(line a1). Then, it prints out the address of the memory (a2), and then\nputs the number zero into the \ufb01rst slot of the newly allocated mem ory\n(a3). Finally , it loops, delaying for a second and incrementing t he value\nstored at the address held in p. With every print statement, it also prints\nout what is called the process identi\ufb01er (the PID) of the running program.\nThis PID is unique per running process.\nAgain, this \ufb01rst result is not too interesting. The newly alloca ted mem-\nory is at address 0x200000. As the program runs, it slowly updates the\nvalue and prints out the result.\nNow , we again run multiple instances of this same program to see\nwhat happens (Figure 2.4). W e see from the example that each ru nning\nprogram has allocated memory at the same address ( 0x200000), and yet\neach seems to be updating the value at 0x200000 independently! It is as\nif each running program has its own private memory , instead of sha ring\nthe same physical memory with other running programs 5 .\nIndeed, that is exactly what is happening here as the OS is virtualiz-\ning memory . Each process accesses its own private virtual address space\n(sometimes just called its address space ), which the OS somehow maps\nonto the physical memory of the machine. A memory reference withi n\none running program does not affect the address space of other proces ses\n(or the OS itself); as far as the running program is concerned, it has phys-\nical memory all to itself. The reality , however , is that physic al memory is\na shared resource, managed by the operating system. Exactly how all of\nthis is accomplished is also the subject of the \ufb01rst part of this b ook, on the\ntopic of virtualization.\n5 For this example to work, you need to make sure address-space rando mization is dis-\nabled; randomization, as it turns out, can be a good defense against ce rtain kinds of security\n\ufb02aws. Read more about it on your own, especially if you want to lea rn how to break into\ncomputer systems via stack-smashing attacks. Not that we would recom mend such a thing...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_11",
        "text": "understand 4: Running The Memory Program Multiple Times",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "running",
          "memory",
          "program",
          "multiple",
          "times"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "3 Concurrency",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "2.3 Concurrency\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 #include \"common.h\"\n4\n5 volatile int counter = 0;\n6 int loops;\n7\n8 void *worker(void *arg) {\n9 int i;\n10 for (i = 0; i < loops; i++) {\n11 counter++;\n12 }\n13 return NULL;\n14 }\n15\n16 int main(int argc, char *argv[]) {\n17 if (argc != 2) {\n18 fprintf(stderr, \"usage: threads <value>\\n\");\n19 exit(1);\n20 }\n21 loops = atoi(argv[1]);\n22 pthread_t p1, p2;\n23 printf(\"Initial value : %d\\n\", counter);\n24\n25 Pthread_create(&p1, NULL, worker, NULL);\n26 Pthread_create(&p2, NULL, worker, NULL);\n27 Pthread_join(p1, NULL);\n28 Pthread_join(p2, NULL);\n29 printf(\"Final value : %d\\n\", counter);\n30 return 0;\n31 }\nFigure 2.5: A Multi-threaded Program ( threads.c)\nAnother main theme of this book is concurrency. W e use this concep-\ntual term to refer to a host of problems that arise, and must be add ressed,\nwhen working on many things at once (i.e., concurrently) in the sa me\nprogram. The problems of concurrency arose \ufb01rst within the operati ng\nsystem itself; as you can see in the examples above on virtualiza tion, the\nOS is juggling many things at once, \ufb01rst running one process, the n an-\nother , and so forth. As it turns out, doing so leads to some deep and\ninteresting problems.\nUnfortunately , the problems of concurrency are no longer limited just\nto the OS itself. Indeed, modern multi-threaded programs exhibit the\nsame problems. Let us demonstrate with an example of a multi-threaded\nprogram (Figure 2.5).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pthread_create(&p1, NULL, worker, NULL);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "worker",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Pthread_create(&p2, NULL, worker, NULL);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "worker",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "same problems. Let us demonstrate with an example of a multi-threaded",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "problems",
          "demonstrate",
          "example",
          "multi",
          "threaded"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 5: A Multi-threaded Program ( threads.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "multi",
          "threaded",
          "program",
          "threads"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrency",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrency"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 I N T R O D U C T I O N TO OP E R AT I N G SY S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nAlthough you might not understand this example fully at the momen t\n(and we\u2019ll learn a lot more about it in later chapters, in the secti on of the\nbook on concurrency), the basic idea is simple. The main program cr eates\ntwo threads using Pthread create()6 . Y ou can think of a thread as a\nfunction running within the same memory space as other functions , with\nmore than one of them active at a time. In this example, each threa d starts\nrunning in a routine called worker(), in which it simply increments a\ncounter in a loop for loops number of times.\nBelow is a transcript of what happens when we run this program wit h\nthe input value for the variable loops set to 1000. The value of loops\ndetermines how many times each of the two workers will increment the\nshared counter in a loop. When the program is run with the value of\nloops set to 1000, what do you expect the \ufb01nal value of counter to be?\nprompt> gcc -o thread thread.c -Wall -pthread\nprompt> ./thread 1000\nInitial value : 0\nFinal value : 2000\nAs you probably guessed, when the two threads are \ufb01nished, the \ufb01 nal\nvalue of the counter is 2000, as each thread incremented the coun ter 1000\ntimes. Indeed, when the input value of loops is set to N, we would\nexpect the \ufb01nal output of the program to be 2N. But life is not so simple,\nas it turns out. Let\u2019s run the same program, but with higher value s for\nloops, and see what happens:\nprompt> ./thread 100000\nInitial value : 0\nFinal value : 143012 // huh??\nprompt> ./thread 100000\nInitial value : 0\nFinal value : 137298 // what the??\nIn this run, when we gave an input value of 100,000, instead of ge tting\na \ufb01nal value of 200,000, we instead \ufb01rst get 143,012. Then, whe n we run\nthe program a second time, we not only again get the wrong value, but\nalso a different value than the last time. In fact, if you run the program\nover and over with high values of loops, you may \ufb01nd that sometimes\nyou even get the right answer! So why is this happening?\nAs it turns out, the reason for these odd and unusual outcomes relate\nto how instructions are executed, which is one at a time. Unfortun ately , a\nkey part of the program above, where the shared counter is increme nted,\n6 The actual call should be to lower-case pthread create(); the upper-case version is\nour own wrapper that calls pthread create() and makes sure that the return code indicates\nthat the call succeeded. See the code for details.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Although you might not understand this example fully at the momen t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "although",
          "might",
          "understand",
          "example",
          "fully",
          "momen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(and we\u2019ll learn a lot more about it in later chapters, in the secti on of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "later",
          "chapters",
          "secti"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "two threads using Pthread create()6 . Y ou can think of a thread as a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "threads",
          "using",
          "pthread",
          "create",
          "think",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "As it turns out, the reason for these odd and unusual outcomes relate",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "turns",
          "reason",
          "unusual",
          "outcomes",
          "relate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The actual call should be to lower-case pthread create(); the upper-case version is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "actual",
          "call",
          "lower",
          "case",
          "pthread",
          "create",
          "upper",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "our own wrapper that calls pthread create() and makes sure that the return code indicates",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wrapper",
          "calls",
          "pthread",
          "create",
          "makes",
          "sure",
          "return",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand and see what happens: prompt> ./thread 100000",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and see what happens",
          "prompt",
          "thread"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand this happening",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "happening"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "4 Persistence",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "2.4 Persistence\nThe third major theme of the course is persistence. In system memory ,\ndata can be easily lost, as devices such as DRAM store values in a volatile\nmanner; when power goes away or the system crashes, any data in me m-\nory is lost. Thus, we need hardware and software to be able to store data\npersistently; such storage is thus critical to any system as users care a\ngreat deal about their data.\nThe hardware comes in the form of some kind of input/output or I/O\ndevice; in modern systems, a hard drive is a common repository for long-\nlived information, although solid-state drives (SSDs) are making head-\nway in this arena as well.\nThe software in the operating system that usually manages the d isk is\ncalled the \ufb01le system ; it is thus responsible for storing any \ufb01les the user\ncreates in a reliable and ef\ufb01cient manner on the disks of the sys tem.\nUnlike the abstractions provided by the OS for the CPU and memory ,\nthe OS does not create a private, virtualized disk for each appli cation.\nRather , it is assumed that often times, users will want to share informa-\ntion that is in \ufb01les. For example, when writing a C program, you mig ht\n\ufb01rst use an editor (e.g., Emacs 7 ) to create and edit the C \ufb01le ( emacs -nw\nmain.c). Once done, you might use the compiler to turn the source code\ninto an executable (e.g., gcc -o main main.c). When you\u2019re \ufb01nished,\nyou might run the new executable (e.g., ./main). Thus, you can see how\n\ufb01les are shared across different processes. First, Emacs crea tes a \ufb01le that\nserves as input to the compiler; the compiler uses that input \ufb01l e to create\na new executable \ufb01le (in many steps \u2014 take a compiler course for de tails);\n\ufb01nally , the new executable is then run. And thus a new program i s born!\n7 Y ou should be using Emacs. If you are using vi, there is probably som ething wrong with\nyou. If you are using something that is not a real code editor , that is e ven worse.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ory is lost. Thus, we need hardware and software to be able to store data",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lost",
          "thus",
          "need",
          "hardware",
          "software",
          "able",
          "store",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "persistently; such storage is thus critical to any system as users care a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "persistently",
          "storage",
          "thus",
          "critical",
          "system",
          "users",
          "care"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "creates in a reliable and ef\ufb01cient manner on the disks of the sys tem.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "reliable",
          "manner",
          "disks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "the OS does not create a private, virtualized disk for each appli cation.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "private",
          "virtualized",
          "disk",
          "appli",
          "cation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "\ufb01rst use an editor (e.g., Emacs 7 ) to create and edit the C \ufb01le ( emacs -nw",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "editor",
          "emacs",
          "create",
          "edit",
          "emacs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "serves as input to the compiler; the compiler uses that input \ufb01l e to create",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "serves",
          "input",
          "compiler",
          "compiler",
          "uses",
          "input",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand persistence",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "persistence"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 I N T R O D U C T I O N TO OP E R AT I N G SY S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\n1 #include <stdio.h>\n2 #include <unistd.h>\n3 #include <assert.h>\n4 #include <fcntl.h>\n5 #include <sys/types.h>\n6\n7 int main(int argc, char *argv[]) {\n8 int fd = open(\"/tmp/file\", O_WRONLY|O_CREAT|O_TRUNC,\n9 S_IRWXU);\n10 assert(fd > -1);\n11 int rc = write(fd, \"hello world\\n\", 13);\n12 assert(rc == 13);\n13 close(fd);\n14 return 0;\n15 }\nFigure 2.6: A Program That Does I/O ( io.c)\nT o understand this better , let\u2019s look at some code. Figure 2.6 pres ents\ncode to create a \ufb01le ( /tmp/file) that contains the string \u201chello world\u201d.\nT o accomplish this task, the program makes three calls into the oper-\nating system. The \ufb01rst, a call to open(), opens the \ufb01le and creates it; the\nsecond, write(), writes some data to the \ufb01le; the third, close(), sim-\nply closes the \ufb01le thus indicating the program won\u2019t be writing an y more\ndata to it. These system calls are routed to the part of the operating sys-\ntem called the \ufb01le system , which then handles the requests and returns\nsome kind of error code to the user .\nY ou might be wondering what the OS does in order to actually write\nto disk. W e would show you but you\u2019d have to promise to close your\neyes \ufb01rst; it is that unpleasant. The \ufb01le system has to do a fai r bit of work:\n\ufb01rst \ufb01guring out where on disk this new data will reside, and the n keep-\ning track of it in various structures the \ufb01le system maintains. Doing so\nrequires issuing I/O requests to the underlying storage devi ce, to either\nread existing structures or update (write) them. As anyone who has writ-\nten a device driver 8 knows, getting a device to do something on your\nbehalf is an intricate and detailed process. It requires a dee p knowledge\nof the low-level device interface and its exact semantics. Fort unately , the\nOS provides a standard and simple way to access devices through its sys-\ntem calls. Thus, the OS is sometimes seen as a standard library .\nOf course, there are many more details in how devices are accesse d,\nand how \ufb01le systems manage data persistently atop said devices . For\nperformance reasons, most \ufb01le systems \ufb01rst delay such writes for a while,\nhoping to batch them into larger groups. T o handle the problems of sys-\ntem crashes during writes, most \ufb01le systems incorporate some kin d of\nintricate write protocol, such as journaling or copy-on-write, carefully\n8 A device driver is some code in the operating system that knows how to d eal with a\nspeci\ufb01c device. W e will talk more about devices and device drivers later .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand this better , let\u2019s look at some code. Figure 2.6 pres ents",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "better",
          "look",
          "code",
          "figure",
          "pres",
          "ents"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "code to create a \ufb01le ( /tmp/file) that contains the string \u201chello world\u201d.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "create",
          "file",
          "contains",
          "string",
          "hello",
          "world"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ating system. The \ufb01rst, a call to open(), opens the \ufb01le and creates it; the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ating",
          "system",
          "call",
          "open",
          "opens",
          "creates"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ten a device driver 8 knows, getting a device to do something on your",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "device",
          "driver",
          "knows",
          "getting",
          "device",
          "something"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "behalf is an intricate and detailed process. It requires a dee p knowledge",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "behalf",
          "intricate",
          "detailed",
          "process",
          "requires",
          "knowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "A device driver is some code in the operating system that knows how to d eal with a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "device",
          "driver",
          "code",
          "operating",
          "system",
          "knows"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 6: A Program That Does I/O ( io.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "program"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "5 Design Goals",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "2.5 Design Goals\nSo now you have some idea of what an OS actually does: it takes phys-\nical resources, such as a CPU, memory , or disk, and virtualizes them. It\nhandles tough and tricky issues related to concurrency. And it stores \ufb01les\npersistently, thus making them safe over the long-term. Given that we\nwant to build such a system, we want to have some goals in mind to h elp\nfocus our design and implementation and make trade-offs as neces sary;\n\ufb01nding the right set of trade-offs is a key to building systems.\nOne of the most basic goals is to build up some abstractions in order\nto make the system convenient and easy to use. Abstractions are fun-\ndamental to everything we do in computer science. Abstraction makes\nit possible to write a large program by dividing it into small an d under-\nstandable pieces, to write such a program in a high-level lang uage like\nC9 without thinking about assembly , to write code in assembly with out\nthinking about logic gates, and to build a processor out of gates wit hout\nthinking too much about transistors. Abstraction is so fundamen tal that\nsometimes we forget its importance, but we won\u2019t here; thus, in eac h sec-\ntion, we\u2019ll discuss some of the major abstractions that have develop ed\nover time, giving you a way to think about pieces of the OS.\nOne goal in designing and implementing an operating system is t o\nprovide high performance; another way to say this is our goal is to mini-\nmize the overheads of the OS. Virtualization and making the system easy\nto use are well worth it, but not at any cost; thus, we must strive t o pro-\nvide virtualization and other OS features without excessive ove rheads.\n9 Some of you might object to calling C a high-level language. Remember t his is an OS\ncourse, though, where we\u2019re simply happy not to have to code in assembl y all the time!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Design Goals",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "goals"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "want to build such a system, we want to have some goals in mind to h elp",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "want",
          "build",
          "system",
          "want",
          "goals",
          "mind"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "focus our design and implementation and make trade-offs as neces sary;",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "focus",
          "design",
          "implementation",
          "make",
          "trade",
          "offs",
          "neces",
          "sary"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "One of the most basic goals is to build up some abstractions in order",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "goals",
          "build",
          "abstractions",
          "order"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "tion, we\u2019ll discuss some of the major abstractions that have develop ed",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tion",
          "discuss",
          "major",
          "abstractions",
          "develop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "One goal in designing and implementing an operating system is t o",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "goal",
          "designing",
          "implementing",
          "operating",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "provide high performance; another way to say this is our goal is to mini-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "provide",
          "high",
          "performance",
          "another",
          "goal",
          "mini"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand design goals",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "goals"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "6 Some History",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "2.6 Some History\nBefore closing this introduction, let us present a brief history of how\noperating systems developed. Like any system built by humans, good\nideas accumulated in operating systems over time, as engineer s learned\nwhat was important in their design. Here, we discuss a few major devel-\nopments. For a richer treatment, see Brinch Hansen\u2019s excellent history of\noperating systems [BH00].\nEarly Operating Systems: Just Libraries\nIn the beginning, the operating system didn\u2019t do too much. Basic ally ,\nit was just a set of libraries of commonly-used functions; for examp le,\ninstead of having each programmer of the system write low-level I /O\nhandling code, the \u201cOS\u201d would provide such APIs, and thus make lif e\neasier for the developer .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "operating systems developed. Like any system built by humans, good",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "operating",
          "systems",
          "developed",
          "like",
          "system",
          "built",
          "humans",
          "good"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ideas accumulated in operating systems over time, as engineer s learned",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ideas",
          "accumulated",
          "operating",
          "systems",
          "time",
          "engineer",
          "learned"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "what was important in their design. Here, we discuss a few major devel-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "important",
          "design",
          "discuss",
          "major",
          "devel"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "easier for the developer .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "easier",
          "developer"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand some history",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "history"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E M S 13\nUsually , on these old mainframe systems, one program ran at a time ,\nas controlled by a human operator . Much of what you think a modern\nOS would do (e.g., deciding what order to run jobs in) was performe d by\nthis operator . If you were a smart developer , you would be nice to thi s\noperator , so that they might move your job to the front of the queue.\nThis mode of computing was known as batch processing, as a number\nof jobs were set up and then run in a \u201cbatch\u201d by the operator . Compute rs,\nas of that point, were not used in an interactive manner , because of cost:\nit was simply too expensive to let a user sit in front of the compute r and\nuse it, as most of the time it would just sit idle then, costing the f acility\nhundreds of thousands of dollars per hour [BH00].\nBeyond Libraries: Protection\nIn moving beyond being a simple library of commonly-used services , op-\nerating systems took on a more central role in managing machines. O ne\nimportant aspect of this was the realization that code run on behal f of the\nOS was special; it had control of devices and thus should be treate d dif-\nferently than normal application code. Why is this? W ell, imagi ne if you\nallowed any application to read from anywhere on the disk; the noti on of\nprivacy goes out the window , as any program could read any \ufb01le. Thus ,\nimplementing a \ufb01le system (to manage your \ufb01les) as a library makes little\nsense. Instead, something else was needed.\nThus, the idea of a system call was invented, pioneered by the Atlas\ncomputing system [K+61,L78]. Instead of providing OS routines a s a li-\nbrary (where you just make a procedure call to access them), the idea here\nwas to add a special pair of hardware instructions and hardware state to\nmake the transition into the OS a more formal, controlled process.\nThe key difference between a system call and a procedure call i s that\na system call transfers control (i.e., jumps) into the OS while simultane-\nously raising the hardware privilege level . User applications run in what\nis referred to as user mode which means the hardware restricts what ap-\nplications can do; for example, an application running in user mod e can\u2019t\ntypically initiate an I/O request to the disk, access any phy sical memory\npage, or send a packet on the network. When a system call is initia ted\n(usually through a special hardware instruction called a trap), the hard-\nware transfers control to a pre-speci\ufb01ed trap handler (that the OS set up\npreviously) and simultaneously raises the privilege level to kernel mode .\nIn kernel mode, the OS has full access to the hardware of the syst em and\nthus can do things like initiate an I/O request or make more memor y\navailable to a program. When the OS is done servicing the reques t, it\npasses control back to the user via a special return-from-trap instruction,\nwhich reverts to user mode while simultaneously passing control back to\nwhere the application left off.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "this operator . If you were a smart developer , you would be nice to thi s",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "operator",
          "smart",
          "developer",
          "would",
          "nice"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "This mode of computing was known as batch processing, as a number",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mode",
          "computing",
          "known",
          "batch",
          "processing",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "important aspect of this was the realization that code run on behal f of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "aspect",
          "realization",
          "code",
          "behal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "implementing a \ufb01le system (to manage your \ufb01les) as a library makes little",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "system",
          "manage",
          "library",
          "makes",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "available to a program. When the OS is done servicing the reques t, it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "available",
          "program",
          "done",
          "servicing",
          "reques"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand because of cost: it was simply too expensive to let a user sit in front of the compute r and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "because of cost",
          "simply",
          "expensive",
          "user",
          "front",
          "compute"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 I N T R O D U C T I O N TO OP E R AT I N G SY S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nThe Era of Multiprogramming\nWhere operating systems really took off was in the era of computing b e-\nyond the mainframe, that of the minicomputer. Classic machines like\nthe PDP family from Digital Equipment made computers hugely mor e\naffordable; thus, instead of having one mainframe per large orga nization,\nnow a smaller collection of people within an organization could likel y\nhave their own computer . Not surprisingly , one of the major impacts of\nthis drop in cost was an increase in developer activity; more smar t people\ngot their hands on computers and thus made computer systems do more\ninteresting and beautiful things.\nIn particular , multiprogramming became commonplace due to the de-\nsire to make better use of machine resources. Instead of just run ning one\njob at a time, the OS would load a number of jobs into memory and switch\nrapidly between them, thus improving CPU utilization. This sw itching\nwas particularly important because I/O devices were slow; hav ing a pro-\ngram wait on the CPU while its I/O was being serviced was a waste of\nCPU time. Instead, why not switch to another job and run it for a whi le?\nThe desire to support multiprogramming and overlap in the prese nce\nof I/O and interrupts forced innovation in the conceptual developm ent of\noperating systems along a number of directions. Issues such as memory\nprotection became important; we wouldn\u2019t want one program to be able\nto access the memory of another program. Understanding how to deal\nwith the concurrency issues introduced by multiprogramming was also\ncritical; making sure the OS was behaving correctly despite t he presence\nof interrupts is a great challenge. W e will study these issues and related\ntopics later in the book.\nOne of the major practical advances of the time was the introducti on\nof the U N I X operating system, primarily thanks to Ken Thompson (and\nDennis Ritchie) at Bell Labs (yes, the phone company). U N I X took many\ngood ideas from different operating systems (particularly from M ultics\n[O72], and some from systems like TENEX [B+72] and the Berkeley Time-\nSharing System [S+68]), but made them simpler and easier to use. Soon\nthis team was shipping tapes containing U N I X source code to people\naround the world, many of whom then got involved and added to the\nsystem themselves; see the Aside (next page) for more detail 10 .\nThe Modern Era\nBeyond the minicomputer came a new type of machine, cheaper , fas ter ,\nand for the masses: the personal computer , or PC as we call it today . Led\nby Apple\u2019s early machines (e.g., the Apple II) and the IBM PC, t his new\nbreed of machine would soon become the dominant force in computing,\n10 W e\u2019ll use asides and other related text boxes to call attention to various items that don\u2019t\nquite \ufb01t the main \ufb02ow of the text. Sometimes, we\u2019ll even use them j ust to make a joke, because\nwhy not have a little fun along the way? Y es, many of the jokes are bad.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "this drop in cost was an increase in developer activity; more smar t people",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "drop",
          "cost",
          "increase",
          "developer",
          "activity",
          "smar",
          "people"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "was particularly important because I/O devices were slow; hav ing a pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "particularly",
          "important",
          "devices",
          "slow"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of I/O and interrupts forced innovation in the conceptual developm ent of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "interrupts",
          "forced",
          "innovation",
          "conceptual",
          "developm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "protection became important; we wouldn\u2019t want one program to be able",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "protection",
          "became",
          "important",
          "want",
          "program",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "to access the memory of another program. Understanding how to deal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "access",
          "memory",
          "another",
          "program",
          "understanding",
          "deal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "critical; making sure the OS was behaving correctly despite t he presence",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "making",
          "sure",
          "behaving",
          "correctly",
          "despite",
          "presence"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand and for the masses: the personal computer , or PC as we call it today . Led",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and for the masses",
          "personal",
          "computer",
          "call",
          "today"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E M S 15\nAS I D E : T H E IM P O RTA N C E O F UN I X\nIt is dif\ufb01cult to overstate the importance of U N I X in the history of oper-\nating systems. In\ufb02uenced by earlier systems (in particular , the famous\nMultics system from MIT), U N I X brought together many great ideas and\nmade a system that was both simple and powerful.\nUnderlying the original \u201cBell Labs\u201d U N I X was the unifying principle of\nbuilding small powerful programs that could be connected togethe r to\nform larger work\ufb02ows. The shell, where you type commands, provided\nprimitives such as pipes to enable such meta-level programming, and\nthus it became easy to string together programs to accomplish a b ig-\nger task. For example, to \ufb01nd lines of a text \ufb01le that have the word\n\u201cfoo\u201d in them, and then to count how many such lines exist, you would\ntype: grep foo file.txt|wc -l, thus using the grep and wc (word\ncount) programs to achieve your task.\nThe U N I X environment was friendly for programmers and developers\nalike, also providing a compiler for the new C programming language .\nMaking it easy for programmers to write their own programs, as wel l as\nshare them, made U N I X enormously popular . And it probably helped a\nlot that the authors gave out copies for free to anyone who asked, an e arly\nform of open-source software .\nAlso of critical importance was the accessibility and readabi lity of the\ncode. Having a beautiful, small kernel written in C invited oth ers to play\nwith the kernel, adding new and cool features. For example, an en ter-\nprising group at Berkeley , led by Bill Joy , made a wonderful distribution\n(the Berkeley Systems Distribution , or BSD) which had some advanced\nvirtual memory , \ufb01le system, and networking subsystems. Joy lat er co-\nfounded Sun Microsystems .\nUnfortunately , the spread of U N I X was slowed a bit as companies tried to\nassert ownership and pro\ufb01t from it, an unfortunate (but common) res ult\nof lawyers getting involved. Many companies had their own varian ts:\nSunOS from Sun Microsystems, AIX from IBM, HPUX (a.k.a. \u201cH-Pucks\u201d)\nfrom HP , and IRIX from SGI. The legal wrangling among A T&T/Bell\nLabs and these other players cast a dark cloud over U N I X, and many\nwondered if it would survive, especially as Windows was introduc ed and\ntook over much of the PC market...\nas their low-cost enabled one machine per desktop instead of a shar ed\nminicomputer per workgroup.\nUnfortunately , for operating systems, the PC at \ufb01rst represent ed a\ngreat leap backwards, as early systems forgot (or never knew of) t he\nlessons learned in the era of minicomputers. For example, early op erat-\ning systems such as DOS (the Disk Operating System , from Microsoft)\ndidn\u2019t think memory protection was important; thus, a malicious (or per-\nhaps just a poorly-programmed) application could scribble all ove r mem-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Underlying the original \u201cBell Labs\u201d U N I X was the unifying principle of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "underlying",
          "original",
          "bell",
          "labs",
          "unifying",
          "principle"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The U N I X environment was friendly for programmers and developers",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "environment",
          "friendly",
          "programmers",
          "developers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Also of critical importance was the accessibility and readabi lity of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "critical",
          "importance",
          "accessibility",
          "readabi",
          "lity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "lessons learned in the era of minicomputers. For example, early op erat-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lessons",
          "learned",
          "minicomputers",
          "example",
          "early",
          "erat"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "didn\u2019t think memory protection was important; thus, a malicious (or per-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "think",
          "memory",
          "protection",
          "important",
          "thus",
          "malicious"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand you would\ntype: grep foo file.txt|wc -l, thus using the grep and wc (word",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "you would\ntype",
          "grep",
          "file",
          "thus",
          "using",
          "grep",
          "word"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 I N T R O D U C T I O N TO OP E R AT I N G SY S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nAS I D E : A N D TH E N CA M E LI N U X\nFortunately for U N I X, a young Finnish hacker named Linus T orvalds de-\ncided to write his own version of U N I X which borrowed heavily on the\nprinciples and ideas behind the original system, but not from th e code\nbase, thus avoiding issues of legality . He enlisted help from ma ny others\naround the world, took advantage of the sophisticated GNU tools that\nalready existed [G85], and soon Linux was born (as well as the modern\nopen-source software movement).\nAs the internet era came into place, most companies (such as Googl e,\nAmazon, Facebook, and others) chose to run Linux, as it was free and\ncould be readily modi\ufb01ed to suit their needs; indeed, it is hard to imag-\nine the success of these new companies had such a system not exist ed.\nAs smart phones became a dominant user-facing platform, Linux f ound\na stronghold there too (via Android), for many of the same reasons. An d\nSteve Jobs took his U N I X-based NeXTStep operating environment with\nhim to Apple, thus making U N I X popular on desktops (though many\nusers of Apple technology are probably not even aware of this fact). Thus\nUN I X lives on, more important today than ever before. The computing\ngods, if you believe in them, should be thanked for this wonderful ou t-\ncome.\nory . The \ufb01rst generations of the Mac OS (v9 and earlier) took a coopera-\ntive approach to job scheduling; thus, a thread that accidenta lly got stuck\nin an in\ufb01nite loop could take over the entire system, forcing a reboot . The\npainful list of OS features missing in this generation of system s is long,\ntoo long for a full discussion here.\nFortunately , after some years of suffering, the old features of mi ni-\ncomputer operating systems started to \ufb01nd their way onto the des ktop.\nFor example, Mac OS X/macOS has U N I X at its core, including all of the\nfeatures one would expect from such a mature system. Windows has s im-\nilarly adopted many of the great ideas in computing history , star ting in\nparticular with Windows NT , a great leap forward in Microsoft OS t ech-\nnology . Even today\u2019s cell phones run operating systems (such as Lin ux)\nthat are much more like what a minicomputer ran in the 1970s than what\na PC ran in the 1980s (thank goodness); it is good to see that the good\nideas developed in the heyday of OS development have found their w ay\ninto the modern world. Even better is that these ideas continue t o de-\nvelop, providing more features and making modern systems even be tter\nfor users and applications.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "principles and ideas behind the original system, but not from th e code",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "principles",
          "ideas",
          "behind",
          "original",
          "system",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "UN I X lives on, more important today than ever before. The computing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lives",
          "important",
          "today",
          "ever",
          "computing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "tive approach to job scheduling; thus, a thread that accidenta lly got stuck",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tive",
          "approach",
          "scheduling",
          "thus",
          "thread",
          "accidenta",
          "stuck"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ideas developed in the heyday of OS development have found their w ay",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ideas",
          "developed",
          "heyday",
          "development",
          "found"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "2.7 Summary\nThus, we have an introduction to the OS. T oday\u2019s operating systems\nmake systems relatively easy to use, and virtually all operat ing systems\nyou use today have been in\ufb02uenced by the developments we will dis cuss\nthroughout the book.\nUnfortunately , due to time constraints, there are a number of pa rts of\nthe OS we won\u2019t cover in the book. For example, there is a lot of net-\nworking code in the operating system; we leave it to you to take the net-\nworking class to learn more about that. Similarly , graphics devices are\nparticularly important; take the graphics course to expand you r knowl-\nedge in that direction. Finally , some operating system books talk a great\ndeal about security; we will do so in the sense that the OS must provide\nprotection between running programs and give users the ability to pro-\ntect their \ufb01les, but we won\u2019t delve into deeper security issues that one\nmight \ufb01nd in a security course.\nHowever , there are many important topics that we will cover , incl ud-\ning the basics of virtualization of the CPU and memory , concurrenc y , and\npersistence via devices and \ufb01le systems. Don\u2019t worry! While the re is a\nlot of ground to cover , most of it is quite cool, and at the end of the road,\nyou\u2019ll have a new appreciation for how computer systems really work.\nNow get to work!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "you use today have been in\ufb02uenced by the developments we will dis cuss",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "today",
          "developments",
          "cuss"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "working class to learn more about that. Similarly , graphics devices are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "working",
          "class",
          "learn",
          "similarly",
          "graphics",
          "devices"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "particularly important; take the graphics course to expand you r knowl-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "particularly",
          "important",
          "take",
          "graphics",
          "course",
          "expand",
          "knowl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "However , there are many important topics that we will cover , incl ud-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "many",
          "important",
          "topics",
          "cover",
          "incl"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "18 I N T R O D U C T I O N TO OP E R AT I N G SY S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "18 I N T R O D U C T I O N TO OP E R AT I N G SY S T E M S\nReferences\n[BS+09] \u201cT olerating File-System Mistakes with EnvyFS\u201d by L. Bair avasundaram, S. Sundarara-\nman, A. Arpaci-Dusseau, R. Arpaci-Dusseau. USENIX \u201909, San Diego , CA, June 2009. A fun\npaper about using multiple \ufb01le systems at once to tolerate a mistake in any one of the m.\n[BH00] \u201cThe Evolution of Operating Systems\u201d by P . Brinch Hansen. In \u2019Cl assic Operating\nSystems: From Batch Processing to Distributed Systems.\u2019 Springe r-V erlag, New Y ork, 2000.\nThis essay provides an intro to a wonderful collection of papers about histori cally signi\ufb01cant systems.\n[B+72] \u201cTENEX, A Paged Time Sharing System for the PDP-10\u201d by D. Bobrow , J. Burch\ufb01el, D.\nMurphy , R. T omlinson. CACM, V olume 15, Number 3, March 1972. TENEX has much of the\nmachinery found in modern operating systems; read more about it to see how mu ch innovation was\nalready in place in the early 1970\u2019s.\n[B75] \u201cThe Mythical Man-Month\u201d by F . Brooks. Addison-W esley , 1975. A classic text on software\nengineering; well worth the read.\n[BOH10] \u201cComputer Systems: A Programmer \u2019s Perspective\u201d by R. Bry ant and D. O\u2019Hallaron.\nAddison-W esley , 2010. Another great intro to how computer systems work. Has a little bit of overlap\nwith this book \u2014 so if you\u2019d like, you can skip the last few chapters of that book, or sim ply read them to\nget a different perspective on some of the same material. After all, one good w ay to build up your own\nknowledge is to hear as many other perspectives as possible, and then develop your own opinion and\nthoughts on the matter . Y ou know, by thinking!\n[G85] \u201cThe GNU Manifesto\u201d by R. Stallman. 1985. www.gnu.org/gnu/manifesto.html.\nA huge part of Linux\u2019s success was no doubt the presence of an excellen t compiler , gcc, and other\nrelevant pieces of open software, thanks to the GNU effort headed by Stallman. S tallman is a visionary\nwhen it comes to open source, and this manifesto lays out his thoughts as to why.\n[K+61] \u201cOne-Level Storage System\u201d by T . Kilburn, D.B.G. Edwards, M.J. Lanigan, F .H. Sumner .\nIRE T ransactions on Electronic Computers, April 1962. The Atlas pioneered much of what you see\nin modern systems. However , this paper is not the best read. If you were to on ly read one, you might\ntry the historical perspective below [L78].\n[L78] \u201cThe Manchester Mark I and Atlas: A Historical Perspective\u201d by S. H. L avington. Com-\nmunications of the ACM, V olume 21:1, January 1978. A nice piece of history on the early devel-\nopment of computer systems and the pioneering efforts of the Atlas. Of course, one could go back and\nread the Atlas papers themselves, but this paper provides a great overvie w and adds some historical\nperspective.\n[O72] \u201cThe Multics System: An Examination of its Structure\u201d by Elliot t Organick. MIT Press,\n1972. A great overview of Multics. So many good ideas, and yet it was an over-design ed system,\nshooting for too much, and thus never really worked. A classic example of what F red Brooks would call\nthe \u201csecond-system effect\u201d [B75].\n[PP03] \u201cIntroduction to Computing Systems: From Bits and Gates to C a nd Beyond\u201d by Y ale\nN. Patt, Sanjay J. Patel. McGraw-Hill, 2003. One of our favorite intro to computing systems books.\nStarts at transistors and gets you all the way up to C; the early material is particularly great.\n[RT74] \u201cThe U N I X Time-Sharing System\u201d by Dennis M. Ritchie, Ken Thompson. CACM, V ol-\nume 17: 7, July 1974. A great summary of UN I X written as it was taking over the world of computing,\nby the people who wrote it.\n[S68] \u201cSDS 940 Time-Sharing System\u201d by Scienti\ufb01c Data Systems. TECH NICAL MANUAL,\nSDS 90 11168, August 1968. Y es, a technical manual was the best we could \ufb01nd. But it is fascinating\nto read these old system documents, and see how much was already in place in the late 1960\u2019s. One of\nthe minds behind the Berkeley Time-Sharing System (which eventually b ecame the SDS system) was\nButler Lampson, who later won a T uring award for his contributions in systems .\n[SS+10] \u201cMembrane: Operating System Support for Restartable File Systems\u201d by S. Sundarara-\nman, S. Subramanian, A. Rajimwale, A. Arpaci-Dusseau, R. Arpaci-Du sseau, M. Swift. F AST\n\u201910, San Jose, CA, February 2010. The great thing about writing your own class notes: you can ad-\nvertise your own research. But this paper is actually pretty neat \u2014 when a \ufb01l e system hits a bug and\ncrashes, Membrane auto-magically restarts it, all without applications or the rest of the system being\naffected.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "knowledge is to hear as many other perspectives as possible, and then develop your own opinion and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "knowledge",
          "hear",
          "many",
          "perspectives",
          "possible",
          "develop",
          "opinion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "thoughts on the matter . Y ou know, by thinking!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thoughts",
          "matter",
          "know",
          "thinking"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "A great overview of Multics. So many good ideas, and yet it was an over-design ed system,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "great",
          "overview",
          "multics",
          "many",
          "good",
          "ideas",
          "design",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Cl assic Operating\nSystems: From Batch Processing to Distributed Systems.\u2019 Springe r-V erlag, New Y ork, 2000.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cl assic operating\nsystems",
          "batch",
          "processing",
          "distributed",
          "systems",
          "springe",
          "erlag"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Computer Systems: A Programmer \u2019s Perspective\u201d by R. Bry ant and D. O\u2019Hallaron.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "computer systems",
          "programmer",
          "perspective",
          "hallaron"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 21: 1, January 1978. A nice piece of history on the early devel-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 21",
          "january",
          "nice",
          "piece",
          "history",
          "early",
          "devel"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand The Multics System: An Examination of its Structure\u201d by Elliot t Organick. MIT Press,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the multics system",
          "examination",
          "structure",
          "elliot",
          "organick",
          "press"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Introduction to Computing Systems: From Bits and Gates to C a nd Beyond\u201d by Y ale",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "introduction to computing systems",
          "bits",
          "gates",
          "beyond"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand ume 17: 7, July 1974. A great summary of UN I X written as it was taking over the world of computing,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ume 17",
          "july",
          "great",
          "summary",
          "written",
          "taking",
          "world",
          "computing"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Membrane: Operating System Support for Restartable File Systems\u201d by S. Sundarara-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "membrane",
          "operating",
          "system",
          "support",
          "restartable",
          "file",
          "systems",
          "sundarara"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T R O D U C T I O N TO OP E R AT I N G SY S T E M S 19\nHomework\nMost (and eventually , all) chapters of this book have homework sec-\ntions at the end. Doing these homeworks is important, as each lets y ou,\nthe reader , gain more experience with the concepts presented w ithin the\nchapter .\nThere are two types of homeworks. The \ufb01rst is based on simulation. A\nsimulation of a computer system is just a simple program that pret ends to\ndo some of the interesting parts of what a real system does, and the n re-\nport some output metrics to show how the system behaves. For example ,\na hard drive simulator might take a series of requests, simulat e how long\nthey would take to get serviced by a hard drive with certain per formance\ncharacteristics, and then report the average latency of the re quests.\nThe cool thing about simulations is they let you easily explore how\nsystems behave without the dif\ufb01culty of running a real system. Indeed,\nthey even let you create systems that cannot exist in the real wor ld (for\nexample, a hard drive with unimaginably fast performance), a nd thus see\nthe potential impact of future technologies.\nOf course, simulations are not without their downsides. By their v ery\nnature, simulations are just approximations of how a real system b ehaves.\nIf an important aspect of real-world behavior is omitted, the simu lation\nwill report bad results. Thus, results from a simulation should a lways be\ntreated with some suspicion. In the end, how a system behaves in t he real\nworld is what matters.\nThe second type of homework requires interaction with real-world\ncode. Some of these homeworks are measurement focused, whereas oth-\ners just require some small-scale development and experiment ation. Both\nare just small forays into the larger world you should be getting i nto,\nwhich is how to write systems code in C on U N I X-based systems. Indeed,\nlarger-scale projects, which go beyond these homeworks, are nee ded to\npush you in this direction; thus, beyond just doing homeworks, we st rongly\nrecommend you do projects to solidify your systems skills. See this page\n(https://github.com/remzi-arpacidusseau/ostep-projects)\nfor some projects.\nT o do these homeworks, you likely have to be on a U N I X-based ma-\nchine, running either Linux, macOS, or some similar system. It s hould\nalso have a C compiler installed (e.g., gcc) as well as Python. Y ou should\nalso know how to edit code in a real code editor of some kind.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tions at the end. Doing these homeworks is important, as each lets y ou,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tions",
          "homeworks",
          "important",
          "lets"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the reader , gain more experience with the concepts presented w ithin the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reader",
          "gain",
          "experience",
          "concepts",
          "presented",
          "ithin"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "they even let you create systems that cannot exist in the real wor ld (for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "even",
          "create",
          "systems",
          "cannot",
          "exist",
          "real"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "If an important aspect of real-world behavior is omitted, the simu lation",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "aspect",
          "real",
          "world",
          "behavior",
          "omitted",
          "simu",
          "lation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ers just require some small-scale development and experiment ation. Both",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "require",
          "small",
          "scale",
          "development",
          "experiment",
          "ation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "also know how to edit code in a real code editor of some kind.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "know",
          "edit",
          "code",
          "real",
          "code",
          "editor",
          "kind"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand https: //github.com/remzi-arpacidusseau/ostep-projects)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "https",
          "github",
          "remzi",
          "arpacidusseau",
          "ostep",
          "projects"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "Part I\nVirtualization\n1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "3\nA Dialogue on Virtualization\nProfessor: And thus we reach the \ufb01rst of our three pieces on operating system s:\nvirtualization.\nStudent: But what is virtualization, oh noble professor?\nProfessor: Imagine we have a peach.\nStudent: A peach? (incredulous)\nProfessor: Y es, a peach. Let us call that the physical peach. But we have many\neaters who would like to eat this peach. What we would like to present t o each\neater is their own peach, so that they can be happy. We call the pea ch we give\neaters virtual peaches; we somehow create many of these virtual peaches out o f\nthe one physical peach. And the important thing: in this illusion, it look s to each\neater like they have a physical peach, but in reality they don\u2019t.\nStudent: So you are sharing the peach, but you don\u2019t even know it?\nProfessor: Right! Exactly.\nStudent: But there\u2019s only one peach.\nProfessor: Y es. And...?\nStudent: Well, if I was sharing a peach with somebody else, I think I would\nnotice.\nProfessor: Ah yes! Good point. But that is the thing with many eaters; most\nof the time they are napping or doing something else, and thus, you c an snatch\nthat peach away and give it to someone else for a while. And thus we cre ate the\nillusion of many virtual peaches, one peach for each person!\nStudent: Sounds like a bad campaign slogan. Y ou are talking about computers,\nright Professor?\nProfessor: Ah, young grasshopper , you wish to have a more concrete example .\nGood idea! Let us take the most basic of resources, the CPU. Assu me there is one\nphysical CPU in a system (though now there are often two or four or m ore). What\nvirtualization does is take that single CPU and make it look like many virtu al\nCPUs to the applications running on the system. Thus, while each app lication\n3",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "eaters virtual peaches; we somehow create many of these virtual peaches out o f",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "eaters",
          "virtual",
          "peaches",
          "somehow",
          "create",
          "many",
          "virtual",
          "peaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the one physical peach. And the important thing: in this illusion, it look s to each",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "physical",
          "peach",
          "important",
          "thing",
          "illusion",
          "look"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Student: So you are sharing the peach, but you don\u2019t even know it?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sharing",
          "peach",
          "even",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: But what is virtualization, oh noble professor?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "virtualization",
          "noble",
          "professor"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: Imagine we have a peach.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "imagine",
          "peach"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: A peach? (incredulous)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "peach",
          "incredulous"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Y es, a peach. Let us call that the physical peach. But we have many",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "peach",
          "call",
          "physical",
          "peach",
          "many"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand And the important thing: in this illusion, it look s to each",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and the important thing",
          "illusion",
          "look"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Student: But there\u2019s only one peach.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "peach"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Student: Well, if I was sharing a peach with somebody else, I think I would",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "sharing",
          "peach",
          "somebody",
          "else",
          "think",
          "would"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand virtualization, oh noble professor",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtualization",
          "noble",
          "professor"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 A D I A L O G U E O NVI RT U A L I Z AT I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 A D I A L O G U E O NVI RT U A L I Z AT I O N\nthinks it has its own CPU to use, there is really only one. And thus the O S has\ncreated a beautiful illusion: it has virtualized the CPU.\nStudent: Wow! That sounds like magic. T ell me more! How does that work?\nProfessor: In time, young student, in good time. Sounds like you are ready to\nbegin.\nStudent: I am! Well, sort of. I must admit, I\u2019m a little worried you are going to\nstart talking about peaches again.\nProfessor: Don\u2019t worry too much; I don\u2019t even like peaches. And thus we be-\ngin...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "created a beautiful illusion: it has virtualized the CPU.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "beautiful",
          "illusion",
          "virtualized"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: Wow! That sounds like magic. T ell me more! How does that work?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "like",
          "magic",
          "work"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: In time, young student, in good time. Sounds like you are ready to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "time",
          "young",
          "student",
          "good",
          "time",
          "sounds",
          "like",
          "ready"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: I am! Well, sort of. I must admit, I\u2019m a little worried you are going to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "sort",
          "must",
          "admit",
          "little",
          "worried",
          "going"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Don\u2019t worry too much; I don\u2019t even like peaches. And thus we be-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "worry",
          "much",
          "even",
          "like",
          "peaches",
          "thus"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4\nThe Abstraction: The Process\nIn this chapter , we discuss one of the most fundamental abstract ions that\nthe OS provides to users: the process. The de\ufb01nition of a process, infor-\nmally , is quite simple: it is a running program [V+65,BH70]. The program\nitself is a lifeless thing: it just sits there on the disk, a bun ch of instructions\n(and maybe some static data), waiting to spring into action. It is the oper-\nating system that takes these bytes and gets them running, tr ansforming\nthe program into something useful.\nIt turns out that one often wants to run more than one program at\nonce; for example, consider your desktop or laptop where you might lik e\nto run a web browser , mail program, a game, a music player , and so forth.\nIn fact, a typical system may be seemingly running tens or even hundreds\nof processes at the same time. Doing so makes the system easy to us e, as\none never need be concerned with whether a CPU is available; one s imply\nruns programs. Hence our challenge:\nTH E CR U X O F T H E PR O B L E M :\nHO W TO PR O V I D E TH E IL L U S I O N OF MA N Y CPU S?\nAlthough there are only a few physical CPUs available, how can th e\nOS provide the illusion of a nearly-endless supply of said CPUs?\nThe OS creates this illusion by virtualizing the CPU. By running one\nprocess, then stopping it and running another , and so forth, the O S can\npromote the illusion that many virtual CPUs exist when in fact th ere is\nonly one physical CPU (or a few). This basic technique, known as time\nsharing of the CPU, allows users to run as many concurrent processes as\nthey would like; the potential cost is performance, as each will r un more\nslowly if the CPU(s) must be shared.\nT o implement virtualization of the CPU, and to implement it wel l, the\nOS will need both some low-level machinery and some high-level in -\ntelligence. W e call the low-level machinery mechanisms; mechanisms\nare low-level methods or protocols that implement a needed piece of\nfunctionality . For example, we\u2019ll learn later how to implement a context\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In this chapter , we discuss one of the most fundamental abstract ions that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "chapter",
          "discuss",
          "fundamental",
          "abstract",
          "ions"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The OS creates this illusion by virtualizing the CPU. By running one",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "illusion",
          "virtualizing",
          "running"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "only one physical CPU (or a few). This basic technique, known as time",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "physical",
          "basic",
          "technique",
          "known",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o implement virtualization of the CPU, and to implement it wel l, the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "virtualization",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "are low-level methods or protocols that implement a needed piece of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "level",
          "methods",
          "protocols",
          "implement",
          "needed",
          "piece"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "functionality . For example, we\u2019ll learn later how to implement a context",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "functionality",
          "example",
          "learn",
          "later",
          "implement",
          "context"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand is quite simple: it is a running program [V+65,BH70]. The program",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "is quite simple",
          "running",
          "program",
          "program"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Hence our challenge: TH E CR U X O F T H E PR O B L E M :",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hence our challenge"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "1 The Abstraction: A Process",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "4.1 The Abstraction: A Process\nThe abstraction provided by the OS of a running program is somethin g\nwe will call a process. As we said above, a process is simply a running\nprogram; at any instant in time, we can summarize a process by ta king an\ninventory of the different pieces of the system it accesses or aff ects during\nthe course of its execution.\nT o understand what constitutes a process, we thus have to under stand\nits machine state : what a program can read or update when it is running.\nAt any given time, what parts of the machine are important to the execu-\ntion of this program?\nOne obvious component of machine state that comprises a process is\nits memory. Instructions lie in memory; the data that the running pro-\ngram reads and writes sits in memory as well. Thus the memory tha t the\nprocess can address (called its address space ) is part of the process.\nAlso part of the process\u2019s machine state are registers; many instructions\nexplicitly read or update registers and thus clearly they are important to\nthe execution of the process.\nNote that there are some particularly special registers that f orm part\nof this machine state. For example, the program counter (PC) (sometimes\ncalled the instruction pointer or IP) tells us which instruction of the pro-\ngram will execute next; similarly a stack pointer and associated frame\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand what constitutes a process, we thus have to under stand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "constitutes",
          "process",
          "thus",
          "stand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "At any given time, what parts of the machine are important to the execu-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "given",
          "time",
          "parts",
          "machine",
          "important",
          "execu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "explicitly read or update registers and thus clearly they are important to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "explicitly",
          "read",
          "update",
          "registers",
          "thus",
          "clearly",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the abstraction: a process",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "abstraction",
          "process"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "2 Process API",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "4.2 Process API\nThough we defer discussion of a real process API until a subsequen t\nchapter , here we \ufb01rst give some idea of what must be included in a ny\ninterface of an operating system. These APIs, in some form, are av ailable\non any modern operating system.\n\u2022 Create: An operating system must include some method to cre-\nate new processes. When you type a command into the shell, or\ndouble-click on an application icon, the OS is invoked to create a\nnew process to run the program you have indicated.\n\u2022 Destroy: As there is an interface for process creation, systems also\nprovide an interface to destroy processes forcefully . Of course, many\nprocesses will run and just exit by themselves when complete; w hen\nthey don\u2019t, however , the user may wish to kill them, and thus an in -\nterface to halt a runaway process is quite useful.\n\u2022 W ait: Sometimes it is useful to wait for a process to stop running;\nthus some kind of waiting interface is often provided.\n\u2022 Miscellaneous Control: Other than killing or waiting for a process,\nthere are sometimes other controls that are possible. For example,\nmost operating systems provide some kind of method to suspend a\nprocess (stop it from running for a while) and then resume it (con-\ntinue it running).\n\u2022 Status: There are usually interfaces to get some status information\nabout a process as well, such as how long it has run for , or what\nstate it is in.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Create: An operating system must include some method to cre-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "operating",
          "system",
          "must",
          "include",
          "method"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "double-click on an application icon, the OS is invoked to create a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "double",
          "click",
          "application",
          "icon",
          "invoked",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "most operating systems provide some kind of method to suspend a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "systems",
          "provide",
          "kind",
          "method",
          "suspend"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Destroy: As there is an interface for process creation, systems also",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "destroy",
          "interface",
          "process",
          "creation",
          "systems",
          "also"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand W ait: Sometimes it is useful to wait for a process to stop running;",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "w ait",
          "sometimes",
          "useful",
          "wait",
          "process",
          "stop",
          "running"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Miscellaneous Control: Other than killing or waiting for a process,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "miscellaneous control",
          "killing",
          "waiting",
          "process"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Status: There are usually interfaces to get some status information",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "status",
          "usually",
          "interfaces",
          "status",
          "information"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand process api",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "3 Process Creation: A Little More Detail",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "4.3 Process Creation: A Little More Detail\nOne mystery that we should unmask a bit is how programs are trans-\nformed into processes. Speci\ufb01cally , how does the OS get a program up\nand running? How does process creation actually work?\nThe \ufb01rst thing that the OS must do to run a program is to load its code\nand any static data (e.g., initialized variables) into memor y , into the ad-\ndress space of the process. Programs initially reside on disk (or , in some\nmodern systems, \ufb02ash-based SSDs ) in some kind of executable format ;\nthus, the process of loading a program and static data into memory r e-\nquires the OS to read those bytes from disk and place them in memor y\nsomewhere (as shown in Figure 4.1).\nIn early (or simple) operating systems, the loading process is don e ea-\ngerly, i.e., all at once before running the program; modern OSes perform\nthe process lazily, i.e., by loading pieces of code or data only as they are\nneeded during program execution. T o truly understand how lazy l oading\nof pieces of code and data works, you\u2019ll have to understand more about\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "needed during program execution. T o truly understand how lazy l oading",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "needed",
          "program",
          "execution",
          "truly",
          "understand",
          "lazy",
          "oading"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of pieces of code and data works, you\u2019ll have to understand more about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pieces",
          "code",
          "data",
          "works",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand process creation: a little more detail",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "creation",
          "little",
          "detail"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the OS get a program up\nand running",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "running"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand process creation actually work",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "creation",
          "actually",
          "work"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "4 Process States",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "4.4 Process States\nNow that we have some idea of what a process is (though we will\ncontinue to re\ufb01ne this notion), and (roughly) how it is created, le t us talk\nabout the different states a process can be in at a given time. The notion\nthat a process can be in one of these states arose in early computer s ystems\n[DV66,V+65]. In a simpli\ufb01ed view , a process can be in one of three states:\n\u2022 Running: In the running state, a process is running on a processor .\nThis means it is executing instructions.\n\u2022 Ready: In the ready state, a process is ready to run but for some\nreason the OS has chosen not to run it at this given moment.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "continue to re\ufb01ne this notion), and (roughly) how it is created, le t us talk",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "continue",
          "notion",
          "roughly",
          "created",
          "talk"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand This: it is executing instructions.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this",
          "executing",
          "instructions"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Ready: In the ready state, a process is ready to run but for some",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ready",
          "ready",
          "state",
          "process",
          "ready"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand process states",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "states"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand running: in the running state, a process is running on a processor .",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "running",
          "running",
          "state",
          "process",
          "running",
          "processor"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 T H E AB S T R A C T I O N : T H E PR O C E S S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 T H E AB S T R A C T I O N : T H E PR O C E S S\nRunning Ready\nBlocked\nDescheduled\nScheduled\nI/O: initiate I/O: done\nFigure 4.2: Process: State T ransitions\n\u2022 Blocked: In the blocked state, a process has performed some kind\nof operation that makes it not ready to run until some other event\ntakes place. A common example: when a process initiates an I/O\nrequest to a disk, it becomes blocked and thus some other process\ncan use the processor .\nIf we were to map these states to a graph, we would arrive at the d i-\nagram in Figure 4.2. As you can see in the diagram, a process can b e\nmoved between the ready and running states at the discretion of t he OS.\nBeing moved from ready to running means the process has been sched-\nuled; being moved from running to ready means the process has been\ndescheduled. Once a process has become blocked (e.g., by initiating an\nI/O operation), the OS will keep it as such until some event occurs (e.g.,\nI/O completion); at that point, the process moves to the ready stat e again\n(and potentially immediately to running again, if the OS so de cides).\nLet\u2019s look at an example of how two processes might transition through\nsome of these states. First, imagine two processes running, eac h of which\nonly use the CPU (they do no I/O). In this case, a trace of the stat e of each\nprocess might look like this (Figure 4.3).\nTime Process 0 Process1 Notes\n1 Running Ready\n2 Running Ready\n3 Running Ready\n4 Running Ready Process 0 now done\n5 \u2013 Running\n6 \u2013 Running\n7 \u2013 Running\n8 \u2013 Running Process 1 now done\nFigure 4.3: T racing Process State: CPU Only\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_5",
        "text": "understand 2: Process: State T ransitions",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "process",
          "state",
          "ransitions"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Blocked: In the blocked state, a process has performed some kind",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "blocked",
          "blocked",
          "state",
          "process",
          "performed",
          "kind"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand A common example: when a process initiates an I/O",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a common example",
          "process",
          "initiates"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 3: T racing Process State: CPU Only",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "racing",
          "process",
          "state"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "5 Data Structures",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "4.5 Data Structures\nThe OS is a program, and like any program, it has some key data stru c-\ntures that track various relevant pieces of information. T o trac k the state\nof each process, for example, the OS likely will keep some kind of pro-\ncess list for all processes that are ready and some additional informa-\ntion to track which process is currently running. The OS must al so track,\nin some way , blocked processes; when an I/O event completes, the O S\nshould make sure to wake the correct process and ready it to run ag ain.\nFigure 4.5 shows what type of information an OS needs to track about\neach process in the xv6 kernel [CK+08]. Similar process structu res exist\nin \u201creal\u201d operating systems such as Linux, Mac OS X, or Windows; l ook\nthem up and see how much more complex they are.\nFrom the \ufb01gure, you can see a couple of important pieces of informa-\ntion the OS tracks about a process. The register context will hold, for a\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "From the \ufb01gure, you can see a couple of important pieces of informa-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "couple",
          "important",
          "pieces",
          "informa"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand data structures",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "data",
          "structures"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 T H E AB S T R A C T I O N : T H E PR O C E S S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 T H E AB S T R A C T I O N : T H E PR O C E S S\n// the registers xv6 will save and restore\n// to stop and subsequently restart a process\nstruct context {\nint eip;\nint esp;\nint ebx;\nint ecx;\nint edx;\nint esi;\nint edi;\nint ebp;\n};\n// the different states a process can be in\nenum proc_state { UNUSED, EMBRYO, SLEEPING,\nRUNNABLE, RUNNING, ZOMBIE };\n// the information xv6 tracks about each process\n// including its register context and state\nstruct proc {\nchar *mem; // Start of process memory\nuint sz; // Size of process memory\nchar *kstack; // Bottom of kernel stack\n// for this process\nenum proc_state state; // Process state\nint pid; // Process ID\nstruct proc *parent; // Parent process\nvoid *chan; // If !zero, sleeping on chan\nint killed; // If !zero, has been killed\nstruct file *ofile[NOFILE]; // Open files\nstruct inode *cwd; // Current directory\nstruct context context; // Switch here to run process\nstruct trapframe *tf; // Trap frame for the\n// current interrupt\n};\nFigure 4.5: The xv6 Proc Structure\nstopped process, the contents of its registers. When a process is s topped,\nits registers will be saved to this memory location; by restoring these reg-\nisters (i.e., placing their values back into the actual phys ical registers), the\nOS can resume running the process. W e\u2019ll learn more about this tec hnique\nknown as a context switch in future chapters.\nY ou can also see from the \ufb01gure that there are some other states a pr o-\ncess can be in, beyond running, ready , and blocked. Sometimes a sy stem\nwill have an initial state that the process is in when it is being created.\nAlso, a process could be placed in a \ufb01nal state where it has exited but\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "OS can resume running the process. W e\u2019ll learn more about this tec hnique",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "resume",
          "running",
          "process",
          "learn",
          "hnique"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "known as a context switch in future chapters.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "context",
          "switch",
          "future",
          "chapters"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "will have an initial state that the process is in when it is being created.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "initial",
          "state",
          "process",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 5: The xv6 Proc Structure",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "proc",
          "structure"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "4.6 Summary\nW e have introduced the most basic abstraction of the OS: the process .\nIt is quite simply viewed as a running program. With this concep tual\nview in mind, we will now move on to the nitty-gritty: the low-leve l\nmechanisms needed to implement processes, and the higher-le vel poli-\ncies required to schedule them in an intelligent way . By combi ning mech-\nanisms and policies, we will build up our understanding of how an op er-\nating system virtualizes the CPU.\n1 Y es, the zombie state. Just like real zombies, these zombies are relatively easy to kill.\nHowever , different techniques are usually recommended.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "mechanisms needed to implement processes, and the higher-le vel poli-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "mechanisms",
          "needed",
          "implement",
          "processes",
          "higher",
          "poli"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "anisms and policies, we will build up our understanding of how an op er-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "anisms",
          "policies",
          "build",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "However , different techniques are usually recommended.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "different",
          "techniques",
          "usually",
          "recommended"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 T H E AB S T R A C T I O N : T H E PR O C E S S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 T H E AB S T R A C T I O N : T H E PR O C E S S\nAS I D E : K E Y PR O C E S S TE R M S\n\u2022 The process is the major OS abstraction of a running program. At\nany point in time, the process can be described by its state: the con-\ntents of memory in its address space , the contents of CPU registers\n(including the program counter and stack pointer , among others),\nand information about I/O (such as open \ufb01les which can be read or\nwritten).\n\u2022 The process API consists of calls programs can make related to pro-\ncesses. T ypically , this includes creation, destruction, and other use-\nful calls.\n\u2022 Processes exist in one of many different process states , including\nrunning, ready to run, and blocked. Different events (e.g., g etting\nscheduled or descheduled, or waiting for an I/O to complete) tran -\nsition a process from one of these states to the other .\n\u2022 A process list contains information about all processes in the sys-\ntem. Each entry is found in what is sometimes called a process\ncontrol block (PCB), which is really just a structure that contains\ninformation about a speci\ufb01c process.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "any point in time, the process can be described by its state: the con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "point",
          "time",
          "process",
          "described",
          "state"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: K E Y PR O C E S S TE R M S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the process is the major os abstraction of a running program. at",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "major",
          "abstraction",
          "running",
          "program"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand the process api consists of calls programs can make related to pro-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "consists",
          "calls",
          "programs",
          "make",
          "related"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand processes exist in one of many different process states , including",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "processes",
          "exist",
          "many",
          "different",
          "process",
          "states",
          "including"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand a process list contains information about all processes in the sys-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "list",
          "contains",
          "information",
          "processes"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "TH E AB S T R A C T I O N : T H E PR O C E S S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "TH E AB S T R A C T I O N : T H E PR O C E S S 11\nReferences\n[BH70] \u201cThe Nucleus of a Multiprogramming System\u201d by Per Brinch Hansen. C ommunica-\ntions of the ACM, V olume 13:4, April 1970. This paper introduces one of the \ufb01rst microkernels in\noperating systems history, called Nucleus. The idea of smaller , more mi nimal systems is a theme that\nrears its head repeatedly in OS history; it all began with Brinch Hansen\u2019s work described herein.\n[CK+08] \u201cThe xv6 Operating System\u201d by Russ Cox, Frans Kaashoek, Robe rt Morris, Nickolai\nZeldovich. From: https://github.com/mit-pdos/xv6-public. The coolest real and little OS in the\nworld. Download and play with it to learn more about the details of how operating syste ms actually\nwork. We have been using an older version (2012-01-30-1-g1c41342) and hen ce some examples in the\nbook may not match the latest in the source.\n[DV66] \u201cProgramming Semantics for Multiprogrammed Computations\u201d b y Jack B. Dennis,\nEarl C. V an Horn. Communications of the ACM, V olume 9, Number 3, March 1 966 . This paper\nde\ufb01ned many of the early terms and concepts around building multiprogramme d systems.\n[L+75] \u201cPolicy/mechanism separation in Hydra\u201d by R. Levin, E. Cohen, W . Corwin, F . Pollack,\nW . Wulf. SOSP \u201975, Austin, T exas, November 1975. An early paper about how to structure operat-\ning systems in a research OS known as Hydra. While Hydra never became a mainstream OS, some of\nits ideas in\ufb02uenced OS designers.\n[V+65] \u201cStructure of the Multics Supervisor \u201d by V .A. V yssotsky , F . J. Corbato, R. M. Graham.\nFall Joint Computer Conference, 1965. An early paper on Multics, which described many of the basic\nideas and terms that we \ufb01nd in modern systems. Some of the vision behind comp uting as a utility are\n\ufb01nally being realized in modern cloud systems.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "rears its head repeatedly in OS history; it all began with Brinch Hansen\u2019s work described herein.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rears",
          "head",
          "repeatedly",
          "history",
          "began",
          "brinch",
          "hansen",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "world. Download and play with it to learn more about the details of how operating syste ms actually",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "world",
          "download",
          "play",
          "learn",
          "details",
          "operating",
          "syste",
          "actually"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "de\ufb01ned many of the early terms and concepts around building multiprogramme d systems.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "early",
          "terms",
          "concepts",
          "around",
          "building",
          "multiprogramme",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ing systems in a research OS known as Hydra. While Hydra never became a mainstream OS, some of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "systems",
          "research",
          "known",
          "hydra",
          "hydra",
          "never",
          "became",
          "mainstream"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "its ideas in\ufb02uenced OS designers.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ideas",
          "designers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Fall Joint Computer Conference, 1965. An early paper on Multics, which described many of the basic",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fall",
          "joint",
          "computer",
          "conference",
          "early",
          "paper",
          "multics",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand V olume 13: 4, April 1970. This paper introduces one of the \ufb01rst microkernels in",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 13",
          "april",
          "paper",
          "introduces",
          "microkernels"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand From: https://github.com/mit-pdos/xv6-public. The coolest real and little OS in the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "from",
          "https",
          "github",
          "pdos",
          "public",
          "coolest",
          "real",
          "little"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "Now , run the same processes, but with the switching behavior s et",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "5. Now , run the same processes, but with the switching behavior s et\nto switch to another process whenever one is W AITING for I/O ( -l\n1:0,4:100 -c -S SWITCH ON IO). What happens now? Use -c\nand -p to con\ufb01rm that you are right.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand l\n1: 0,4:100 -c -S SWITCH ON IO). What happens now? Use -c",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l\n1",
          "switch",
          "happens"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "6",
    "title": "One other important behavior is what to do when an I/O com-",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "6. One other important behavior is what to do when an I/O com-\npletes. With -I IO RUN LATER, when an I/O completes, the pro-\ncess that issued it is not necessarily run right away; rather , whatever\nwas running at the time keeps running. What happens when you\nrun this combination of processes? (Run ./process-run.py -l\n3:0,5:100,5:100,5:100 -S SWITCH\nON IO -I IO RUN LATER\n-c -p) Are system resources being effectively utilized?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One other important behavior is what to do when an I/O com-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "behavior"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand l\n3: 0,5:100,5:100,5:100 -S SWITCH",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l\n3",
          "switch"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand c -p) are system resources being effectively utilized?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "resources",
          "effectively",
          "utilized"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "7",
    "title": "Now run the same processes, but with -I IO RUN IMMEDIATE set,",
    "document_source": "book.pdf",
    "start_line": 41,
    "type": "chapter",
    "content": "7. Now run the same processes, but with -I IO RUN IMMEDIATE set,\nwhich immediately runs the process that issued the I/O. How does\nthis behavior differ? Why might running a process that just com-\npleted an I/O again be a good idea?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand this behavior differ",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "behavior",
          "differ"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "Now run with some randomly generated processes: -s 1 -l 3:50,3:50",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "8. Now run with some randomly generated processes: -s 1 -l 3:50,3:50\nor -s 2 -l 3:50,3:50 or -s 3 -l 3:50,3:50. See if you can\npredict how the trace will turn out. What happens when you use\nthe \ufb02ag -I IO\nRUN IMMEDIATE vs. -I IO RUN LATER? What hap-\npens when you use -S SWITCH ON IO vs. -S SWITCH ON END?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand l 3: 50,3:50 or -s 3 -l 3:50,3:50. See if you can",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l 3"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "1 The fork() System Call",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "5.1 The fork() System Call\nThe fork() system call is used to create a new process [C63]. How-\never , be forewarned: it is certainly the strangest routine you w ill ever\ncall1 . More speci\ufb01cally , you have a running program whose code looks\nlike what you see in Figure 5.1; examine the code, or better yet, t ype it in\nand run it yourself!\n1 W ell, OK, we admit that we don\u2019t know that for sure; who knows what routine s you\ncall when no one is looking? But fork() is pretty odd, no matter how unusual your routine-\ncalling patterns are.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The fork() system call is used to create a new process [C63]. How-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fork",
          "system",
          "call",
          "used",
          "create",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "W ell, OK, we admit that we don\u2019t know that for sure; who knows what routine s you",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "admit",
          "know",
          "sure",
          "knows",
          "routine"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand be forewarned: it is certainly the strangest routine you w ill ever",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "be forewarned",
          "certainly",
          "strangest",
          "routine",
          "ever"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the fork() system call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fork",
          "system",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 IN T E R L U D E : P R O C E S S API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 IN T E R L U D E : P R O C E S S API\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 #include <unistd.h>\n4\n5 int main(int argc, char *argv[]) {\n6 printf(\"hello world (pid:%d)\\n\", (int) getpid());\n7 int rc = fork();\n8 if (rc < 0) {\n9 // fork failed\n10 fprintf(stderr, \"fork failed\\n\");\n11 exit(1);\n12 } else if (rc == 0) {\n13 // child (new process)\n14 printf(\"hello, I am child (pid:%d)\\n\", (int) getpid());\n15 } else {\n16 // parent goes down this path (main)\n17 printf(\"hello, I am parent of %d (pid:%d)\\n\",\n18 rc, (int) getpid());\n19 }\n20 return 0;\n21 }\n22\nFigure 5.1: Calling fork() (p1.c)\nWhen you run this program (called p1.c), you\u2019ll see the following:\nprompt> ./p1\nhello world (pid:29146)\nhello, I am parent of 29147 (pid:29146)\nhello, I am child (pid:29147)\nprompt>\nLet us understand what happened in more detail in p1.c. When it\n\ufb01rst started running, the process prints out a hello world messa ge; in-\ncluded in that message is its process identi\ufb01er , also known as a PID. The\nprocess has a PID of 29146; in U N I X systems, the PID is used to name\nthe process if one wants to do something with the process, such as ( for\nexample) stop it from running. So far , so good.\nNow the interesting part begins. The process calls the fork() system\ncall, which the OS provides as a way to create a new process. The od d\npart: the process that is created is an (almost) exact copy of the calling pro-\ncess. That means that to the OS, it now looks like there are two copies of\nthe program p1 running, and both are about to return from the fork()\nsystem call. The newly-created process (called the child, in contrast to the\ncreating parent) doesn\u2019t start running at main(), like you might expect\n(note, the \u201chello, world\u201d message only got printed out once); rather , it\njust comes into life as if it had called fork() itself.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let us understand what happened in more detail in p1.c. When it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "happened",
          "detail"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "cluded in that message is its process identi\ufb01er , also known as a PID. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cluded",
          "message",
          "process",
          "also",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "call, which the OS provides as a way to create a new process. The od d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "provides",
          "create",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "part: the process that is created is an (almost) exact copy of the calling pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "part",
          "process",
          "created",
          "almost",
          "exact",
          "copy",
          "calling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "system call. The newly-created process (called the child, in contrast to the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "call",
          "newly",
          "created",
          "process",
          "called",
          "child",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand That: that to the OS, it now looks like there are two copies of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "that",
          "looks",
          "like",
          "copies"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand pid: %d)\\n\", (int) getpid());",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pid",
          "getpid"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 1: Calling fork() (p1.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "calling",
          "fork"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : P R O C E S S API 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : P R O C E S S API 3\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 #include <unistd.h>\n4 #include <sys/wait.h>\n5\n6 int main(int argc, char *argv[]) {\n7 printf(\"hello world (pid:%d)\\n\", (int) getpid());\n8 int rc = fork();\n9 if (rc < 0) { // fork failed; exit\n10 fprintf(stderr, \"fork failed\\n\");\n11 exit(1);\n12 } else if (rc == 0) { // child (new process)\n13 printf(\"hello, I am child (pid:%d)\\n\", (int) getpid());\n14 } else { // parent goes down this path (main)\n15 int rc_wait = wait(NULL);\n16 printf(\"hello, I am parent of %d (rc_wait:%d) (pid:%d)\\n\",\n17 rc, rc_wait, (int) getpid());\n18 }\n19 return 0;\n20 }\n21\nFigure 5.2: Calling fork() And wait() (p2.c)\nY ou might have noticed: the child isn\u2019t an exact copy . Speci\ufb01cally , al-\nthough it now has its own copy of the address space (i.e., its own priv ate\nmemory), its own registers, its own PC, and so forth, the value it r eturns\nto the caller of fork() is different. Speci\ufb01cally , while the parent receives\nthe PID of the newly-created child, the child receives a retur n code of\nzero. This differentiation is useful, because it is simple the n to write the\ncode that handles the two different cases (as above).\nY ou might also have noticed: the output (of p1.c) is not deterministic.\nWhen the child process is created, there are now two active proce sses in\nthe system that we care about: the parent and the child. Assumi ng we\nare running on a system with a single CPU (for simplicity), then either\nthe child or the parent might run at that point. In our example (ab ove),\nthe parent did and thus printed out its message \ufb01rst. In other ca ses, the\nopposite might happen, as we show in this output trace:\nprompt> ./p1\nhello world (pid:29146)\nhello, I am child (pid:29147)\nhello, I am parent of 29147 (pid:29146)\nprompt>\nThe CPU scheduler, a topic we\u2019ll discuss in great detail soon, deter-\nmines which process runs at a given moment in time; because the s ched-\nuler is complex, we cannot usually make strong assumptions about w hat\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the PID of the newly-created child, the child receives a retur n code of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "newly",
          "created",
          "child",
          "child",
          "receives",
          "retur",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "When the child process is created, there are now two active proce sses in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "child",
          "process",
          "created",
          "active",
          "proce",
          "sses"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand pid: %d)\\n\", (int) getpid());",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pid",
          "getpid"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 2: Calling fork() And wait() (p2.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "calling",
          "fork",
          "wait"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "2 The wait() System Call",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "5.2 The wait() System Call\nSo far , we haven\u2019t done much: just created a child that prints out a\nmessage and exits. Sometimes, as it turns out, it is quite useful for a\nparent to wait for a child process to \ufb01nish what it has been doing. This\ntask is accomplished with the wait() system call (or its more complete\nsibling waitpid()); see Figure 5.2 for details.\nIn this example ( p2.c), the parent process calls wait() to delay its\nexecution until the child \ufb01nishes executing. When the child i s done,\nwait() returns to the parent.\nAdding a wait() call to the code above makes the output determin-\nistic. Can you see why? Go ahead, think about it.\n(waiting for you to think .... and done)\nNow that you have thought a bit, here is the output:\nprompt> ./p2\nhello world (pid:29266)\nhello, I am child (pid:29267)\nhello, I am parent of 29267 (rc_wait:29267) (pid:29266)\nprompt>\nWith this code, we now know that the child will always print \ufb01rst.\nWhy do we know that? W ell, it might simply run \ufb01rst, as before, an d\nthus print before the parent. However , if the parent does happen to run\n\ufb01rst, it will immediately call wait(); this system call won\u2019t return until\nthe child has run and exited 2 . Thus, even when the parent runs \ufb01rst, it\npolitely waits for the child to \ufb01nish running, then wait() returns, and\nthen the parent prints its message.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "So far , we haven\u2019t done much: just created a child that prints out a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "done",
          "much",
          "created",
          "child",
          "prints"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "With this code, we now know that the child will always print \ufb01rst.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "know",
          "child",
          "always",
          "print"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Why do we know that? W ell, it might simply run \ufb01rst, as before, an d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "know",
          "might",
          "simply"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand t done much: just created a child that prints out a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t done much",
          "created",
          "child",
          "prints"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the wait() system call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "system",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "5",
    "title": "3 Finally , The exec() System Call",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "5.3 Finally , The exec() System Call\nA \ufb01nal and important piece of the process creation API is the exec()\nsystem call 3 . This system call is useful when you want to run a program\nthat is different from the calling program. For example, callin g fork()\n2 There are a few cases where wait() returns before the child exits; read the man page\nfor more details, as always. And beware of any absolute and unquali \ufb01ed statements this book\nmakes, such as \u201cthe child will always print \ufb01rst\u201d or \u201cU N I X is the best thing in the world, even\nbetter than ice cream.\u201d\n3 On Linux, there are six variants of exec(): execl(), execlp(), execle(),\nexecv(), execvp(), and execvpe(). Read the man pages to learn more.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A \ufb01nal and important piece of the process creation API is the exec()",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "piece",
          "process",
          "creation",
          "exec"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "execv(), execvp(), and execvpe(). Read the man pages to learn more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "execv",
          "execvp",
          "execvpe",
          "read",
          "pages",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand finally , the exec() system call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "exec",
          "system",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : P R O C E S S API 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : P R O C E S S API 5\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 #include <unistd.h>\n4 #include <string.h>\n5 #include <sys/wait.h>\n6\n7 int main(int argc, char *argv[]) {\n8 printf(\"hello world (pid:%d)\\n\", (int) getpid());\n9 int rc = fork();\n10 if (rc < 0) { // fork failed; exit\n11 fprintf(stderr, \"fork failed\\n\");\n12 exit(1);\n13 } else if (rc == 0) { // child (new process)\n14 printf(\"hello, I am child (pid:%d)\\n\", (int) getpid());\n15 char *myargs[3];\n16 myargs[0] = strdup(\"wc\"); // program: \"wc\" (word count)\n17 myargs[1] = strdup(\"p3.c\"); // argument: file to count\n18 myargs[2] = NULL; // marks end of array\n19 execvp(myargs[0], myargs); // runs word count\n20 printf(\"this shouldn\u2019t print out\");\n21 } else { // parent goes down this path (main)\n22 int rc_wait = wait(NULL);\n23 printf(\"hello, I am parent of %d (rc_wait:%d) (pid:%d)\\n\",\n24 rc, rc_wait, (int) getpid());\n25 }\n26 return 0;\n27 }\n28\nFigure 5.3: Calling fork(), wait(), And exec() (p3.c)\nin p2.c is only useful if you want to keep running copies of the same\nprogram. However , often you want to run a different program; exec()\ndoes just that (Figure 5.3).\nIn this example, the child process calls execvp() in order to run the\nprogram wc, which is the word counting program. In fact, it runs wc on\nthe source \ufb01le p3.c, thus telling us how many lines, words, and bytes are\nfound in the \ufb01le:\nprompt> ./p3\nhello world (pid:29383)\nhello, I am child (pid:29384)\n29 107 1030 p3.c\nhello, I am parent of 29384 (rc_wait:29384) (pid:29383)\nprompt>\nThe fork() system call is strange; its partner in crime, exec(), is not\nso normal either . What it does: given the name of an executable (e .g., wc),\nand some arguments (e.g., p3.c), it loads code (and static data) from that\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand pid: %d)\\n\", (int) getpid());",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pid",
          "getpid"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 3: Calling fork(), wait(), And exec() (p3.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "calling",
          "fork",
          "wait",
          "exec"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand What it does: given the name of an executable (e .g., wc),",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "what it does",
          "given",
          "name",
          "executable"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "4 Why? Motivating The API",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "5.4 Why? Motivating The API\nOf course, one big question you might have: why would we build\nsuch an odd interface to what should be the simple act of creating a new\nprocess? W ell, as it turns out, the separation of fork() and exec() is\nessential in building a U N I X shell, because it lets the shell run code after\nthe call to fork() but before the call to exec(); this code can alter the\nenvironment of the about-to-be-run program, and thus enables a va riety\nof interesting features to be readily built.\nThe shell is just a user program 4 . It shows you a prompt and then\nwaits for you to type something into it. Y ou then type a command (i.e .,\nthe name of an executable program, plus any arguments) into it; in most\ncases, the shell then \ufb01gures out where in the \ufb01le system the exe cutable\nresides, calls fork() to create a new child process to run the command,\ncalls some variant of exec() to run the command, and then waits for the\ncommand to complete by calling wait(). When the child completes, the\nshell returns from wait() and prints out a prompt again, ready for your\nnext command.\nThe separation of fork() and exec() allows the shell to do a whole\nbunch of useful things rather easily . For example:\nprompt> wc p3.c > newfile.txt\n4 And there are lots of shells; tcsh, bash, and zsh to name a few . Y ou should pick one,\nread its man pages, and learn more about it; all U N I X experts do.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "essential in building a U N I X shell, because it lets the shell run code after",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "essential",
          "building",
          "shell",
          "lets",
          "shell",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "resides, calls fork() to create a new child process to run the command,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "resides",
          "calls",
          "fork",
          "create",
          "child",
          "process",
          "command"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "read its man pages, and learn more about it; all U N I X experts do.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "pages",
          "learn",
          "experts"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand For example: prompt> wc p3.c > newfile.txt",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "for example",
          "prompt",
          "newfile"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand why? motivating the api",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "motivating"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : P R O C E S S API 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : P R O C E S S API 7\nIn the example above, the output of the program wc is redirected into\nthe output \ufb01le newfile.txt (the greater-than sign is how said redirec-\ntion is indicated). The way the shell accomplishes this task is quite sim-\nple: when the child is created, before calling exec(), the shell closes\nstandard output and opens the \ufb01le newfile.txt. By doing so, any out-\nput from the soon-to-be-running program wc are sent to the \ufb01le instead\nof the screen.\nFigure 5.4 (page 8) shows a program that does exactly this. The re ason\nthis redirection works is due to an assumption about how the operati ng\nsystem manages \ufb01le descriptors. Speci\ufb01cally , U N I X systems start looking\nfor free \ufb01le descriptors at zero. In this case, STDOUT FILENO will be the\n\ufb01rst available one and thus get assigned when open() is called. Subse-\nquent writes by the child process to the standard output \ufb01le des criptor ,\nfor example by routines such as printf(), will then be routed transpar-\nently to the newly-opened \ufb01le instead of the screen.\nHere is the output of running the p4.c program:\nprompt> ./p4\nprompt> cat p4.output\n32 109 846 p4.c\nprompt>\nY ou\u2019ll notice (at least) two interesting tidbits about this outpu t. First,\nwhen p4 is run, it looks as if nothing has happened; the shell just prints\nthe command prompt and is immediately ready for your next command.\nHowever , that is not the case; the program p4 did indeed call fork() to\ncreate a new child, and then run the wc program via a call to execvp().\nY ou don\u2019t see any output printed to the screen because it has been r edi-\nrected to the \ufb01le p4.output. Second, you can see that when we cat the\noutput \ufb01le, all the expected output from running wc is found. Cool, right?\nUN I X pipes are implemented in a similar way , but with the pipe()\nsystem call. In this case, the output of one process is connected to an in-\nkernel pipe (i.e., queue), and the input of another process is connected\nto that same pipe; thus, the output of one process seamlessly is us ed as\ninput to the next, and long and useful chains of commands can be st rung\ntogether . As a simple example, consider looking for a word in a \ufb01le, a nd\nthen counting how many times said word occurs; with pipes and the u til-\nities grep and wc, it is easy; just type grep -o foo file | wc -l\ninto the command prompt and marvel at the result.\nFinally , while we just have sketched out the process API at a hig h level,\nthere is a lot more detail about these calls out there to be learned and\ndigested; we\u2019ll learn more, for example, about \ufb01le descriptors wh en we\ntalk about \ufb01le systems in the third part of the book. For now , suf\ufb01ce i t\nto say that the fork()/exec() combination is a powerful way to create\nand manipulate processes.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ple: when the child is created, before calling exec(), the shell closes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "child",
          "created",
          "calling",
          "exec",
          "shell",
          "closes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "create a new child, and then run the wc program via a call to execvp().",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "child",
          "program",
          "call",
          "execvp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "UN I X pipes are implemented in a similar way , but with the pipe()",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "pipes",
          "implemented",
          "similar",
          "pipe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "there is a lot more detail about these calls out there to be learned and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "detail",
          "calls",
          "learned"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "digested; we\u2019ll learn more, for example, about \ufb01le descriptors wh en we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "digested",
          "learn",
          "example",
          "descriptors"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "to say that the fork()/exec() combination is a powerful way to create",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fork",
          "exec",
          "combination",
          "powerful",
          "create"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "5 Process Control And Users",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "5.5 Process Control And Users\nBeyond fork(), exec(), and wait(), there are a lot of other inter-\nfaces for interacting with processes in U N I X systems. For example, the\nkill() system call is used to send signals to a process, including di-\nrectives to pause, die, and other useful imperatives. For conve nience,\nin most U N I X shells, certain keystroke combinations are con\ufb01gured to\ndeliver a speci\ufb01c signal to the currently running process; for example,\ncontrol-c sends a SIGINT (interrupt) to the process (normally terminating\nit) and control-z sends a SIGTSTP (stop) signal thus pausing the process\nin mid-execution (you can resume it later with a command, e.g., t he fg\nbuilt-in command found in many shells).\nThe entire signals subsystem provides a rich infrastructure to deliver\nexternal events to processes, including ways to receive and p rocess those\nsignals within individual processes, and ways to send signal s to individ-\nual processes as well as entire process groups . T o use this form of com-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand process control and users",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "control",
          "users"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "6 Useful T ools",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "5.6 Useful T ools\nThere are many command-line tools that are useful as well. For exa m-\nple, using the ps command allows you to see which processes are run-\nning; read the man pages for some useful \ufb02ags to pass to ps. The tool top\nis also quite helpful, as it displays the processes of the syste m and how\nmuch CPU and other resources they are eating up. Humorously , many\ntimes when you run it, top claims it is the top resource hog; perhaps it is\na bit of an egomaniac. The command kill can be used to send arbitrary\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand useful t ools",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "useful",
          "ools"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "5",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "5.7 Summary\nW e have introduced some of the APIs dealing with U N I X process cre-\nation: fork(), exec(), and wait(). However , we have just skimmed\nthe surface. For more detail, read Stevens and Rago [SR05], of cours e,\nparticularly the chapters on Process Control, Process Relationsh ips, and\nSignals; there is much to extract from the wisdom therein.\nWhile our passion for the U N I X process API remains strong, we should\nalso note that such positivity is not uniform. For example, a recen t pa-\nper by systems researchers from Microsoft, Boston University , an d ETH\nin Switzerland details some problems with fork(), and advocates for\nother , simpler process creation APIs such as spawn() [B+19]. Read it,\nand the related work it refers to, to understand this different vantage\npoint. While it\u2019s generally good to trust this book, remember too tha t\nthe authors have opinions; those opinions may not (always) be as wide ly\nshared as you might think.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and the related work it refers to, to understand this different vantage",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "related",
          "work",
          "refers",
          "understand",
          "different",
          "vantage"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand ation: fork(), exec(), and wait(). However , we have just skimmed",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ation",
          "fork",
          "exec",
          "wait",
          "however",
          "skimmed"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : P R O C E S S API 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : P R O C E S S API 11\nAS I D E : K E Y PR O C E S S API T E R M S\n\u2022 Each process has a name; in most systems, that name is a number\nknown as a process ID (PID).\n\u2022 The fork() system call is used in U N I X systems to create a new pro-\ncess. The creator is called the parent; the newly created process is\ncalled the child. As sometimes occurs in real life [J16], the child\nprocess is a nearly identical copy of the parent.\n\u2022 The wait() system call allows a parent to wait for its child to com-\nplete execution.\n\u2022 The exec() family of system calls allows a child to break free from\nits similarity to its parent and execute an entirely new progr am.\n\u2022 A U N I X shell commonly uses fork(), wait(), and exec() to\nlaunch user commands; the separation of fork and exec enables fea -\ntures like input/output redirection , pipes, and other cool features,\nall without changing anything about the programs being run.\n\u2022 Process control is available in the form of signals, which can cause\njobs to stop, continue, or even terminate.\n\u2022 Which processes can be controlled by a particular person is encap -\nsulated in the notion of a user; the operating system allows multiple\nusers onto the system, and ensures users can only control their own\nprocesses.\n\u2022 A superuser can control all processes (and indeed do many other\nthings); this role should be assumed infrequently and with cau tion\nfor security reasons.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known as a process ID (PID).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The fork() system call is used in U N I X systems to create a new pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fork",
          "system",
          "call",
          "used",
          "systems",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "cess. The creator is called the parent; the newly created process is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cess",
          "creator",
          "called",
          "parent",
          "newly",
          "created",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: K E Y PR O C E S S API T E R M S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand each process has a name; in most systems, that name is a number",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "name",
          "systems",
          "name",
          "number"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand the wait() system call allows a parent to wait for its child to com-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "system",
          "call",
          "allows",
          "parent",
          "wait",
          "child"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand the exec() family of system calls allows a child to break free from",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "exec",
          "family",
          "system",
          "calls",
          "allows",
          "child",
          "break",
          "free"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand a u n i x shell commonly uses fork(), wait(), and exec() to",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shell",
          "commonly",
          "uses",
          "fork",
          "wait",
          "exec"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand process control is available in the form of signals, which can cause",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "control",
          "available",
          "form",
          "signals",
          "cause"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 IN T E R L U D E : P R O C E S S API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 IN T E R L U D E : P R O C E S S API\nReferences\n[B+19] \u201cA fork() in the road\u201d by Andrew Baumann, Jonathan Appavoo, Orran K rieger , Tim-\nothy Roscoe. HotOS \u201919, Bertinoro, Italy . A fun paper full of fork()ing rage. Read it to get an\nopposing viewpoint on the UN I X process API. Presented at the always lively HotOS workshop, where\nsystems researchers go to present extreme opinions in the hopes of push ing the community in new di-\nrections.\n[C63] \u201cA Multiprocessor System Design\u201d by Melvin E. Conway . AFIPS \u20196 3 Fall Joint Computer\nConference, New Y ork, USA 1963. An early paper on how to design multiprocessing systems; may\nbe the \ufb01rst place the term fork() was used in the discussion of spawning new processes.\n[DV66] \u201cProgramming Semantics for Multiprogrammed Computations\u201d b y Jack B. Dennis and\nEarl C. V an Horn. Communications of the ACM, V olume 9, Number 3, March 1 966. A classic\npaper that outlines the basics of multiprogrammed computer systems. Undoubte dly had great in\ufb02uence\non Project MAC, Multics, and eventually UN I X.\n[J16] \u201cThey could be twins!\u201d by Phoebe Jackson-Edwards. The Daily Mail. March 1, 2016.\nA vailable: www.dailymail.co.uk/femail/article-3469189/Photos-children-look-\nIDENTICAL-parents-age-sweep-web.html . This hard-hitting piece of journalism shows a\nbunch of weirdly similar child/parent photos and is frankly kind of mesme rizing. Go ahead, waste two\nminutes of your life and check it out. But don\u2019t forget to come back here! Th is, in a microcosm, is the\ndanger of sur\ufb01ng the web.\n[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems\nReview , V olume 15:5, October 1983. Lampson\u2019s famous hints on how to design computer systems.\nY ou should read it at some point in your life, and probably at many points in your life.\n[QI15] \u201cWith Great Power Comes Great Responsibility\u201d by The Quote Inv estigator . A vailable:\nhttps://quoteinvestigator.com/2015/07/23/great-power. The quote investigator\nconcludes that the earliest mention of this concept is 1793, in a collection of decrees made at the French\nNational Convention. The speci\ufb01c quote: \u201cIls doivent envisager qu\u2019une gr ande responsabilit est la\nsuite insparable d\u2019un grand pouvoir\u201d, which roughly translates to \u201cThey m ust consider that great\nresponsibility follows inseparably from great power .\u201d Only in 1962 di d the following words appear in\nSpider-Man: \u201c...with great power there must also come\u2013great responsib ility!\u201d So it looks like the French\nRevolution gets credit for this one, not Stan Lee. Sorry, Stan.\n[SR05] \u201cAdvanced Programming in the U N I X Environment\u201d by W . Richard Stevens, Stephen\nA. Rago. Addison-W esley , 2005. All nuances and subtleties of using UN I X APIs are found herein.\nBuy this book! Read it! And most importantly, live it.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[C63] \u201cA Multiprocessor System Design\u201d by Melvin E. Conway . AFIPS \u20196 3 Fall Joint Computer",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "multiprocessor",
          "system",
          "design",
          "melvin",
          "conway",
          "afips",
          "fall",
          "joint"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Conference, New Y ork, USA 1963. An early paper on how to design multiprocessing systems; may",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "conference",
          "early",
          "paper",
          "design",
          "multiprocessing",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hints",
          "computer",
          "systems",
          "design",
          "butler",
          "lampson",
          "erating",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Review , V olume 15:5, October 1983. Lampson\u2019s famous hints on how to design computer systems.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "review",
          "olume",
          "october",
          "lampson",
          "famous",
          "hints",
          "design",
          "computer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "concludes that the earliest mention of this concept is 1793, in a collection of decrees made at the French",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concludes",
          "earliest",
          "mention",
          "concept",
          "collection",
          "decrees",
          "made",
          "french"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Buy this book! Read it! And most importantly, live it.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "book",
          "read",
          "importantly",
          "live"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand A vailable: www.dailymail.co.uk/femail/article-3469189/Photos-children-look-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "dailymail",
          "femail",
          "article",
          "photos",
          "children",
          "look"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand V olume 15: 5, October 1983. Lampson\u2019s famous hints on how to design computer systems.",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "v olume 15",
          "october",
          "lampson",
          "famous",
          "hints",
          "design",
          "computer",
          "systems"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A vailable: https://quoteinvestigator.com/2015/07/23/great-power. The quote investigator",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "https",
          "quoteinvestigator",
          "great",
          "power",
          "quote",
          "investigator"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand The speci\ufb01c quote: \u201cIls doivent envisager qu\u2019une gr ande responsabilit est la",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the speci\ufb01c quote",
          "doivent",
          "envisager",
          "ande",
          "responsabilit"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Man: \u201c...with great power there must also come\u2013great responsib ility!\u201d So it looks like the French",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "man",
          "great",
          "power",
          "must",
          "also",
          "come",
          "great",
          "responsib",
          "ility"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "W rite a program that opens a \ufb01le (with the open() system call)",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "2. W rite a program that opens a \ufb01le (with the open() system call)\nand then calls fork() to create a new process. Can both the child\nand parent access the \ufb01le descriptor returned by open()? What\nhappens when they are writing to the \ufb01le concurrently , i.e., a t the\nsame time?\n3. W rite another program using fork(). The child process should\nprint \u201chello\u201d; the parent process should print \u201cgoodbye\u201d. Y ou shoul d\ntry to ensure that the child process always prints \ufb01rst; can you do\nthis without calling wait() in the parent?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and then calls fork() to create a new process. Can both the child",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "calls",
          "fork",
          "create",
          "process",
          "child"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "W rite a program that calls fork() and then calls some form of",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "4. W rite a program that calls fork() and then calls some form of\nexec() to run the program /bin/ls. See if you can try all of the\nvariants of exec(), including (on Linux) execl(), execle(),\nexeclp(), execv(), execvp(), and execvpe(). Why do\nyou think there are so many variants of the same basic call?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Now write a program that uses wait() to wait for the child process",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "5. Now write a program that uses wait() to wait for the child process\nto \ufb01nish in the parent. What does wait() return? What happens if\nyou use wait() in the child?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "W rite a slight modi\ufb01cation of the previous program, this time us -",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "6. W rite a slight modi\ufb01cation of the previous program, this time us -\ning waitpid() instead of wait(). When would waitpid() be\nuseful?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "7",
    "title": "W rite a program that creates a child process, and then in the c hild",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "7. W rite a program that creates a child process, and then in the c hild\ncloses standard output ( STDOUT FILENO). What happens if the child\ncalls printf() to print some output after closing the descriptor?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W rite a program that creates a child process, and then in the c hild",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "program",
          "creates",
          "child",
          "process",
          "hild"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "8",
    "title": "W rite a program that creates two children, and connects the s tan-",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "8. W rite a program that creates two children, and connects the s tan-\ndard output of one to the standard input of the other , using the\npipe() system call.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W rite a program that creates two children, and connects the s tan-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "program",
          "creates",
          "children",
          "connects"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "1 Basic T echnique: Limited Direct Execution",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "6.1 Basic T echnique: Limited Direct Execution\nT o make a program run as fast as one might expect, not surprisingl y\nOS developers came up with a technique, which we call limited direct\nexecution. The \u201cdirect execution\u201d part of the idea is simple: just run the\nprogram directly on the CPU. Thus, when the OS wishes to start a p ro-\ngram running, it creates a process entry for it in a process list, allocates\nsome memory for it, loads the program code into memory (from disk), lo-\ncates its entry point (i.e., the main() routine or something similar), jumps\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "OS developers came up with a technique, which we call limited direct",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developers",
          "came",
          "technique",
          "call",
          "limited",
          "direct"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "gram running, it creates a process entry for it in a process list, allocates",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "gram",
          "running",
          "creates",
          "process",
          "entry",
          "process",
          "list",
          "allocates"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1 Basic T echnique: Limited Direct Execution",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 basic t echnique",
          "limited",
          "direct",
          "execution"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "2 Problem #1: Restricted Operations",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "6.2 Problem #1: Restricted Operations\nDirect execution has the obvious advantage of being fast; the prog ram\nruns natively on the hardware CPU and thus executes as quickly as one\nwould expect. But running on the CPU introduces a problem: what if\nthe process wishes to perform some kind of restricted operation, su ch\nas issuing an I/O request to a disk, or gaining access to more sys tem\nresources such as CPU or memory?\nTH E CR U X : H O W TO PE R F O R M RE S T R I C T E D OP E R AT I O N S\nA process must be able to perform I/O and some other restricted oper -\nations, but without giving the process complete control over the sys tem.\nHow can the OS and hardware work together to do so?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A process must be able to perform I/O and some other restricted oper -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "must",
          "able",
          "perform",
          "restricted",
          "oper"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: Restricted Operations",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "restricted",
          "operations"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand problem #1: restricted operations",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "restricted",
          "operations"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : L I M I T E D DI R E C T EX E C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N 3\nAS I D E : W H Y SY S T E M CA L L S LO O K LI K E PR O C E D U R E CA L L S\nY ou may wonder why a call to a system call, such as open() or read(),\nlooks exactly like a typical procedure call in C; that is, if it look s just like\na procedure call, how does the system know it\u2019s a system call, and do all\nthe right stuff? The simple reason: it is a procedure call, but hidden in-\nside that procedure call is the famous trap instruction. More spe ci\ufb01cally ,\nwhen you call open() (for example), you are executing a procedure call\ninto the C library . Therein, whether for open() or any of the other sys-\ntem calls provided, the library uses an agreed-upon calling con vention\nwith the kernel to put the arguments to open() in well-known locations\n(e.g., on the stack, or in speci\ufb01c registers), puts the system- call number\ninto a well-known location as well (again, onto the stack or a regis ter),\nand then executes the aforementioned trap instruction. The code in the\nlibrary after the trap unpacks return values and returns cont rol to the\nprogram that issued the system call. Thus, the parts of the C lib rary that\nmake system calls are hand-coded in assembly , as they need to c arefully\nfollow convention in order to process arguments and return values c or-\nrectly , as well as execute the hardware-speci\ufb01c trap instru ction. And now\nyou know why you personally don\u2019t have to write assembly code to trap\ninto an OS; somebody has already written that assembly for you.\nOne approach would simply be to let any process do whatever it wan ts\nin terms of I/O and other related operations. However , doing so would\nprevent the construction of many kinds of systems that are desira ble. For\nexample, if we wish to build a \ufb01le system that checks permissi ons before\ngranting access to a \ufb01le, we can\u2019t simply let any user process is sue I/Os\nto the disk; if we did, a process could simply read or write the ent ire disk\nand thus all protections would be lost.\nThus, the approach we take is to introduce a new processor mode,\nknown as user mode ; code that runs in user mode is restricted in what it\ncan do. For example, when running in user mode, a process can\u2019t issu e\nI/O requests; doing so would result in the processor raising an ex ception;\nthe OS would then likely kill the process.\nIn contrast to user mode is kernel mode , which the operating system\n(or kernel) runs in. In this mode, code that runs can do what it lik es, in-\ncluding privileged operations such as issuing I/O requests an d executing\nall types of restricted instructions.\nW e are still left with a challenge, however: what should a user p ro-\ncess do when it wishes to perform some kind of privileged operation ,\nsuch as reading from disk? T o enable this, virtually all modern hard-\nware provides the ability for user programs to perform a system call .\nPioneered on ancient machines such as the Atlas [K+61,L78], sy stem calls\nallow the kernel to carefully expose certain key pieces of funct ionality to\nuser programs, such as accessing the \ufb01le system, creating and destroy-\ning processes, communicating with other processes, and allocati ng more\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "a procedure call, how does the system know it\u2019s a system call, and do all",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "procedure",
          "call",
          "system",
          "know",
          "system",
          "call"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "with the kernel to put the arguments to open() in well-known locations",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "kernel",
          "arguments",
          "open",
          "well",
          "known",
          "locations"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "into a well-known location as well (again, onto the stack or a regis ter),",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "well",
          "known",
          "location",
          "well",
          "onto",
          "stack",
          "regis"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "you know why you personally don\u2019t have to write assembly code to trap",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "personally",
          "write",
          "assembly",
          "code",
          "trap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "One approach would simply be to let any process do whatever it wan ts",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "would",
          "simply",
          "process",
          "whatever"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Thus, the approach we take is to introduce a new processor mode,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "approach",
          "take",
          "introduce",
          "processor",
          "mode"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "known as user mode ; code that runs in user mode is restricted in what it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "user",
          "mode",
          "code",
          "runs",
          "user",
          "mode",
          "restricted"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "In contrast to user mode is kernel mode , which the operating system",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "contrast",
          "user",
          "mode",
          "kernel",
          "mode",
          "operating",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: W H Y SY S T E M CA L L S LO O K LI K E PR O C E D U R E CA L L S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand The simple reason: it is a procedure call, but hidden in-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the simple reason",
          "procedure",
          "call",
          "hidden"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand however: what should a user p ro-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "user"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand the system know it\u2019s a system call, and do all\nthe right stuff",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "know",
          "system",
          "call",
          "right",
          "stuff"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 M E C H A N I S M : L I M I T E D DI R E C T EX ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nTI P : U S E PR O T E C T E D CO N T R O L TR A N S F E R\nThe hardware assists the OS by providing different modes of exec ution.\nIn user mode , applications do not have full access to hardware resources.\nIn kernel mode , the OS has access to the full resources of the machine.\nSpecial instructions to trap into the kernel and return-from-trap back to\nuser-mode programs are also provided, as well as instructions th at allow\nthe OS to tell the hardware where the trap table resides in memory .\nmemory . Most operating systems provide a few hundred calls (see t he\nPOSIX standard for details [P10]); early Unix systems exposed a more\nconcise subset of around twenty calls.\nT o execute a system call, a program must execute a special trap instruc-\ntion. This instruction simultaneously jumps into the kernel an d raises the\nprivilege level to kernel mode; once in the kernel, the system c an now per-\nform whatever privileged operations are needed (if allowed), an d thus do\nthe required work for the calling process. When \ufb01nished, the OS c alls a\nspecial return-from-trap instruction, which, as you might expect, returns\ninto the calling user program while simultaneously reducing t he privi-\nlege level back to user mode.\nThe hardware needs to be a bit careful when executing a trap, i n that it\nmust make sure to save enough of the caller \u2019s registers in order to be able\nto return correctly when the OS issues the return-from-trap in struction.\nOn x86, for example, the processor will push the program counter , \ufb02 ags,\nand a few other registers onto a per-process kernel stack ; the return-from-\ntrap will pop these values off the stack and resume execution of th e user-\nmode program (see the Intel systems manuals [I11] for details). Other\nhardware systems use different conventions, but the basic conc epts are\nsimilar across platforms.\nThere is one important detail left out of this discussion: how does th e\ntrap know which code to run inside the OS? Clearly , the calling pr ocess\ncan\u2019t specify an address to jump to (as you would when making a pro-\ncedure call); doing so would allow programs to jump anywhere into the\nkernel which clearly is a V ery Bad Idea 1 . Thus the kernel must carefully\ncontrol what code executes upon a trap.\nThe kernel does so by setting up a trap table at boot time. When the\nmachine boots up, it does so in privileged (kernel) mode, and thus is free\nto con\ufb01gure machine hardware as need be. One of the \ufb01rst things t he OS\nthus does is to tell the hardware what code to run when certain ex cep-\ntional events occur . For example, what code should run when a hard-\ndisk interrupt takes place, when a keyboard interrupt occurs, or when\na program makes a system call? The OS informs the hardware of the\n1 Imagine jumping into code to access a \ufb01le, but just after a permission check; in fact, it is\nlikely such an ability would enable a wily programmer to get the k ernel to run arbitrary code\nsequences [S07]. In general, try to avoid V ery Bad Ideas like this one .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "There is one important detail left out of this discussion: how does th e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "detail",
          "left",
          "discussion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "trap know which code to run inside the OS? Clearly , the calling pr ocess",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trap",
          "know",
          "code",
          "inside",
          "clearly",
          "calling",
          "ocess"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: U S E PR O T E C T E D CO N T R O L TR A N S F E R",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand th e\ntrap know which code to run inside the OS",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "trap",
          "know",
          "code",
          "inside"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : L I M I T E D DI R E C T EX E C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N 5\nOS @ boot Hardware\n(kernel mode)\ninitialize trap table\nremember address of...\nsyscall handler\nOS @ run Hardware Program\n(kernel mode) (user mode)\nCreate entry for process list\nAllocate memory for program\nLoad program into memory\nSetup user stack with argv\nFill kernel stack with reg/PC\nreturn-from-trap\nrestore regs\n(from kernel stack)\nmove to user mode\njump to main\nRun main()\n...\nCall system call\ntrap into OS\nsave regs\n(to kernel stack)\nmove to kernel mode\njump to trap handler\nHandle trap\nDo work of syscall\nreturn-from-trap\nrestore regs\n(from kernel stack)\nmove to user mode\njump to PC after trap\n...\nreturn from main\ntrap (via exit())\nFree memory of process\nRemove from process list\nFigure 6.2: Limited Direct Execution Protocol\nlocations of these trap handlers , usually with some kind of special in-\nstruction. Once the hardware is informed, it remembers the loca tion of\nthese handlers until the machine is next rebooted, and thus the hardware\nknows what to do (i.e., what code to jump to) when system calls and other\nexceptional events take place.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Create entry for process list",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "entry",
          "process",
          "list"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "knows what to do (i.e., what code to jump to) when system calls and other",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knows",
          "code",
          "jump",
          "system",
          "calls"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 2: Limited Direct Execution Protocol",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "limited",
          "direct",
          "execution",
          "protocol"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 M E C H A N I S M : L I M I T E D DI R E C T EX ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nTI P : B E WA RY OF US E R IN P U T S IN SE C U R E SY S T E M S\nEven though we have taken great pains to protect the OS during sy stem\ncalls (by adding a hardware trapping mechanism, and ensurin g all calls to\nthe OS are routed through it), there are still many other aspects to imple-\nmenting a secure operating system that we must consider . One of these\nis the handling of arguments at the system call boundary; the OS must\ncheck what the user passes in and ensure that arguments are pr operly\nspeci\ufb01ed, or otherwise reject the call.\nFor example, with a write() system call, the user speci\ufb01es an address\nof a buffer as a source of the write call. If the user (either accid entally\nor maliciously) passes in a \u201cbad\u201d address (e.g., one inside the k ernel\u2019s\nportion of the address space), the OS must detect this and reject the call.\nOtherwise, it would be possible for a user to read all of kernel mem ory;\ngiven that kernel (virtual) memory also usually includes all of the physi-\ncal memory of the system, this small slip would enable a program to read\nthe memory of any other process in the system.\nIn general, a secure system must treat user inputs with great suspicion.\nNot doing so will undoubtedly lead to easily hacked software, a de spair-\ning sense that the world is an unsafe and scary place, and the los s of job\nsecurity for the all-too-trusting OS developer .\nT o specify the exact system call, a system-call number is usually as-\nsigned to each system call. The user code is thus responsible for placing\nthe desired system-call number in a register or at a speci\ufb01ed l ocation on\nthe stack; the OS, when handling the system call inside the tra p handler ,\nexamines this number , ensures it is valid, and, if it is, exec utes the corre-\nsponding code. This level of indirection serves as a form of protection;\nuser code cannot specify an exact address to jump to, but rather m ust\nrequest a particular service via number .\nOne last aside: being able to execute the instruction to tell t he hard-\nware where the trap tables are is a very powerful capability . T hus, as you\nmight have guessed, it is also a privileged operation. If you try to exe-\ncute this instruction in user mode, the hardware won\u2019t let you, and you\ncan probably guess what will happen (hint: adios, offending prog ram).\nPoint to ponder: what horrible things could you do to a system if you\ncould install your own trap table? Could you take over the machine?\nThe timeline (with time increasing downward, in Figure 6.2) s umma-\nrizes the protocol. W e assume each process has a kernel stack wher e reg-\nisters (including general purpose registers and the program c ounter) are\nsaved to and restored from (by the hardware) when transitioning into and\nout of the kernel.\nThere are two phases in the limited direct execution ( LDE) protocol.\nIn the \ufb01rst (at boot time), the kernel initializes the trap tabl e, and the\nCPU remembers its location for subsequent use. The kernel does so via a\nprivileged instruction (all privileged instructions are hig hlighted in bold).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "security for the all-too-trusting OS developer .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "security",
          "trusting",
          "developer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One last aside: being able to execute the instruction to tell t he hard-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "aside",
          "able",
          "execute",
          "instruction",
          "tell",
          "hard"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: B E WA RY OF US E R IN P U T S IN SE C U R E SY S T E M S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand hint: adios, offending prog ram).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hint",
          "adios",
          "offending",
          "prog"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Point to ponder: what horrible things could you do to a system if you",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "point to ponder",
          "horrible",
          "things",
          "could",
          "system"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "3 Problem #2: Switching Between Processes",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "6.3 Problem #2: Switching Between Processes\nThe next problem with direct execution is achieving a switch be tween\nprocesses. Switching between processes should be simple, right ? The\nOS should just decide to stop one process and start another . What\u2019s t he\nbig deal? But it actually is a little bit tricky: speci\ufb01cally , if a process is\nrunning on the CPU, this by de\ufb01nition means the OS is not running. If\nthe OS is not running, how can it do anything at all? (hint: it can \u2019t) While\nthis sounds almost philosophical, it is a real problem: there is cl early no\nway for the OS to take an action if it is not running on the CPU. Thus w e\narrive at the crux of the problem.\nTH E CR U X : H O W TO RE G A I N CO N T R O L OF TH E CPU\nHow can the operating system regain control of the CPU so that it can\nswitch between processes?\nA Cooperative Approach: W ait For System Calls\nOne approach that some systems have taken in the past (for exampl e,\nearly versions of the Macintosh operating system [M11], or the old X erox\nAlto system [A79]) is known as the cooperative approach. In this style,\nthe OS trusts the processes of the system to behave reasonably . Processes\nthat run for too long are assumed to periodically give up the CPU so that\nthe OS can decide to run some other task.\nThus, you might ask, how does a friendly process give up the CPU in\nthis utopian world? Most processes, as it turns out, transfer contr ol of\nthe CPU to the OS quite frequently by making system calls , for example,\nto open a \ufb01le and subsequently read it, or to send a message to anot her\nmachine, or to create a new process. Systems like this often inclu de an\nexplicit yield system call, which does nothing except to transfer control\nto the OS so it can run other processes.\nApplications also transfer control to the OS when they do somethi ng\nillegal. For example, if an application divides by zero, or tries to access\nmemory that it shouldn\u2019t be able to access, it will generate a trap to the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A Cooperative Approach: W ait For System Calls",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cooperative",
          "approach",
          "system",
          "calls"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One approach that some systems have taken in the past (for exampl e,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "systems",
          "taken",
          "past",
          "exampl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Alto system [A79]) is known as the cooperative approach. In this style,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "alto",
          "system",
          "known",
          "cooperative",
          "approach",
          "style"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "machine, or to create a new process. Systems like this often inclu de an",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "machine",
          "create",
          "process",
          "systems",
          "like",
          "often",
          "inclu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "memory that it shouldn\u2019t be able to access, it will generate a trap to the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "able",
          "access",
          "generate",
          "trap"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand this by de\ufb01nition: the OS is not running. If",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this by de\ufb01nition",
          "running"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 2: Switching Between Processes",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "switching",
          "processes"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand a friendly process give up the CPU in\nthis utopian world",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "friendly",
          "process",
          "give",
          "utopian",
          "world"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 M E C H A N I S M : L I M I T E D DI R E C T EX ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nOS. The OS will then have control of the CPU again (and likely termi nate\nthe offending process).\nThus, in a cooperative scheduling system, the OS regains control of\nthe CPU by waiting for a system call or an illegal operation of some ki nd\nto take place. Y ou might also be thinking: isn\u2019t this passive ap proach less\nthan ideal? What happens, for example, if a process (whether ma licious,\nor just full of bugs) ends up in an in\ufb01nite loop, and never makes a sy stem\ncall? What can the OS do then?\nA Non-Cooperative Approach: The OS T akes Control\nWithout some additional help from the hardware, it turns out the OS can\u2019t\ndo much at all when a process refuses to make system calls (or mis takes)\nand thus return control to the OS. In fact, in the cooperative approa ch,\nyour only recourse when a process gets stuck in an in\ufb01nite loop is to\nresort to the age-old solution to all problems in computer systems: reboot\nthe machine . Thus, we again arrive at a subproblem of our general quest\nto gain control of the CPU.\nTH E CR U X : H O W TO GA I N CO N T R O L WI T H O U T CO O P E R AT I O N\nHow can the OS gain control of the CPU even if processes are not being\ncooperative? What can the OS do to ensure a rogue process does not tak e\nover the machine?\nThe answer turns out to be simple and was discovered by a number\nof people building computer systems many years ago: a timer interrupt\n[M+63]. A timer device can be programmed to raise an interrupt every\nso many milliseconds; when the interrupt is raised, the curre ntly running\nprocess is halted, and a pre-con\ufb01gured interrupt handler in the OS runs.\nAt this point, the OS has regained control of the CPU, and thus can d o\nwhat it pleases: stop the current process, and start a differen t one.\nAs we discussed before with system calls, the OS must inform the\nhardware of which code to run when the timer interrupt occurs; th us,\nat boot time, the OS does exactly that. Second, also during the boot\nsequence, the OS must start the timer , which is of course a privi leged\nTI P : D E A L I N G WI T H AP P L I C AT I O N MI S B E H AV I O R\nOperating systems often have to deal with misbehaving process es, those\nthat either through design (maliciousness) or accident (bugs) attempt to\ndo something that they shouldn\u2019t. In modern systems, the way the O S\ntries to handle such malfeasance is to simply terminate the of fender . One\nstrike and you\u2019re out! Perhaps brutal, but what else should the OS do\nwhen you try to access memory illegally or execute an illegal ins truction?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A Non-Cooperative Approach: The OS T akes Control",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cooperative",
          "approach",
          "akes",
          "control"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "that either through design (maliciousness) or accident (bugs) attempt to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "either",
          "design",
          "maliciousness",
          "accident",
          "bugs",
          "attempt"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Cooperative Approach: The OS T akes Control",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cooperative approach",
          "akes",
          "control"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : L I M I T E D DI R E C T EX E C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N 9\noperation. Once the timer has begun, the OS can thus feel safe in that\ncontrol will eventually be returned to it, and thus the OS is fre e to run\nuser programs. The timer can also be turned off (also a privileg ed opera-\ntion), something we will discuss later when we understand concu rrency\nin more detail.\nNote that the hardware has some responsibility when an interrup t oc-\ncurs, in particular to save enough of the state of the program that was\nrunning when the interrupt occurred such that a subsequent re turn-from-\ntrap instruction will be able to resume the running program corr ectly .\nThis set of actions is quite similar to the behavior of the hardwar e during\nan explicit system-call trap into the kernel, with various re gisters thus\ngetting saved (e.g., onto a kernel stack) and thus easily rest ored by the\nreturn-from-trap instruction.\nSaving and Restoring Context\nNow that the OS has regained control, whether cooperatively via a s ys-\ntem call, or more forcefully via a timer interrupt, a decision has to be\nmade: whether to continue running the currently-running proc ess, or\nswitch to a different one. This decision is made by a part of the ope rating\nsystem known as the scheduler; we will discuss scheduling policies in\ngreat detail in the next few chapters.\nIf the decision is made to switch, the OS then executes a low-lev el\npiece of code which we refer to as a context switch . A context switch is\nconceptually simple: all the OS has to do is save a few register values\nfor the currently-executing process (onto its kernel stack, for example)\nand restore a few for the soon-to-be-executing process (from its ker nel\nstack). By doing so, the OS thus ensures that when the return-fr om-trap\ninstruction is \ufb01nally executed, instead of returning to the pr ocess that was\nrunning, the system resumes execution of another process.\nT o save the context of the currently-running process, the OS wil l ex-\necute some low-level assembly code to save the general purpose re gis-\nters, PC, and the kernel stack pointer of the currently-runnin g process,\nand then restore said registers, PC, and switch to the kernel s tack for the\nsoon-to-be-executing process. By switching stacks, the kernel enters the\ncall to the switch code in the context of one process (the one that was in-\nterrupted) and returns in the context of another (the soon-to-be-e xecuting\none). When the OS then \ufb01nally executes a return-from-trap inst ruction,\nTI P : U S E TH E TI M E R IN T E R R U P T TO RE G A I N CO N T R O L\nThe addition of a timer interrupt gives the OS the ability to run again\non a CPU even if processes act in a non-cooperative fashion. Thus, th is\nhardware feature is essential in helping the OS maintain cont rol of the\nmachine.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": ", something we will discuss later when we understand concu rrency",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "something",
          "discuss",
          "later",
          "understand",
          "concu",
          "rrency"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "trap instruction will be able to resume the running program corr ectly .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trap",
          "instruction",
          "able",
          "resume",
          "running",
          "program",
          "corr",
          "ectly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "system known as the scheduler; we will discuss scheduling policies in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "known",
          "scheduler",
          "discuss",
          "scheduling",
          "policies"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "conceptually simple: all the OS has to do is save a few register values",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "conceptually",
          "simple",
          "save",
          "register",
          "values"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "hardware feature is essential in helping the OS maintain cont rol of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "feature",
          "essential",
          "helping",
          "maintain",
          "cont"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand TI P: U S E TH E TI M E R IN T E R R U P T TO RE G A I N CO N T R O L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 M E C H A N I S M : L I M I T E D DI R E C T EX...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nTI P : R E B O O T IS US E F U L\nEarlier on, we noted that the only solution to in\ufb01nite loops (and simi lar\nbehaviors) under cooperative preemption is to reboot the machine. While\nyou may scoff at this hack, researchers have shown that reboot (or in gen-\neral, starting over some piece of software) can be a hugely useful tool in\nbuilding robust systems [C+04].\nSpeci\ufb01cally , reboot is useful because it moves software back to a k nown\nand likely more tested state. Reboots also reclaim stale or leake d re-\nsources (e.g., memory) which may otherwise be hard to handle. Fi nally ,\nreboots are easy to automate. For all of these reasons, it is not uncomm on\nin large-scale cluster Internet services for system managem ent software\nto periodically reboot sets of machines in order to reset them and t hus\nobtain the advantages listed above.\nThus, next time you reboot, you are not just enacting some ugly hack.\nRather , you are using a time-tested approach to improving the be havior\nof a computer system. W ell done!\nthe soon-to-be-executing process becomes the currently-runnin g process.\nAnd thus the context switch is complete.\nA timeline of the entire process is shown in Figure 6.3. In this ex ample,\nProcess A is running and then is interrupted by the timer inter rupt. The\nhardware saves its registers (onto its kernel stack) and ente rs the kernel\n(switching to kernel mode). In the timer interrupt handler , t he OS decides\nto switch from running Process A to Process B. At that point, it cal ls the\nswitch() routine, which carefully saves current register values (int o the\nprocess structure of A), restores the registers of Process B (from i ts process\nstructure entry), and then switches contexts , speci\ufb01cally by changing the\nstack pointer to use B\u2019s kernel stack (and not A \u2019s). Finally , the O S returns-\nfrom-trap, which restores B\u2019s registers and starts running it.\nNote that there are two types of register saves/restores that ha ppen\nduring this protocol. The \ufb01rst is when the timer interrupt occurs ; in this\ncase, the user registers of the running process are implicitly saved by the\nhardware, using the kernel stack of that process. The second is when the\nOS decides to switch from A to B; in this case, the kernel registers are ex-\nplicitly saved by the software (i.e., the OS), but this time into memory in\nthe process structure of the process. The latter action moves the s ystem\nfrom running as if it just trapped into the kernel from A to as if i t just\ntrapped into the kernel from B.\nT o give you a better sense of how such a switch is enacted, Figure 6 .4\nshows the context switch code for xv6. See if you can make sense of it\n(you\u2019ll have to know a bit of x86, as well as some xv6, to do so). The\ncontext structures old and new are found in the old and new process\u2019s\nprocess structures, respectively .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Rather , you are using a time-tested approach to improving the be havior",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rather",
          "using",
          "time",
          "tested",
          "approach",
          "improving",
          "havior"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(you\u2019ll have to know a bit of x86, as well as some xv6, to do so). The",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "know",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: R E B O O T IS US E F U L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "4 W orried About Concurrency?",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "6.4 W orried About Concurrency?\nSome of you, as attentive and thoughtful readers, may be now think-\ning: \u201cHmm... what happens when, during a system call, a timer interrupt\noccurs?\u201d or \u201cWhat happens when you\u2019re handling one interrupt and a n-\nother one happens? Doesn\u2019t that get hard to handle in the kernel?\u201d Good\nquestions \u2014 we really have some hope for you yet!\nThe answer is yes, the OS does indeed need to be concerned as to wh at\nhappens if, during interrupt or trap handling, another interr upt occurs.\nThis, in fact, is the exact topic of the entire second piece of this book, on\nconcurrency; we\u2019ll defer a detailed discussion until then.\nT o whet your appetite, we\u2019ll just sketch some basics of how the OS\nhandles these tricky situations. One simple thing an OS might do is dis-\nable interrupts during interrupt processing; doing so ensures that when\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand ing: \u201cHmm... what happens when, during a system call, a timer interrupt",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ing",
          "happens",
          "system",
          "call",
          "timer",
          "interrupt"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand w orried about concurrency?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "orried",
          "concurrency"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "5 Summary",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "6.5 Summary\nW e have described some key low-level mechanisms to implement C PU\nvirtualization, a set of techniques which we collectively refe r to as limited\ndirect execution . The basic idea is straightforward: just run the program\nyou want to run on the CPU, but \ufb01rst make sure to set up the hardwar e\nso as to limit what the process can do without OS assistance.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have described some key low-level mechanisms to implement C PU",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "described",
          "level",
          "mechanisms",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "virtualization, a set of techniques which we collectively refe r to as limited",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "virtualization",
          "techniques",
          "collectively",
          "refe",
          "limited"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : L I M I T E D DI R E C T EX E C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N 13\nAS I D E : H O W LO N G CO N T E X T SW I T C H E S TA K E\nA natural question you might have is: how long does something like a\ncontext switch take? Or even a system call? For those of you that are cu-\nrious, there is a tool called lmbench [MS96] that measures exactly those\nthings, as well as a few other performance measures that might b e rele-\nvant.\nResults have improved quite a bit over time, roughly tracking pr ocessor\nperformance. For example, in 1996 running Linux 1.3.37 on a 200- MHz\nP6 CPU, system calls took roughly 4 microseconds, and a context swit ch\nroughly 6 microseconds [MS96]. Modern systems perform almost an or-\nder of magnitude better , with sub-microsecond results on system s with\n2- or 3-GHz processors.\nIt should be noted that not all operating-system actions track CPU per-\nformance. As Ousterhout observed, many OS operations are memory\nintensive, and memory bandwidth has not improved as dramatical ly as\nprocessor speed over time [O90]. Thus, depending on your workload,\nbuying the latest and greatest processor may not speed up your OS a s\nmuch as you might hope.\nThis general approach is taken in real life as well. For example , those\nof you who have children, or , at least, have heard of children, may be\nfamiliar with the concept of baby proo\ufb01ng a room: locking cabinets con-\ntaining dangerous stuff and covering electrical sockets. When the room is\nthus readied, you can let your baby roam freely , secure in the know ledge\nthat the most dangerous aspects of the room have been restricted.\nIn an analogous manner , the OS \u201cbaby proofs\u201d the CPU, by \ufb01rst (dur-\ning boot time) setting up the trap handlers and starting an inte rrupt timer ,\nand then by only running processes in a restricted mode. By doing s o, the\nOS can feel quite assured that processes can run ef\ufb01ciently , on ly requir-\ning OS intervention to perform privileged operations or when they have\nmonopolized the CPU for too long and thus need to be switched out.\nW e thus have the basic mechanisms for virtualizing the CPU in p lace.\nBut a major question is left unanswered: which process should we r un at\na given time? It is this question that the scheduler must answe r , and thus\nthe next topic of our study .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "This general approach is taken in real life as well. For example , those",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "general",
          "approach",
          "taken",
          "real",
          "life",
          "well",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "familiar with the concept of baby proo\ufb01ng a room: locking cabinets con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "familiar",
          "concept",
          "baby",
          "room",
          "locking",
          "cabinets"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "thus readied, you can let your baby roam freely , secure in the know ledge",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "readied",
          "baby",
          "roam",
          "freely",
          "secure",
          "know",
          "ledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: H O W LO N G CO N T E X T SW I T C H E S TA K E",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 M E C H A N I S M : L I M I T E D DI R E C T EX...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nAS I D E : K E Y CPU V I RT U A L I Z AT I O N TE R M S (M E C H A N I S M S )\n\u2022 The CPU should support at least two modes of execution: a re-\nstricted user mode and a privileged (non-restricted) kernel mode .\n\u2022 T ypical user applications run in user mode, and use a system call\nto trap into the kernel to request operating system services.\n\u2022 The trap instruction saves register state carefully , change s the hard-\nware status to kernel mode, and jumps into the OS to a pre-speci \ufb01ed\ndestination: the trap table .\n\u2022 When the OS \ufb01nishes servicing a system call, it returns to the user\nprogram via another special return-from-trap instruction, which re-\nduces privilege and returns control to the instruction after th e trap\nthat jumped into the OS.\n\u2022 The trap tables must be set up by the OS at boot time, and make\nsure that they cannot be readily modi\ufb01ed by user programs. All\nof this is part of the limited direct execution protocol which runs\nprograms ef\ufb01ciently but without loss of OS control.\n\u2022 Once a program is running, the OS must use hardware mechanisms\nto ensure the user program does not run forever , namely the timer\ninterrupt. This approach is a non-cooperative approach to CPU\nscheduling.\n\u2022 Sometimes the OS, during a timer interrupt or system call, might\nwish to switch from running the current process to a different on e,\na low-level technique known as a context switch .\n.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "interrupt. This approach is a non-cooperative approach to CPU",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interrupt",
          "approach",
          "cooperative",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a low-level technique known as a context switch .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "level",
          "technique",
          "known",
          "context",
          "switch"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: K E Y CPU V I RT U A L I Z AT I O N TE R M S (M E C H A N I S M S )",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the cpu should support at least two modes of execution: a re-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "least",
          "modes",
          "execution"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand t ypical user applications run in user mode, and use a system call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ypical",
          "user",
          "applications",
          "user",
          "mode",
          "system",
          "call"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand the trap instruction saves register state carefully , change s the hard-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "trap",
          "instruction",
          "saves",
          "register",
          "state",
          "carefully",
          "change",
          "hard"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand when the os \ufb01nishes servicing a system call, it returns to the user",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "servicing",
          "system",
          "call",
          "returns",
          "user"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand the trap tables must be set up by the os at boot time, and make",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "trap",
          "tables",
          "must",
          "boot",
          "time",
          "make"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand once a program is running, the os must use hardware mechanisms",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "running",
          "must",
          "hardware",
          "mechanisms"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : L I M I T E D DI R E C T EX E C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N 15\nReferences\n[A79] \u201cAlto User \u2019s Handbook\u201d by Xerox. Xerox Palo Alto Research C enter , September 1979.\nA vailable: http://history-computer.com/Library/AltoUsersHandbook.pdf. An\namazing system, way ahead of its time. Became famous because Steve Jobs visited, took notes, and built\nLisa and eventually Mac.\n[C+04] \u201cMicroreboot \u2014 A T echnique for Cheap Recovery\u201d by G. Candea, S. Ka wamoto, Y .\nFujiki, G. Friedman, A. Fox. OSDI \u201904, San Francisco, CA, December 2 004. An excellent paper\npointing out how far one can go with reboot in building more robust systems.\n[I11] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manual\u201d b y V olume 3A and 3B:\nSystem Programming Guide. Intel Corporation, January 2011. This is just a boring manual, but\nsometimes those are useful.\n[K+61] \u201cOne-Level Storage System\u201d by T . Kilburn, D.B.G. Edwards, M.J. Lanigan, F .H. Sumner .\nIRE T ransactions on Electronic Computers, April 1962. The Atlas pioneered much of what you see\nin modern systems. However , this paper is not the best one to read. If you wer e to only read one, you\nmight try the historical perspective below [L78].\n[L78] \u201cThe Manchester Mark I and Atlas: A Historical Perspective\u201d by S. H. L avington. Com-\nmunications of the ACM, 21:1, January 1978. A history of the early development of computers and\nthe pioneering efforts of Atlas.\n[M+63] \u201cA Time-Sharing Debugging System for a Small Computer \u201d by J. McCa rthy , S. Boilen,\nE. Fredkin, J. C. R. Licklider . AFIPS \u201963 (Spring), May , 1963, New Y ork , USA. An early paper\nabout time-sharing that refers to using a timer interrupt; the quote that discu sses it: \u201cThe basic task of\nthe channel 17 clock routine is to decide whether to remove the current us er from core and if so to decide\nwhich user program to swap in as he goes out.\u201d\n[MS96] \u201clmbench: Portable tools for performance analysis\u201d by Larry McV oy a nd Carl Staelin.\nUSENIX Annual T echnical Conference, January 1996. A fun paper about how to measure a number\nof different things about your OS and its performance. Download lmbench and give it a try.\n[M11] \u201cMac OS 9\u201d by Apple Computer , Inc.. January 2011. http://en.wikipedia.org/wiki/\nMac\nOS 9 . Y ou can probably even \ufb01nd an OS 9 emulator out there if you want to; check it out, it\u2019 s a\nfun little Mac!\n[O90] \u201cWhy Aren\u2019t Operating Systems Getting Faster as Fast as Hardwa re?\u201d by J. Ouster-\nhout. USENIX Summer Conference, June 1990. A classic paper on the nature of operating system\nperformance.\n[P10] \u201cThe Single UNIX Speci\ufb01cation, V ersion 3\u201d by The Open Group, May 2010 . A vailable:\nhttp://www.unix.org/version3/. This is hard and painful to read, so probably avoid it if you\ncan. Like, unless someone is paying you to read it. Or , you\u2019re just so curi ous you can\u2019t help it!\n[S07] \u201cThe Geometry of Innocent Flesh on the Bone: Return-into-libc without Function Calls\n(on the x86)\u201d by Hovav Shacham. CCS \u201907, October 2007. One of those awesome, mind-blowing\nideas that you\u2019ll see in research from time to time. The author shows that if you c an jump into code\narbitrarily, you can essentially stitch together any code sequence you like (gi ven a large code base); read\nthe paper for the details. The technique makes it even harder to defend again st malicious attacks, alas.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[I11] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manual\u201d b y V olume 3A and 3B:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "intel",
          "architectures",
          "software",
          "developer",
          "manual",
          "olume"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "munications of the ACM, 21:1, January 1978. A history of the early development of computers and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "munications",
          "january",
          "history",
          "early",
          "development",
          "computers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[MS96] \u201clmbench: Portable tools for performance analysis\u201d by Larry McV oy a nd Carl Staelin.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lmbench",
          "portable",
          "tools",
          "performance",
          "analysis",
          "larry",
          "carl",
          "staelin"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "arbitrarily, you can essentially stitch together any code sequence you like (gi ven a large code base); read",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "arbitrarily",
          "essentially",
          "stitch",
          "together",
          "code",
          "sequence",
          "like",
          "large"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "the paper for the details. The technique makes it even harder to defend again st malicious attacks, alas.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "paper",
          "details",
          "technique",
          "makes",
          "even",
          "harder",
          "defend",
          "malicious"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand sharing that: using a timer interrupt; the quote that discu sses it: \u201cThe basic task of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sharing that",
          "using",
          "timer",
          "interrupt",
          "quote",
          "discu",
          "sses",
          "basic",
          "task"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable: http://history-computer.com/Library/AltoUsersHandbook.pdf. An",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "history",
          "computer",
          "library",
          "altousershandbook"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 21: 1, January 1978. A history of the early development of computers and",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "21",
          "january",
          "history",
          "early",
          "development",
          "computers"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand http: //en.wikipedia.org/wiki/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "wikipedia",
          "wiki"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand A vailable: http://www.unix.org/version3/. This is hard and painful to read, so probably avoid it if you",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "unix",
          "hard",
          "painful",
          "read",
          "probably",
          "avoid"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 M E C H A N I S M : L I M I T E D DI R E C T EX...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 M E C H A N I S M : L I M I T E D DI R E C T EX E C U T I O N\nHomework (Measurement)\nAS I D E : M E A S U R E M E N T HO M E W O R K S\nMeasurement homeworks are small exercises where you write code t o\nrun on a real machine, in order to measure some aspect of OS or hardwa re\nperformance. The idea behind such homeworks is to give you a littl e bit\nof hands-on experience with a real operating system.\nIn this homework, you\u2019ll measure the costs of a system call and contex t\nswitch. Measuring the cost of a system call is relatively easy . For example,\nyou could repeatedly call a simple system call (e.g., performin g a 0-byte\nread), and time how long it takes; dividing the time by the numbe r of\niterations gives you an estimate of the cost of a system call.\nOne thing you\u2019ll have to take into account is the precision and acc u-\nracy of your timer . A typical timer that you can use is gettimeofday();\nread the man page for details. What you\u2019ll see there is that gettimeofday()\nreturns the time in microseconds since 1970; however , this does n ot mean\nthat the timer is precise to the microsecond. Measure back-to-b ack calls\nto gettimeofday() to learn something about how precise the timer re-\nally is; this will tell you how many iterations of your null system- call\ntest you\u2019ll have to run in order to get a good measurement result. If\ngettimeofday() is not precise enough for you, you might look into\nusing the rdtsc instruction available on x86 machines.\nMeasuring the cost of a context switch is a little trickier . The l mbench\nbenchmark does so by running two processes on a single CPU, and se t-\nting up two U N I X pipes between them; a pipe is just one of many ways\nprocesses in a U N I X system can communicate with one another . The \ufb01rst\nprocess then issues a write to the \ufb01rst pipe, and waits for a read on the\nsecond; upon seeing the \ufb01rst process waiting for something to read from\nthe second pipe, the OS puts the \ufb01rst process in the blocked state , and\nswitches to the other process, which reads from the \ufb01rst pipe and then\nwrites to the second. When the second process tries to read from th e \ufb01rst\npipe again, it blocks, and thus the back-and-forth cycle of commu nication\ncontinues. By measuring the cost of communicating like this repe atedly ,\nlmbench can make a good estimate of the cost of a context switch. Y ou\ncan try to re-create something similar here, using pipes, or pe rhaps some\nother communication mechanism such as U N I X sockets.\nOne dif\ufb01culty in measuring context-switch cost arises in syst ems with\nmore than one CPU; what you need to do on such a system is ensure that\nyour context-switching processes are located on the same processor . For-\ntunately , most operating systems have calls to bind a process to a partic-\nular processor; on Linux, for example, the sched\nsetaffinity() call\nis what you\u2019re looking for . By ensuring both processes are on the same\nprocessor , you are making sure to measure the cost of the OS stopping\none process and restoring another on the same CPU.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to gettimeofday() to learn something about how precise the timer re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "gettimeofday",
          "learn",
          "something",
          "precise",
          "timer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "can try to re-create something similar here, using pipes, or pe rhaps some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "something",
          "similar",
          "using",
          "pipes",
          "rhaps"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: M E A S U R E M E N T HO M E W O R K S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "1 W orkload Assumptions",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "7.1 W orkload Assumptions\nBefore getting into the range of possible policies, let us \ufb01rst ma ke a\nnumber of simplifying assumptions about the processes running i n the\nsystem, sometimes collectively called the workload. Determining the\nworkload is a critical part of building policies, and the more you kn ow\nabout workload, the more \ufb01ne-tuned your policy can be.\nThe workload assumptions we make here are mostly unrealistic, bu t\nthat is alright (for now), because we will relax them as we go, and even-\ntually develop what we will refer to as ... (dramatic pause) ...\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "workload is a critical part of building policies, and the more you kn ow",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "workload",
          "critical",
          "part",
          "building",
          "policies"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tually develop what we will refer to as ... (dramatic pause) ...",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tually",
          "develop",
          "refer",
          "dramatic",
          "pause"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand w orkload assumptions",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "orkload",
          "assumptions"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "2 Scheduling Metrics",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "7.2 Scheduling Metrics\nBeyond making workload assumptions, we also need one more thing\nto enable us to compare different scheduling policies: a scheduling met-\nric. A metric is just something that we use to measure something, and\nthere are a number of different metrics that make sense in sche duling.\nFor now , however , let us also simplify our life by simply having a s in-\ngle metric: turnaround time . The turnaround time of a job is de\ufb01ned\nas the time at which the job completes minus the time at which the job\narrived in the system. More formally , the turnaround time Tturnaround is:\nTturnaround = Tcompletion \u2212 Tarrival (7.1)\nBecause we have assumed that all jobs arrive at the same time, f or now\nTarrival = 0 and hence Tturnaround = Tcompletion. This fact will change\nas we relax the aforementioned assumptions.\nY ou should note that turnaround time is a performance metric, which\nwill be our primary focus this chapter . Another metric of interes t is fair-\nness, as measured (for example) by Jain\u2019s Fairness Index [J91]. Perfor-\nmance and fairness are often at odds in scheduling; a scheduler , for ex-\nample, may optimize performance but at the cost of preventing a fe w jobs\nfrom running, thus decreasing fairness. This conundrum shows u s that\nlife isn\u2019t always perfect.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to enable us to compare different scheduling policies: a scheduling met-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "enable",
          "compare",
          "different",
          "scheduling",
          "policies",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand gle metric: turnaround time . The turnaround time of a job is de\ufb01ned",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "gle metric",
          "turnaround",
          "time",
          "turnaround",
          "time"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand scheduling metrics",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "scheduling",
          "metrics"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "7",
    "title": "3 First In, First Out (FIFO)",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "7.3 First In, First Out (FIFO)\nThe most basic algorithm we can implement is known as First In, First\nOut (FIFO) scheduling or sometimes First Come, First Served (FCFS).\n1 Said in the same way you would say \u201cA fully-operational Death Star .\u201d\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The most basic algorithm we can implement is known as First In, First",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "basic",
          "algorithm",
          "implement",
          "known",
          "first",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand first in, first out (fifo)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "first",
          "first",
          "fifo"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G : I N T R O D U C T I O N 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G : I N T R O D U C T I O N 3\nFIFO has a number of positive properties: it is clearly simple an d thus\neasy to implement. And, given our assumptions, it works pretty w ell.\nLet\u2019s do a quick example together . Imagine three jobs arrive in t he\nsystem, A, B, and C, at roughly the same time ( Tarrival = 0). Because\nFIFO has to put some job \ufb01rst, let\u2019s assume that while they all arr ived\nsimultaneously , A arrived just a hair before B which arrived ju st a hair\nbefore C. Assume also that each job runs for 10 seconds. What will t he\naverage turnaround time be for these jobs?\n0 20 40 60 80 100 120\nTime\nA B C\nFigure 7.1: FIFO Simple Example\nFrom Figure 7.1, you can see that A \ufb01nished at 10, B at 20, and C at 3 0.\nThus, the average turnaround time for the three jobs is simply 10+20+30\n3 =\n20. Computing turnaround time is as easy as that.\nNow let\u2019s relax one of our assumptions. In particular , let\u2019s relax as -\nsumption 1, and thus no longer assume that each job runs for the sam e\namount of time. How does FIFO perform now? What kind of workload\ncould you construct to make FIFO perform poorly?\n(think about this before reading on ... keep thinking ... got it?!)\nPresumably you\u2019ve \ufb01gured this out by now , but just in case, let\u2019s do\nan example to show how jobs of different lengths can lead to trouble for\nFIFO scheduling. In particular , let\u2019s again assume three jobs (A, B, and\nC), but this time A runs for 100 seconds while B and C run for 10 each .\n0 20 40 60 80 100 120\nTime\nA B C\nFigure 7.2: Why FIFO Is Not That Great\nAs you can see in Figure 7.2, Job A runs \ufb01rst for the full 100 seconds\nbefore B or C even get a chance to run. Thus, the average turnaroun d\ntime for the system is high: a painful 110 seconds ( 100+110+120\n3 = 110).\nThis problem is generally referred to as the convoy effect [B+79], where\na number of relatively-short potential consumers of a resource get queued\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "easy to implement. And, given our assumptions, it works pretty w ell.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "easy",
          "implement",
          "given",
          "assumptions",
          "works",
          "pretty"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 2: Why FIFO Is Not That Great",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "fifo",
          "great"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand , but this time a runs for 100 seconds while b and c run for 10 each .",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "time",
          "runs",
          "seconds"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand FIFO perform now",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "fifo",
          "perform"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "4 Shortest Job First (SJF)",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "7.4 Shortest Job First (SJF)\nIt turns out that a very simple approach solves this problem; in fa ct\nit is an idea stolen from operations research [C54,PV56] and appl ied to\nscheduling of jobs in computer systems. This new scheduling dis cipline\nis known as Shortest Job First (SJF) , and the name should be easy to\nremember because it describes the policy quite completely: it runs the\nshortest job \ufb01rst, then the next shortest, and so on.\n0 20 40 60 80 100 120\nTime\nB C A\nFigure 7.3: SJF Simple Example\nLet\u2019s take our example above but with SJF as our scheduling policy .\nFigure 7.3 shows the results of running A, B, and C. Hopefully the dia-\ngram makes it clear why SJF performs much better with regards to aver-\nage turnaround time. Simply by running B and C before A, SJF reduce s\naverage turnaround from 110 seconds to 50 ( 10+20+120\n3 = 50), more than\na factor of two improvement.\n2 Recommended action in this case: either quickly switch to a different li ne, or take a long,\ndeep, and relaxing breath. That\u2019s right, breathe in, breathe out. It wi ll be OK, don\u2019t worry .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "It turns out that a very simple approach solves this problem; in fa ct",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "turns",
          "simple",
          "approach",
          "solves",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "is known as Shortest Job First (SJF) , and the name should be easy to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "shortest",
          "first",
          "name",
          "easy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "remember because it describes the policy quite completely: it runs the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "remember",
          "describes",
          "policy",
          "quite",
          "completely",
          "runs"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand shortest job first (sjf)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shortest",
          "first"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "5 Shortest Time-to-Completion First (STCF)",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "7.5 Shortest Time-to-Completion First (STCF)\nT o address this concern, we need to relax assumption 3 (that jobs must\nrun to completion), so let\u2019s do that. W e also need some machinery w ithin\nthe scheduler itself. As you might have guessed, given our prev ious dis-\ncussion about timer interrupts and context switching, the sche duler can\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand shortest time-to-completion first (stcf)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shortest",
          "time",
          "completion",
          "first",
          "stcf"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "6 A New Metric: Response Time",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "7.6 A New Metric: Response Time\nThus, if we knew job lengths, and that jobs only used the CPU, and ou r\nonly metric was turnaround time, STCF would be a great policy . In fa ct,\nfor a number of early batch computing systems, these types of sche duling\nalgorithms made some sense. However , the introduction of time-sha red\nmachines changed all that. Now users would sit at a terminal and de-\nmand interactive performance from the system as well. And thus , a new\nmetric was born: response time.\nW e de\ufb01ne response time as the time from when the job arrives in a\nsystem to the \ufb01rst time it is scheduled 3 . More formally:\nTresponse = Tfirstrun \u2212 Tarrival (7.2)\n3 Some de\ufb01ne it slightly differently , e.g., to also include the time unt il the job produces\nsome kind of \u201cresponse\u201d; our de\ufb01nition is the best-case version of t his, essentially assuming\nthat the job produces a response instantaneously .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "algorithms made some sense. However , the introduction of time-sha red",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "made",
          "sense",
          "however",
          "introduction",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "some kind of \u201cresponse\u201d; our de\ufb01nition is the best-case version of t his, essentially assuming",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "kind",
          "response",
          "best",
          "case",
          "version",
          "essentially",
          "assuming"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand More formally: Tresponse = Tfirstrun \u2212 Tarrival (7.2)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "more formally",
          "tresponse",
          "tfirstrun",
          "tarrival"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a new metric: response time",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "metric",
          "response",
          "time"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "7 Round Robin",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "7.7 Round Robin\nT o solve this problem, we will introduce a new scheduling algorit hm,\nclassically referred to as Round-Robin (RR) scheduling [K64]. The basic\nidea is simple: instead of running jobs to completion, RR runs a job for a\ntime slice (sometimes called a scheduling quantum ) and then switches\nto the next job in the run queue. It repeatedly does so until the j obs are\n\ufb01nished. For this reason, RR is sometimes called time-slicing. Note that\nthe length of a time slice must be a multiple of the timer-interr upt period;\nthus if the timer interrupts every 10 milliseconds, the time s lice could be\n10, 20, or any other multiple of 10 ms.\nT o understand RR in more detail, let\u2019s look at an example. Assume\nthree jobs A, B, and C arrive at the same time in the system, and t hat\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o solve this problem, we will introduce a new scheduling algorit hm,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "problem",
          "introduce",
          "scheduling",
          "algorit"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T o understand RR in more detail, let\u2019s look at an example. Assume",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "detail",
          "look",
          "example",
          "assume"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand round robin",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "round",
          "robin"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 SC H E D U L I N G : I N T R O D U C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 SC H E D U L I N G : I N T R O D U C T I O N\nTI P : A M O RT I Z AT I O N CA N RE D U C E CO S T S\nThe general technique of amortization is commonly used in systems\nwhen there is a \ufb01xed cost to some operation. By incurring that cost l ess\noften (i.e., by performing the operation fewer times), the total c ost to the\nsystem is reduced. For example, if the time slice is set to 10 ms , and the\ncontext-switch cost is 1 ms, roughly 10% of time is spent context sw itch-\ning and is thus wasted. If we want to amortize this cost, we can increase\nthe time slice, e.g., to 100 ms. In this case, less than 1% of tim e is spent\ncontext switching, and thus the cost of time-slicing has been am ortized.\nthey each wish to run for 5 seconds. An SJF scheduler runs each job t o\ncompletion before running another (Figure 7.6). In contrast, RR w ith a\ntime-slice of 1 second would cycle through the jobs quickly (Figur e 7.7).\nThe average response time of RR is: 0+1+2\n3 = 1; for SJF , average re-\nsponse time is: 0+5+10\n3 = 5.\nAs you can see, the length of the time slice is critical for RR. The shorter\nit is, the better the performance of RR under the response-time m etric.\nHowever , making the time slice too short is problematic: suddenl y the\ncost of context switching will dominate overall performance. Thus , de-\nciding on the length of the time slice presents a trade-off to a sy stem de-\nsigner , making it long enough to amortize the cost of switching without\nmaking it so long that the system is no longer responsive.\nNote that the cost of context switching does not arise solely from the\nOS actions of saving and restoring a few registers. When programs run,\nthey build up a great deal of state in CPU caches, TLBs, branch p redictors,\nand other on-chip hardware. Switching to another job causes this s tate\nto be \ufb02ushed and new state relevant to the currently-running job to be\nbrought in, which may exact a noticeable performance cost [MB91] .\nRR, with a reasonable time slice, is thus an excellent schedul er if re-\nsponse time is our only metric. But what about our old friend turnarou nd\ntime? Let\u2019s look at our example above again. A, B, and C, each with ru n-\nning times of 5 seconds, arrive at the same time, and RR is the sch eduler\nwith a (long) 1-second time slice. W e can see from the picture abov e that\nA \ufb01nishes at 13, B at 14, and C at 15, for an average of 14. Pretty aw ful!\nIt is not surprising, then, that RR is indeed one of the worst policies if\nturnaround time is our metric. Intuitively , this should make se nse: what\nRR is doing is stretching out each job as long as it can, by only runni ng\neach job for a short bit before moving to the next. Because turnaroun d\ntime only cares about when jobs \ufb01nish, RR is nearly pessimal, eve n worse\nthan simple FIFO in many cases.\nMore generally , any policy (such as RR) that is fair, i.e., that evenly di-\nvides the CPU among active processes on a small time scale, will p erform\npoorly on metrics such as turnaround time. Indeed, this is an inhe rent\ntrade-off: if you are willing to be unfair , you can run shorter jobs to com-\npletion, but at the cost of response time; if you instead value fair ness,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The general technique of amortization is commonly used in systems",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "general",
          "technique",
          "amortization",
          "commonly",
          "used",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "completion before running another (Figure 7.6). In contrast, RR w ith a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "completion",
          "running",
          "another",
          "figure",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "As you can see, the length of the time slice is critical for RR. The shorter",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "length",
          "time",
          "slice",
          "critical",
          "shorter"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: A M O RT I Z AT I O N CA N RE D U C E CO S T S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand off: if you are willing to be unfair , you can run shorter jobs to com-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "off",
          "willing",
          "unfair",
          "shorter",
          "jobs"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "8 Incorporating I/O",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "7.8 Incorporating I/O\nFirst we will relax assumption 4 \u2014 of course all programs perform\nI/O. Imagine a program that didn\u2019t take any input: it would produc e the\nsame output each time. Imagine one without output: it is the prover bial\ntree falling in the forest, with no one to see it; it doesn\u2019t matter that it ran.\nA scheduler clearly has a decision to make when a job initiates a n I/O\nrequest, because the currently-running job won\u2019t be using the C PU dur-\ning the I/O; it is blocked waiting for I/O completion. If the I/O is sent to\na hard disk drive, the process might be blocked for a few millisec onds or\nlonger , depending on the current I/O load of the drive. Thus, the s ched-\nuler should probably schedule another job on the CPU at that time.\nThe scheduler also has to make a decision when the I/O completes .\nWhen that occurs, an interrupt is raised, and the OS runs and mov es\nthe process that issued the I/O from blocked back to the ready sta te. Of\ncourse, it could even decide to run the job at that point. How should t he\nOS treat each job?\nT o understand this issue better , let us assume we have two jobs , A and\nB, which each need 50 ms of CPU time. However , there is one obvious\ndifference: A runs for 10 ms and then issues an I/O request (ass ume here\nthat I/Os each take 10 ms), whereas B simply uses the CPU for 50 m s and\nperforms no I/O. The scheduler runs A \ufb01rst, then B after (Figur e 7.8).\nAssume we are trying to build a STCF scheduler . How should such a\nscheduler account for the fact that A is broken up into 5 10-ms sub -jobs,\n4 A saying that confuses people, because it should be \u201cY ou can\u2019t keep your cake and eat it\ntoo\u201d (which is kind of obvious, no?). Amazingly , there is a wikipedia pa ge about this saying;\neven more amazingly , it is kind of fun to read [W15]. As they say in Ita lian, you can\u2019t Avere la\nbotte piena e la moglie ubriaca.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand this issue better , let us assume we have two jobs , A and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "issue",
          "better",
          "assume",
          "jobs"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand t take any input: it would produc e the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t take any input",
          "would",
          "produc"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Imagine one without output: it is the prover bial",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "imagine one without output",
          "prover",
          "bial"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand incorporating i/o",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "incorporating"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "9 No More Oracle",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "7.9 No More Oracle\nWith a basic approach to I/O in place, we come to our \ufb01nal assump-\ntion: that the scheduler knows the length of each job. As we said be fore,\nthis is likely the worst assumption we could make. In fact, in a ge neral-\npurpose OS (like the ones we care about), the OS usually knows very little\nabout the length of each job. Thus, how can we build an approach that be-\nhaves like SJF/STCF without such a priori knowledge? Further , how can\nwe incorporate some of the ideas we have seen with the RR scheduler so\nthat response time is also quite good?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "With a basic approach to I/O in place, we come to our \ufb01nal assump-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "approach",
          "place",
          "come",
          "assump"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tion: that the scheduler knows the length of each job. As we said be fore,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "scheduler",
          "knows",
          "length",
          "said",
          "fore"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "purpose OS (like the ones we care about), the OS usually knows very little",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "purpose",
          "like",
          "ones",
          "care",
          "usually",
          "knows",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "about the length of each job. Thus, how can we build an approach that be-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "length",
          "thus",
          "build",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "haves like SJF/STCF without such a priori knowledge? Further , how can",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "haves",
          "like",
          "stcf",
          "without",
          "priori",
          "knowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand no more oracle",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "oracle"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "10 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "7.10 Summary\nW e have introduced the basic ideas behind scheduling and deve loped\ntwo families of approaches. The \ufb01rst runs the shortest job remain ing and\nthus optimizes turnaround time; the second alternates between all jobs\nand thus optimizes response time. Both are bad where the other is g ood,\nalas, an inherent trade-off common in systems. W e have also seen how we\nmight incorporate I/O into the picture, but have still not solved the prob-\nlem of the fundamental inability of the OS to see into the future . Shortly ,\nwe will see how to overcome this problem, by building a scheduler t hat\nuses the recent past to predict the future. This scheduler is known as the\nmulti-level feedback queue, and it is the topic of the next chapter .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "two families of approaches. The \ufb01rst runs the shortest job remain ing and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "families",
          "approaches",
          "runs",
          "shortest",
          "remain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "might incorporate I/O into the picture, but have still not solved the prob-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "might",
          "incorporate",
          "picture",
          "still",
          "solved",
          "prob"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "lem of the fundamental inability of the OS to see into the future . Shortly ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "inability",
          "future",
          "shortly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "uses the recent past to predict the future. This scheduler is known as the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "uses",
          "recent",
          "past",
          "predict",
          "future",
          "scheduler",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 SC H E D U L I N G : I N T R O D U C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 SC H E D U L I N G : I N T R O D U C T I O N\nReferences\n[B+79] \u201cThe Convoy Phenomenon\u201d by M. Blasgen, J. Gray , M. Mitoma, T . Price. ACM Op -\nerating Systems Review , 13:2, April 1979. Perhaps the \ufb01rst reference to convoys, which occurs in\ndatabases as well as the OS.\n[C54] \u201cPriority Assignment in W aiting Line Problems\u201d by A. Cobham. Jou rnal of Operations\nResearch, 2:70, pages 70\u201376, 1954. The pioneering paper on using an SJF approach in scheduling the\nrepair of machines.\n[K64] \u201cAnalysis of a Time-Shared Processor \u201d by Leonard Kleinrock. Nav al Research Logistics\nQuarterly , 11:1, pages 59\u201373, March 1964. May be the \ufb01rst reference to the round-robin scheduling\nalgorithm; certainly one of the \ufb01rst analyses of said approach to scheduling a ti me-shared system.\n[CK68] \u201cComputer Scheduling Methods and their Countermeasures\u201d by Ed ward G. Coffman\nand Leonard Kleinrock. AFIPS \u201968 (Spring), April 1968. An excellent early introduction to and\nanalysis of a number of basic scheduling disciplines.\n[J91] \u201cThe Art of Computer Systems Performance Analysis: T echniques for Ex perimental De-\nsign, Measurement, Simulation, and Modeling\u201d by R. Jain. Interscience, Ne w Y ork, April 1991.\nThe standard text on computer systems measurement. A great reference for y our library, for sure.\n[O45] \u201cAnimal Farm\u201d by George Orwell. Secker and W arburg (London), 1945 . A great but\ndepressing allegorical book about power and its corruptions. Some say it is a c ritique of Stalin and the\npre-WWII Stalin era in the U.S.S.R; we say it\u2019s a critique of pigs.\n[PV56] \u201cMachine Repair as a Priority W aiting-Line Problem\u201d by Thomas E. Phipp s Jr ., W . R.\nV an V oorhis. Operations Research, 4:1, pages 76\u201386, February 195 6. Follow-on work that gen-\neralizes the SJF approach to machine repair from Cobham\u2019s original work; also postu lates the utility of\nan STCF approach in such an environment. Speci\ufb01cally, \u201cThere are certain types of repair work, ...\ninvolving much dismantling and covering the \ufb02oor with nuts and bolts, which certainly should not be\ninterrupted once undertaken; in other cases it would be inadvisable to contin ue work on a long job if one\nor more short ones became available (p.81).\u201d\n[MB91] \u201cThe effect of context switches on cache performance\u201d by Jeffrey C. Mogul, A nita Borg.\nASPLOS, 1991. A nice study on how cache performance can be affected by context switching; less of an\nissue in today\u2019s systems where processors issue billions of instruction s per second but context-switches\nstill happen in the millisecond time range.\n[W15] \u201cY ou can\u2019t have your cake and eat it\u201d by Authors: Unknown.. Wikiped ia (as of Decem-\nber 2015). http://en.wikipedia.org/wiki/You\ncan\u2019t have your cake and eat it.\nThe best part of this page is reading all the similar idioms from other languag es. In T amil, you can\u2019t\n\u201chave both the moustache and drink the soup.\u201d\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Research, 2:70, pages 70\u201376, 1954. The pioneering paper on using an SJF approach in scheduling the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "research",
          "pages",
          "pioneering",
          "paper",
          "using",
          "approach",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "algorithm; certainly one of the \ufb01rst analyses of said approach to scheduling a ti me-shared system.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "certainly",
          "analyses",
          "said",
          "approach",
          "scheduling",
          "shared",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[CK68] \u201cComputer Scheduling Methods and their Countermeasures\u201d by Ed ward G. Coffman",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "computer",
          "scheduling",
          "methods",
          "countermeasures",
          "ward",
          "coffman"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "eralizes the SJF approach to machine repair from Cobham\u2019s original work; also postu lates the utility of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "eralizes",
          "approach",
          "machine",
          "repair",
          "cobham",
          "original",
          "work",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "an STCF approach in such an environment. Speci\ufb01cally, \u201cThere are certain types of repair work, ...",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "stcf",
          "approach",
          "environment",
          "certain",
          "types",
          "repair",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "interrupted once undertaken; in other cases it would be inadvisable to contin ue work on a long job if one",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interrupted",
          "undertaken",
          "cases",
          "would",
          "inadvisable",
          "contin",
          "work",
          "long"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "[W15] \u201cY ou can\u2019t have your cake and eat it\u201d by Authors: Unknown.. Wikiped ia (as of Decem-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cake",
          "authors",
          "unknown",
          "wikiped",
          "decem"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 13: 2, April 1979. Perhaps the \ufb01rst reference to convoys, which occurs in",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "13",
          "april",
          "perhaps",
          "reference",
          "convoys",
          "occurs"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2: 70, pages 70\u201376, 1954. The pioneering paper on using an SJF approach in scheduling the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "pages",
          "pioneering",
          "paper",
          "using",
          "approach",
          "scheduling"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 11: 1, pages 59\u201373, March 1964. May be the \ufb01rst reference to the round-robin scheduling",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "11",
          "pages",
          "march",
          "reference",
          "round",
          "robin",
          "scheduling"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 4: 1, pages 76\u201386, February 195 6. Follow-on work that gen-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "pages",
          "february",
          "follow",
          "work"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand by Authors: Unknown.. Wikiped ia (as of Decem-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "by authors",
          "unknown",
          "wikiped",
          "decem"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand http: //en.wikipedia.org/wiki/You",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "wikipedia",
          "wiki"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Compute the response time and turnaround time when running",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. Compute the response time and turnaround time when running\nthree jobs of length 200 with the SJF and FIFO schedulers.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now do the same but with jobs of different lengths: 100, 200, an d",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "2. Now do the same but with jobs of different lengths: 100, 200, an d\n300.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Now do the same, but also with the RR scheduler and a time-sli ce",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "3. Now do the same, but also with the RR scheduler and a time-sli ce\nof 1.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "For what types of workloads does SJF deliver the same turnaround",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "4. For what types of workloads does SJF deliver the same turnaround\ntimes as FIFO?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "5",
    "title": "For what types of workloads and quantum lengths does SJF deliver",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "5. For what types of workloads and quantum lengths does SJF deliver\nthe same response times as RR?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "6",
    "title": "What happens to response time with SJF as job lengths increase ?",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "6. What happens to response time with SJF as job lengths increase ?\nCan you use the simulator to demonstrate the trend?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Can you use the simulator to demonstrate the trend?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "simulator",
          "demonstrate",
          "trend"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_7",
    "number": "7",
    "title": "What happens to response time with RR as quantum lengths in-",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "7. What happens to response time with RR as quantum lengths in-\ncrease? Can you write an equation that gives the worst-case re-\nsponse time, given N jobs?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8\nScheduling:\nThe Multi-Level Feedback Queue\nIn this chapter , we\u2019ll tackle the problem of developing one of the mos t\nwell-known approaches to scheduling, known as the Multi-level Feed-\nback Queue (MLFQ) . The Multi-level Feedback Queue (MLFQ) sched-\nuler was \ufb01rst described by Corbato et al. in 1962 [C+62] in a sys tem\nknown as the Compatible Time-Sharing System (CTSS), and this work,\nalong with later work on Multics, led the ACM to award Corbato its\nhighest honor , the T uring A ward. The scheduler has subsequently been\nre\ufb01ned throughout the years to the implementations you will encou nter\nin some modern systems.\nThe fundamental problem MLFQ tries to address is two-fold. Firs t, it\nwould like to optimize turnaround time , which, as we saw in the previous\nnote, is done by running shorter jobs \ufb01rst; unfortunately , the OS d oesn\u2019t\ngenerally know how long a job will run for , exactly the knowledge tha t\nalgorithms like SJF (or STCF) require. Second, MLFQ would like to mak e\na system feel responsive to interactive users (i.e., users si tting and staring\nat the screen, waiting for a process to \ufb01nish), and thus minimiz e response\ntime; unfortunately , algorithms like Round Robin reduce response tim e\nbut are terrible for turnaround time. Thus, our problem: given th at we\nin general do not know anything about a process, how can we build a\nscheduler to achieve these goals? How can the scheduler learn, as the\nsystem runs, the characteristics of the jobs it is running, and thus make\nbetter scheduling decisions?\nTH E CR U X :\nHO W TO SC H E D U L E WI T H O U T PE R F E C T KN O W L E D G E ?\nHow can we design a scheduler that both minimizes response time f or\ninteractive jobs while also minimizing turnaround time withou t a priori\nknowledge of job length?\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In this chapter , we\u2019ll tackle the problem of developing one of the mos t",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "chapter",
          "tackle",
          "problem",
          "developing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "well-known approaches to scheduling, known as the Multi-level Feed-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "well",
          "known",
          "approaches",
          "scheduling",
          "known",
          "multi",
          "level",
          "feed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "uler was \ufb01rst described by Corbato et al. in 1962 [C+62] in a sys tem",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "uler",
          "described",
          "corbato"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "known as the Compatible Time-Sharing System (CTSS), and this work,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "compatible",
          "time",
          "sharing",
          "system",
          "ctss",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "re\ufb01ned throughout the years to the implementations you will encou nter",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "throughout",
          "years",
          "implementations",
          "encou",
          "nter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "The fundamental problem MLFQ tries to address is two-fold. Firs t, it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "problem",
          "mlfq",
          "tries",
          "address",
          "fold",
          "firs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "generally know how long a job will run for , exactly the knowledge tha t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "generally",
          "know",
          "long",
          "exactly",
          "knowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "algorithms like SJF (or STCF) require. Second, MLFQ would like to mak e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "like",
          "stcf",
          "require",
          "second",
          "mlfq",
          "would",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "time; unfortunately , algorithms like Round Robin reduce response tim e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "time",
          "unfortunately",
          "algorithms",
          "like",
          "round",
          "robin",
          "reduce",
          "response"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "in general do not know anything about a process, how can we build a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "general",
          "know",
          "anything",
          "process",
          "build"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 8\nScheduling: The Multi-Level Feedback Queue",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8\nscheduling",
          "multi",
          "level",
          "feedback",
          "queue"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "1 MLFQ: Basic Rules",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "8.1 MLFQ: Basic Rules\nT o build such a scheduler , in this chapter we will describe th e basic\nalgorithms behind a multi-level feedback queue; although the speci\ufb01cs of\nmany implemented MLFQs differ [E95], most approaches are simi lar .\nIn our treatment, the MLFQ has a number of distinct queues, each\nassigned a different priority level. At any given time, a job that is ready\nto run is on a single queue. MLFQ uses priorities to decide which job\nshould run at a given time: a job with higher priority (i.e., a job on a\nhigher queue) is chosen to run.\nOf course, more than one job may be on a given queue, and thus have\nthe same priority . In this case, we will just use round-robin scheduling\namong those jobs.\nThus, we arrive at the \ufb01rst two basic rules for MLFQ:\n\u2022 Rule 1: If Priority(A) > Priority(B), A runs (B doesn\u2019t).\n\u2022 Rule 2: If Priority(A) = Priority(B), A & B run in RR.\nThe key to MLFQ scheduling therefore lies in how the scheduler s ets\npriorities. Rather than giving a \ufb01xed priority to each job, MLFQ varies\nthe priority of a job based on its observed behavior . If, for example, a job\nrepeatedly relinquishes the CPU while waiting for input from t he key-\nboard, MLFQ will keep its priority high, as this is how an interac tive\nprocess might behave. If, instead, a job uses the CPU intensive ly for long\nperiods of time, MLFQ will reduce its priority . In this way , MLFQ will try\nto learn about processes as they run, and thus use the history of the job to\npredict its future behavior .\nIf we were to put forth a picture of what the queues might look like a t\na given instant, we might see something like the following (Figu re 8.1).\nIn the \ufb01gure, two jobs (A and B) are at the highest priority level , while job\nC is in the middle and Job D is at the lowest priority . Given our curr ent\nknowledge of how MLFQ works, the scheduler would just alternate ti me\nslices between A and B because they are the highest priority job s in the\nsystem; poor jobs C and D would never even get to run \u2014 an outrage!\nOf course, just showing a static snapshot of some queues does not re-\nally give you an idea of how MLFQ works. What we need is to under-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o build such a scheduler , in this chapter we will describe th e basic",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "build",
          "scheduler",
          "chapter",
          "describe",
          "basic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "algorithms behind a multi-level feedback queue; although the speci\ufb01cs of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "behind",
          "multi",
          "level",
          "feedback",
          "queue",
          "although"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "many implemented MLFQs differ [E95], most approaches are simi lar .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "many",
          "implemented",
          "mlfqs",
          "differ",
          "approaches",
          "simi"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "to learn about processes as they run, and thus use the history of the job to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "processes",
          "thus",
          "history"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "knowledge of how MLFQ works, the scheduler would just alternate ti me",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowledge",
          "mlfq",
          "works",
          "scheduler",
          "would",
          "alternate"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand Rule 2: If Priority(A) = Priority(B), A & B run in RR.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 2",
          "priority",
          "priority"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand mlfq: basic rules",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "mlfq",
          "basic",
          "rules"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand rule 1: if priority(a) > priority(b), a runs (b doesn\u2019t).",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rule",
          "priority",
          "priority",
          "runs"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "2 Attempt #1: How T o Change Priority",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "8.2 Attempt #1: How T o Change Priority\nW e now must decide how MLFQ is going to change the priority level\nof a job (and thus which queue it is on) over the lifetime of a job. T o do\nthis, we must keep in mind our workload: a mix of interactive jobs th at\nare short-running (and may frequently relinquish the CPU), a nd some\nlonger-running \u201cCPU-bound\u201d jobs that need a lot of CPU time but whe re\nresponse time isn\u2019t important. Here is our \ufb01rst attempt at a priori ty-\nadjustment algorithm:\n\u2022 Rule 3: When a job enters the system, it is placed at the highest\npriority (the topmost queue).\n\u2022 Rule 4a: If a job uses up an entire time slice while running, its pri-\nority is reduced (i.e., it moves down one queue).\n\u2022 Rule 4b: If a job gives up the CPU before the time slice is up, it stays\nat the same priority level.\nExample 1: A Single Long-Running Job\nLet\u2019s look at some examples. First, we\u2019ll look at what happens when th ere\nhas been a long running job in the system. Figure 8.2 shows what ha ppens\nto this job over time in a three-queue scheduler .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "response time isn\u2019t important. Here is our \ufb01rst attempt at a priori ty-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "response",
          "time",
          "important",
          "attempt",
          "priori"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "adjustment algorithm:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "adjustment",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: How T o Change Priority",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "change",
          "priority"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand adjustment algorithm: \u2022 Rule 3: When a job enters the system, it is placed at the highest",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "adjustment algorithm",
          "rule",
          "enters",
          "system",
          "placed",
          "highest"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Rule 4a: If a job uses up an entire time slice while running, its pri-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 4a",
          "uses",
          "entire",
          "time",
          "slice",
          "running"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Rule 4b: If a job gives up the CPU before the time slice is up, it stays",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 4b",
          "gives",
          "time",
          "slice",
          "stays"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Example 1: A Single Long-Running Job",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "example 1",
          "single",
          "long",
          "running"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4\nSC H E D U L I N G :\nTH E MU LT I-L E V E L FE E D B A C K QU E U E\nQ2\nQ1\nQ0\n0 50 100 150 200\nFigure 8.2: Long-running Job Over Time\nAs you can see in the example, the job enters at the highest priori ty\n(Q2). After a single time-slice of 10 ms, the scheduler reduce s the job\u2019s\npriority by one, and thus the job is on Q1. After running at Q1 for a ti me\nslice, the job is \ufb01nally lowered to the lowest priority in the syst em (Q0),\nwhere it remains. Pretty simple, no?\nExample 2: Along Came A Short Job\nNow let\u2019s look at a more complicated example, and hopefully see how\nMLFQ tries to approximate SJF . In this example, there are two job s: A,\nwhich is a long-running CPU-intensive job, and B, which is a shor t-running\ninteractive job. Assume A has been running for some time, and the n B ar-\nrives. What will happen? Will MLFQ approximate SJF for B?\nFigure 8.3 plots the results of this scenario. A (shown in black) i s run-\nning along in the lowest-priority queue (as would any long-runnin g CPU-\nintensive jobs); B (shown in gray) arrives at time T = 100, and thus is\nQ0\nQ1\nQ2\n0 50 100 150 200\nFigure 8.3: Along Came An Interactive Job\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 2: Long-running Job Over Time",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "long",
          "running",
          "time"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Example 2: Along Came A Short Job",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "example 2",
          "along",
          "came",
          "short"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 3: Along Came An Interactive Job",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "along",
          "came",
          "interactive"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G :",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G :\nTH E MU LT I-L E V E L FE E D B A C K QU E U E 5\nQ0\nQ1\nQ2\n0 50 100 150 200\nFigure 8.4: A Mixed I/O-intensive and CPU-intensive W orkload\ninserted into the highest queue; as its run-time is short (only 20 ms), B\ncompletes before reaching the bottom queue, in two time slices; t hen A\nresumes running (at low priority).\nFrom this example, you can hopefully understand one of the major\ngoals of the algorithm: because it doesn\u2019t know whether a job will be a\nshort job or a long-running job, it \ufb01rst assumes it might be a short job, thus\ngiving the job high priority . If it actually is a short job, it will run quickly\nand complete; if it is not a short job, it will slowly move down the queu es,\nand thus soon prove itself to be a long-running more batch-like proc ess.\nIn this manner , MLFQ approximates SJF .\nExample 3: What About I/O?\nLet\u2019s now look at an example with some I/O. As Rule 4b states above, if a\nprocess gives up the processor before using up its time slice, we k eep it at\nthe same priority level. The intent of this rule is simple: if an interactive\njob, for example, is doing a lot of I/O (say by waiting for user input f rom\nthe keyboard or mouse), it will relinquish the CPU before its time slice is\ncomplete; in such case, we don\u2019t wish to penalize the job and thus s imply\nkeep it at the same level.\nFigure 8.4 shows an example of how this works, with an interactive job\nB (shown in gray) that needs the CPU only for 1 ms before performing a n\nI/O competing for the CPU with a long-running batch job A (shown in\nblack). The MLFQ approach keeps B at the highest priority becau se B\nkeeps releasing the CPU; if B is an interactive job, MLFQ furth er achieves\nits goal of running interactive jobs quickly .\nProblems With Our Current MLFQ\nW e thus have a basic MLFQ. It seems to do a fairly good job, sharing the\nCPU fairly between long-running jobs, and letting short or I/O-i ntensive\ninteractive jobs run quickly . Unfortunately , the approach we h ave devel-\noped thus far contains serious \ufb02aws. Can you think of any?\n(This is where you pause and think as deviously as you can)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "From this example, you can hopefully understand one of the major",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "hopefully",
          "understand",
          "major"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "goals of the algorithm: because it doesn\u2019t know whether a job will be a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goals",
          "algorithm",
          "know",
          "whether"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": ". The MLFQ approach keeps B at the highest priority becau se B",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mlfq",
          "approach",
          "keeps",
          "highest",
          "priority",
          "becau"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "its goal of running interactive jobs quickly .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goal",
          "running",
          "interactive",
          "jobs",
          "quickly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "interactive jobs run quickly . Unfortunately , the approach we h ave devel-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interactive",
          "jobs",
          "quickly",
          "unfortunately",
          "approach",
          "devel"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 4: A Mixed I/O-intensive and CPU-intensive W orkload",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "mixed",
          "intensive",
          "intensive",
          "orkload"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6\nSC H E D U L I N G :\nTH E MU LT I-L E V E L FE E D B A C K QU E U E\nQ2\nQ1\nQ0\n0 50 100 150 200\nQ2\nQ1\nQ0\n0 50 100 150 200\nFigure 8.5: Without (Left) and With (Right) Priority Boost\nFirst, there is the problem of starvation: if there are \u201ctoo many\u201d in-\nteractive jobs in the system, they will combine to consume all CPU time,\nand thus long-running jobs will never receive any CPU time (they starve).\nW e\u2019d like to make some progress on these jobs even in this scenario.\nSecond, a smart user could rewrite their program to game the sched-\nuler. Gaming the scheduler generally refers to the idea of doing some -\nthing sneaky to trick the scheduler into giving you more than you r fair\nshare of the resource. The algorithm we have described is suscep tible to\nthe following attack: before the time slice is over , issue an I/O op eration\n(to some \ufb01le you don\u2019t care about) and thus relinquish the CPU; doing so\nallows you to remain in the same queue, and thus gain a higher per cent-\nage of CPU time. When done right (e.g., by running for 99% of a time s lice\nbefore relinquishing the CPU), a job could nearly monopolize the CP U.\nFinally , a program may change its behavior over time; what was CPU-\nbound may transition to a phase of interactivity . With our curren t ap-\nproach, such a job would be out of luck and not be treated like the other\ninteractive jobs in the system.\nTI P : S C H E D U L I N G MU S T BE SE C U R E FR O M AT TA C K\nY ou might think that a scheduling policy , whether inside the OS itself\n(as discussed herein), or in a broader context (e.g., in a distri buted stor-\nage system\u2019s I/O request handling [Y+18]), is not a security concern, but\nin increasingly many cases, it is exactly that. Consider the m odern dat-\nacenter , in which users from around the world share CPUs, memorie s,\nnetworks, and storage systems; without care in policy design and en-\nforcement, a single user may be able to adversely harm others an d gain\nadvantage for itself. Thus, scheduling policy forms an importan t part of\nthe security of a system, and should be carefully constructed.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "share of the resource. The algorithm we have described is suscep tible to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "share",
          "resource",
          "algorithm",
          "described",
          "suscep",
          "tible"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "networks, and storage systems; without care in policy design and en-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "networks",
          "storage",
          "systems",
          "without",
          "care",
          "policy",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "forcement, a single user may be able to adversely harm others an d gain",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "forcement",
          "single",
          "user",
          "able",
          "adversely",
          "harm",
          "others",
          "gain"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Gaming the scheduler generally: the idea of doing some -",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "gaming the scheduler generally",
          "idea"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 5: Without (Left) and With (Right) Priority Boost",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "without",
          "left",
          "right",
          "priority",
          "boost"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand TI P: S C H E D U L I N G MU S T BE SE C U R E FR O M AT TA C K",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "3 Attempt #2: The Priority Boost",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "8.3 Attempt #2: The Priority Boost\nLet\u2019s try to change the rules and see if we can avoid the problem of\nstarvation. What could we do in order to guarantee that CPU-bound jobs\nwill make some progress (even if it is not much?).\nThe simple idea here is to periodically boost the priority of all the jobs\nin system. There are many ways to achieve this, but let\u2019s just d o some-\nthing simple: throw them all in the topmost queue; hence, a new ru le:\n\u2022 Rule 5: After some time period S, move all the jobs in the system\nto the topmost queue.\nOur new rule solves two problems at once. First, processes are gua r-\nanteed not to starve: by sitting in the top queue, a job will share the CPU\nwith other high-priority jobs in a round-robin fashion, and thus ev entu-\nally receive service. Second, if a CPU-bound job has become intera ctive,\nthe scheduler treats it properly once it has received the priori ty boost.\nLet\u2019s see an example. In this scenario, we just show the behavior of\na long-running job when competing for the CPU with two short-runni ng\ninteractive jobs. T wo graphs are shown in Figure 8.5 (page 6). O n the left,\nthere is no priority boost, and thus the long-running job gets star ved once\nthe two short jobs arrive; on the right, there is a priority boost eve ry 50\nms (which is likely too small of a value, but used here for the exam ple),\nand thus we at least guarantee that the long-running job will ma ke some\nprogress, getting boosted to the highest priority every 50 ms and thus\ngetting to run periodically .\nOf course, the addition of the time period S leads to the obvious ques-\ntion: what should S be set to? John Ousterhout, a well-regarded systems\nresearcher [O11], used to call such values in systems voo-doo constants,\nbecause they seemed to require some form of black magic to set the m cor-\nrectly . Unfortunately , S has that \ufb02avor . If it is set too high, long-running\njobs could starve; too low , and interactive jobs may not get a proper s hare\nof the CPU.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Our new rule solves two problems at once. First, processes are gua r-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rule",
          "solves",
          "problems",
          "first",
          "processes"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand thing simple: throw them all in the topmost queue; hence, a new ru le:",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "thing simple",
          "throw",
          "topmost",
          "queue",
          "hence"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Rule 5: After some time period S, move all the jobs in the system",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 5",
          "time",
          "period",
          "move",
          "jobs",
          "system"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand anteed not to starve: by sitting in the top queue, a job will share the CPU",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "anteed not to starve",
          "sitting",
          "queue",
          "share"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand tion: what should S be set to? John Ousterhout, a well-regarded systems",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "john",
          "ousterhout",
          "well",
          "regarded",
          "systems"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand attempt #2: the priority boost",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "attempt",
          "priority",
          "boost"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "4 Attempt #3: Better Accounting",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "8.4 Attempt #3: Better Accounting\nW e now have one more problem to solve: how to prevent gaming of\nour scheduler? The real culprit here, as you might have guessed , are\nRules 4a and 4b, which let a job retain its priority by relinquis hing the\nCPU before the time slice expires. So what should we do?\nThe solution here is to perform better accounting of CPU time at each\nlevel of the MLFQ. Instead of forgetting how much of a time slice a pr o-\ncess used at a given level, the scheduler should keep track; onc e a process\nhas used its allotment, it is demoted to the next priority queue. Whether\nit uses the time slice in one long burst or many small ones does not mat ter .\nW e thus rewrite Rules 4a and 4b to the following single rule:\n\u2022 Rule 4: Once a job uses up its time allotment at a given level (re-\ngardless of how many times it has given up the CPU), its priority i s\nreduced (i.e., it moves down one queue).\nLet\u2019s look at an example. Figure 8.6 (page 7) shows what happens\nwhen a workload tries to game the scheduler with the old Rules 4a a nd 4b\n(on the left) as well the new anti-gaming Rule 4. Without any prot ection\nfrom gaming, a process can issue an I/O just before a time slice en ds and\nthus dominate CPU time. With such protections in place, regardl ess of\nthe I/O behavior of the process, it slowly moves down the queues, and\nthus cannot gain an unfair share of the CPU.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e now have one more problem to solve: how to prevent gaming of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "solve",
          "prevent",
          "gaming"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand attempt #3: better accounting",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "attempt",
          "better",
          "accounting"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand rule 4: once a job uses up its time allotment at a given level (re-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rule",
          "uses",
          "time",
          "allotment",
          "given",
          "level"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "8",
    "title": "5 T uning MLFQ And Other Issues",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "8.5 T uning MLFQ And Other Issues\nA few other issues arise with MLFQ scheduling. One big question is\nhow to parameterize such a scheduler . For example, how many queues\nshould there be? How big should the time slice be per queue? How ofte n\nshould priority be boosted in order to avoid starvation and account for\nchanges in behavior? There are no easy answers to these questi ons, and\nthus only some experience with workloads and subsequent tuning of the\nscheduler will lead to a satisfactory balance.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand t uning mlfq and other issues",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "uning",
          "mlfq",
          "issues"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G :",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G :\nTH E MU LT I-L E V E L FE E D B A C K QU E U E 9\nTI P : A V O I D VO O-D O O CO N S TA N T S (O U S T E R H O U T \u2019 S LAW)\nA voiding voo-doo constants is a good idea whenever possible. Unfor-\ntunately , as in the example above, it is often dif\ufb01cult. One coul d try to\nmake the system learn a good value, but that too is not straightforw ard.\nThe frequent result: a con\ufb01guration \ufb01le \ufb01lled with default par ameter val-\nues that a seasoned administrator can tweak when something isn\u2019t quite\nworking correctly . As you can imagine, these are often left unmodi \ufb01ed,\nand thus we are left to hope that the defaults work well in the \ufb01el d. This\ntip brought to you by our old OS professor , John Ousterhout, and hence\nwe call it Ousterhout\u2019s Law.\nFor example, most MLFQ variants allow for varying time-slice len gth\nacross different queues. The high-priority queues are usuall y given short\ntime slices; they are comprised of interactive jobs, after all, and thus\nquickly alternating between them makes sense (e.g., 10 or few er millisec-\nonds). The low-priority queues, in contrast, contain long-runnin g jobs\nthat are CPU-bound; hence, longer time slices work well (e.g., 1 00s of\nms). Figure 8.7 (page 8) shows an example in which two jobs run for 20\nms at the highest queue (with a 10-ms time slice), 40 ms in the m iddle\n(20-ms time slice), and with a 40-ms time slice at the lowest.\nThe Solaris MLFQ implementation \u2014 the Time-Sharing scheduling\nclass, or TS \u2014 is particularly easy to con\ufb01gure; it provides a set of tables\nthat determine exactly how the priority of a process is altered th rough-\nout its lifetime, how long each time slice is, and how often to boost th e\npriority of a job [AD00]; an administrator can muck with this tabl e in or-\nder to make the scheduler behave in different ways. Default v alues for\nthe table are 60 queues, with slowly increasing time-slice le ngths from\n20 milliseconds (highest priority) to a few hundred millisecon ds (lowest),\nand priorities boosted around every 1 second or so.\nOther MLFQ schedulers don\u2019t use a table or the exact rules descri bed\nin this chapter; rather they adjust priorities using mathema tical formu-\nlae. For example, the FreeBSD scheduler (version 4.3) uses a form ula to\ncalculate the current priority level of a job, basing it on how much CPU\nthe process has used [LM+89]; in addition, usage is decayed over time,\nproviding the desired priority boost in a different manner than d escribed\nherein. See Epema\u2019s paper for an excellent overview of such decay-usage\nalgorithms and their properties [E95].\nFinally , many schedulers have a few other features that you mig ht en-\ncounter . For example, some schedulers reserve the highest prior ity levels\nfor operating system work; thus typical user jobs can never obtain the\nhighest levels of priority in the system. Some systems also allow s ome\nuser advice to help set priorities; for example, by using the command-line\nutility nice you can increase or decrease the priority of a job (somewhat)\nand thus increase or decrease its chances of running at any give n time.\nSee the man page for more.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "make the system learn a good value, but that too is not straightforw ard.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "system",
          "learn",
          "good",
          "value",
          "straightforw"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": ". The low-priority queues, in contrast, contain long-runnin g jobs",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "priority",
          "queues",
          "contrast",
          "contain",
          "long",
          "runnin",
          "jobs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The Solaris MLFQ implementation \u2014 the Time-Sharing scheduling",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "solaris",
          "mlfq",
          "implementation",
          "time",
          "sharing",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "algorithms and their properties [E95].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "properties"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: A V O I D VO O-D O O CO N S TA N T S (O U S T E R H O U T \u2019 S LAW)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand The frequent result: a con\ufb01guration \ufb01le \ufb01lled with default par ameter val-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the frequent result",
          "default",
          "ameter"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "6 MLFQ: Summary",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "8.6 MLFQ: Summary\nW e have described a scheduling approach known as the Multi-Lev el\nFeedback Queue (MLFQ). Hopefully you can now see why it is called\nthat: it has multiple levels of queues, and uses feedback to determine the\npriority of a given job. History is its guide: pay attention to how job s\nbehave over time and treat them accordingly .\nThe re\ufb01ned set of MLFQ rules, spread throughout the chapter , are re-\nproduced here for your viewing pleasure:\n\u2022 Rule 1: If Priority(A) > Priority(B), A runs (B doesn\u2019t).\n\u2022 Rule 2: If Priority(A) = Priority(B), A & B run in round-robin fash-\nion using the time slice (quantum length) of the given queue.\n\u2022 Rule 3: When a job enters the system, it is placed at the highest\npriority (the topmost queue).\n\u2022 Rule 4: Once a job uses up its time allotment at a given level (re-\ngardless of how many times it has given up the CPU), its priority i s\nreduced (i.e., it moves down one queue).\n\u2022 Rule 5: After some time period S, move all the jobs in the system\nto the topmost queue.\nMLFQ is interesting for the following reason: instead of demandin g\na priori knowledge of the nature of a job, it observes the execution of a\njob and prioritizes it accordingly . In this way , it manages to ac hieve the\nbest of both worlds: it can deliver excellent overall performance (similar\nto SJF/STCF) for short-running interactive jobs, and is fair and m akes\nprogress for long-running CPU-intensive workloads. For this reas on,\nmany systems, including BSD U N I X derivatives [LM+89, B86], Solaris\n[M06], and Windows NT and subsequent Windows operating systems\n[CS97] use a form of MLFQ as their base scheduler .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have described a scheduling approach known as the Multi-Lev el",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "scheduling",
          "approach",
          "known",
          "multi"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a priori knowledge of the nature of a job, it observes the execution of a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "priori",
          "knowledge",
          "nature",
          "observes",
          "execution"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand History is its guide: pay attention to how job s",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "history is its guide",
          "attention"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Rule 2: If Priority(A) = Priority(B), A & B run in round-robin fash-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 2",
          "priority",
          "priority",
          "round",
          "robin",
          "fash"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Rule 3: When a job enters the system, it is placed at the highest",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 3",
          "enters",
          "system",
          "placed",
          "highest"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Rule 4: Once a job uses up its time allotment at a given level (re-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 4",
          "uses",
          "time",
          "allotment",
          "given",
          "level"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Rule 5: After some time period S, move all the jobs in the system",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rule 5",
          "time",
          "period",
          "move",
          "jobs",
          "system"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand mlfq: summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "mlfq",
          "summary"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand rule 1: if priority(a) > priority(b), a runs (b doesn\u2019t).",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rule",
          "priority",
          "priority",
          "runs"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G :",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G :\nTH E MU LT I-L E V E L FE E D B A C K QU E U E 11\nReferences\n[AD00] \u201cMultilevel Feedback Queue Scheduling in Solaris\u201d by Andrea A rpaci-Dusseau. A vail-\nable: http://www .ostep.org/Citations/notes-solaris.pdf. A great short set of notes by one of the\nauthors on the details of the Solaris scheduler . OK, we are probably biased in th is description, but the\nnotes are pretty darn good.\n[B86] \u201cThe Design of the U N I X Operating System\u201d by M.J. Bach. Prentice-Hall, 1986. One of the\nclassic old books on how a real UN I X operating system is built; a de\ufb01nite must-read for kernel hackers.\n[C+62] \u201cAn Experimental Time-Sharing System\u201d by F . J. Corbato, M. M. D aggett, R. C. Daley .\nIFIPS 1962. A bit hard to read, but the source of many of the \ufb01rst ideas in multi-level fee dback schedul-\ning. Much of this later went into Multics, which one could argue was the most in\ufb02uential operating\nsystem of all time.\n[CS97] \u201cInside Windows NT\u201d by Helen Custer and David A. Solomon. Micro soft Press, 1997.\nThe NT book, if you want to learn about something other than UN I X. Of course, why would you? OK,\nwe\u2019re kidding; you might actually work for Microsoft some day you know.\n[E95] \u201cAn Analysis of Decay-Usage Scheduling in Multiprocessors\u201d by D .H.J. Epema. SIG-\nMETRICS \u201995. A nice paper on the state of the art of scheduling back in the mid 1990s, inclu ding a\ngood overview of the basic approach behind decay-usage schedulers.\n[LM+89] \u201cThe Design and Implementation of the 4.3BSD U N I X Operating System\u201d by S.J. Lef-\n\ufb02er , M.K. McKusick, M.J. Karels, J.S. Quarterman. Addison-W esley , 1989 . Another OS classic,\nwritten by four of the main people behind BSD. The later versions of this book, w hile more up to date,\ndon\u2019t quite match the beauty of this one.\n[M06] \u201cSolaris Internals: Solaris 10 and OpenSolaris Kernel Architectu re\u201d by Richard Mc-\nDougall. Prentice-Hall, 2006. A good book about Solaris and how it works.\n[O11] \u201cJohn Ousterhout\u2019s Home Page\u201d by John Ousterhout. www.stanford.edu/\u02dcouster/.\nThe home page of the famous Professor Ousterhout. The two co-authors of this book had the pleasure of\ntaking graduate operating systems from Ousterhout while in graduate school; ind eed, this is where the\ntwo co-authors got to know each other , eventually leading to marriage, kids, and even this book. Thus,\nyou really can blame Ousterhout for this entire mess you\u2019re in.\n[P+95] \u201cInformed Prefetching and Caching\u201d by R.H. Patterson, G.A. Gibson, E. G inting, D.\nStodolsky , J. Zelenka. SOSP \u201995, Copper Mountain, Colorado, October 1995. A fun paper about\nsome very cool ideas in \ufb01le systems, including how applications can give th e OS advice about what \ufb01les\nit is accessing and how it plans to access them.\n[Y+18] \u201cPrincipled Schedulability Analysis for Distributed Storag e Systems using Thread Ar-\nchitecture Models\u201d by Suli Y ang, Jing Liu, Andrea C. Arpaci-Dusseau, Re mzi H. Arpaci-\nDusseau. OSDI \u201918, San Diego, California. A recent work of our group that demonstrates the\ndif\ufb01culty of scheduling I/O requests within modern distributed storage systems such as Hive/HDFS,\nCassandra, MongoDB, and Riak. Without care, a single user might be able to mon opolize system re-\nsources.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[B86] \u201cThe Design of the U N I X Operating System\u201d by M.J. Bach. Prentice-Hall, 1986. One of the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "operating",
          "system",
          "bach",
          "prentice",
          "hall"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The NT book, if you want to learn about something other than UN I X. Of course, why would you? OK,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "book",
          "want",
          "learn",
          "something",
          "course",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "we\u2019re kidding; you might actually work for Microsoft some day you know.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "kidding",
          "might",
          "actually",
          "work",
          "microsoft",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "good overview of the basic approach behind decay-usage schedulers.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "good",
          "overview",
          "basic",
          "approach",
          "behind",
          "decay",
          "usage",
          "schedulers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[LM+89] \u201cThe Design and Implementation of the 4.3BSD U N I X Operating System\u201d by S.J. Lef-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "implementation",
          "operating",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "two co-authors got to know each other , eventually leading to marriage, kids, and even this book. Thus,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "authors",
          "know",
          "eventually",
          "leading",
          "marriage",
          "kids",
          "even",
          "book"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "[Y+18] \u201cPrincipled Schedulability Analysis for Distributed Storag e Systems using Thread Ar-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "principled",
          "schedulability",
          "analysis",
          "distributed",
          "storag",
          "systems",
          "using",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "Dusseau. OSDI \u201918, San Diego, California. A recent work of our group that demonstrates the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "dusseau",
          "osdi",
          "diego",
          "california",
          "recent",
          "work",
          "group",
          "demonstrates"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "Cassandra, MongoDB, and Riak. Without care, a single user might be able to mon opolize system re-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "cassandra",
          "mongodb",
          "riak",
          "without",
          "care",
          "single",
          "user",
          "might"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand able: http://www .ostep.org/Citations/notes-solaris.pdf. A great short set of notes by one of the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "http",
          "ostep",
          "citations",
          "notes",
          "solaris",
          "great",
          "short",
          "notes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Solaris Internals: Solaris 10 and OpenSolaris Kernel Architectu re\u201d by Richard Mc-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "solaris internals",
          "solaris",
          "opensolaris",
          "kernel",
          "architectu",
          "richard"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Run a few randomly-generated problems with just two jobs and",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1. Run a few randomly-generated problems with just two jobs and\ntwo queues; compute the MLFQ execution trace for each. Make\nyour life easier by limiting the length of each job and turning off\nI/Os.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "How would you run the scheduler to reproduce each of the exam-",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "2. How would you run the scheduler to reproduce each of the exam-\nples in the chapter?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "How would you con\ufb01gure the scheduler parameters to behave just",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "3. How would you con\ufb01gure the scheduler parameters to behave just\nlike a round-robin scheduler?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Craft a workload with two jobs and scheduler parameters so tha t",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "4. Craft a workload with two jobs and scheduler parameters so tha t\none job takes advantage of the older Rules 4a and 4b (turned on\nwith the -S \ufb02ag) to game the scheduler and obtain 99% of the CPU\nover a particular time interval.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "5",
    "title": "Given a system with a quantum length of 10 ms in its highest qu eue,",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "5. Given a system with a quantum length of 10 ms in its highest qu eue,\nhow often would you have to boost jobs back to the highest priority\nlevel (with the -B \ufb02ag) in order to guarantee that a single long-\nrunning (and potentially-starving) job gets at least 5% of the C PU?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "6",
    "title": "One question that arises in scheduling is which end of a queue to",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "6. One question that arises in scheduling is which end of a queue to\nadd a job that just \ufb01nished I/O; the -I \ufb02ag changes this behavior\nfor this scheduling simulator . Play around with some workloads\nand see if you can see the effect of this \ufb02ag.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "1 Basic Concept: Tickets Represent Y our Share",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "9.1 Basic Concept: Tickets Represent Y our Share\nUnderlying lottery scheduling is one very basic concept: tickets, which\nare used to represent the share of a resource that a process (or use r or\nwhatever) should receive. The percent of tickets that a process has repre-\nsents its share of the system resource in question.\nLet\u2019s look at an example. Imagine two processes, A and B, and furth er\nthat A has 75 tickets while B has only 25. Thus, what we would like is for\nA to receive 75% of the CPU and B the remaining 25%.\nLottery scheduling achieves this probabilistically (but not d eterminis-\ntically) by holding a lottery every so often (say , every time sli ce). Holding\na lottery is straightforward: the scheduler must know how many tot al\ntickets there are (in our example, there are 100). The schedul er then picks\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Basic Concept: Tickets Represent Y our Share",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "concept",
          "tickets",
          "represent",
          "share"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Underlying lottery scheduling is one very basic concept: tickets, which",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "underlying",
          "lottery",
          "scheduling",
          "basic",
          "concept",
          "tickets"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "a lottery is straightforward: the scheduler must know how many tot al",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lottery",
          "straightforward",
          "scheduler",
          "must",
          "know",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1 Basic Concept: Tickets Represent Y our Share",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 basic concept",
          "tickets",
          "represent",
          "share"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S C H E D U L I N G : P R O P O RT I O N A L SH ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S C H E D U L I N G : P R O P O RT I O N A L SH A R E\nTI P : U S E RA N D O M N E S S\nOne of the most beautiful aspects of lottery scheduling is its use of ran-\ndomness. When you have to make a decision, using such a randomized\napproach is often a robust and simple way of doing so.\nRandom approaches has at least three advantages over more tradit ional\ndecisions. First, random often avoids strange corner-case behav iors that\na more traditional algorithm may have trouble handling. For examp le,\nconsider the LRU replacement policy (studied in more detail in a future\nchapter on virtual memory); while often a good replacement algorit hm,\nLRU attains worst-case performance for some cyclic-sequential work-\nloads. Random, on the other hand, has no such worst case.\nSecond, random also is lightweight, requiring little state to t rack alter-\nnatives. In a traditional fair-share scheduling algorithm, t racking how\nmuch CPU each process has received requires per-process accoun ting,\nwhich must be updated after running each process. Doing so rand omly\nnecessitates only the most minimal of per-process state (e.g., t he number\nof tickets each has).\nFinally , random can be quite fast. As long as generating a random num-\nber is quick, making the decision is also, and thus random can be u sed\nin a number of places where speed is required. Of course, the fas ter the\nneed, the more random tends towards pseudo-random.\na winning ticket, which is a number from 0 to 99 1 . Assuming A holds\ntickets 0 through 74 and B 75 through 99, the winning ticket simp ly de-\ntermines whether A or B runs. The scheduler then loads the state of that\nwinning process and runs it.\nHere is an example output of a lottery scheduler \u2019s winning ticket s:\n63 85 70 39 76 17 29 41 36 39 10 99 68 83 63 62 43 0 49\nHere is the resulting schedule:\nA A A A A A A A A A A A A A A\nB B B B\nAs you can see from the example, the use of randomness in lottery\nscheduling leads to a probabilistic correctness in meeting th e desired pro-\nportion, but no guarantee. In our example above, B only gets to run 4 out\nof 20 time slices (20%), instead of the desired 25% allocation. How ever ,\nthe longer these two jobs compete, the more likely they are to achi eve the\ndesired percentages.\n1 Computer Scientists always start counting at 0. It is so odd to non-comp uter-types that\nfamous people have felt obliged to write about why we do it this way [D 82].\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "approach is often a robust and simple way of doing so.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "often",
          "robust",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Random approaches has at least three advantages over more tradit ional",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "random",
          "approaches",
          "least",
          "three",
          "advantages",
          "tradit",
          "ional"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "a more traditional algorithm may have trouble handling. For examp le,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "traditional",
          "algorithm",
          "trouble",
          "handling",
          "examp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "natives. In a traditional fair-share scheduling algorithm, t racking how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "natives",
          "traditional",
          "fair",
          "share",
          "scheduling",
          "algorithm",
          "racking"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: U S E RA N D O M N E S S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand s winning ticket s: 63 85 70 39 76 17 29 41 36 39 10 99 68 83 63 62 43 0 49",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s winning ticket s"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "2 Ticket Mechanisms",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "9.2 Ticket Mechanisms\nLottery scheduling also provides a number of mechanisms to mani p-\nulate tickets in different and sometimes useful ways. One way is with\nthe concept of ticket currency . Currency allows a user with a set of tick-\nets to allocate tickets among their own jobs in whatever currency they\nwould like; the system then automatically converts said curren cy into the\ncorrect global value.\nFor example, assume users A and B have each been given 100 ticke ts.\nUser A is running two jobs, A1 and A2, and gives them each 500 tic kets\n(out of 1000 total) in A \u2019s currency . User B is running only 1 job and gi ves\nit 10 tickets (out of 10 total). The system converts A1\u2019s and A2\u2019s all ocation\nfrom 500 each in A \u2019s currency to 50 each in the global currency; si milarly ,\nB1\u2019s 10 tickets is converted to 100 tickets. The lottery is then h eld over the\nglobal ticket currency (200 total) to determine which job runs.\nUser A -> 500 (A\u2019s currency) to A1 -> 50 (global currency)\n-> 500 (A\u2019s currency) to A2 -> 50 (global currency)\nUser B -> 10 (B\u2019s currency) to B1 -> 100 (global currency)\nAnother useful mechanism is ticket transfer . With transfers, a process\ncan temporarily hand off its tickets to another process. This abi lity is\nespecially useful in a client/server setting, where a clien t process sends\na message to a server asking it to do some work on the client\u2019s behal f.\nT o speed up the work, the client can pass the tickets to the serv er and\nthus try to maximize the performance of the server while the ser ver is\nhandling the client\u2019s request. When \ufb01nished, the server then transfers the\ntickets back to the client and all is as before.\nFinally , ticket in\ufb02ation can sometimes be a useful technique. With\nin\ufb02ation, a process can temporarily raise or lower the number of tic kets\nit owns. Of course, in a competitive scenario with processes that do not\ntrust one another , this makes little sense; one greedy process cou ld give\nitself a vast number of tickets and take over the machine. Rathe r , in\ufb02ation\ncan be applied in an environment where a group of processes trust on e\nanother; in such a case, if any one process knows it needs more CPU ti me,\nit can boost its ticket value as a way to re\ufb02ect that need to the sy stem, all\nwithout communicating with any other processes.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the concept of ticket currency . Currency allows a user with a set of tick-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concept",
          "ticket",
          "currency",
          "currency",
          "allows",
          "user",
          "tick"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Finally , ticket in\ufb02ation can sometimes be a useful technique. With",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "ticket",
          "sometimes",
          "useful",
          "technique"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "another; in such a case, if any one process knows it needs more CPU ti me,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "another",
          "case",
          "process",
          "knows",
          "needs"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand ticket mechanisms",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ticket",
          "mechanisms"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand > 500 (a\u2019s currency) to a2 -> 50 (global currency)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "currency",
          "global",
          "currency"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "3 Implementation",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "9.3 Implementation\nProbably the most amazing thing about lottery scheduling is the s im-\nplicity of its implementation. All you need is a good random number\ngenerator to pick the winning ticket, a data structure to trac k the pro-\ncesses of the system (e.g., a list), and the total number of ticke ts.\nLet\u2019s assume we keep the processes in a list. Here is an example c om-\nprised of three processes, A, B, and C, each with some number of tic kets.\nhead Job:A\nTix:100\nJob:B\nTix:50\nJob:C\nTix:250 NULL\nT o make a scheduling decision, we \ufb01rst have to pick a random numb er\n(the winner) from the total number of tickets (400) 2 Let\u2019s say we pick the\nnumber 300. Then, we simply traverse the list, with a simple c ounter\nused to help us \ufb01nd the winner (Figure 9.1).\nThe code walks the list of processes, adding each ticket value to counter\nuntil the value exceeds winner. Once that is the case, the current list el-\nement is the winner . With our example of the winning ticket bein g 300,\nthe following takes place. First, counter is incremented to 100 to ac-\ncount for A \u2019s tickets; because 100 is less than 300, the loop continu es.\nThen counter would be updated to 150 (B\u2019s tickets), still less than 300\nand thus again we continue. Finally , counter is updated to 400 (clearly\ngreater than 300), and thus we break out of the loop with current point-\ning at C (the winner).\n2 Surprisingly , as pointed out by Bj \u00a8orn Lindberg, this can be challenging to do\ncorrectly; for more details, see http://stackoverflow.com/questions/2509679/\nhow-to-generate-a-random-number-from-within-a-range.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Implementation",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "plicity of its implementation. All you need is a good random number",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "plicity",
          "implementation",
          "need",
          "good",
          "random",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_7",
        "text": "understand see http: //stackoverflow.com/questions/2509679/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "see http",
          "stackoverflow",
          "questions"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand implementation",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "implementation"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "0",
    "title": "0",
    "document_source": "book.pdf",
    "start_line": 2,
    "type": "chapter",
    "content": "0.0",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "0",
    "title": "2",
    "document_source": "book.pdf",
    "start_line": 3,
    "type": "chapter",
    "content": "0.2",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "0",
    "title": "4",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "0.4",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "0",
    "title": "6",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "0.6",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "0",
    "title": "8",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "0.8",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "1",
    "title": "0",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1.0\nJob Length\nUnfairness\nFigure 9.2: Lottery Fairness Study\nT o make this process most ef\ufb01cient, it might generally be best t o or-\nganize the list in sorted order , from the highest number of ticket s to the\nlowest. The ordering does not affect the correctness of the algorith m;\nhowever , it does ensure in general that the fewest number of list itera-\ntions are taken, especially if there are a few processes that pos sess most\nof the tickets.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 2: Lottery Fairness Study",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "lottery",
          "fairness",
          "study"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_7",
    "number": "9",
    "title": "4 An Example",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "9.4 An Example\nT o make the dynamics of lottery scheduling more understandable , we\nnow perform a brief study of the completion time of two jobs competing\nagainst one another , each with the same number of tickets (100) a nd same\nrun time ( R, which we will vary).\nIn this scenario, we\u2019d like for each job to \ufb01nish at roughly the same\ntime, but due to the randomness of lottery scheduling, sometimes one\njob \ufb01nishes before the other . T o quantify this difference, we de \ufb01ne a\nsimple unfairness metric , U which is simply the time the \ufb01rst job com-\npletes divided by the time that the second job completes. For exam ple,\nif R = 10, and the \ufb01rst job \ufb01nishes at time 10 (and the second job at 20),\nU = 10\n20 = 0.5. When both jobs \ufb01nish at nearly the same time, U will be\nquite close to 1. In this scenario, that is our goal: a perfectly fa ir scheduler\nwould achieve U = 1.\nFigure 9.2 plots the average unfairness as the length of the two jobs\n(R) is varied from 1 to 1000 over thirty trials (results are genera ted via the\nsimulator provided at the end of the chapter). As you can see from th e\ngraph, when the job length is not very long, average unfairness c an be\nquite severe. Only as the jobs run for a signi\ufb01cant number of time slices\ndoes the lottery scheduler approach the desired outcome.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o make the dynamics of lottery scheduling more understandable , we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "dynamics",
          "lottery",
          "scheduling",
          "understandable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "quite close to 1. In this scenario, that is our goal: a perfectly fa ir scheduler",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quite",
          "close",
          "scenario",
          "goal",
          "perfectly",
          "scheduler"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "does the lottery scheduler approach the desired outcome.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lottery",
          "scheduler",
          "approach",
          "desired",
          "outcome"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand that is our goal: a perfectly fa ir scheduler",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "that is our goal",
          "perfectly",
          "scheduler"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand an example",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "5 How T o Assign Tickets?",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "9.5 How T o Assign Tickets?\nOne problem we have not addressed with lottery scheduling is: how\nto assign tickets to jobs? This problem is a tough one, because of cou rse\nhow the system behaves is strongly dependent on how tickets are al lo-\ncated. One approach is to assume that the users know best; in suc h a\ncase, each user is handed some number of tickets, and a user can a llocate\ntickets to any jobs they run as desired. However , this solution is a non-\nsolution: it really doesn\u2019t tell you what to do. Thus, given a set of job s,\nthe \u201cticket-assignment problem\u201d remains open.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "cated. One approach is to assume that the users know best; in suc h a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cated",
          "approach",
          "assume",
          "users",
          "know",
          "best"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand solution: it really doesn\u2019t tell you what to do. Thus, given a set of job s,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "really",
          "tell",
          "thus",
          "given"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand how t o assign tickets?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assign",
          "tickets"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "9",
    "title": "6 Why Not Deterministic?",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "9.6 Why Not Deterministic?\nY ou might also be wondering: why use randomness at all? As we saw\nabove, while randomness gets us a simple (and approximately corr ect)\nscheduler , it occasionally will not deliver the exact right prop ortions, es-\npecially over short time scales. For this reason, W aldspurger in vented\nstride scheduling , a deterministic fair-share scheduler [W95].\nStride scheduling is also straightforward. Each job in the syst em has\na stride, which is inverse in proportion to the number of tickets i t has. In\nour example above, with jobs A, B, and C, with 100, 50, and 250 tick ets,\nrespectively , we can compute the stride of each by dividing some large\nnumber by the number of tickets each process has been assigned. For\nexample, if we divide 10,000 by each of those ticket values, we ob tain\nthe following stride values for A, B, and C: 100, 200, and 40. W e ca ll\nthis value the stride of each process; every time a process runs, we will\nincrement a counter for it (called its pass value) by its stride to track its\nglobal progress.\nThe scheduler then uses the stride and pass to determine whic h pro-\ncess should run next. The basic idea is simple: at any given tim e, pick\nthe process to run that has the lowest pass value so far; when you r un\na process, increment its pass counter by its stride. A pseudocode imple-\nmentation is provided by W aldspurger [W95]:\ncurr = remove_min(queue); // pick client with min pass\nschedule(curr); // run for quantum\ncurr->pass += curr->stride; // update pass using stride\ninsert(queue, curr); // return curr to queue\nIn our example, we start with three processes (A, B, and C), with stride\nvalues of 100, 200, and 40, and all with pass values initially a t 0. Thus, at\n\ufb01rst, any of the processes might run, as their pass values are eq ually low .\nAssume we pick A (arbitrarily; any of the processes with equal l ow pass\nvalues can be chosen). A runs; when \ufb01nished with the time slice , we\nupdate its pass value to 100. Then we run B, whose pass value is t hen\nset to 200. Finally , we run C, whose pass value is incremented t o 40. At\nthis point, the algorithm will pick the lowest pass value, which is C\u2019s, and\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "this point, the algorithm will pick the lowest pass value, which is C\u2019s, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "point",
          "algorithm",
          "pick",
          "lowest",
          "pass",
          "value"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand and C: 100, 200, and 40. W e ca ll",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and c"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand why not deterministic?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "deterministic"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "7 The Linux Completely Fair Scheduler (CFS)",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "9.7 The Linux Completely Fair Scheduler (CFS)\nDespite these earlier works in fair-share scheduling, the cu rrent Linux\napproach achieves similar goals in an alternate manner . The sc heduler ,\nentitled the Completely Fair Scheduler (or CFS) [J09], implements fair-\nshare scheduling, but does so in a highly ef\ufb01cient and scalabl e manner .\nT o achieve its ef\ufb01ciency goals, CFS aims to spend very little t ime mak-\ning scheduling decisions, through both its inherent design and its clever\nuse of data structures well-suited to the task. Recent studie s have shown\nthat scheduler ef\ufb01ciency is surprisingly important; speci\ufb01 cally , in a study\nof Google datacenters, Kanev et al. show that even after aggressi ve opti-\nmization, scheduling uses about 5% of overall datacenter CPU tim e. Re-\nducing that overhead as much as possible is thus a key goal in moder n\nscheduler architecture.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "approach achieves similar goals in an alternate manner . The sc heduler ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "achieves",
          "similar",
          "goals",
          "alternate",
          "manner",
          "heduler"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "entitled the Completely Fair Scheduler (or CFS) [J09], implements fair-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "entitled",
          "completely",
          "fair",
          "scheduler",
          "implements",
          "fair"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T o achieve its ef\ufb01ciency goals, CFS aims to spend very little t ime mak-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "achieve",
          "goals",
          "aims",
          "spend",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ing scheduling decisions, through both its inherent design and its clever",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "scheduling",
          "decisions",
          "inherent",
          "design",
          "clever"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "that scheduler ef\ufb01ciency is surprisingly important; speci\ufb01 cally , in a study",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "scheduler",
          "surprisingly",
          "important",
          "cally",
          "study"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "ducing that overhead as much as possible is thus a key goal in moder n",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ducing",
          "overhead",
          "much",
          "possible",
          "thus",
          "goal",
          "moder"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the linux completely fair scheduler (cfs)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "linux",
          "completely",
          "fair",
          "scheduler"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 S C H E D U L I N G : P R O P O RT I O N A L SH ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 S C H E D U L I N G : P R O P O RT I O N A L SH A R E\n0 50 100 150 200 250\nTime\nA B C D A B C D A B A B A B\nFigure 9.4: CFS Simple Example\nBasic Operation\nWhereas most schedulers are based around the concept of a \ufb01xed tim e\nslice, CFS operates a bit differently . Its goal is simple: to fa irly divide a\nCPU evenly among all competing processes. It does so through a simp le\ncounting-based technique known as virtual runtime (vruntime).\nAs each process runs, it accumulates vruntime. In the most basic\ncase, each process\u2019s vruntime increases at the same rate, in proportion\nwith physical (real) time. When a scheduling decision occurs, CFS will\npick the process with the lowest vruntime to run next.\nThis raises a question: how does the scheduler know when to stop\nthe currently running process, and run the next one? The tension here is\nclear: if CFS switches too often, fairness is increased, as CFS will ensure\nthat each process receives its share of CPU even over miniscule t ime win-\ndows, but at the cost of performance (too much context switching); i f CFS\nswitches less often, performance is increased (reduced contex t switching),\nbut at the cost of near-term fairness.\nCFS manages this tension through various control parameters. The\n\ufb01rst is sched\nlatency. CFS uses this value to determine how long one\nprocess should run before considering a switch (effectively det ermining\nits time slice but in a dynamic fashion). A typical sched latency value\nis 48 (milliseconds); CFS divides this value by the number ( n) of processes\nrunning on the CPU to determine the time slice for a process, and t hus\nensures that over this period of time, CFS will be completely fair .\nFor example, if there are n = 4 processes running, CFS divides the\nvalue of sched latency by n to arrive at a per-process time slice of 12\nms. CFS then schedules the \ufb01rst job and runs it until it has used 12 ms\nof (virtual) runtime, and then checks to see if there is a job wit h lower\nvruntime to run instead. In this case, there is, and CFS would switch\nto one of the three other jobs, and so forth. Figure 9.4 shows an examp le\nwhere the four jobs (A, B, C, D) each run for two time slices in this fashion;\ntwo of them (C, D) then complete, leaving just two remaining, wh ich then\neach run for 24 ms in round-robin fashion.\nBut what if there are \u201ctoo many\u201d processes running? W ouldn\u2019t that\nlead to too small of a time slice, and thus too many context switche s?\nGood question! And the answer is yes.\nT o address this issue, CFS adds another parameter , min granularity,\nwhich is usually set to a value like 6 ms. CFS will never set the time slice\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Whereas most schedulers are based around the concept of a \ufb01xed tim e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "whereas",
          "schedulers",
          "based",
          "around",
          "concept"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "slice, CFS operates a bit differently . Its goal is simple: to fa irly divide a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "slice",
          "operates",
          "differently",
          "goal",
          "simple",
          "irly",
          "divide"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "counting-based technique known as virtual runtime (vruntime).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "counting",
          "based",
          "technique",
          "known",
          "virtual",
          "runtime",
          "vruntime"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "This raises a question: how does the scheduler know when to stop",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "raises",
          "question",
          "scheduler",
          "know",
          "stop"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the scheduler know when to stop\nthe currently running process, and run the next one",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "scheduler",
          "know",
          "stop",
          "currently",
          "running",
          "process",
          "next"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G : P R O P O RT I O N A L SH A R...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G : P R O P O RT I O N A L SH A R E 9\nof a process to less than this value, ensuring that not too much tim e is\nspent in scheduling overhead.\nFor example, if there are ten processes running, our original cal cula-\ntion would divide sched latency by ten to determine the time slice\n(result: 4.8 ms). However , because of min granularity, CFS will set\nthe time slice of each process to 6 ms instead. Although CFS won\u2019t (q uite)\nbe perfectly fair over the target scheduling latency ( sched latency) of\n48 ms, it will be close, while still achieving high CPU ef\ufb01cien cy .\nNote that CFS utilizes a periodic timer interrupt, which means it can\nonly make decisions at \ufb01xed time intervals. This interrupt goes off fre-\nquently (e.g., every 1 ms), giving CFS a chance to wake up and d etermine\nif the current job has reached the end of its run. If a job has a time slice\nthat is not a perfect multiple of the timer interrupt interval, that is OK;\nCFS tracks vruntime precisely , which means that over the long haul, it\nwill eventually approximate ideal sharing of the CPU.\nW eighting (Niceness)\nCFS also enables controls over process priority , enabling users or admin-\nistrators to give some processes a higher share of the CPU. It does t his\nnot with tickets, but through a classic U N I X mechanism known as the\nnice level of a process. The nice parameter can be set anywhere from -2 0\nto +19 for a process, with a default of 0. Positive nice values impl y lower\npriority and negative values imply higher priority; when you\u2019re too nice,\nyou just don\u2019t get as much (scheduling) attention, alas.\nCFS maps the nice value of each process to a weight, as shown here:\nstatic const int prio_to_weight[40] = {\n/* -20 */ 88761, 71755, 56483, 46273, 36291,\n/* -15 */ 29154, 23254, 18705, 14949, 11916,\n/* -10 */ 9548, 7620, 6100, 4904, 3906,\n/* -5 */ 3121, 2501, 1991, 1586, 1277,\n/* 0 */ 1024, 820, 655, 526, 423,\n/* 5 */ 335, 272, 215, 172, 137,\n/* 10 */ 110, 87, 70, 56, 45,\n/* 15 */ 36, 29, 23, 18, 15,\n};\nThese weights allow us to compute the effective time slice of eac h pro-\ncess (as we did before), but now accounting for their priority diff erences.\nThe formula used to do so is as follows:\ntime\nslicek = weightk\u2211 n\u2212 1\ni=0 weighti\n\u00b7 sched latency (9.1)\nLet\u2019s do an example to see how this works. Assume there are two\njobs, A and B. A, because it\u2019s our most precious job, is given a higher pri-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "not with tickets, but through a classic U N I X mechanism known as the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tickets",
          "classic",
          "mechanism",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand which: that over the long haul, it",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which",
          "long",
          "haul"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand result: 4.8 ms). However , because of min granularity, CFS will set",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "result",
          "however",
          "granularity"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand as shown here: static const int prio_to_weight[40] = {",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as shown here",
          "static",
          "const"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 S C H E D U L I N G : P R O P O RT I O N A L SH...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 S C H E D U L I N G : P R O P O RT I O N A L SH A R E\nority by assigning it a nice value of -5; B, because we hates it 3 , just has the\ndefault priority (nice value equal to 0). This means weightA (from the ta-\nble) is 3121, whereas weightB is 1024. If you then compute the time slice\nof each job, you\u2019ll \ufb01nd that A \u2019s time slice is about 3\n4 of sched latency\n(hence, 36 ms), and B\u2019s about 1\n4 (hence, 12 ms).\nIn addition to generalizing the time slice calculation, the wa y CFS cal-\nculates vruntime must also be adapted. Here is the new formula, which\ntakes the actual run time that process i has accrued ( runtimei) and scales\nit inversely by the weight of the process. In our running example , A \u2019s\nvruntime will accumulate at one-third the rate of B\u2019s.\nvruntimei = vruntimei + weight0\nweighti\n\u00b7 runtimei (9.2)\nOne smart aspect of the construction of the table of weights above is\nthat the table preserves CPU proportionality ratios when the dif ference in\nnice values is constant. For example, if process A instead had a n ice value\nof 5 (not -5), and process B had a nice value of 10 (not 0), CFS would\nschedule them in exactly the same manner as before. Run through the\nmath yourself to see why .\nUsing Red-Black T rees\nOne major focus of CFS is ef\ufb01ciency , as stated above. For a schedule r ,\nthere are many facets of ef\ufb01ciency , but one of them is as simple as this:\nwhen the scheduler has to \ufb01nd the next job to run, it should do so a s\nquickly as possible. Simple data structures like lists don\u2019t sca le: modern\nsystems sometimes are comprised of 1000s of processes, and thus se arch-\ning through a long-list every so many milliseconds is wasteful.\nCFS addresses this by keeping processes in a red-black tree [B72]. A\nred-black tree is one of many types of balanced trees; in contrast to a\nsimple binary tree (which can degenerate to list-like perfor mance un-\nder worst-case insertion patterns), balanced trees do a littl e extra work\nto maintain low depths, and thus ensure that operations are logar ithmic\n(and not linear) in time.\nCFS does not keep all process in this structure; rather , only running\n(or runnable) processes are kept therein. If a process goes to sle ep (say ,\nwaiting on an I/O to complete, or for a network packet to arrive), it is\nremoved from the tree and kept track of elsewhere.\nLet\u2019s look at an example to make this more clear . Assume there are t en\njobs, and that they have the following values of vruntime: 1, 5, 9, 10, 14,\n18, 17, 21, 22, and 24. If we kept these jobs in an ordered list, \ufb01n ding the\nnext job to run would be simple: just remove the \ufb01rst element. Howe ver ,\nwhen placing that job back into the list (in order), we would have to scan\n3 Y es, yes, we are using bad grammar here on purpose, please don\u2019t s end in a bug \ufb01x.\nWhy? W ell, just a most mild of references to the Lord of the Rings, and ou r favorite anti-hero\nGollum, nothing to get too excited about.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "red-black tree is one of many types of balanced trees; in contrast to a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "black",
          "tree",
          "many",
          "types",
          "balanced",
          "trees",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand This: weightA (from the ta-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this",
          "weighta"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G : P R O P O RT I O N A L SH A R...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G : P R O P O RT I O N A L SH A R E 11\n1\n5\n9\n10\n14\n18\n17 22\n21 24\nFigure 9.5: CFS Red-Black T ree\nthe list, looking for the right spot to insert it, an O(n) operation. Any\nsearch is also quite inef\ufb01cient, also taking linear time on av erage.\nKeeping the same values in a red-black tree makes most operation s\nmore ef\ufb01cient, as depicted in Figure 9.5. Processes are ordered in the tree\nby vruntime, and most operations (such as insertion and deletion) are\nlogarithmic in time, i.e., O(log n). When n is in the thousands, logarith-\nmic is noticeably more ef\ufb01cient than linear .\nDealing With I/O And Sleeping Processes\nOne problem with picking the lowest vruntime to run next arises with\njobs that have gone to sleep for a long period of time. Imagine two pro-\ncesses, A and B, one of which (A) runs continuously , and the other (B )\nwhich has gone to sleep for a long period of time (say , 10 seconds). Wh en\nB wakes up, its vruntime will be 10 seconds behind A \u2019s, and thus (if\nwe\u2019re not careful), B will now monopolize the CPU for the next 10 sec-\nonds while it catches up, effectively starving A.\nCFS handles this case by altering the vruntime of a job when it wakes\nup. Speci\ufb01cally , CFS sets the vruntime of that job to the minimum value\nfound in the tree (remember , the tree only contains running jobs) [B+18].\nIn this way , CFS avoids starvation, but not without a cost: jobs that sleep\nfor short periods of time frequently do not ever get their fair shar e of the\nCPU [AC97].\nOther CFS Fun\nCFS has many other features, too many to discuss at this point in t he\nbook. It includes numerous heuristics to improve cache performan ce, has\nstrategies for handling multiple CPUs effectively (as discu ssed later in the\nbook), can schedule across large groups of processes (instead of tre ating\neach process as an independent entity), and many other interes ting fea-\ntures. Read recent research, starting with Bouron [B+18], to l earn more.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "9",
    "title": "8 Summary",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "9.8 Summary\nW e have introduced the concept of proportional-share scheduling a nd\nbrie\ufb02y discussed three approaches: lottery scheduling, stri de scheduling,\nand the Completely Fair Scheduler (CFS) of Linux. Lottery uses ran dom-\nness in a clever way to achieve proportional share; stride does so deter-\nministically . CFS, the only \u201creal\u201d scheduler discussed in thi s chapter , is a\nbit like weighted round-robin with dynamic time slices, but bu ilt to scale\nand perform well under load; to our knowledge, it is the most widely\nused fair-share scheduler in existence today .\nNo scheduler is a panacea, and fair-share schedulers have th eir fair\nshare of problems. One issue is that such approaches do not partic ularly\nmesh well with I/O [AC97]; as mentioned above, jobs that perform I /O\noccasionally may not get their fair share of CPU. Another issue is t hat\nthey leave open the hard problem of ticket or priority assignment, i.e.,\nhow do you know how many tickets your browser should be allocated, or\nto what nice value to set your text editor? Other general-purpos e sched-\nulers (such as the MLFQ we discussed previously , and other simi lar Linux\nschedulers) handle these issues automatically and thus may b e more eas-\nily deployed.\nThe good news is that there are many domains in which these prob-\nlems are not the dominant concern, and proportional-share schedul ers\nare used to great effect. For example, in a virtualized data center (or\ncloud), where you might like to assign one-quarter of your CPU cycles\nto the Windows VM and the rest to your base Linux installation, pr opor-\ntional sharing can be simple and effective. The idea can also b e extended\nto other resources; see W aldspurger [W02] for further details on how to\nproportionally share memory in VMW are\u2019s ESX Server .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have introduced the concept of proportional-share scheduling a nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "introduced",
          "concept",
          "proportional",
          "share",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "brie\ufb02y discussed three approaches: lottery scheduling, stri de scheduling,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "discussed",
          "three",
          "approaches",
          "lottery",
          "scheduling",
          "stri",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "and perform well under load; to our knowledge, it is the most widely",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "perform",
          "well",
          "load",
          "knowledge",
          "widely"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "share of problems. One issue is that such approaches do not partic ularly",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "share",
          "problems",
          "issue",
          "approaches",
          "partic",
          "ularly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "how do you know how many tickets your browser should be allocated, or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "many",
          "tickets",
          "browser",
          "allocated"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SC H E D U L I N G : P R O P O RT I O N A L SH A R...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SC H E D U L I N G : P R O P O RT I O N A L SH A R E 13\nReferences\n[AC97] \u201cExtending Proportional-Share Scheduling to a Network of W orks tations\u201d by Andrea\nC. Arpaci-Dusseau and David E. Culler . PDPT A \u201997, June 1997. A paper by one of the authors on\nhow to extend proportional-share scheduling to work better in a clustered environment.\n[B+18] \u201cThe Battle of the Schedulers: FreeBSD ULE vs. Linux CFS\u201d by J. B ouron, S. Chevalley ,\nB. Lepers, W . Zwaenepoel, R. Gouicem, J. Lawall, G. Muller , J. Sope na. USENIX A TC \u201918,\nJuly 2018, Boston, Massachusetts. A recent, detailed work comparing Linux CFS and the FreeBSD\nschedulers. An excellent overview of each scheduler is also provi ded. The result of the comparison:\ninconclusive (in some cases CFS was better , and in others, ULE (the BSD scheduler), was. Sometimes\nin life there are no easy answers.\n[B72] \u201cSymmetric binary B-T rees: Data Structure And Maintenance Algor ithms\u201d by Rudolf\nBayer . Acta Informatica, V olume 1, Number 4, December 1972. A cool balanced tree introduced\nbefore you were born (most likely). One of many balanced trees out there; study your algorithms book\nfor more alternatives!\n[D82] \u201cWhy Numbering Should Start At Zero\u201d by Edsger Dijkstra, Au gust 1982. A vailable:\nhttp://www.cs.utexas.edu/users/EWD/ewd08xx/EWD831.PDF. A short note from E.\nDijkstra, one of the pioneers of computer science. We\u2019ll be hearing much m ore on this guy in the\nsection on Concurrency. In the meanwhile, enjoy this note, which includes this motivating quote: \u201cOne\nof my colleagues \u2014 not a computing scientist \u2014 accused a number of younger computing scientists of\n\u2019pedantry\u2019 because they started numbering at zero.\u201d The note explains why d oing so is logical.\n[K+15] \u201cPro\ufb01ling A W arehouse-scale Computer \u201d by S. Kanev , P . Ranganat han, J. P . Darago,\nK. Hazelwood, T . Moseley , G. W ei, D. Brooks. ISCA \u201915, June, 2015 , Portland, Oregon. A\nfascinating study of where the cycles go in modern data centers, which are increasingly where most of\ncomputing happens. Almost 20% of CPU time is spent in the operating system , 5% in the scheduler\nalone!\n[J09] \u201cInside The Linux 2.6 Completely Fair Scheduler \u201d by M. Tim Jones. De cember 15, 2009.\nhttp://ostep.org/Citations/inside-cfs.pdf. A simple overview of CFS from its ear-\nlier days. CFS was created by Ingo Molnar in a short burst of creativity whic h led to a 100K kernel\npatch developed in 62 hours.\n[KL88] \u201cA Fair Share Scheduler \u201d by J. Kay and P . Lauder . CACM, V olume 3 1 Issue 1, January\n1988. An early reference to a fair-share scheduler .\n[WW94] \u201cLottery Scheduling: Flexible Proportional-Share Resource Ma nagement\u201d by Carl A.\nW aldspurger and William E. W eihl. OSDI \u201994, November 1994. The landmark paper on lottery\nscheduling that got the systems community re-energized about scheduling, fair sharing, and the power\nof simple randomized algorithms.\n[W95] \u201cLottery and Stride Scheduling: Flexible Proportional-Share R esource Management\u201d by\nCarl A. W aldspurger . Ph.D. Thesis, MIT , 1995. The award-winning thesis of Waldspurger\u2019s that\noutlines lottery and stride scheduling. If you\u2019re thinking of writing a Ph. D. dissertation at some point,\nyou should always have a good example around, to give you something to strive for: this is such a good\none.\n[W02] \u201cMemory Resource Management in VMware ESX Server \u201d by Carl A. W a ldspurger .\nOSDI \u201902, Boston, Massachusetts. The paper to read about memory management in VMMs (a.k.a.,\nhypervisors). In addition to being relatively easy to read, the paper contains n umerous cool ideas about\nthis new type of VMM-level memory management.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "before you were born (most likely). One of many balanced trees out there; study your algorithms book",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "born",
          "likely",
          "many",
          "balanced",
          "trees",
          "study",
          "algorithms",
          "book"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "\u2019pedantry\u2019 because they started numbering at zero.\u201d The note explains why d oing so is logical.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pedantry",
          "started",
          "numbering",
          "zero",
          "note",
          "explains",
          "oing",
          "logical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "lier days. CFS was created by Ingo Molnar in a short burst of creativity whic h led to a 100K kernel",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lier",
          "days",
          "created",
          "ingo",
          "molnar",
          "short",
          "burst",
          "creativity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "patch developed in 62 hours.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "patch",
          "developed",
          "hours"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "of simple randomized algorithms.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "randomized",
          "algorithms"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand T rees: Data Structure And Maintenance Algor ithms\u201d by Rudolf",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t rees",
          "data",
          "structure",
          "maintenance",
          "algor",
          "ithms",
          "rudolf"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand A vailable: http://www.cs.utexas.edu/users/EWD/ewd08xx/EWD831.PDF. A short note from E.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "utexas",
          "users",
          "short",
          "note"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand http: //ostep.org/Citations/inside-cfs.pdf. A simple overview of CFS from its ear-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "ostep",
          "citations",
          "inside",
          "simple",
          "overview"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Lottery Scheduling: Flexible Proportional-Share Resource Ma nagement\u201d by Carl A.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lottery scheduling",
          "flexible",
          "proportional",
          "share",
          "resource",
          "nagement",
          "carl"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Lottery and Stride Scheduling: Flexible Proportional-Share R esource Management\u201d by",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lottery and stride scheduling",
          "flexible",
          "proportional",
          "share",
          "esource",
          "management"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Compute the solutions for simulations with 3 jobs and random seeds",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "1. Compute the solutions for simulations with 3 jobs and random seeds\nof 1, 2, and 3.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now run with two speci\ufb01c jobs: each of length 10, but one (job 0)",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "2. Now run with two speci\ufb01c jobs: each of length 10, but one (job 0)\nwith just 1 ticket and the other (job 1) with 100 (e.g., -l 10:1,10:100).\nWhat happens when the number of tickets is so imbalanced? Will\njob 0 ever run before job 1 completes? How often? In general, what\ndoes such a ticket imbalance do to the behavior of lottery schedul -\ning?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "When running with two jobs of length 100 and equal ticket alloc a-",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "3. When running with two jobs of length 100 and equal ticket alloc a-\ntions of 100 ( -l 100:100,100:100), how unfair is the scheduler?\nRun with some different random seeds to determine the (probabil is-\ntic) answer; let unfairness be determined by how much earlier one\njob \ufb01nishes than the other .",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand l 100: 100,100:100), how unfair is the scheduler?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l 100",
          "unfair",
          "scheduler"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "How does your answer to the previous question change as the quan-",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "4. How does your answer to the previous question change as the quan-\ntum size ( -q) gets larger?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand your answer to the previous question change as the quan-\ntum size ( -q) gets larger",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "answer",
          "previous",
          "question",
          "change",
          "quan",
          "size",
          "gets",
          "larger"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "5",
    "title": "Can you make a version of the graph that is found in the chapter?",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "5. Can you make a version of the graph that is found in the chapter?\nWhat else would be worth exploring? How would the graph look\nwith a stride scheduler?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10\nMultiprocessor Scheduling (Advanced)\nThis chapter will introduce the basics of multiprocessor scheduling . As\nthis topic is relatively advanced, it may be best to cover it after you have\nstudied the topic of concurrency in some detail (i.e., the second m ajor\n\u201ceasy piece\u201d of the book).\nAfter years of existence only in the high-end of the computing spe c-\ntrum, multiprocessor systems are increasingly commonplace, and have\nfound their way into desktop machines, laptops, and even mobile d e-\nvices. The rise of the multicore processor , in which multiple CPU cores\nare packed onto a single chip, is the source of this proliferation; these\nchips have become popular as computer architects have had a dif\ufb01 cult\ntime making a single CPU much faster without using (way) too muc h\npower . And thus we all now have a few CPUs available to us, which i s a\ngood thing, right?\nOf course, there are many dif\ufb01culties that arise with the arri val of more\nthan a single CPU. A primary one is that a typical application (i .e., some C\nprogram you wrote) only uses a single CPU; adding more CPUs does not\nmake that single application run faster . T o remedy this proble m, you\u2019ll\nhave to rewrite your application to run in parallel, perhaps using threads\n(as discussed in great detail in the second piece of this book). Mu lti-\nthreaded applications can spread work across multiple CPUs and thus\nrun faster when given more CPU resources.\nAS I D E : A D VA N C E D CH A P T E R S\nAdvanced chapters require material from a broad swath of the book t o\ntruly understand, while logically \ufb01tting into a section that i s earlier than\nsaid set of prerequisite materials. For example, this chapter on multipro-\ncessor scheduling makes much more sense if you\u2019ve \ufb01rst read the mi ddle\npiece on concurrency; however , it logically \ufb01ts into the part of th e book\non virtualization (generally) and CPU scheduling (speci\ufb01cal ly). Thus, it\nis recommended such chapters be covered out of order; in this case, after\nthe second piece of the book.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "power . And thus we all now have a few CPUs available to us, which i s a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "power",
          "thus",
          "cpus",
          "available"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "truly understand, while logically \ufb01tting into a section that i s earlier than",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "truly",
          "understand",
          "logically",
          "section",
          "earlier"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand AS I D E: A D VA N C E D CH A P T E R S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "10",
    "title": "1 Background: Multiprocessor Architecture",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "10.1 Background: Multiprocessor Architecture\nT o understand the new issues surrounding multiprocessor sched ul-\ning, we have to understand a new and fundamental difference b etween\nsingle-CPU hardware and multi-CPU hardware. This differen ce centers\naround the use of hardware caches (e.g., Figure 10.1), and exactly how\ndata is shared across multiple processors. W e now discuss this is sue fur-\nther , at a high level. Details are available elsewhere [CSG99 ], in particular\nin an upper-level or perhaps graduate computer architecture c ourse.\nIn a system with a single CPU, there are a hierarchy of hardware\ncaches that in general help the processor run programs faster . Caches\nare small, fast memories that (in general) hold copies of popular data that\nis found in the main memory of the system. Main memory , in contrast,\nholds all of the data, but access to this larger memory is slower . By keep-\ning frequently accessed data in a cache, the system can make t he large,\nslow memory appear to be a fast one.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand the new issues surrounding multiprocessor sched ul-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "issues",
          "surrounding",
          "multiprocessor",
          "sched"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ing, we have to understand a new and fundamental difference b etween",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "fundamental",
          "difference",
          "etween"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "is found in the main memory of the system. Main memory , in contrast,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "found",
          "main",
          "memory",
          "system",
          "main",
          "memory",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1 Background: Multiprocessor Architecture",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 background",
          "multiprocessor",
          "architecture"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand background: multiprocessor architecture",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "background",
          "multiprocessor",
          "architecture"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "MU LT I P R O C E S S O R SC H E D U L I N G (A D ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "MU LT I P R O C E S S O R SC H E D U L I N G (A D VA N C E D) 3\nMemory\nCPU CPU\nCache Cache\nBus\nFigure 10.2: T wo CPUs With Caches Sharing Memory\nAs an example, consider a program that issues an explicit load in struc-\ntion to fetch a value from memory , and a simple system with only a si ngle\nCPU; the CPU has a small cache (say 64 KB) and a large main memory .\nThe \ufb01rst time a program issues this load, the data resides in mai n mem-\nory , and thus takes a long time to fetch (perhaps in the tens of nan osec-\nonds, or even hundreds). The processor , anticipating that the da ta may be\nreused, puts a copy of the loaded data into the CPU cache. If the pr ogram\nlater fetches this same data item again, the CPU \ufb01rst checks f or it in the\ncache; if it \ufb01nds it there, the data is fetched much more quickl y (say , just\na few nanoseconds), and thus the program runs faster .\nCaches are thus based on the notion of locality, of which there are\ntwo kinds: temporal locality and spatial locality . The idea behind tem-\nporal locality is that when a piece of data is accessed, it is like ly to be\naccessed again in the near future; imagine variables or even i nstructions\nthemselves being accessed over and over again in a loop. The idea b e-\nhind spatial locality is that if a program accesses a data item a t address\nx, it is likely to access data items near x as well; here, think of a program\nstreaming through an array , or instructions being executed one a fter the\nother . Because locality of these types exist in many programs, ha rdware\nsystems can make good guesses about which data to put in a cache an d\nthus work well.\nNow for the tricky part: what happens when you have multiple pro-\ncessors in a single system, with a single shared main memory , as we see\nin Figure 10.2?\nAs it turns out, caching with multiple CPUs is much more compli-\ncated. Imagine, for example, that a program running on CPU 1 read s\na data item (with value D) at address A; because the data is not in the\ncache on CPU 1, the system fetches it from main memory , and gets th e\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 2: T wo CPUs With Caches Sharing Memory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "cpus",
          "caches",
          "sharing",
          "memory"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "The program then re-reads the value at address A; there is no such data",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "2. The program then re-reads the value at address A; there is no such data\nCPU 2\u2019s cache, and thus the system fetches the value from main me mory ,\nand gets the old value D instead of the correct value D\u2032. Oops!\nThis general problem is called the problem of cache coherence , and\nthere is a vast research literature that describes many diff erent subtleties\ninvolved with solving the problem [SHW11]. Here, we will skip all of the\nnuance and make some major points; take a computer architecture c lass\n(or three) to learn more.\nThe basic solution is provided by the hardware: by monitoring mem-\nory accesses, hardware can ensure that basically the \u201cright t hing\u201d hap-\npens and that the view of a single shared memory is preserved. On e way\nto do this on a bus-based system (as described above) is to use an old\ntechnique known as bus snooping [G83]; each cache pays attention to\nmemory updates by observing the bus that connects them to main me m-\nory . When a CPU then sees an update for a data item it holds in its ca che,\nit will notice the change and either invalidate its copy (i.e., remove it\nfrom its own cache) or update it (i.e., put the new value into its cache\ntoo). W rite-back caches, as hinted at above, make this more compli cated\n(because the write to main memory isn\u2019t visible until later), b ut you can\nimagine how the basic scheme might work.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "there is a vast research literature that describes many diff erent subtleties",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "vast",
          "research",
          "literature",
          "describes",
          "many",
          "diff",
          "erent",
          "subtleties"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(or three) to learn more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "three",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "to do this on a bus-based system (as described above) is to use an old",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "based",
          "system",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "technique known as bus snooping [G83]; each cache pays attention to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "technique",
          "known",
          "snooping",
          "cache",
          "pays",
          "attention"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "10",
    "title": "2 Don\u2019t Forget Synchronization",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "10.2 Don\u2019t Forget Synchronization\nGiven that the caches do all of this work to provide coherence, do p ro-\ngrams (or the OS itself) have to worry about anything when they ac cess\nshared data? The answer , unfortunately , is yes, and is documen ted in\ngreat detail in the second piece of this book on the topic of concurrenc y .\nWhile we won\u2019t get into the details here, we\u2019ll sketch/review som e of the\nbasic ideas here (assuming you\u2019re familiar with concurrency).\nWhen accessing (and in particular , updating) shared data it ems or\nstructures across CPUs, mutual exclusion primitives (such as locks) should\nlikely be used to guarantee correctness (other approaches, suc h as build-\ning lock-free data structures, are complex and only used on occasion;\nsee the chapter on deadlock in the piece on concurrency for details ). For\nexample, assume we have a shared queue being accessed on multi ple\nCPUs concurrently . Without locks, adding or removing elements fr om\nthe queue concurrently will not work as expected, even with the u nder-\nlying coherence protocols; one needs locks to atomically update the data\nstructure to its new state.\nT o make this more concrete, imagine this code sequence, which is used\nto remove an element from a shared linked list, as we see in Figur e 10.3.\nImagine if threads on two CPUs enter this routine at the same tim e. If\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "likely be used to guarantee correctness (other approaches, suc h as build-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "likely",
          "used",
          "guarantee",
          "correctness",
          "approaches",
          "build"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand don\u2019t forget synchronization",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "forget",
          "synchronization"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "10",
    "title": "3 One Final Issue: Cache Af\ufb01nity",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "10.3 One Final Issue: Cache Af\ufb01nity\nOne \ufb01nal issue arises in building a multiprocessor cache sched uler ,\nknown as cache af\ufb01nity [TTG95]. This notion is simple: a process, when\nrun on a particular CPU, builds up a fair bit of state in the cache s (and\nTLBs) of the CPU. The next time the process runs, it is often advan ta-\ngeous to run it on the same CPU, as it will run faster if some of its st ate\nis already present in the caches on that CPU. If, instead, one ru ns a pro-\ncess on a different CPU each time, the performance of the process w ill be\nworse, as it will have to reload the state each time it runs (note i t will run\ncorrectly on a different CPU thanks to the cache coherence protocol s of\nthe hardware). Thus, a multiprocessor scheduler should conside r cache\naf\ufb01nity when making its scheduling decisions, perhaps prefe rring to keep\na process on the same CPU if at all possible.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known as cache af\ufb01nity [TTG95]. This notion is simple: a process, when",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "cache",
          "notion",
          "simple",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand one final issue: cache af\ufb01nity",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "final",
          "issue",
          "cache"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "10",
    "title": "4 Single-Queue Scheduling",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "10.4 Single-Queue Scheduling\nWith this background in place, we now discuss how to build a sched -\nuler for a multiprocessor system. The most basic approach is to sim ply\nreuse the basic framework for single processor scheduling, by pu tting all\njobs that need to be scheduled into a single queue; we call this single-\nqueue multiprocessor scheduling or SQMS for short. This approach\nhas the advantage of simplicity; it does not require much work to t ake an\nexisting policy that picks the best job to run next and adapt it t o work on\nmore than one CPU (where it might pick the best two jobs to run, if t here\nare two CPUs, for example).\nHowever , SQMS has obvious shortcomings. The \ufb01rst problem is a lack\nof scalability. T o ensure the scheduler works correctly on multiple CPUs,\nthe developers will have inserted some form of locking into the code, as\ndescribed above. Locks ensure that when SQMS code accesses the si ngle\nqueue (say , to \ufb01nd the next job to run), the proper outcome arises.\nLocks, unfortunately , can greatly reduce performance, partic ularly as\nthe number of CPUs in the systems grows [A91]. As contention for suc h\na single lock increases, the system spends more and more time in l ock\noverhead and less time doing the work the system should be doing (not e:\nit would be great to include a real measurement of this in here som eday).\nThe second main problem with SQMS is cache af\ufb01nity . For example,\nlet us assume we have \ufb01ve jobs to run ( A, B, C, D, E) and four processors.\nOur scheduling queue thus looks like this:\nQueue A B C D E NULL\nOver time, assuming each job runs for a time slice and then anothe r\njob is chosen, here is a possible job schedule across CPUs:\nCPU 3\nCPU 2\nCPU 1\nCPU 0\nD C B A E\nC B A E D\nB A E D C\nA E D C B\n... (repeat) ...\n... (repeat) ...\n... (repeat) ...\n... (repeat) ...\nBecause each CPU simply picks the next job to run from the globall y-\nshared queue, each job ends up bouncing around from CPU to CPU, thu s\ndoing exactly the opposite of what would make sense from the stand-\npoint of cache af\ufb01nity .\nT o handle this problem, most SQMS schedulers include some kind of\naf\ufb01nity mechanism to try to make it more likely that process wil l continue\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "uler for a multiprocessor system. The most basic approach is to sim ply",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "uler",
          "multiprocessor",
          "system",
          "basic",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "queue multiprocessor scheduling or SQMS for short. This approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "queue",
          "multiprocessor",
          "scheduling",
          "sqms",
          "short",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the developers will have inserted some form of locking into the code, as",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developers",
          "inserted",
          "form",
          "locking",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "described above. Locks ensure that when SQMS code accesses the si ngle",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "locks",
          "ensure",
          "sqms",
          "code",
          "accesses",
          "ngle"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "queue (say , to \ufb01nd the next job to run), the proper outcome arises.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "queue",
          "next",
          "proper",
          "outcome",
          "arises"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand not e: it would be great to include a real measurement of this in here som eday).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "not e",
          "would",
          "great",
          "include",
          "real",
          "measurement",
          "eday"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand single-queue scheduling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "queue",
          "scheduling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "10",
    "title": "5 Multi-Queue Scheduling",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "10.5 Multi-Queue Scheduling\nBecause of the problems caused in single-queue schedulers, som e sys-\ntems opt for multiple queues, e.g., one per CPU. W e call this appr oach\nmulti-queue multiprocessor scheduling (or MQMS).\nIn MQMS, our basic scheduling framework consists of multiple sche dul-\ning queues. Each queue will likely follow a particular schedul ing disci-\npline, such as round robin, though of course any algorithm can be use d.\nWhen a job enters the system, it is placed on exactly one scheduli ng\nqueue, according to some heuristic (e.g., random, or picking one w ith\nfewer jobs than others). Then it is scheduled essentially inde pendently ,\nthus avoiding the problems of information sharing and synchroniza tion\nfound in the single-queue approach.\nFor example, assume we have a system where there are just two CP Us\n(labeled CPU 0 and CPU 1), and some number of jobs enter the system :\nA, B, C, and D for example. Given that each CPU has a scheduling queue\nnow , the OS has to decide into which queue to place each job. It mi ght do\nsomething like this:\nQ0 A C Q1 B D\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "pline, such as round robin, though of course any algorithm can be use d.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pline",
          "round",
          "robin",
          "though",
          "course",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "fewer jobs than others). Then it is scheduled essentially inde pendently ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fewer",
          "jobs",
          "others",
          "scheduled",
          "essentially",
          "inde",
          "pendently"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "found in the single-queue approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "found",
          "single",
          "queue",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand multi-queue scheduling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "multi",
          "queue",
          "scheduling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 M U LT I P R O C E S S O R SC H E D U L I N G (A...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 M U LT I P R O C E S S O R SC H E D U L I N G (A D VA N C E D)\nDepending on the queue scheduling policy , each CPU now has two\njobs to choose from when deciding what should run. For example, with\nround robin , the system might produce a schedule that looks like this:\nCPU 1\nCPU 0 A A C C A A C C A A C C\nB B D D B B D D B B D D  ... \n ... \nMQMS has a distinct advantage of SQMS in that it should be inher-\nently more scalable. As the number of CPUs grows, so too does the num -\nber of queues, and thus lock and cache contention should not become a\ncentral problem. In addition, MQMS intrinsically provides cac he af\ufb01nity;\njobs stay on the same CPU and thus reap the advantage of reusing ca ched\ncontents therein.\nBut, if you\u2019ve been paying attention, you might see that we have a n ew\nproblem, which is fundamental in the multi-queue based approa ch: load\nimbalance. Let\u2019s assume we have the same set up as above (four jobs,\ntwo CPUs), but then one of the jobs (say C) \ufb01nishes. W e now have the\nfollowing scheduling queues:\nQ0 A Q1 B D\nIf we then run our round-robin policy on each queue of the system, we\nwill see this resulting schedule:\nCPU 1\nCPU 0 A A A A A A A A A A A A\nB B D D B B D D B B D D  ... \n ... \nAs you can see from this diagram, A gets twice as much CPU as B\nand D, which is not the desired outcome. Even worse, let\u2019s imagine that\nboth A and C \ufb01nish, leaving just jobs B and D in the system. The two\nscheduling queues, and resulting timeline, will look like thi s:\nQ0 Q1 B D\nCPU 0\nCPU 1\nB B D D B B D D B B D D  ... \nHow terrible \u2013 CPU 0 is idle! (insert dramatic and sinister music here)\nAnd thus our CPU usage timeline looks quite sad.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "problem, which is fundamental in the multi-queue based approa ch: load",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "fundamental",
          "multi",
          "queue",
          "based",
          "approa",
          "load"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "and D, which is not the desired outcome. Even worse, let\u2019s imagine that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "desired",
          "outcome",
          "even",
          "worse",
          "imagine"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "And thus load is balanced:",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "1. And thus load is balanced:\nCPU 0\nCPU 1\nA A A A B A B A B B B B\nB D B D D D D D A D A D  ...\n...\nOf course, many other possible migration patterns exist. But now f or\nthe tricky part: how should the system decide to enact such a mig ration?\n1 Little known fact is that the home planet of Cybertron was destroyed b y bad CPU\nscheduling decisions. And now let that be the \ufb01rst and last reference to T rans formers in this\nbook, for which we sincerely apologize.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Little known fact is that the home planet of Cybertron was destroyed b y bad CPU",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "little",
          "known",
          "fact",
          "home",
          "planet",
          "cybertron",
          "destroyed"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "10",
    "title": "6 Linux Multiprocessor Schedulers",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "10.6 Linux Multiprocessor Schedulers\nInterestingly , in the Linux community , no common solution has ap-\nproached to building a multiprocessor scheduler . Over time, th ree dif-\nferent schedulers arose: the O(1) scheduler , the Completely F air Sched-\nuler (CFS), and the BF Scheduler (BFS) 2 . See Meehean\u2019s dissertation for\nan excellent overview of the strengths and weaknesses of said sc hedulers\n[M11]; here we just summarize a few of the basics.\nBoth O(1) and CFS use multiple queues, whereas BFS uses a singl e\nqueue, showing that both approaches can be successful. Of course , there\nare many other details which separate these schedulers. For ex ample, the\nO(1) scheduler is a priority-based scheduler (similar to the MLFQ dis-\ncussed before), changing a process\u2019s priority over time and then s chedul-\ning those with highest priority in order to meet various scheduli ng objec-\ntives; interactivity is a particular focus. CFS, in contrast, i s a deterministic\nproportional-share approach (more like Stride scheduling, as dis cussed\nearlier). BFS, the only single-queue approach among the three, i s also\nproportional-share, but based on a more complicated scheme known as\nEarliest Eligible Virtual Deadline First (EEVDF) [SA96]. Re ad more about\nthese modern algorithms on your own; you should be able to understand\nhow they work now!",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "queue, showing that both approaches can be successful. Of course , there",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "queue",
          "showing",
          "approaches",
          "successful",
          "course"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tives; interactivity is a particular focus. CFS, in contrast, i s a deterministic",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tives",
          "interactivity",
          "particular",
          "focus",
          "contrast",
          "deterministic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "proportional-share approach (more like Stride scheduling, as dis cussed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proportional",
          "share",
          "approach",
          "like",
          "stride",
          "scheduling",
          "cussed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": ". BFS, the only single-queue approach among the three, i s also",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "queue",
          "approach",
          "among",
          "three",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "proportional-share, but based on a more complicated scheme known as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proportional",
          "share",
          "based",
          "complicated",
          "scheme",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "these modern algorithms on your own; you should be able to understand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "modern",
          "algorithms",
          "able",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand ferent schedulers arose: the O(1) scheduler , the Completely F air Sched-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ferent schedulers arose",
          "scheduler",
          "completely",
          "sched"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand linux multiprocessor schedulers",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "linux",
          "multiprocessor",
          "schedulers"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "10",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "10.7 Summary\nW e have seen various approaches to multiprocessor scheduling. T he\nsingle-queue approach (SQMS) is rather straightforward to buil d and bal-\nances load well but inherently has dif\ufb01culty with scaling to m any pro-\ncessors and cache af\ufb01nity . The multiple-queue approach (MQMS) scales\nbetter and handles cache af\ufb01nity well, but has trouble with loa d imbal-\nance and is more complicated. Whichever approach you take, there is no\nsimple answer: building a general purpose scheduler remains a daunting\ntask, as small code changes can lead to large behavioral differ ences. Only\nundertake such an exercise if you know exactly what you are doing, or ,\nat least, are getting paid a large amount of money to do so.\n2 Look up what BF stands for on your own; be forewarned, it is not for the faint of heart.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have seen various approaches to multiprocessor scheduling. T he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "seen",
          "various",
          "approaches",
          "multiprocessor",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "single-queue approach (SQMS) is rather straightforward to buil d and bal-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "queue",
          "approach",
          "sqms",
          "rather",
          "straightforward",
          "buil"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "cessors and cache af\ufb01nity . The multiple-queue approach (MQMS) scales",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cessors",
          "cache",
          "multiple",
          "queue",
          "approach",
          "mqms",
          "scales"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ance and is more complicated. Whichever approach you take, there is no",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ance",
          "complicated",
          "whichever",
          "approach",
          "take"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "undertake such an exercise if you know exactly what you are doing, or ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "undertake",
          "exercise",
          "know",
          "exactly"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "MU LT I P R O C E S S O R SC H E D U L I N G (A D ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "MU LT I P R O C E S S O R SC H E D U L I N G (A D VA N C E D) 11\nReferences\n[A90] \u201cThe Performance of Spin Lock Alternatives for Shared-Memory Multipr ocessors\u201d by\nThomas E. Anderson. IEEE TPDS V olume 1:1, January 1990. A classic paper on how different\nlocking alternatives do and don\u2019t scale. By T om Anderson, very well known re searcher in both systems\nand networking. And author of a very \ufb01ne OS textbook, we must say.\n[B+10] \u201cAn Analysis of Linux Scalability to Many Cores Abstract\u201d by S ilas Boyd-Wickizer ,\nAustin T . Clements, Y andong Mao, Aleksey Pesterev , M. Frans Kaashoek , Robert Morris, Nick-\nolai Zeldovich. OSDI \u201910, V ancouver , Canada, October 2010. A terri\ufb01c modern paper on the\ndif\ufb01culties of scaling Linux to many cores.\n[CSG99] \u201cParallel Computer Architecture: A Hardware/Software Ap proach\u201d by David E.\nCuller , Jaswinder Pal Singh, and Anoop Gupta. Morgan Kaufmann, 1999. A treasure \ufb01lled\nwith details about parallel machines and algorithms. As Mark Hill humorously observes on the jacket,\nthe book contains more information than most research papers.\n[FLR98] \u201cThe Implementation of the Cilk-5 Multithreaded Language\u201d by Matteo Frigo, Charles\nE. Leiserson, Keith Randall. PLDI \u201998, Montreal, Canada, June 1998. Cilk is a lightweight\nlanguage and runtime for writing parallel programs, and an excellent examp le of the work-stealing\nparadigm.\n[G83] \u201cUsing Cache Memory T o Reduce Processor-Memory T raf\ufb01c\u201d by James R. G oodman.\nISCA \u201983, Stockholm, Sweden, June 1983. The pioneering paper on how to use bus snooping, i.e.,\npaying attention to requests you see on the bus, to build a cache coherence protoc ol. Goodman\u2019s research\nover many years at Wisconsin is full of cleverness, this being but one e xample.\n[M11] \u201cT owards T ransparent CPU Scheduling\u201d by Joseph T . Meehean. Doctoral Dissertation\nat University of Wisconsin\u2014Madison, 2011. A dissertation that covers a lot of the details of how\nmodern Linux multiprocessor scheduling works. Pretty awesome! But, as co-ad visors of Joe\u2019s, we may\nbe a bit biased here.\n[SHW11] \u201cA Primer on Memory Consistency and Cache Coherence\u201d by Daniel J. Sor in, Mark\nD. Hill, and David A. W ood. Synthesis Lectures in Computer Architect ure. Morgan and Clay-\npool Publishers, May 2011. A de\ufb01nitive overview of memory consistency and multiprocessor caching.\nRequired reading for anyone who likes to know way too much about a given topic.\n[SA96] \u201cEarliest Eligible Virtual Deadline First: A Flexible and Accurate Mechanism for Pro-\nportional Share Resource Allocation\u201d by Ion Stoica and Hussein Abde l-W ahab. T echnical Re-\nport TR-95-22, Old Dominion University , 1996. A tech report on this cool scheduling idea, from\nIon Stoica, now a professor at U.C. Berkeley and world expert in networking, di stributed systems, and\nmany other things.\n[TTG95] \u201cEvaluating the Performance of Cache-Af\ufb01nity Scheduling in Shared-Memo ry Mul-\ntiprocessors\u201d by Josep T orrellas, Andrew T ucker , Anoop Gupta. Jou rnal of Parallel and Dis-\ntributed Computing, V olume 24:2, February 1995. This is not the \ufb01rst paper on the topic, but it has\ncitations to earlier work, and is a more readable and practical paper than some of the ear lier queuing-\nbased analysis papers.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "locking alternatives do and don\u2019t scale. By T om Anderson, very well known re searcher in both systems",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "locking",
          "alternatives",
          "scale",
          "anderson",
          "well",
          "known",
          "searcher",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "with details about parallel machines and algorithms. As Mark Hill humorously observes on the jacket,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "details",
          "parallel",
          "machines",
          "algorithms",
          "mark",
          "hill",
          "humorously",
          "observes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[FLR98] \u201cThe Implementation of the Cilk-5 Multithreaded Language\u201d by Matteo Frigo, Charles",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation",
          "cilk",
          "multithreaded",
          "language",
          "matteo",
          "frigo",
          "charles"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Required reading for anyone who likes to know way too much about a given topic.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "required",
          "reading",
          "anyone",
          "likes",
          "know",
          "much",
          "given",
          "topic"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Parallel Computer Architecture: A Hardware/Software Ap proach\u201d by David E.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "parallel computer architecture",
          "hardware",
          "software",
          "proach",
          "david"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 24: 2, February 1995. This is not the \ufb01rst paper on the topic, but it has",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 24",
          "february",
          "paper",
          "topic"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "T o start things off, let\u2019s learn how to use the simulator to stud y how",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. T o start things off, let\u2019s learn how to use the simulator to stud y how\nto build an effective multi-processor scheduler . The \ufb01rst sim ulation\nwill run just one job, which has a run-time of 30, and a working-set\nsize of 200. Run this job (called job \u2019a\u2019 here) on one simulated CPU\nas follows: ./multi.py -n 1 -L a:30:200. How long will it\ntake to complete? T urn on the -c \ufb02ag to see a \ufb01nal answer , and the\n-t \ufb02ag to see a tick-by-tick trace of the job and how it is scheduled.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o start things off, let\u2019s learn how to use the simulator to stud y how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "things",
          "learn",
          "simulator",
          "stud"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand t \ufb02ag to see a tick-by-tick trace of the job and how it is scheduled.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "tick",
          "tick",
          "trace",
          "scheduled"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now increase the cache size so as to make the job\u2019s working set",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "2. Now increase the cache size so as to make the job\u2019s working set\n(size=200) \ufb01t into the cache (which, by default, is size=100 ); for\nexample, run ./multi.py -n 1 -L a:30:200 -M 300. Can\nyou predict how fast the job will run once it \ufb01ts in cache? (hint:\nremember the key parameter of the warm\nrate, which is set by the\n-r \ufb02ag) Check your answer by running with the solve \ufb02ag ( -c) en-\nabled.\n3. One cool thing about multi.py is that you can see more detail\nabout what is going on with different tracing \ufb02ags. Run the same\nsimulation as above, but this time with time\nleft tracing enabled\n(-T). This \ufb02ag shows both the job that was scheduled on a CPU\nat each time step, as well as how much run-time that job has left\nafter each tick has run. What do you notice about how that second\ncolumn decreases?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "r \ufb02ag) Check your answer by running with the solve \ufb02ag ( -c) en-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "check",
          "answer",
          "running",
          "solve"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand hint: remember the key parameter of the warm",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hint",
          "remember",
          "parameter",
          "warm"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand going on with different tracing \ufb02ags. Run the same\nsimulation as above, but this time with time\nleft tracing enabled\n(-T). This \ufb02ag shows both the job that was scheduled on a CPU\nat each time step, as well as how much run-time that job has left\nafter each tick has run. What do you notice about how that second\ncolumn decreases",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "going",
          "different",
          "tracing",
          "simulation",
          "time",
          "time",
          "left",
          "tracing"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Now add one more bit of tracing, to show the status of each CPU",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "4. Now add one more bit of tracing, to show the status of each CPU\ncache for each job, with the -C \ufb02ag. For each job, each cache will\neither show a blank space (if the cache is cold for that job) or a \u2019w\u2019\n(if the cache is warm for that job). At what point does the cache\nbecome warm for job \u2019a\u2019 in this simple example? What happens\nas you change the warmup\ntime parameter ( -w) to lower or higher\nvalues than the default?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "5",
    "title": "At this point, you should have a good idea of how the simula-",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "5. At this point, you should have a good idea of how the simula-\ntor works for a single job running on a single CPU. But hey , isn\u2019t\nthis a multi-processor CPU scheduling chapter? Oh yeah! So let\u2019s\nstart working with multiple jobs. Speci\ufb01cally , let\u2019s run the foll ow-\ning three jobs on a two-CPU system (i.e., type ./multi.py -n\n2 -L a:100:100,b:100:50,c:100:50) Can you predict how\nlong this will take, given a round-robin centralized scheduler ? Use\n-c to see if you were right, and then dive down into details with -t\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand L a: 100:100,b:100:50,c:100:50) Can you predict how",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l a",
          "predict"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand c to see if you were right, and then dive down into details with -t",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "right",
          "dive",
          "details"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "6",
    "title": "Now we\u2019ll apply some explicit controls to study cache af\ufb01nity , as",
    "document_source": "book.pdf",
    "start_line": 3,
    "type": "chapter",
    "content": "6. Now we\u2019ll apply some explicit controls to study cache af\ufb01nity , as\ndescribed in the chapter . T o do this, you\u2019ll need the -A \ufb02ag. This\n\ufb02ag can be used to limit which CPUs the scheduler can place a pa r-\nticular job upon. In this case, let\u2019s use it to place jobs \u2019b\u2019 and \u2019c\u2019 on\nCPU 1, while restricting \u2019a\u2019 to CPU 0. This magic is accomplishe d\nby typing this ./multi.py -n 2 -L a:100:100,b:100:50,\nc:100:50 -A a:0,b:1,c:1 ; don\u2019t forget to turn on various trac-\ning options to see what is really happening! Can you predict how\nfast this version will run? Why does it do better? Will other com-\nbinations of \u2019a\u2019, \u2019b\u2019, and \u2019c\u2019 onto the two processors run faster or\nslower?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now we\u2019ll apply some explicit controls to study cache af\ufb01nity , as",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "apply",
          "explicit",
          "controls",
          "study",
          "cache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "described in the chapter . T o do this, you\u2019ll need the -A \ufb02ag. This",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "chapter",
          "need"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand c: 100:50 -A a:0,b:1,c:1 ; don\u2019t forget to turn on various trac-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "c",
          "forget",
          "turn",
          "various",
          "trac"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand really happening! Can you predict how\nfast this version will run",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "really",
          "happening",
          "predict",
          "fast",
          "version"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "7",
    "title": "One interesting aspect of caching multiprocessors is the oppor tu-",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "7. One interesting aspect of caching multiprocessors is the oppor tu-\nnity for better-than-expected speed up of jobs when using multi -\nple CPUs (and their caches) as compared to running jobs on a sin-\ngle processor . Speci\ufb01cally , when you run on N CPUs, sometimes\nyou can speed up by more than a factor of N, a situation entitled\nsuper-linear speedup . T o experiment with this, use the job descrip-\ntion here ( -L a:100:100,b:100:100,c:100:100) with a small\ncache ( -M 50) to create three jobs. Run this on systems with 1, 2,\nand 3 CPUs ( -n 1, -n 2, -n 3). Now , do the same, but with a\nlarger per-CPU cache of size 100. What do you notice about per-\nformance as the number of CPUs scales? Use -c to con\ufb01rm your\nguesses, and other tracing \ufb02ags to dive even deeper .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ple CPUs (and their caches) as compared to running jobs on a sin-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "cpus",
          "caches",
          "compared",
          "running",
          "jobs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "cache ( -M 50) to create three jobs. Run this on systems with 1, 2,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cache",
          "create",
          "three",
          "jobs",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand L a: 100:100,b:100:100,c:100:100) with a small",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l a",
          "small"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "8",
    "title": "One other aspect of the simulator worth studying is the per-CPU",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "8. One other aspect of the simulator worth studying is the per-CPU\nscheduling option, the -p \ufb02ag. Run with two CPUs again, and this\nthree job con\ufb01guration ( -L a:100:100,b:100:50,c:100:50).\nHow does this option do, as opposed to the hand-controlled af\ufb01nity\nlimits you put in place above? How does performance change as\nyou alter the \u2019peek interval\u2019 ( -P) to lower or higher values? How\ndoes this per-CPU approach work as the number of CPUs scales?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "does this per-CPU approach work as the number of CPUs scales?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "work",
          "number",
          "cpus",
          "scales"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand L a: 100:100,b:100:50,c:100:50).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "l a"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand this option do, as opposed to the hand-controlled af\ufb01nity\nlimits you put in place above",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "option",
          "opposed",
          "hand",
          "controlled",
          "limits",
          "place"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand performance change as\nyou alter the \u2019peek interval\u2019 ( -P) to lower or higher values",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "change",
          "alter",
          "peek",
          "interval",
          "lower",
          "higher",
          "values"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "9",
    "title": "Finally , feel free to just generate random workloads and see i f you",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "9. Finally , feel free to just generate random workloads and see i f you\ncan predict their performance on different numbers of processors ,\ncache sizes, and scheduling options. If you do this, you\u2019ll soon be\na multi-processor scheduling master , which is a pretty awesome\nthing to be. Good luck!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "11\nSummary Dialogue on CPU Virtualization\nProfessor: So, Student, did you learn anything?\nStudent: Well, Professor , that seems like a loaded question. I think you only\nwant me to say \u201cyes.\u201d\nProfessor: That\u2019s true. But it\u2019s also still an honest question. Come on, give a\nprofessor a break, will you?\nStudent: OK, OK. I think I did learn a few things. First, I learned a little about\nhow the OS virtualizes the CPU. There are a bunch of important mechanisms\nthat I had to understand to make sense of this: traps and trap ha ndlers, timer\ninterrupts, and how the OS and the hardware have to carefully save and restore\nstate when switching between processes.\nProfessor: Good, good!\nStudent: All those interactions do seem a little complicated though; how can I\nlearn more?\nProfessor: Well, that\u2019s a good question. I think there is no substitute for doing;\njust reading about these things doesn\u2019t quite give you the proper s ense. Do the\nclass projects and I bet by the end it will all kind of make sense.\nStudent: Sounds good. What else can I tell you?\nProfessor: Well, did you get some sense of the philosophy of the OS in your\nquest to understand its basic machinery?\nStudent: Hmm... I think so. It seems like the OS is fairly paranoid. It wants\nto make sure it stays in charge of the machine. While it wants a progra m to run\nas ef\ufb01ciently as possible (and hence the whole reasoning behind limited direct\nexecution), the OS also wants to be able to say \u201cAh! Not so fast my friend\u201d\nin case of an errant or malicious process. Paranoia rules the day, an d certainly\nkeeps the OS in charge of the machine. Perhaps that is why we think o f the OS\nas a resource manager .\nProfessor: Y es indeed \u2014 sounds like you are starting to put it together! Nice.\nStudent: Thanks.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Professor: So, Student, did you learn anything?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "student",
          "learn",
          "anything"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Student: OK, OK. I think I did learn a few things. First, I learned a little about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "think",
          "learn",
          "things",
          "first",
          "learned",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "how the OS virtualizes the CPU. There are a bunch of important mechanisms",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "virtualizes",
          "bunch",
          "important",
          "mechanisms"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "that I had to understand to make sense of this: traps and trap ha ndlers, timer",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "make",
          "sense",
          "traps",
          "trap",
          "ndlers",
          "timer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "learn more?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "class projects and I bet by the end it will all kind of make sense.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "class",
          "projects",
          "kind",
          "make",
          "sense"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "quest to understand its basic machinery?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quest",
          "understand",
          "basic",
          "machinery"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": ", the OS also wants to be able to say \u201cAh! Not so fast my friend\u201d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "wants",
          "able",
          "fast",
          "friend"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: Well, Professor , that seems like a loaded question. I think you only",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "professor",
          "seems",
          "like",
          "loaded",
          "question",
          "think"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: That\u2019s true. But it\u2019s also still an honest question. Come on, give a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "true",
          "also",
          "still",
          "honest",
          "question",
          "come",
          "give"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: All those interactions do seem a little complicated though; how can I",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "interactions",
          "seem",
          "little",
          "complicated",
          "though"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Well, that\u2019s a good question. I think there is no substitute for doing;",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "good",
          "question",
          "think",
          "substitute"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Student: Sounds good. What else can I tell you?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "good",
          "else",
          "tell"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Professor: Well, did you get some sense of the philosophy of the OS in your",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "sense",
          "philosophy"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Student: Hmm... I think so. It seems like the OS is fairly paranoid. It wants",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "think",
          "seems",
          "like",
          "fairly",
          "paranoid",
          "wants"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S U M M A RYDI A L O G U E O NCPU V I RT U A L I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S U M M A RYDI A L O G U E O NCPU V I RT U A L I Z AT I O N\nProfessor: And what about the policies on top of those mechanisms \u2014 any\ninteresting lessons there?\nStudent: Some lessons to be learned there for sure. Perhaps a little obvious, b ut\nobvious can be good. Like the notion of bumping short jobs to the fron t of the\nqueue \u2014 I knew that was a good idea ever since the one time I was buyin g some\ngum at the store, and the guy in front of me had a credit card that wo uldn\u2019t work.\nHe was no short job, let me tell you.\nProfessor: That sounds oddly rude to that poor fellow. What else?\nStudent: Well, that you can build a smart scheduler that tries to be like SJF\nand RR all at once \u2014 that MLFQ was pretty neat. Building up a real sch eduler\nseems dif\ufb01cult.\nProfessor: Indeed it is. That\u2019s why there is still controversy to this day over\nwhich scheduler to use; see the Linux battles between CFS, BFS, an d the O(1)\nscheduler , for example. And no, I will not spell out the full name of BFS .\nStudent: And I won\u2019t ask you to! These policy battles seem like they could rage\nforever; is there really a right answer?\nProfessor: Probably not. After all, even our own metrics are at odds: if your\nscheduler is good at turnaround time, it\u2019s bad at response time, an d vice versa.\nAs Lampson said, perhaps the goal isn\u2019t to \ufb01nd the best solution, bu t rather to\navoid disaster .\nStudent: That\u2019s a little depressing.\nProfessor: Good engineering can be that way. And it can also be uplifting!\nIt\u2019s just your perspective on it, really. I personally think being prag matic is a\ngood thing, and pragmatists realize that not all problems have clean and easy\nsolutions. Anything else that caught your fancy?\nStudent: I really liked the notion of gaming the scheduler; it seems like that\nmight be something to look into when I\u2019m next running a job on Amazon\u2019s EC2\nservice. Maybe I can steal some cycles from some other unsuspect ing (and more\nimportantly, OS-ignorant) customer!\nProfessor: It looks like I might have created a monster! Professor Frankenste in\nis not what I\u2019d like to be called, you know.\nStudent: But isn\u2019t that the idea? T o get us excited about something, so much so\nthat we look into it on our own? Lighting \ufb01res and all that?\nProfessor: I guess so. But I didn\u2019t think it would work!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: Some lessons to be learned there for sure. Perhaps a little obvious, b ut",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "lessons",
          "learned",
          "sure",
          "perhaps",
          "little",
          "obvious"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "As Lampson said, perhaps the goal isn\u2019t to \ufb01nd the best solution, bu t rather to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lampson",
          "said",
          "perhaps",
          "goal",
          "best",
          "solution",
          "rather"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "importantly, OS-ignorant) customer!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "importantly",
          "ignorant",
          "customer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Professor: It looks like I might have created a monster! Professor Frankenste in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "looks",
          "like",
          "might",
          "created",
          "monster",
          "professor",
          "frankenste"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "is not what I\u2019d like to be called, you know.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "like",
          "called",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: That sounds oddly rude to that poor fellow. What else?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "sounds",
          "oddly",
          "rude",
          "poor",
          "fellow",
          "else"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: Well, that you can build a smart scheduler that tries to be like SJF",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "build",
          "smart",
          "scheduler",
          "tries",
          "like"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Indeed it is. That\u2019s why there is still controversy to this day over",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "indeed",
          "still",
          "controversy"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Student: And I won\u2019t ask you to! These policy battles seem like they could rage",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "policy",
          "battles",
          "seem",
          "like",
          "could",
          "rage"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Professor: Probably not. After all, even our own metrics are at odds: if your",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "probably",
          "even",
          "metrics",
          "odds"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Student: That\u2019s a little depressing.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "little",
          "depressing"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Professor: Good engineering can be that way. And it can also be uplifting!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good",
          "engineering",
          "also",
          "uplifting"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12\nA Dialogue on Memory Virtualization\nStudent: So, are we done with virtualization?\nProfessor: No!\nStudent: Hey, no reason to get so excited; I was just asking a question. Stud ents\nare supposed to do that, right?\nProfessor: Well, professors do always say that, but really they mean this: ask\nquestions, if they are good questions, and you have actually put a little thought\ninto them.\nStudent: Well, that sure takes the wind out of my sails.\nProfessor: Mission accomplished. In any case, we are not nearly done with\nvirtualization! Rather , you have just seen how to virtualize the CPU, but really\nthere is a big monster waiting in the closet: memory. V irtualizing memor y is\ncomplicated and requires us to understand many more intricate det ails about\nhow the hardware and OS interact.\nStudent: That sounds cool. Why is it so hard?\nProfessor: Well, there are a lot of details, and you have to keep them straight\nin your head to really develop a mental model of what is going on. We\u2019ll s tart\nsimple, with very basic techniques like base/bounds, and slowly add co mplexity\nto tackle new challenges, including fun topics like TLBs and multi-level pa ge\ntables. Eventually, we\u2019ll be able to describe the workings of a fully-func tional\nmodern virtual memory manager .\nStudent: Neat! Any tips for the poor student, inundated with all of this infor-\nmation and generally sleep-deprived?\nProfessor: For the sleep deprivation, that\u2019s easy: sleep more (and party less ).\nFor understanding virtual memory, start with this: every address generated\nby a user program is a virtual address. The OS is just providing an illusion\nto each process, speci\ufb01cally that it has its own large and private memo ry; with\nsome hardware help, the OS will turn these pretend virtual addres ses into real\nphysical addresses, and thus be able to locate the desired informat ion.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "complicated and requires us to understand many more intricate det ails about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "complicated",
          "requires",
          "understand",
          "many",
          "intricate",
          "ails"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in your head to really develop a mental model of what is going on. We\u2019ll s tart",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "head",
          "really",
          "develop",
          "mental",
          "model",
          "going",
          "tart"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "simple, with very basic techniques like base/bounds, and slowly add co mplexity",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "basic",
          "techniques",
          "like",
          "base",
          "bounds",
          "slowly",
          "mplexity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "tables. Eventually, we\u2019ll be able to describe the workings of a fully-func tional",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tables",
          "eventually",
          "able",
          "describe",
          "workings",
          "fully",
          "func",
          "tional"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "For understanding virtual memory, start with this: every address generated",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "virtual",
          "memory",
          "start",
          "every",
          "address",
          "generated"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "physical addresses, and thus be able to locate the desired informat ion.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "physical",
          "addresses",
          "thus",
          "able",
          "locate",
          "desired",
          "informat"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Hey, no reason to get so excited; I was just asking a question. Stud ents",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "reason",
          "excited",
          "asking",
          "question",
          "stud",
          "ents"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Well, professors do always say that, but really they mean this: ask",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "professors",
          "always",
          "really",
          "mean"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Well, that sure takes the wind out of my sails.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "sure",
          "takes",
          "wind",
          "sails"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: Mission accomplished. In any case, we are not nearly done with",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "mission",
          "accomplished",
          "case",
          "nearly",
          "done"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Student: That sounds cool. Why is it so hard?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "cool",
          "hard"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Professor: Well, there are a lot of details, and you have to keep them straight",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "details",
          "keep",
          "straight"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Student: Neat! Any tips for the poor student, inundated with all of this infor-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "neat",
          "tips",
          "poor",
          "student",
          "inundated",
          "infor"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Professor: For the sleep deprivation, that\u2019s easy: sleep more (and party less ).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "sleep",
          "deprivation",
          "easy",
          "sleep",
          "party",
          "less"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand going on. We\u2019ll s tart\nsimple, with very basic techniques like base/bounds, and slowly add co mplexity\nto tackle new challenges, including fun topics like TLBs and multi-level pa ge\ntables. Eventually, we\u2019ll be able to describe the workings of a fully-func tional\nmodern virtual memory manager .\nStudent: Neat! Any tips for the poor student, inundated with all of this infor-\nmation and generally sleep-deprived",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "going",
          "tart",
          "simple",
          "basic",
          "techniques",
          "like",
          "base",
          "bounds"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 A D I A L O G U E O NME M O RYVI RT U A L I Z AT...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 A D I A L O G U E O NME M O RYVI RT U A L I Z AT I O N\nStudent: OK, I think I can remember that... (to self) every address from a us er\nprogram is virtual, every address from a user program is virtual, eve ry ...\nProfessor: What are you mumbling about?\nStudent: Oh nothing.... (awkward pause) ... Anyway, why does the OS wan t\nto provide this illusion again?\nProfessor: Mostly ease of use: the OS will give each program the view that it\nhas a large contiguous address space to put its code and data into; thus, as a\nprogrammer , you never have to worry about things like \u201cwhere sho uld I store this\nvariable?\u201d because the virtual address space of the program is lar ge and has lots\nof room for that sort of thing. Life, for a programmer , becomes much more tricky\nif you have to worry about \ufb01tting all of your code data into a small, cro wded\nmemory.\nStudent: Why else?\nProfessor: Well, isolation and protection are big deals, too. We don\u2019t want\none errant program to be able to read, or worse, overwrite, some other program\u2019s\nmemory, do we?\nStudent: Probably not. Unless it\u2019s a program written by someone you don\u2019t\nlike.\nProfessor: Hmmm.... I think we might need to add a class on morals and ethics\nto your schedule for next semester . Perhaps OS class isn\u2019t getting the right mes-\nsage across.\nStudent: Maybe we should. But remember , it\u2019s not me who taught us that the\nproper OS response to errant process behavior is to kill the offendin g process!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "one errant program to be able to read, or worse, overwrite, some other program\u2019s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "errant",
          "program",
          "able",
          "read",
          "worse",
          "overwrite",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Professor: What are you mumbling about?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "mumbling"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Oh nothing.... (awkward pause) ... Anyway, why does the OS wan t",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "nothing",
          "awkward",
          "pause",
          "anyway"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Mostly ease of use: the OS will give each program the view that it",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "mostly",
          "ease",
          "give",
          "program",
          "view"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: Well, isolation and protection are big deals, too. We don\u2019t want",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "isolation",
          "protection",
          "deals",
          "want"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: Probably not. Unless it\u2019s a program written by someone you don\u2019t",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "probably",
          "unless",
          "program",
          "written",
          "someone"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Hmmm.... I think we might need to add a class on morals and ethics",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "hmmm",
          "think",
          "might",
          "need",
          "class",
          "morals",
          "ethics"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Student: Maybe we should. But remember , it\u2019s not me who taught us that the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "maybe",
          "remember",
          "taught"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "13",
    "title": "1 Early Systems",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "13.1 Early Systems\nFrom the perspective of memory , early machines didn\u2019t provide muc h\nof an abstraction to users. Basically , the physical memory of the machine\nlooked something like what you see in Figure 13.1 (page 2).\nThe OS was a set of routines (a library , really) that sat in memory (start-\ning at physical address 0 in this example), and there would be on e run-\nning program (a process) that currently sat in physical memory ( starting\nat physical address 64k in this example) and used the rest of me mory .\nThere were few illusions here, and the user didn\u2019t expect much f rom the\nOS. Life was sure easy for OS developers in those days, wasn\u2019t it?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "OS. Life was sure easy for OS developers in those days, wasn\u2019t it?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "life",
          "sure",
          "easy",
          "developers",
          "days"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand early systems",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "early",
          "systems"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "13",
    "title": "2 Multiprogramming and Time Sharing",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "13.2 Multiprogramming and Time Sharing\nAfter a time, because machines were expensive, people began t o share\nmachines more effectively . Thus the era of multiprogramming was born\n[DV66], in which multiple processes were ready to run at a give n time,\nand the OS would switch between them, for example when one decide d\nto perform an I/O. Doing so increased the effective utilization of the\nCPU. Such increases in ef\ufb01ciency were particularly important in those\ndays where each machine cost hundreds of thousands or even million s of\ndollars (and you thought your Mac was expensive!).\nSoon enough, however , people began demanding more of machines,\nand the era of time sharing was born [S59, L60, M62, M83]. Speci\ufb01cally ,\nmany realized the limitations of batch computing, particularl y on pro-\ngrammers themselves [CV65], who were tired of long (and hence i neffec-\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "CPU. Such increases in ef\ufb01ciency were particularly important in those",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "increases",
          "particularly",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand multiprogramming and time sharing",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "multiprogramming",
          "time",
          "sharing"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 T H E AB S T R A C T I O N : A D D R E S S SPA C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 T H E AB S T R A C T I O N : A D D R E S S SPA C E S\nmax\n64KB\n0KB\nCurrent Program\n(code, data, etc.)\nOperating System\n(code, data, etc.)\nFigure 13.1: Operating Systems: The Early Days\ntive) program-debug cycles. The notion of interactivity became impor-\ntant, as many users might be concurrently using a machine, eac h waiting\nfor (or hoping for) a timely response from their currently-executi ng tasks.\nOne way to implement time sharing would be to run one process for a\nshort while, giving it full access to all memory (Figure 13.1), then stop it,\nsave all of its state to some kind of disk (including all of physica l mem-\nory), load some other process\u2019s state, run it for a while, and thus imp le-\nment some kind of crude sharing of the machine [M+63].\nUnfortunately , this approach has a big problem: it is way too slow ,\nparticularly as memory grows. While saving and restoring regis ter-level\nstate (the PC, general-purpose registers, etc.) is relative ly fast, saving the\nentire contents of memory to disk is brutally non-performant. Thu s, what\nwe\u2019d rather do is leave processes in memory while switching betw een\nthem, allowing the OS to implement time sharing ef\ufb01ciently (a s shown in\nFigure 13.2, page 3).\nIn the diagram, there are three processes (A, B, and C) and each of\nthem have a small part of the 512KB physical memory carved out for\nthem. Assuming a single CPU, the OS chooses to run one of the process es\n(say A), while the others (B and C) sit in the ready queue waitin g to run.\nAs time sharing became more popular , you can probably guess that\nnew demands were placed on the operating system. In particular , allow-\ning multiple programs to reside concurrently in memory makes protec-\ntion an important issue; you don\u2019t want a process to be able to read, or\nworse, write some other process\u2019s memory .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One way to implement time sharing would be to run one process for a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "time",
          "sharing",
          "would",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Unfortunately , this approach has a big problem: it is way too slow ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unfortunately",
          "approach",
          "problem",
          "slow"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "them, allowing the OS to implement time sharing ef\ufb01ciently (a s shown in",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "allowing",
          "implement",
          "time",
          "sharing",
          "shown"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "tion an important issue; you don\u2019t want a process to be able to read, or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "important",
          "issue",
          "want",
          "process",
          "able",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1: Operating Systems: The Early Days",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "operating",
          "systems",
          "early",
          "days"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "13",
    "title": "3 The Address Space",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "13.3 The Address Space\nHowever , we have to keep those pesky users in mind, and doing so\nrequires the OS to create an easy to use abstraction of physical memory .\nW e call this abstraction the address space , and it is the running program\u2019s\nview of memory in the system. Understanding this fundamental O S ab-\nstraction of memory is key to understanding how memory is virtuali zed.\nThe address space of a process contains all of the memory state of the\nrunning program. For example, the code of the program (the instruc-\ntions) have to live in memory somewhere, and thus they are in the a d-\ndress space. The program, while it is running, uses a stack to keep track\nof where it is in the function call chain as well as to allocate loca l variables\nand pass parameters and return values to and from routines. Fin ally , the\nheap is used for dynamically-allocated, user-managed memory , such as\nthat you might receive from a call to malloc() in C or new in an object-\noriented language such as C++ or Java. Of course, there are other t hings\nin there too (e.g., statically-initialized variables), but for now let us just\nassume those three components: code, stack, and heap.\nIn the example in Figure 13.3 (page 4), we have a tiny address s pace\n(only 16KB) 1 . The program code lives at the top of the address space\n1 W e will often use small examples like this because (a) it is a pain t o represent a 32-bit\naddress space and (b) the math is harder . W e like simple math.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "requires the OS to create an easy to use abstraction of physical memory .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "requires",
          "create",
          "easy",
          "abstraction",
          "physical",
          "memory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "view of memory in the system. Understanding this fundamental O S ab-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "view",
          "memory",
          "system",
          "understanding",
          "fundamental"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "straction of memory is key to understanding how memory is virtuali zed.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "straction",
          "memory",
          "understanding",
          "memory",
          "virtuali"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the address space",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "address",
          "space"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 T H E AB S T R A C T I O N : A D D R E S S SPA C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 T H E AB S T R A C T I O N : A D D R E S S SPA C E S\n16KB\n15KB\n2KB\n1KB\n0KB\nStack\n(free)\nHeap\nProgram Code the code segment:\nwhere instructions live\nthe heap segment:\ncontains malloc\u2019d data\ndynamic data structures\n(it grows downward)\n(it grows upward)\nthe stack segment:\ncontains local variables\narguments to routines, \nreturn values, etc.\nFigure 13.3: An Example Address Space\n(starting at 0 in this example, and is packed into the \ufb01rst 1K of the ad-\ndress space). Code is static (and thus easy to place in memory), so we can\nplace it at the top of the address space and know that it won\u2019t need an y\nmore space as the program runs.\nNext, we have the two regions of the address space that may grow\n(and shrink) while the program runs. Those are the heap (at the t op) and\nthe stack (at the bottom). W e place them like this because each w ishes to\nbe able to grow , and by putting them at opposite ends of the address\nspace, we can allow such growth: they just have to grow in opposite\ndirections. The heap thus starts just after the code (at 1KB) an d grows\ndownward (say when a user requests more memory via malloc()); the\nstack starts at 16KB and grows upward (say when a user makes a pr oce-\ndure call). However , this placement of stack and heap is just a c onvention;\nyou could arrange the address space in a different way if you\u2019d lik e (as\nwe\u2019ll see later , when multiple threads co-exist in an address space, no\nnice way to divide the address space like this works anymore, al as).\nOf course, when we describe the address space, what we are desc rib-\ning is the abstraction that the OS is providing to the running program.\nThe program really isn\u2019t in memory at physical addresses 0 throug h 16KB;\nrather it is loaded at some arbitrary physical address(es). Ex amine pro-\ncesses A, B, and C in Figure 13.2; there you can see how each proces s is\nloaded into memory at a different address. And hence the problem :\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "place it at the top of the address space and know that it won\u2019t need an y",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "place",
          "address",
          "space",
          "know",
          "need"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "be able to grow , and by putting them at opposite ends of the address",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "grow",
          "putting",
          "opposite",
          "ends",
          "address"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Of course, when we describe the address space, what we are desc rib-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "describe",
          "address",
          "space",
          "desc"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand the heap segment: contains malloc\u2019d data",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the heap segment",
          "contains",
          "malloc",
          "data"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand the stack segment: contains local variables",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the stack segment",
          "contains",
          "local",
          "variables"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 3: An Example Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "example",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "13",
    "title": "4 Goals",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "13.4 Goals\nThus we arrive at the job of the OS in this set of notes: to virtualiz e\nmemory . The OS will not only virtualize memory , though; it will do s o\nwith style. T o make sure the OS does so, we need some goals to guide u s.\nW e have seen these goals before (think of the Introduction), and we \u2019ll see\nthem again, but they are certainly worth repeating.\nOne major goal of a virtual memory (VM) system is transparency2 .\nThe OS should implement virtual memory in a way that is invisibl e to\nthe running program. Thus, the program shouldn\u2019t be aware of the fa ct\nthat memory is virtualized; rather , the program behaves as if i t has its\nown private physical memory . Behind the scenes, the OS (and har dware)\ndoes all the work to multiplex memory among many different jobs, an d\nhence implements the illusion.\nAnother goal of VM is ef\ufb01ciency . The OS should strive to make the\nvirtualization as ef\ufb01cient as possible, both in terms of time (i.e., not mak-\ning programs run much more slowly) and space (i.e., not using too mu ch\nmemory for structures needed to support virtualization). In imp lement-\ning time-ef\ufb01cient virtualization, the OS will have to rely on h ardware\nsupport, including hardware features such as TLBs (which we w ill learn\nabout in due course).\nFinally , a third VM goal is protection. The OS should make sure to\nprotect processes from one another as well as the OS itself from pro-\n2 This usage of transparency is sometimes confusing; some students think tha t \u201cbeing\ntransparent\u201d means keeping everything out in the open, i.e., what gove rnment should be like.\nHere, it means the opposite: that the illusion provided by the OS shou ld not be visible to ap-\nplications. Thus, in common usage, a transparent system is one that is ha rd to notice, not one\nthat responds to requests as stipulated by the Freedom of Informat ion Act.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_2",
        "text": "with style. T o make sure the OS does so, we need some goals to guide u s.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "style",
          "make",
          "sure",
          "need",
          "goals",
          "guide"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "W e have seen these goals before (think of the Introduction), and we \u2019ll see",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "seen",
          "goals",
          "think",
          "introduction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "One major goal of a virtual memory (VM) system is transparency2 .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "major",
          "goal",
          "virtual",
          "memory",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The OS should implement virtual memory in a way that is invisibl e to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "virtual",
          "memory",
          "invisibl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "hence implements the illusion.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hence",
          "implements",
          "illusion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "Another goal of VM is ef\ufb01ciency . The OS should strive to make the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "goal",
          "strive",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "support, including hardware features such as TLBs (which we w ill learn",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "including",
          "hardware",
          "features",
          "tlbs",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "Finally , a third VM goal is protection. The OS should make sure to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "third",
          "goal",
          "protection",
          "make",
          "sure"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand it: the opposite: that the illusion provided by the OS shou ld not be visible to ap-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it",
          "opposite",
          "illusion",
          "provided",
          "shou",
          "visible"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand goals",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "goals"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "13",
    "title": "5 Summary",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "13.5 Summary\nW e have seen the introduction of a major OS subsystem: virtual mem -\nory . The VM system is responsible for providing the illusion of a lar ge,\nsparse, private address space to programs, which hold all of the ir instruc-\ntions and data therein. The OS, with some serious hardware help, w ill\ntake each of these virtual memory references, and turn them int o physi-\ncal addresses, which can be presented to the physical memory i n order to\nfetch the desired information. The OS will do this for many proces ses at\nonce, making sure to protect programs from one another , as well as pr o-\ntect the OS. The entire approach requires a great deal of mechani sm (lots\nof low-level machinery) as well as some critical policies to work; we\u2019ll\nstart from the bottom up, describing the critical mechanisms \ufb01r st. And\nthus we proceed!\n3 Or , we\u2019ll convince you to drop the course. But hold on; if you make it throu gh VM, you\u2019ll\nlikely make it all the way!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tect the OS. The entire approach requires a great deal of mechani sm (lots",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tect",
          "entire",
          "approach",
          "requires",
          "great",
          "deal",
          "mechani",
          "lots"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of low-level machinery) as well as some critical policies to work; we\u2019ll",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "level",
          "machinery",
          "well",
          "critical",
          "policies",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "start from the bottom up, describing the critical mechanisms \ufb01r st. And",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "bottom",
          "describing",
          "critical",
          "mechanisms"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "TH E AB S T R A C T I O N : A D D R E S S SPA C E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "TH E AB S T R A C T I O N : A D D R E S S SPA C E S 7\nAS I D E : E V E RY AD D R E S S YO U SE E IS VI RT U A L\nEver write a C program that prints out a pointer? The value you see\n(some large number , often printed in hexadecimal), is a virtual address .\nEver wonder where the code of your program is found? Y ou can print\nthat out too, and yes, if you can print it, it also is a virtual addre ss. In\nfact, any address you can see as a programmer of a user-level progr am\nis a virtual address. It\u2019s only the OS, through its tricky techniq ues of\nvirtualizing memory , that knows where in the physical memory of t he\nmachine these instructions and data values lie. So never forget : if you\nprint out an address in a program, it\u2019s a virtual one, an illusion of h ow\nthings are laid out in memory; only the OS (and the hardware) knows the\nreal truth.\nHere\u2019s a little program ( va.c) that prints out the locations of the main()\nroutine (where code lives), the value of a heap-allocated value r eturned\nfrom malloc(), and the location of an integer on the stack:\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 int main(int argc, char *argv[]) {\n4 printf(\"location of code : %p\\n\", main);\n5 printf(\"location of heap : %p\\n\", malloc(100e6));\n6 int x = 3;\n7 printf(\"location of stack: %p\\n\", &x);\n8 return x;\n9 }\nWhen run on a 64-bit Mac, we get the following output:\nlocation of code : 0x1095afe50\nlocation of heap : 0x1096008c0\nlocation of stack: 0x7fff691aea64\nFrom this, you can see that code comes \ufb01rst in the address space, th en\nthe heap, and the stack is all the way at the other end of this larg e virtual\nspace. All of these addresses are virtual, and will be transla ted by the OS\nand hardware in order to fetch values from their true physical l ocations.\n.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "virtualizing memory , that knows where in the physical memory of t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing",
          "memory",
          "knows",
          "physical",
          "memory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "things are laid out in memory; only the OS (and the hardware) knows the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "things",
          "laid",
          "memory",
          "hardware",
          "knows"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: E V E RY AD D R E S S YO U SE E IS VI RT U A L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand location of heap: %p\\n\", malloc(100e6));",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "location of heap",
          "malloc"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 T H E AB S T R A C T I O N : A D D R E S S SPA C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 T H E AB S T R A C T I O N : A D D R E S S SPA C E S\nReferences\n[BH70] \u201cThe Nucleus of a Multiprogramming System\u201d by Per Brinch Hansen. C ommunica-\ntions of the ACM, 13:4, April 1970. The \ufb01rst paper to suggest that the OS, or kernel, should be\na minimal and \ufb02exible substrate for building customized operating systems ; this theme is revisited\nthroughout OS research history.\n[CV65] \u201cIntroduction and Overview of the Multics System\u201d by F . J. Corba to, V . A. V yssotsky .\nFall Joint Computer Conference, 1965. A great early Multics paper . Here is the great quote about\ntime sharing: \u201cThe impetus for time-sharing \ufb01rst arose from professional p rogrammers because of their\nconstant frustration in debugging programs at batch processing installations. Thus, the original goal\nwas to time-share computers to allow simultaneous access by several persons wh ile giving to each of\nthem the illusion of having the whole machine at his disposal.\u201d\n[DV66] \u201cProgramming Semantics for Multiprogrammed Computations\u201d b y Jack B. Dennis,\nEarl C. V an Horn. Communications of the ACM, V olume 9, Number 3, March 1 966. An early\npaper (but not the \ufb01rst) on multiprogramming.\n[L60] \u201cMan-Computer Symbiosis\u201d by J. C. R. Licklider . IRE T ransactio ns on Human Factors in\nElectronics, HFE-1:1, March 1960. A funky paper about how computers and people are going to enter\ninto a symbiotic age; clearly well ahead of its time but a fascinating read none theless.\n[M62] \u201cTime-Sharing Computer Systems\u201d by J. McCarthy . Management and the Co mputer\nof the Future, MIT Press, Cambridge, MA, 1962. Probably McCarthy\u2019s earliest recorded paper\non time sharing. In another paper [M83], he claims to have been thinking of the ide a since 1957.\nMcCarthy left the systems area and went on to become a giant in Arti\ufb01cial Intel ligence at Stanford,\nincluding the creation of the LISP programming language. See McCarthy\u2019s hom e page for more info:\nhttp://www-formal.stanford.edu/jmc/\n[M+63] \u201cA Time-Sharing Debugging System for a Small Computer \u201d by J. McCa rthy , S. Boilen,\nE. Fredkin, J. C. R. Licklider . AFIPS \u201963 (Spring), New Y ork, NY , May 19 63. A great early example\nof a system that swapped program memory to the \u201cdrum\u201d when the program wasn\u2019t r unning, and then\nback into \u201ccore\u201d memory when it was about to be run.\n[M83] \u201cReminiscences on the History of Time Sharing\u201d by John McCarthy . 1983. A vailable:\nhttp://www-formal.stanford.edu/jmc/history/timesharing/timesharing.html. A terri\ufb01c his-\ntorical note on where the idea of time-sharing might have come fzshortm, includ ing some doubts towards\nthose who cite Strachey\u2019s work [S59] as the by pioneering work in this area..\n[NS07] \u201cV algrind: A Framework for Heavyweight Dynamic Binary Instr umentation\u201d by N.\nNethercote, J. Seward. PLDI 2007, San Diego, California, June 2007. V algrind is a lifesaver of a\nprogram for those who use unsafe languages like C. Read this paper to learn about its very cool binary\ninstrumentation techniques \u2013 it\u2019s really quite impressive.\n[R+89] \u201cMach: A System Software kernel\u201d by R. Rashid, D. Julin, D. Orr , R. Sanzi, R. Baron,\nA. Forin, D. Golub, M. Jones. COMPCON \u201989, February 1989. Although not the \ufb01rst project on\nmicrokernels per se, the Mach project at CMU was well-known and in\ufb02uential; it still lives today deep\nin the bowels of Mac OS X.\n[S59] \u201cTime Sharing in Large Fast Computers\u201d by C. Strachey . Proceed ings of the International\nConference on Information Processing, UNESCO, June 1959. One of the earliest references on time\nsharing.\n[S+03] \u201cImproving the Reliability of Commodity Operating System s\u201d by M. M. Swift, B. N.\nBershad, H. M. Levy . SOSP \u201903. The \ufb01rst paper to show how microkernel-like thinking can improve\noperating system reliability.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "constant frustration in debugging programs at batch processing installations. Thus, the original goal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "constant",
          "frustration",
          "debugging",
          "programs",
          "batch",
          "processing",
          "installations",
          "thus"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "program for those who use unsafe languages like C. Read this paper to learn about its very cool binary",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "unsafe",
          "languages",
          "like",
          "read",
          "paper",
          "learn",
          "cool"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "instrumentation techniques \u2013 it\u2019s really quite impressive.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "instrumentation",
          "techniques",
          "really",
          "quite",
          "impressive"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "microkernels per se, the Mach project at CMU was well-known and in\ufb02uential; it still lives today deep",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "microkernels",
          "mach",
          "project",
          "well",
          "known",
          "still",
          "lives",
          "today"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 13: 4, April 1970. The \ufb01rst paper to suggest that the OS, or kernel, should be",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "13",
          "april",
          "paper",
          "suggest",
          "kernel"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 1: 1, March 1960. A funky paper about how computers and people are going to enter",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "march",
          "funky",
          "paper",
          "computers",
          "people",
          "going",
          "enter"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A vailable: http://www-formal.stanford.edu/jmc/history/timesharing/timesharing.html. A terri\ufb01c his-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "formal",
          "stanford",
          "history",
          "timesharing",
          "timesharing",
          "html"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand V algrind: A Framework for Heavyweight Dynamic Binary Instr umentation\u201d by N.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v algrind",
          "framework",
          "heavyweight",
          "dynamic",
          "binary",
          "instr",
          "umentation"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Mach: A System Software kernel\u201d by R. Rashid, D. Julin, D. Orr , R. Sanzi, R. Baron,",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "mach",
          "system",
          "software",
          "kernel",
          "rashid",
          "julin",
          "sanzi",
          "baron"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "The \ufb01rst Linux tool you should check out is the very simple tool",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1. The \ufb01rst Linux tool you should check out is the very simple tool\nfree. First, type man free and read its entire manual page; it\u2019s\nshort, don\u2019t worry!",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now , run free, perhaps using some of the arguments that might",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "2. Now , run free, perhaps using some of the arguments that might\nbe useful (e.g., -m, to display memory totals in megabytes). How\nmuch memory is in your system? How much is free? Do these\nnumbers match your intuition?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Next, create a little program that uses a certain amount of mem ory ,",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "3. Next, create a little program that uses a certain amount of mem ory ,\ncalled memory-user.c. This program should take one command-\nline argument: the number of megabytes of memory it will use.\nWhen run, it should allocate an array , and constantly stream thr ough\nthe array , touching each entry . The program should do this inde\ufb01 -\nnitely , or , perhaps, for a certain amount of time also speci\ufb01ed at the\ncommand line.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Next, create a little program that uses a certain amount of mem ory ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "next",
          "create",
          "little",
          "program",
          "uses",
          "certain",
          "amount"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand line argument: the number of megabytes of memory it will use.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "line argument",
          "number",
          "megabytes",
          "memory"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Now , while running your memory-user program, also (in a dif-",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "4. Now , while running your memory-user program, also (in a dif-\nferent terminal window , but on the same machine) run the free\ntool. How do the memory usage totals change when your program\nis running? How about when you kill the memory-user program?\nDo the numbers match your expectations? T ry this for different\namounts of memory usage. What happens when you use really\nlarge amounts of memory?\n5. Let\u2019s try one more tool, known as pmap. Spend some time, and read\nthe pmap manual page in detail.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s try one more tool, known as pmap. Spend some time, and read",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tool",
          "known",
          "pmap",
          "spend",
          "time",
          "read"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "6",
    "title": "T o use pmap, you have to know the process ID of the process you\u2019re",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "6. T o use pmap, you have to know the process ID of the process you\u2019re\ninterested in. Thus, \ufb01rst run ps auxw to see a list of all processes;\nthen, pick an interesting one, such as a browser . Y ou can also use\nyour memory-user program in this case (indeed, you can even\nhave that program call getpid() and print out its PID for your\nconvenience).",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o use pmap, you have to know the process ID of the process you\u2019re",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pmap",
          "know",
          "process",
          "process"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "7",
    "title": "Now run pmap on some of these processes, using various \ufb02ags (like",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "7. Now run pmap on some of these processes, using various \ufb02ags (like\n-X) to reveal many details about the process. What do you see?\nHow many different entities make up a modern address space, as\nopposed to our simple conception of code/stack/heap?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "opposed to our simple conception of code/stack/heap?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "opposed",
          "simple",
          "conception",
          "code",
          "stack",
          "heap"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand x) to reveal many details about the process. what do you see?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reveal",
          "many",
          "details",
          "process"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_7",
    "number": "8",
    "title": "Finally , let\u2019s run pmap on your your memory-user program, with",
    "document_source": "book.pdf",
    "start_line": 40,
    "type": "chapter",
    "content": "8. Finally , let\u2019s run pmap on your your memory-user program, with\ndifferent amounts of used memory . What do you see here? Does\nthe output from pmap match your expectations?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "14",
    "title": "1 T ypes of Memory",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "14.1 T ypes of Memory\nIn running a C program, there are two types of memory that are allo-\ncated. The \ufb01rst is called stack memory , and allocations and deallocations\nof it are managed implicitly by the compiler for you, the programmer; for\nthis reason it is sometimes called automatic memory .\nDeclaring memory on the stack in C is easy . For example, let\u2019s say y ou\nneed some space in a function func() for an integer , called x. T o declare\nsuch a piece of memory , you just do something like this:\nvoid func() {\nint x; // declares an integer on the stack\n...\n}\nThe compiler does the rest, making sure to make space on the stack\nwhen you call into func(). When you return from the function, the com-\npiler deallocates the memory for you; thus, if you want some informat ion\nto live beyond the call invocation, you had better not leave that in forma-\ntion on the stack.\n1 Indeed, we hope all chapters are! But this one is shorter and pointier , w e think.\n1",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand t ypes of memory",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ypes",
          "memory"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "14",
    "title": "2 The malloc() Call",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "14.2 The malloc() Call\nThe malloc() call is quite simple: you pass it a size asking for some\nroom on the heap, and it either succeeds and gives you back a pointer to\nthe newly-allocated space, or fails and returns NULL2 .\nThe manual page shows what you need to do to use malloc; type man\nmalloc at the command line and you will see:\n#include <stdlib.h>\n...\nvoid *malloc(size_t size);\nFrom this information, you can see that all you need to do is include\nthe header \ufb01le stdlib.h to use malloc. In fact, you don\u2019t really need to\neven do this, as the C library , which all C programs link with by default,\nhas the code for malloc() inside of it; adding the header just lets the\ncompiler check whether you are calling malloc() correctly (e.g., passing\nthe right number of arguments to it, of the right type).\nThe single parameter malloc() takes is of type size\nt which sim-\nply describes how many bytes you need. However , most programmers\ndo not type in a number here directly (such as 10); indeed, it wou ld be\nconsidered poor form to do so. Instead, various routines and macros ar e\n2 Note that NULL in C isn\u2019t really anything special at all, just a macro for the value zer o.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "malloc at the command line and you will see:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "malloc",
          "command",
          "line"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ply describes how many bytes you need. However , most programmers",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describes",
          "many",
          "bytes",
          "need",
          "however",
          "programmers"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand call is quite simple: you pass it a size asking for some",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "call is quite simple",
          "pass",
          "size",
          "asking"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the malloc() call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "malloc",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : M E M O RY API 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : M E M O RY API 3\nTI P : W H E N IN DO U B T, T RY IT OU T\nIf you aren\u2019t sure how some routine or operator you are using behaves,\nthere is no substitute for simply trying it out and making sure i t behaves\nas you expect. While reading the manual pages or other documentat ion\nis useful, how it works in practice is what matters. W rite some cod e and\ntest it! That is no doubt the best way to make sure your code behave s as\nyou desire. Indeed, that is what we did to double-check the thin gs we\nwere saying about sizeof() were actually true!\nutilized. For example, to allocate space for a double-precision \ufb02 oating\npoint value, you simply do this:\ndouble *d = (double *) malloc(sizeof(double));\nW ow , that\u2019s lot of double-ing! This invocation of malloc() uses the\nsizeof() operator to request the right amount of space; in C, this is\ngenerally thought of as a compile-time operator , meaning that the actual\nsize is known at compile time and thus a number (in this case, 8, for a\ndouble) is substituted as the argument to malloc(). For this reason,\nsizeof() is correctly thought of as an operator and not a function call\n(a function call would take place at run time).\nY ou can also pass in the name of a variable (and not just a type) to\nsizeof(), but in some cases you may not get the desired results, so be\ncareful. For example, let\u2019s look at the following code snippet:\nint *x = malloc(10 * sizeof(int));\nprintf(\"%d\\n\", sizeof(x));\nIn the \ufb01rst line, we\u2019ve declared space for an array of 10 integers , which\nis \ufb01ne and dandy . However , when we use sizeof() in the next line,\nit returns a small value, such as 4 (on 32-bit machines) or 8 (on 64 -bit\nmachines). The reason is that in this case, sizeof() thinks we are sim-\nply asking how big a pointer to an integer is, not how much memory we\nhave dynamically allocated. However , sometimes sizeof() does work\nas you might expect:\nint x[10];\nprintf(\"%d\\n\", sizeof(x));\nIn this case, there is enough static information for the compiler t o\nknow that 40 bytes have been allocated.\nAnother place to be careful is with strings. When declaring sp ace for a\nstring, use the following idiom: malloc(strlen(s) + 1), which gets\nthe length of the string using the function strlen(), and adds 1 to it\nin order to make room for the end-of-string character . Using sizeof()\nmay lead to trouble here.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "size is known at compile time and thus a number (in this case, 8, for a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "size",
          "known",
          "compile",
          "time",
          "thus",
          "number",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "know that 40 bytes have been allocated.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "bytes",
          "allocated"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: W H E N IN DO U B T, T RY IT OU T",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand you simply do this: double *d = (double *) malloc(sizeof(double));",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "you simply do this",
          "double",
          "double",
          "malloc",
          "sizeof",
          "double"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand use the following idiom: malloc(strlen(s) + 1), which gets",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "use the following idiom",
          "malloc",
          "strlen",
          "gets"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "14",
    "title": "3 The free() Call",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "14.3 The free() Call\nAs it turns out, allocating memory is the easy part of the equation;\nknowing when, how , and even if to free memory is the hard part. T o f ree\nheap memory that is no longer in use, programmers simply call free():\nint *x = malloc(10 * sizeof(int));\n...\nfree(x);\nThe routine takes one argument, a pointer returned by malloc().\nThus, you might notice, the size of the allocated region is not passe d in\nby the user , and must be tracked by the memory-allocation librar y itself.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "knowing when, how , and even if to free memory is the hard part. T o f ree",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowing",
          "even",
          "free",
          "memory",
          "hard",
          "part"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the free() call",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "14",
    "title": "4 Common Errors",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "14.4 Common Errors\nThere are a number of common errors that arise in the use of malloc()\nand free(). Here are some we\u2019ve seen over and over again in teaching\nthe undergraduate operating systems course. All of these examp les com-\npile and run with nary a peep from the compiler; while compiling a C\nprogram is necessary to build a correct C program, it is far from su f\ufb01-\ncient, as you will learn (often in the hard way).\nCorrect memory management has been such a problem, in fact, that\nmany newer languages have support for automatic memory manage-\nment. In such languages, while you call something akin to malloc()\nto allocate memory (usually new or something similar to allocate a new\nobject), you never have to call something to free space; rather , a garbage\ncollector runs and \ufb01gures out what memory you no longer have refer-\nences to and frees it for you.\nForgetting T o Allocate Memory\nMany routines expect memory to be allocated before you call them. F or\nexample, the routine strcpy(dst, src) copies a string from a source\npointer to a destination pointer . However , if you are not careful, y ou\nmight do this:\nchar *src = \"hello\";\nchar *dst; // oops! unallocated\nstrcpy(dst, src); // segfault and die\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "cient, as you will learn (often in the hard way).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cient",
          "learn",
          "often",
          "hard"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand common errors",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "errors"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : M E M O RY API 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : M E M O RY API 5\nTI P : I T CO M P I L E D OR IT RA N \u0338= IT IS CO R R E C T\nJust because a program compiled(!) or even ran once or many times cor-\nrectly does not mean the program is correct. Many events may have c on-\nspired to get you to a point where you believe it works, but then some -\nthing changes and it stops. A common student reaction is to say (or y ell)\n\u201cBut it worked before!\u201d and then blame the compiler , operating sys tem,\nhardware, or even (dare we say it) the professor . But the problem i s usu-\nally right where you think it would be, in your code. Get to work and\ndebug it before you blame those other components.\nWhen you run this code, it will likely lead to a segmentation fault 3 ,\nwhich is a fancy term for YOU DID SOMETHING WRONG WITH\nMEMORY YOU FOOLISH PROGRAMMER AND I AM ANGRY .\nIn this case, the proper code might instead look like this:\nchar *src = \"hello\";\nchar *dst = (char *) malloc(strlen(src) + 1);\nstrcpy(dst, src); // work properly\nAlternately , you could use strdup() and make your life even easier .\nRead the strdup man page for more information.\nNot Allocating Enough Memory\nA related error is not allocating enough memory , sometimes called a buffer\nover\ufb02ow . In the example above, a common error is to make almost enough\nroom for the destination buffer .\nchar *src = \"hello\";\nchar *dst = (char *) malloc(strlen(src)); // too small!\nstrcpy(dst, src); // work properly\nOddly enough, depending on how malloc is implemented and many\nother details, this program will often run seemingly correctly . In some\ncases, when the string copy executes, it writes one byte too far p ast the\nend of the allocated space, but in some cases this is harmless, pe rhaps\noverwriting a variable that isn\u2019t used anymore. In some cases, th ese over-\n\ufb02ows can be incredibly harmful, and in fact are the source of many secu-\nrity vulnerabilities in systems [W06]. In other cases, the ma lloc library\nallocated a little extra space anyhow , and thus your program actu ally\ndoesn\u2019t scribble on some other variable\u2019s value and works quite \ufb01ne. In\neven other cases, the program will indeed fault and crash. And t hus we\nlearn another valuable lesson: even though it ran correctly once, doesn\u2019t\nmean it\u2019s correct.\n3 Although it sounds arcane, you will soon learn why such an illegal me mory access is\ncalled a segmentation fault; if that isn\u2019t incentive to read on, what is?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Oddly enough, depending on how malloc is implemented and many",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "oddly",
          "enough",
          "depending",
          "malloc",
          "implemented",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "learn another valuable lesson: even though it ran correctly once, doesn\u2019t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "another",
          "valuable",
          "lesson",
          "even",
          "though",
          "correctly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Although it sounds arcane, you will soon learn why such an illegal me mory access is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "although",
          "sounds",
          "arcane",
          "soon",
          "learn",
          "illegal",
          "mory",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: I T CO M P I L E D OR IT RA N \u0338= IT IS CO R R E C T",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 IN T E R L U D E : M E M O RY API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 IN T E R L U D E : M E M O RY API\nForgetting to Initialize Allocated Memory\nWith this error , you call malloc() properly , but forget to \ufb01ll in some val-\nues into your newly-allocated data type. Don\u2019t do this! If you do for get,\nyour program will eventually encounter an uninitialized read , where it\nreads from the heap some data of unknown value. Who knows what\nmight be in there? If you\u2019re lucky , some value such that the progra m still\nworks (e.g., zero). If you\u2019re not lucky , something random and harmfu l.\nForgetting T o Free Memory\nAnother common error is known as a memory leak , and it occurs when\nyou forget to free memory . In long-running applications or systems (such\nas the OS itself), this is a huge problem, as slowly leaking memor y even-\ntually leads one to run out of memory , at which point a restart is req uired.\nThus, in general, when you are done with a chunk of memory , you should\nmake sure to free it. Note that using a garbage-collected langu age doesn\u2019t\nhelp here: if you still have a reference to some chunk of memory , no\ngarbage collector will ever free it, and thus memory leaks remai n a prob-\nlem even in more modern languages.\nIn some cases, it may seem like not calling free() is reasonable. For\nexample, your program is short-lived, and will soon exit; in this c ase,\nwhen the process dies, the OS will clean up all of its allocated pa ges and\nthus no memory leak will take place per se. While this certainl y \u201cworks\u201d\n(see the aside on page 7), it is probably a bad habit to develop, so be wary\nof choosing such a strategy . In the long run, one of your goals as a pro-\ngrammer is to develop good habits; one of those habits is understand ing\nhow you are managing memory , and (in languages like C), freeing t he\nblocks you have allocated. Even if you can get away with not doing so,\nit is probably good to get in the habit of freeing each and every byt e you\nexplicitly allocate.\nFreeing Memory Before Y ou Are Done With It\nSometimes a program will free memory before it is \ufb01nished using it; such\na mistake is called a dangling pointer , and it, as you can guess, is also a\nbad thing. The subsequent use can crash the program, or overwrit e valid\nmemory (e.g., you called free(), but then called malloc() again to\nallocate something else, which then recycles the errantly-fr eed memory).\nFreeing Memory Repeatedly\nPrograms also sometimes free memory more than once; this is known as\nthe double free . The result of doing so is unde\ufb01ned. As you can imag-\nine, the memory-allocation library might get confused and do all sorts of\nweird things; crashes are a common outcome.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "reads from the heap some data of unknown value. Who knows what",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reads",
          "heap",
          "data",
          "unknown",
          "value",
          "knows"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Another common error is known as a memory leak , and it occurs when",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "common",
          "error",
          "known",
          "memory",
          "leak",
          "occurs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "(see the aside on page 7), it is probably a bad habit to develop, so be wary",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "aside",
          "page",
          "probably",
          "habit",
          "develop",
          "wary"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "of choosing such a strategy . In the long run, one of your goals as a pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "choosing",
          "strategy",
          "long",
          "goals"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "grammer is to develop good habits; one of those habits is understand ing",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "grammer",
          "develop",
          "good",
          "habits",
          "habits",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Programs also sometimes free memory more than once; this is known as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "programs",
          "also",
          "sometimes",
          "free",
          "memory",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "weird things; crashes are a common outcome.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "weird",
          "things",
          "crashes",
          "common",
          "outcome"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand t\nhelp here: if you still have a reference to some chunk of memory , no",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t\nhelp here",
          "still",
          "reference",
          "chunk",
          "memory"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : M E M O RY API 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : M E M O RY API 7\nAS I D E : W H Y NO ME M O RY IS LE A K E D ON C E YO U R PR O C E S S EX I T S\nWhen you write a short-lived program, you might allocate some space\nusing malloc(). The program runs and is about to complete: is there\nneed to call free() a bunch of times just before exiting? While it seems\nwrong not to, no memory will be \u201clost\u201d in any real sense. The reason is\nsimple: there are really two levels of memory management in the system.\nThe \ufb01rst level of memory management is performed by the OS, which\nhands out memory to processes when they run, and takes it back whe n\nprocesses exit (or otherwise die). The second level of management\nis within each process, for example within the heap when you call\nmalloc() and free(). Even if you fail to call free() (and thus leak\nmemory in the heap), the operating system will reclaim all the memory of\nthe process (including those pages for code, stack, and, as relev ant here,\nheap) when the program is \ufb01nished running. No matter what the s tate\nof your heap in your address space, the OS takes back all of those pag es\nwhen the process dies, thus ensuring that no memory is lost despi te the\nfact that you didn\u2019t free it.\nThus, for short-lived programs, leaking memory often does not cause any\noperational problems (though it may be considered poor form). When\nyou write a long-running server (such as a web server or database man-\nagement system, which never exit), leaked memory is a much big ger is-\nsue, and will eventually lead to a crash when the application r uns out of\nmemory . And of course, leaking memory is an even larger issue insi de\none particular program: the operating system itself. Showing us on ce\nagain: those who write the kernel code have the toughest job of all. ..\nCalling free() Incorrectly\nOne last problem we discuss is the call of free() incorrectly . After all,\nfree() expects you only to pass to it one of the pointers you received\nfrom malloc() earlier . When you pass in some other value, bad things\ncan (and do) happen. Thus, such invalid frees are dangerous and of\ncourse should also be avoided.\nSummary\nAs you can see, there are lots of ways to abuse memory . Because of fre -\nquent errors with memory , a whole ecosphere of tools have developed to\nhelp \ufb01nd such problems in your code. Check out both purify [HJ92] and\nvalgrind [SN05]; both are excellent at helping you locate the source of\nyour memory-related problems. Once you become accustomed to using\nthese powerful tools, you will wonder how you survived without them.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "quent errors with memory , a whole ecosphere of tools have developed to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "quent",
          "errors",
          "memory",
          "whole",
          "ecosphere",
          "tools",
          "developed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "these powerful tools, you will wonder how you survived without them.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "powerful",
          "tools",
          "wonder",
          "survived",
          "without"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: W H Y NO ME M O RY IS LE A K E D ON C E YO U R PR O C E S S EX I T S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand The reason is\nsimple: there are really two levels of memory management in the system.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the reason is\nsimple",
          "really",
          "levels",
          "memory",
          "management",
          "system"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand again: those who write the kernel code have the toughest job of all. ..",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "again",
          "write",
          "kernel",
          "code",
          "toughest"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "14",
    "title": "5 Underlying OS Support",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "14.5 Underlying OS Support\nY ou might have noticed that we haven\u2019t been talking about system\ncalls when discussing malloc() and free(). The reason for this is sim-\nple: they are not system calls, but rather library calls. Thus the malloc li-\nbrary manages space within your virtual address space, but it self is built\non top of some system calls which call into the OS to ask for more mem-\nory or release some back to the system.\nOne such system call is called brk, which is used to change the loca-\ntion of the program\u2019s break: the location of the end of the heap. It takes\none argument (the address of the new break), and thus either inc reases or\ndecreases the size of the heap based on whether the new break is l arger\nor smaller than the current break. An additional call sbrk is passed an\nincrement but otherwise serves a similar purpose.\nNote that you should never directly call either brk or sbrk. They\nare used by the memory-allocation library; if you try to use them, you\nwill likely make something go (horribly) wrong. Stick to malloc() and\nfree() instead.\nFinally , you can also obtain memory from the operating system via t he\nmmap() call. By passing in the correct arguments, mmap() can create an\nanonymous memory region within your program \u2014 a region which is not\nassociated with any particular \ufb01le but rather with swap space , something\nwe\u2019ll discuss in detail later on in virtual memory . This memory ca n then\nalso be treated like a heap and managed as such. Read the manua l page\nof mmap() for more details.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "mmap() call. By passing in the correct arguments, mmap() can create an",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mmap",
          "call",
          "passing",
          "correct",
          "arguments",
          "mmap",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand ple: they are not system calls, but rather library calls. Thus the malloc li-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ple",
          "system",
          "calls",
          "rather",
          "library",
          "calls",
          "thus",
          "malloc"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand s break: the location of the end of the heap. It takes",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s break",
          "location",
          "heap",
          "takes"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand underlying os support",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "underlying",
          "support"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "14",
    "title": "6 Other Calls",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "14.6 Other Calls\nThere are a few other calls that the memory-allocation library su p-\nports. For example, calloc() allocates memory and also zeroes it be-\nfore returning; this prevents some errors where you assume that m emory\nis zeroed and forget to initialize it yourself (see the paragrap h on \u201cunini-\ntialized reads\u201d above). The routine realloc() can also be useful, when\nyou\u2019ve allocated space for something (say , an array), and then nee d to\nadd something to it: realloc() makes a new larger region of memory ,\ncopies the old region into it, and returns the pointer to the new re gion.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand other calls",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "calls"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "14",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "14.7 Summary\nW e have introduced some of the APIs dealing with memory allocation.\nAs always, we have just covered the basics; more details are ava ilable\nelsewhere. Read the C book [KR88] and Stevens [SR05] (Chapter 7) f or\nmore information. For a cool modern paper on how to detect and correct\nmany of these problems automatically , see Novark et al. [N+07]; t his\npaper also contains a nice summary of common problems and some neat\nideas on how to \ufb01nd and \ufb01x them.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : M E M O RY API 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : M E M O RY API 9\nReferences\n[HJ92] \u201cPurify: Fast Detection of Memory Leaks and Access Errors\u201d by R. Hastings, B. Joyce.\nUSENIX Winter \u201992. The paper behind the cool Purify tool, now a commercial product.\n[KR88] \u201cThe C Programming Language\u201d by Brian Kernighan, Dennis Ritchie. Pre ntice-Hall\n1988. The C book, by the developers of C. Read it once, do some programming, then re ad it again, and\nthen keep it near your desk or wherever you program.\n[N+07] \u201cExterminator: Automatically Correcting Memory Errors wi th High Probability\u201d by\nG. Novark, E. D. Berger , B. G. Zorn. PLDI 2007, San Diego, Califor nia. A cool paper on \ufb01nding\nand correcting memory errors automatically, and a great overview of many common e rrors in C and\nC++ programs. An extended version of this paper is available CACM (V olume 5 1, Issue 12, December\n2008).\n[SN05] \u201cUsing V algrind to Detect Unde\ufb01ned V alue Errors with Bit-pre cision\u201d by J. Seward, N.\nNethercote. USENIX \u201905. How to use valgrind to \ufb01nd certain types of errors.\n[SR05] \u201cAdvanced Programming in the U N I X Environment\u201d by W . Richard Stevens, Stephen\nA. Rago. Addison-W esley , 2005. We\u2019ve said it before, we\u2019ll say it again: read this book many times\nand use it as a reference whenever you are in doubt. The authors are always su rprised at how each time\nthey read something in this book, they learn something new, even after many year s of C programming.\n[W06] \u201cSurvey on Buffer Over\ufb02ow Attacks and Countermeasures\u201d by T . W erthman. A vail-\nable: www .nds.rub.de/lehre/seminar/SS06/W erthmann\nBufferOver\ufb02ow .pdf. A nice survey of\nbuffer over\ufb02ows and some of the security problems they cause. Refers to man y of the famous exploits.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The C book, by the developers of C. Read it once, do some programming, then re ad it again, and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "book",
          "developers",
          "read",
          "programming"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "they read something in this book, they learn something new, even after many year s of C programming.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "something",
          "book",
          "learn",
          "something",
          "even",
          "many",
          "year"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Purify: Fast Detection of Memory Leaks and Access Errors\u201d by R. Hastings, B. Joyce.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "purify",
          "fast",
          "detection",
          "memory",
          "leaks",
          "access",
          "errors",
          "hastings",
          "joyce"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Exterminator: Automatically Correcting Memory Errors wi th High Probability\u201d by",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "exterminator",
          "automatically",
          "correcting",
          "memory",
          "errors",
          "high",
          "probability"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand ll say it again: read this book many times",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ll say it again",
          "read",
          "book",
          "many",
          "times"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand able: www .nds.rub.de/lehre/seminar/SS06/W erthmann",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "lehre",
          "seminar",
          "erthmann"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "Next, compile this program with symbol information included (w ith",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "2. Next, compile this program with symbol information included (w ith\nthe -g \ufb02ag). Doing so let\u2019s put more information into the exe-\ncutable, enabling the debugger to access more useful informat ion\nabout variable names and the like. Run the program under the de-\nbugger by typing gdb null and then, once gdb is running, typing\nrun. What does gdb show you?\n3. Finally , use the valgrind tool on this program. W e\u2019ll use the memcheck\ntool that is a part of valgrind to analyze what happens. Run\nthis by typing in the following: valgrind --leak-check=yes\nnull. What happens when you run this? Can you interpret the\noutput from the tool?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tool that is a part of valgrind to analyze what happens. Run",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tool",
          "part",
          "valgrind",
          "analyze",
          "happens"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "W rite a simple program that allocates memory using malloc() but",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "4. W rite a simple program that allocates memory using malloc() but\nforgets to free it before exiting. What happens when this progra m\nruns? Can you use gdb to \ufb01nd any problems with it? How about\nvalgrind (again with the --leak-check=yes \ufb02ag)?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "W rite a program that creates an array of integers called data of size",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "5. W rite a program that creates an array of integers called data of size\n100 using malloc; then, set data[100] to zero. What happens\nwhen you run this program? What happens when you run this\nprogram using valgrind? Is the program correct?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W rite a program that creates an array of integers called data of size",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "program",
          "creates",
          "array",
          "integers",
          "called",
          "data",
          "size"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Create a program that allocates an array of integers (as above) , frees",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "6. Create a program that allocates an array of integers (as above) , frees\nthem, and then tries to print the value of one of the elements of\nthe array . Does the program run? What happens when you use\nvalgrind on it?\n7. Now pass a funny value to free (e.g., a pointer in the middle of t he\narray you allocated above). What happens? Do you need tools to\n\ufb01nd this type of problem?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Create a program that allocates an array of integers (as above) , frees",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "program",
          "allocates",
          "array",
          "integers",
          "frees"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : M E M O RY API 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : M E M O RY API 11\n8. T ry out some of the other interfaces to memory allocation. For ex-\nample, create a simple vector-like data structure and relate d rou-\ntines that use realloc() to manage the vector . Use an array to\nstore the vectors elements; when a user adds an entry to the vec-\ntor , use realloc() to allocate more space for it. How well does\nsuch a vector perform? How does it compare to a linked list? Use\nvalgrind to help you \ufb01nd bugs.\n9. Spend more time and read about using gdb and valgrind. Know-\ning your tools is critical; spend the time and learn how to become\nan expert debugger in the U N I X and C environment.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ample, create a simple vector-like data structure and relate d rou-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ample",
          "create",
          "simple",
          "vector",
          "like",
          "data",
          "structure",
          "relate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "such a vector perform? How does it compare to a linked list? Use",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "vector",
          "perform",
          "compare",
          "linked",
          "list"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Spend more time and read about using gdb and valgrind. Know-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "spend",
          "time",
          "read",
          "using",
          "valgrind",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ing your tools is critical; spend the time and learn how to become",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tools",
          "critical",
          "spend",
          "time",
          "learn",
          "become"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand it compare to a linked list",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "linked",
          "list"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "15\nMechanism: Address Translation\nIn developing the virtualization of the CPU, we focused on a genera l\nmechanism known as limited direct execution (or LDE). The idea be-\nhind LDE is simple: for the most part, let the program run directl y on the\nhardware; however , at certain key points in time (such as when a process\nissues a system call, or a timer interrupt occurs), arrange so t hat the OS\ngets involved and makes sure the \u201cright\u201d thing happens. Thus, the OS,\nwith a little hardware support, tries its best to get out of the wa y of the\nrunning program, to deliver an ef\ufb01cient virtualization; however , by inter-\nposing at those critical points in time, the OS ensures that it maintai ns\ncontrol over the hardware. Ef\ufb01ciency and control together are two of the\nmain goals of any modern operating system.\nIn virtualizing memory , we will pursue a similar strategy , at taining\nboth ef\ufb01ciency and control while providing the desired virtuali zation. Ef-\n\ufb01ciency dictates that we make use of hardware support, which at \ufb01rst\nwill be quite rudimentary (e.g., just a few registers) but wi ll grow to be\nfairly complex (e.g., TLBs, page-table support, and so forth, a s you will\nsee). Control implies that the OS ensures that no application is allowed\nto access any memory but its own; thus, to protect applications fr om one\nanother , and the OS from applications, we will need help from the h ard-\nware here too. Finally , we will need a little more from the VM syste m, in\nterms of \ufb02exibility ; speci\ufb01cally , we\u2019d like for programs to be able to use\ntheir address spaces in whatever way they would like, thus mak ing the\nsystem easier to program. And thus we arrive at the re\ufb01ned crux :\nTH E CR U X :\nHO W TO EFFI C I E N T LY AN D FL E X I B LY VI RT U A L I Z E ME M O RY\nHow can we build an ef\ufb01cient virtualization of memory? How do\nwe provide the \ufb02exibility needed by applications? How do we main tain\ncontrol over which memory locations an application can access, and t hus\nensure that application memory accesses are properly restrict ed? How\ndo we do all of this ef\ufb01ciently?\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In developing the virtualization of the CPU, we focused on a genera l",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developing",
          "virtualization",
          "focused",
          "genera"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "mechanism known as limited direct execution (or LDE). The idea be-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mechanism",
          "known",
          "limited",
          "direct",
          "execution",
          "idea"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "posing at those critical points in time, the OS ensures that it maintai ns",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "posing",
          "critical",
          "points",
          "time",
          "ensures",
          "maintai"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "main goals of any modern operating system.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "goals",
          "modern",
          "operating",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "In virtualizing memory , we will pursue a similar strategy , at taining",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "virtualizing",
          "memory",
          "pursue",
          "similar",
          "strategy",
          "taining"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "fairly complex (e.g., TLBs, page-table support, and so forth, a s you will",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fairly",
          "complex",
          "tlbs",
          "page",
          "table",
          "support",
          "forth"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "terms of \ufb02exibility ; speci\ufb01cally , we\u2019d like for programs to be able to use",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "terms",
          "like",
          "programs",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand hind LDE is simple: for the most part, let the program run directl y on the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hind lde is simple",
          "part",
          "program",
          "directl"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "15",
    "title": "1 Assumptions",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "15.1 Assumptions\nOur \ufb01rst attempts at virtualizing memory will be very simple, almost\nlaughably so. Go ahead, laugh all you want; pretty soon it will be t he OS\nlaughing at you, when you try to understand the ins and outs of TLBs ,\nmulti-level page tables, and other technical wonders. Don\u2019t lik e the idea\nof the OS laughing at you? W ell, you may be out of luck then; that\u2019s jus t\nhow the OS rolls.\nSpeci\ufb01cally , we will assume for now that the user \u2019s address space must\nbe placed contiguously in physical memory . W e will also assume, for sim-\nplicity , that the size of the address space is not too big; speci\ufb01 cally , that\nit is less than the size of physical memory . Finally , we will also assume that\neach address space is exactly the same size . Don\u2019t worry if these assump-\ntions sound unrealistic; we will relax them as we go, thus achiev ing a\nrealistic virtualization of memory .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "laughing at you, when you try to understand the ins and outs of TLBs ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "laughing",
          "understand",
          "outs",
          "tlbs"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand assumptions",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assumptions"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "15",
    "title": "2 An Example",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "15.2 An Example\nT o understand better what we need to do to implement address t rans-\nlation, and why we need such a mechanism, let\u2019s look at a simple exa m-\nple. Imagine there is a process whose address space is as indica ted in\nFigure 15.1. What we are going to examine here is a short code sequ ence\nthat loads a value from memory , increments it by three, and then s tores\nthe value back into memory . Y ou can imagine the C-language repr esen-\ntation of this code might look like this:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand better what we need to do to implement address t rans-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "understand",
          "better",
          "need",
          "implement",
          "address",
          "rans"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand an example",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : A D D R E S S TR A N S L AT I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : A D D R E S S TR A N S L AT I O N 3\nTI P : I N T E R P O S I T I O N IS PO W E R F U L\nInterposition is a generic and powerful technique that is often u sed to\ngreat effect in computer systems. In virtualizing memory , the hardware\nwill interpose on each memory access, and translate each virtua l address\nissued by the process to a physical address where the desired i nforma-\ntion is actually stored. However , the general technique of inter position is\nmuch more broadly applicable; indeed, almost any well-de\ufb01ned i nterface\ncan be interposed upon, to add new functionality or improve some othe r\naspect of the system. One of the usual bene\ufb01ts of such an approach i s\ntransparency; the interposition often is done without changing the client\nof the interface, thus requiring no changes to said client.\nvoid func() {\nint x = 3000; // thanks, Perry.\nx = x + 3; // line of code we are interested in\n...\nThe compiler turns this line of code into assembly , which might l ook\nsomething like this (in x86 assembly). Use objdump on Linux or otool\non a Mac to disassemble it:\n128: movl 0x0(%ebx), %eax ;load 0+ebx into eax\n132: addl $0x03, %eax ;add 3 to eax register\n135: movl %eax, 0x0(%ebx) ;store eax back to mem\nThis code snippet is relatively straightforward; it presumes that the\naddress of x has been placed in the register ebx, and then loads the value\nat that address into the general-purpose register eax using the movl in-\nstruction (for \u201clongword\u201d move). The next instruction adds 3 to eax,\nand the \ufb01nal instruction stores the value in eax back into memory at that\nsame location.\nIn Figure 15.1 (page 4), observe how both the code and data are laid\nout in the process\u2019s address space; the three-instruction code se quence is\nlocated at address 128 (in the code section near the top), and the v alue\nof the variable x at address 15 KB (in the stack near the bottom). In the\n\ufb01gure, the initial value of x is 3000, as shown in its location on the stack.\nWhen these instructions run, from the perspective of the process , the\nfollowing memory accesses take place.\n\u2022 Fetch instruction at address 128\n\u2022 Execute this instruction (load from address 15 KB)\n\u2022 Fetch instruction at address 132\n\u2022 Execute this instruction (no memory reference)\n\u2022 Fetch the instruction at address 135\n\u2022 Execute this instruction (store to address 15 KB)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Interposition is a generic and powerful technique that is often u sed to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interposition",
          "generic",
          "powerful",
          "technique",
          "often"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tion is actually stored. However , the general technique of inter position is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "actually",
          "stored",
          "however",
          "general",
          "technique",
          "inter",
          "position"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "aspect of the system. One of the usual bene\ufb01ts of such an approach i s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "aspect",
          "system",
          "usual",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: I N T E R P O S I T I O N IS PO W E R F U L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 132: addl $0x03, %eax ;add 3 to eax register",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "132",
          "addl",
          "register"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 135: movl %eax, 0x0(%ebx) ;store eax back to mem",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "135",
          "movl",
          "store",
          "back"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand fetch instruction at address 128",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fetch",
          "instruction",
          "address"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand execute this instruction (load from address 15 kb)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "execute",
          "instruction",
          "load",
          "address"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand fetch instruction at address 132",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fetch",
          "instruction",
          "address"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand execute this instruction (no memory reference)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "execute",
          "instruction",
          "memory",
          "reference"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand fetch the instruction at address 135",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fetch",
          "instruction",
          "address"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand execute this instruction (store to address 15 kb)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "execute",
          "instruction",
          "store",
          "address"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 M E C H A N I S M : A D D R E S S TR A N S L AT ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 M E C H A N I S M : A D D R E S S TR A N S L AT I O N\n16KB\n15KB\n14KB\n4KB\n3KB\n2KB\n1KB\n0KB\nStack\n(free)\nHeap\nProgram Code\n128\n132\n135\nmovl 0x0(%ebx),%eax\naddl 0x03, %eax\nmovl %eax,0x0(%ebx)\n3000\nFigure 15.1: A Process And Its Address Space\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 1: A Process And Its Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "process",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "15",
    "title": "3 Dynamic (Hardware-based) Relocation",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "15.3 Dynamic (Hardware-based) Relocation\nT o gain some understanding of hardware-based address transla tion,\nwe\u2019ll \ufb01rst discuss its \ufb01rst incarnation. Introduced in the \ufb01rst time-sharing\nmachines of the late 1950\u2019s is a simple idea referred to as base and bounds;\nthe technique is also referred to as dynamic relocation ; we\u2019ll use both\nterms interchangeably [SS74].\nSpeci\ufb01cally , we\u2019ll need two hardware registers within each CP U: one\nis called the base register , and the other the bounds (sometimes called a\nlimit register). This base-and-bounds pair is going to allow us to pla ce the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o gain some understanding of hardware-based address transla tion,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "gain",
          "understanding",
          "hardware",
          "based",
          "address",
          "transla",
          "tion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the technique is also referred to as dynamic relocation ; we\u2019ll use both",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "technique",
          "also",
          "referred",
          "dynamic",
          "relocation"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand dynamic (hardware-based) relocation",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "dynamic",
          "hardware",
          "based",
          "relocation"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 M E C H A N I S M : A D D R E S S TR A N S L AT ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 M E C H A N I S M : A D D R E S S TR A N S L AT I O N\nAS I D E : S O F T WA R E-B A S E D RE L O C AT I O N\nIn the early days, before hardware support arose, some systems pe r-\nformed a crude form of relocation purely via software methods. The\nbasic technique is referred to as static relocation, in which a piece of soft-\nware known as the loader takes an executable that is about to be run and\nrewrites its addresses to the desired offset in physical memor y .\nFor example, if an instruction was a load from address 1000 into a r eg-\nister (e.g., movl 1000, %eax), and the address space of the program\nwas loaded starting at address 3000 (and not 0, as the program thi nks),\nthe loader would rewrite the instruction to offset each address b y 3000\n(e.g., movl 4000, %eax). In this way , a simple static relocation of the\nprocess\u2019s address space is achieved.\nHowever , static relocation has numerous problems. First and most i m-\nportantly , it does not provide protection, as processes can generat e bad\naddresses and thus illegally access other process\u2019s or even OS me mory; in\ngeneral, hardware support is likely needed for true protection [ WL+93].\nAnother negative is that once placed, it is dif\ufb01cult to later re locate an ad-\ndress space to another location [M65].\naddress space anywhere we\u2019d like in physical memory , and do so w hile\nensuring that the process can only access its own address space.\nIn this setup, each program is written and compiled as if it is loa ded at\naddress zero. However , when a program starts running, the OS dec ides\nwhere in physical memory it should be loaded and sets the base reg ister\nto that value. In the example above, the OS decides to load the pr ocess at\nphysical address 32 KB and thus sets the base register to this value.\nInteresting things start to happen when the process is runnin g. Now ,\nwhen any memory reference is generated by the process, it is translated\nby the processor in the following manner:\nphysical address = virtual address + base\nEach memory reference generated by the process is a virtual address;\nthe hardware in turn adds the contents of the base register to th is address\nand the result is a physical address that can be issued to the memory\nsystem.\nT o understand this better , let\u2019s trace through what happens wh en a\nsingle instruction is executed. Speci\ufb01cally , let\u2019s look at one ins truction\nfrom our earlier sequence:\n128: movl 0x0(%ebx), %eax\nThe program counter (PC) is set to 128; when the hardware needs t o\nfetch this instruction, it \ufb01rst adds the value to the base regi ster value\nof 32 KB (32768) to get a physical address of 32896; the hardware then\nfetches the instruction from that physical address. Next, the processor\nbegins executing the instruction. At some point, the process the n issues\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "formed a crude form of relocation purely via software methods. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "formed",
          "crude",
          "form",
          "relocation",
          "purely",
          "software",
          "methods"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "basic technique is referred to as static relocation, in which a piece of soft-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "technique",
          "referred",
          "static",
          "relocation",
          "piece",
          "soft"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ware known as the loader takes an executable that is about to be run and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ware",
          "known",
          "loader",
          "takes",
          "executable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o understand this better , let\u2019s trace through what happens wh en a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "better",
          "trace",
          "happens"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: S O F T WA R E-B A S E D RE L O C AT I O N",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : A D D R E S S TR A N S L AT I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : A D D R E S S TR A N S L AT I O N 7\nTI P : H A R D WA R E-B A S E D DY N A M I C RE L O C AT I O N\nWith dynamic relocation, a little hardware goes a long way . Namel y , a\nbase register is used to transform virtual addresses (generated b y the pro-\ngram) into physical addresses. A bounds (or limit) register ensures that\nsuch addresses are within the con\ufb01nes of the address space. T oge ther\nthey provide a simple and ef\ufb01cient virtualization of memory .\nthe load from virtual address 15 KB, which the processor takes and again\nadds to the base register (32 KB), getting the \ufb01nal physical a ddress of\n47 KB and thus the desired contents.\nT ransforming a virtual address into a physical address is exa ctly the\ntechnique we refer to as address translation; that is, the hardware takes a\nvirtual address the process thinks it is referencing and tran sforms it into\na physical address which is where the data actually resides. Because this\nrelocation of the address happens at runtime, and because we can move\naddress spaces even after the process has started running, th e technique\nis often referred to as dynamic relocation [M65].\nNow you might be asking: what happened to that bounds (limit) reg -\nister? After all, isn\u2019t this the base and bounds approach? Indeed, it is. As\nyou might have guessed, the bounds register is there to help wit h protec-\ntion. Speci\ufb01cally , the processor will \ufb01rst check that the memory r eference\nis within bounds to make sure it is legal; in the simple example above, the\nbounds register would always be set to 16 KB. If a process generat es a vir-\ntual address that is greater than the bounds, or one that is negat ive, the\nCPU will raise an exception, and the process will likely be term inated.\nThe point of the bounds is thus to make sure that all addresses gen erated\nby the process are legal and within the \u201cbounds\u201d of the process.\nW e should note that the base and bounds registers are hardware st ruc-\ntures kept on the chip (one pair per CPU). Sometimes people call the\npart of the processor that helps with address translation the memory\nmanagement unit (MMU) ; as we develop more sophisticated memory-\nmanagement techniques, we will be adding more circuitry to th e MMU.\nA small aside about bound registers, which can be de\ufb01ned in one of\ntwo ways. In one way (as above), it holds the size of the address space,\nand thus the hardware checks the virtual address against it \ufb01 rst before\nadding the base. In the second way , it holds the physical address of the\nend of the address space, and thus the hardware \ufb01rst adds the ba se and\nthen makes sure the address is within bounds. Both methods are log ically\nequivalent; for simplicity , we\u2019ll usually assume the former me thod.\nExample T ranslations\nT o understand address translation via base-and-bounds in more detail,\nlet\u2019s take a look at an example. Imagine a process with an address s pace of\nsize 4 KB (yes, unrealistically small) has been loaded at phys ical address\n16 KB. Here are the results of a number of address translations:\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "technique we refer to as address translation; that is, the hardware takes a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "technique",
          "refer",
          "address",
          "translation",
          "hardware",
          "takes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "address spaces even after the process has started running, th e technique",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "address",
          "spaces",
          "even",
          "process",
          "started",
          "running",
          "technique"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ister? After all, isn\u2019t this the base and bounds approach? Indeed, it is. As",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ister",
          "base",
          "bounds",
          "approach",
          "indeed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "management unit (MMU) ; as we develop more sophisticated memory-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "management",
          "unit",
          "develop",
          "sophisticated",
          "memory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "management techniques, we will be adding more circuitry to th e MMU.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "management",
          "techniques",
          "adding",
          "circuitry"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "then makes sure the address is within bounds. Both methods are log ically",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "makes",
          "sure",
          "address",
          "within",
          "bounds",
          "methods",
          "ically"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "T o understand address translation via base-and-bounds in more detail,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "address",
          "translation",
          "base",
          "bounds",
          "detail"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: H A R D WA R E-B A S E D DY N A M I C RE L O C AT I O N",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "15",
    "title": "4 Hardware Support: A Summary",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "15.4 Hardware Support: A Summary\nLet us now summarize the support we need from the hardware (also\nsee Figure 15.3, page 9). First, as discussed in the chapter on CPU virtual-\nization, we require two different CPU modes. The OS runs in privileged\nmode (or kernel mode), where it has access to the entire machine; appli-\ncations run in user mode, where they are limited in what they can do. A\nsingle bit, perhaps stored in some kind of processor status word , indi-\ncates which mode the CPU is currently running in; upon certain s pecial\noccasions (e.g., a system call or some other kind of exception or inter rupt),\nthe CPU switches modes.\nThe hardware must also provide the base and bounds registers them-\nselves; each CPU thus has an additional pair of registers, part of the mem-\nory management unit (MMU) of the CPU. When a user program is run-\nning, the hardware will translate each address, by adding th e base value\nto the virtual address generated by the user program. The hard ware must\nalso be able to check whether the address is valid, which is ac complished\nby using the bounds register and some circuitry within the CPU.\nThe hardware should provide special instructions to modify the b ase\nand bounds registers, allowing the OS to change them when diffe rent\nprocesses run. These instructions are privileged; only in kernel (or priv-\nileged) mode can the registers be modi\ufb01ed. Imagine the havoc a us er\nprocess could wreak 1 if it could arbitrarily change the base register while\n1 Is there anything other than \u201chavoc\u201d that can be \u201cwreaked\u201d? [W17]\nAS I D E : D ATA ST R U C T U R E \u2014 T H E FR E E LI S T\nThe OS must track which parts of free memory are not in use, so as to\nbe able to allocate memory to processes. Many different data str uctures\ncan of course be used for such a task; the simplest (which we will a ssume\nhere) is a free list , which simply is a list of the ranges of the physical\nmemory which are not currently in use.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "also be able to check whether the address is valid, which is ac complished",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "able",
          "check",
          "whether",
          "address",
          "valid",
          "complished"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "be able to allocate memory to processes. Many different data str uctures",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "allocate",
          "memory",
          "processes",
          "many",
          "different",
          "data",
          "uctures"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: D ATA ST R U C T U R E \u2014 T H E FR E E LI S T",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand hardware support: a summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "support",
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "15",
    "title": "5 Operating System Issues",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "15.5 Operating System Issues\nJust as the hardware provides new features to support dynamic r elo-\ncation, the OS now has new issues it must handle; the combination of\nhardware support and OS management leads to the implementati on of\na simple virtual memory . Speci\ufb01cally , there are a few critical junctures\nwhere the OS must get involved to implement our base-and-bounds ver-\nsion of virtual memory .\nFirst, the OS must take action when a process is created, \ufb01nding space\nfor its address space in memory . Fortunately , given our assumpti ons that\neach address space is (a) smaller than the size of physical mem ory and\n(b) the same size, this is quite easy for the OS; it can simply vie w physical\nmemory as an array of slots, and track whether each one is free or in\nuse. When a new process is created, the OS will have to search a d ata\nstructure (often called a free list) to \ufb01nd room for the new address space\nand then mark it used. With variable-sized address spaces, l ife is more\ncomplicated, but we will leave that concern for future chapters .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "hardware support and OS management leads to the implementati on of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hardware",
          "support",
          "management",
          "leads",
          "implementati"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a simple virtual memory . Speci\ufb01cally , there are a few critical junctures",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "virtual",
          "memory",
          "critical",
          "junctures"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "where the OS must get involved to implement our base-and-bounds ver-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "must",
          "involved",
          "implement",
          "base",
          "bounds"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "First, the OS must take action when a process is created, \ufb01nding space",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "first",
          "must",
          "take",
          "action",
          "process",
          "created",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "use. When a new process is created, the OS will have to search a d ata",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "created",
          "search"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand operating system issues",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "system",
          "issues"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 M E C H A N I S M : A D D R E S S TR A N S L AT...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 M E C H A N I S M : A D D R E S S TR A N S L AT I O N\nOS Requirements Notes\nMemory management Need to allocate memory for new processes;\nReclaim memory from terminated processes;\nGenerally manage memory via free list\nBase/bounds management Must set base/bounds properly upon context switch\nException handling Code to run when exceptions arise;\nlikely action is to terminate offending process\nFigure 15.4: Dynamic Relocation: Operating System Responsibilities\nLet\u2019s look at an example. In Figure 15.2 (page 5), you can see the OS\nusing the \ufb01rst slot of physical memory for itself, and that it has r elocated\nthe process from the example above into the slot starting at physi cal mem-\nory address 32 KB. The other two slots are free (16 KB-32 KB and 48 K B-\n64 KB); thus, the free list should consist of these two entries.\nSecond, the OS must do some work when a process is terminated (i.e.,\nwhen it exits gracefully , or is forcefully killed because it mi sbehaved),\nreclaiming all of its memory for use in other processes or the OS. Upon\ntermination of a process, the OS thus puts its memory back on the fre e\nlist, and cleans up any associated data structures as need be.\nThird, the OS must also perform a few additional steps when a cont ext\nswitch occurs. There is only one base and bounds register pair on ea ch\nCPU, after all, and their values differ for each running progra m, as each\nprogram is loaded at a different physical address in memory . Thu s, the\nOS must save and restore the base-and-bounds pair when it switches be-\ntween processes. Speci\ufb01cally , when the OS decides to stop runni ng a pro-\ncess, it must save the values of the base and bounds registers to memory ,\nin some per-process structure such as the process structure or process\ncontrol block (PCB). Similarly , when the OS resumes a running process\n(or runs it the \ufb01rst time), it must set the values of the base and b ounds on\nthe CPU to the correct values for this process.\nW e should note that when a process is stopped (i.e., not running), i t is\npossible for the OS to move an address space from one location in mem-\nory to another rather easily . T o move a process\u2019s address space, th e OS\n\ufb01rst deschedules the process; then, the OS copies the address s pace from\nthe current location to the new location; \ufb01nally , the OS updates t he saved\nbase register (in the process structure) to point to the new loca tion. When\nthe process is resumed, its (new) base register is restored, an d it begins\nrunning again, oblivious that its instructions and data are now i n a com-\npletely new spot in memory .\nFourth, the OS must provide exception handlers , or functions to be\ncalled, as discussed above; the OS installs these handlers at boot time (via\nprivileged instructions). For example, if a process tries to ac cess mem-\nory outside its bounds, the CPU will raise an exception; the OS mus t be\nprepared to take action when such an exception arises. The common reac-\ntion of the OS will be one of hostility: it will likely terminate the offending\nprocess. The OS should be highly protective of the machine it is ru nning,\nand thus it does not take kindly to a process trying to access memor y or\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 4: Dynamic Relocation: Operating System Responsibilities",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "dynamic",
          "relocation",
          "operating",
          "system",
          "responsibilities"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "15",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "15.6 Summary\nIn this chapter , we have extended the concept of limited direct exe-\ncution with a speci\ufb01c mechanism used in virtual memory , known as ad-\ndress translation. With address translation, the OS can control each and\nevery memory access from a process, ensuring the accesses stay w ithin\nthe bounds of the address space. Key to the ef\ufb01ciency of this tech nique\nis hardware support, which performs the translation quickly for each ac-\ncess, turning virtual addresses (the process\u2019s view of memory) i nto phys-\nical ones (the actual view). All of this is performed in a way that is trans-\nparent to the process that has been relocated; the process has no idea it s\nmemory references are being translated, making for a wonderful illusion.\nW e have also seen one particular form of virtualization, known as b ase\nand bounds or dynamic relocation. Base-and-bounds virtualizati on is\nquite ef\ufb01cient , as only a little more hardware logic is required to add a\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In this chapter , we have extended the concept of limited direct exe-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "chapter",
          "extended",
          "concept",
          "limited",
          "direct"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "cution with a speci\ufb01c mechanism used in virtual memory , known as ad-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cution",
          "mechanism",
          "used",
          "virtual",
          "memory",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "W e have also seen one particular form of virtualization, known as b ase",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "seen",
          "particular",
          "form",
          "virtualization",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 M E C H A N I S M : A D D R E S S TR A N S L AT...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 M E C H A N I S M : A D D R E S S TR A N S L AT I O N\nOS @ run Hardware Program\n(kernel mode) (user mode)\nT o start process A:\nallocate entry\nin process table\nalloc memory for process\nset base/bound registers\nreturn-from-trap (into A)\nrestore registers of A\nmove to user mode\njump to A \u2019s (initial) PC\nProcess A runs\nFetch instruction\ntranslate virtual address\nperform fetch\nExecute instruction\nif explicit load/store:\nensure address is legal\ntranslate virtual address\nperform load/store\n(A runs...)\nTimer interrupt\nmove to kernel mode\njump to handler\nHandle timer\ndecide: stop A, run B\ncall switch() routine\nsave regs(A)\nto proc-struct(A)\n(including base/bounds)\nrestore regs(B)\nfrom proc-struct(B)\n(including base/bounds)\nreturn-from-trap (into B)\nrestore registers of B\nmove to user mode\njump to B\u2019s PC\nProcess B runs\nExecute bad load\nLoad is out-of-bounds;\nmove to kernel mode\njump to trap handler\nHandle the trap\ndecide to kill process B\ndeallocate B\u2019s memory\nfree B\u2019s entry\nin process table\nFigure 15.6: Limited Direct Execution (Dynamic Relocation) @ Runtime\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand store: ensure address is legal",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "store",
          "ensure",
          "address",
          "legal"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 6: Limited Direct Execution (Dynamic Relocation) @ Runtime",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "limited",
          "direct",
          "execution",
          "dynamic",
          "relocation",
          "runtime"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "ME C H A N I S M : A D D R E S S TR A N S L AT I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "ME C H A N I S M : A D D R E S S TR A N S L AT I O N 13\nbase register to the virtual address and check that the addre ss generated\nby the process is in bounds. Base-and-bounds also offers protection; the\nOS and hardware combine to ensure no process can generate memory\nreferences outside its own address space. Protection is certain ly one of\nthe most important goals of the OS; without it, the OS could not control\nthe machine (if processes were free to overwrite memory , they cou ld eas-\nily do nasty things like overwrite the trap table and take over t he system).\nUnfortunately , this simple technique of dynamic relocation does have\nits inef\ufb01ciencies. For example, as you can see in Figure 15.2 (p age 5), the\nrelocated process is using physical memory from 32 KB to 48 KB; how-\never , because the process stack and heap are not too big, all of the space\nbetween the two is simply wasted. This type of waste is usually called in-\nternal fragmentation, as the space inside the allocated unit is not all used\n(i.e., is fragmented) and thus wasted. In our current approach , although\nthere might be enough physical memory for more processes, we are cu r-\nrently restricted to placing an address space in a \ufb01xed-size d slot and thus\ninternal fragmentation can arise 2 . Thus, we are going to need more so-\nphisticated machinery , to try to better utilize physical me mory and avoid\ninternal fragmentation. Our \ufb01rst attempt will be a slight gen eralization\nof base and bounds known as segmentation, which we will discuss next.2 A different solution might instead place a \ufb01xed-sized stack within the address space,\njust below the code region, and a growing heap below that. However , thi s limits \ufb02exibility\nby making recursion and deeply-nested function calls challenging, and thus i s something we\nhope to avoid.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the most important goals of the OS; without it, the OS could not control",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "goals",
          "without",
          "could",
          "control"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Unfortunately , this simple technique of dynamic relocation does have",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unfortunately",
          "simple",
          "technique",
          "dynamic",
          "relocation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "(i.e., is fragmented) and thus wasted. In our current approach , although",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fragmented",
          "thus",
          "wasted",
          "current",
          "approach",
          "although"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "of base and bounds known as segmentation, which we will discuss next.2 A different solution might instead place a \ufb01xed-sized stack within the address space,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "base",
          "bounds",
          "known",
          "segmentation",
          "discuss",
          "next",
          "different",
          "solution"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 M E C H A N I S M : A D D R E S S TR A N S L AT...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 M E C H A N I S M : A D D R E S S TR A N S L AT I O N\nReferences\n[M65] \u201cOn Dynamic Program Relocation\u201d by W .C. McGee. IBM Systems Journal , V olume 4:3,\n1965, pages 184\u2013199. This paper is a nice summary of early work on dynamic relocation, as well as\nsome basics on static relocation.\n[P90] \u201cRelocating loader for MS-DOS .EXE executable \ufb01les\u201d by Kenneth D. A . Pillay . Micro-\nprocessors & Microsystems archive, V olume 14:7 (September 1990). An example of a relocating\nloader for MS-DOS. Not the \ufb01rst one, but just a relatively modern example of how such a system works.\n[SS74] \u201cThe Protection of Information in Computer Systems\u201d by J. Salt zer and M. Schroeder .\nCACM, July 1974. From this paper: \u201cThe concepts of base-and-bound register and hardware-interp reted\ndescriptors appeared, apparently independently, between 1957 and 195 9 on three projects with diverse\ngoals. At M.I.T ., McCarthy suggested the base-and-bound idea as part of the mem ory protection system\nnecessary to make time-sharing feasible. IBM independently developed th e base-and-bound register as a\nmechanism to permit reliable multiprogramming of the Stretch (7030) comp uter system. At Burroughs,\nR. Barton suggested that hardware-interpreted descriptors would provide di rect support for the naming\nscope rules of higher level languages in the B5000 computer system.\u201d W e found this quote on Mark\nSmotherman\u2019s cool history pages [S04]; see them for more information.\n[S04] \u201cSystem Call Support\u201d by Mark Smotherman. May 2004. people.cs.clemson.edu/\n\u02dcmark/syscall.html. A neat history of system call support. Smotherman has also collected some\nearly history on items like interrupts and other fun aspects of computing history . See his web pages for\nmore details.\n[WL+93] \u201cEf\ufb01cient Software-based Fault Isolation\u201d by Robert W ahbe , Steven Lucco, Thomas\nE. Anderson, Susan L. Graham. SOSP \u201993. A terri\ufb01c paper about how you can use compiler support\nto bound memory references from a program, without hardware support. The p aper sparked renewed\ninterest in software techniques for isolation of memory references.\n[W17] Answer to footnote: \u201cIs there anything other than havoc that can be wre aked?\u201d by\nW aciuma W anjohi. October 2017. Amazingly, this enterprising reader found the answer via google\u2019s\nNgram viewing tool (available at the following URL: http://books.google.com/ngrams).\nThe answer , thanks to Mr . Wanjohi: \u201cIt\u2019s only since about 1970 that \u2019wreak havoc\u2019 has been more\npopular than \u2019wreak vengeance\u2019. In the 1800s, the word wreak was almost always f ollowed by \u2019his/their\nvengeance\u2019.\u201d Apparently, when you wreak, you are up to no good, but at least w reakers have some\noptions now.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "CACM, July 1974. From this paper: \u201cThe concepts of base-and-bound register and hardware-interp reted",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cacm",
          "july",
          "paper",
          "concepts",
          "base",
          "bound",
          "register",
          "hardware"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "goals. At M.I.T ., McCarthy suggested the base-and-bound idea as part of the mem ory protection system",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goals",
          "mccarthy",
          "suggested",
          "base",
          "bound",
          "idea",
          "part",
          "protection"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "necessary to make time-sharing feasible. IBM independently developed th e base-and-bound register as a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "necessary",
          "make",
          "time",
          "sharing",
          "feasible",
          "independently",
          "developed",
          "base"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "interest in software techniques for isolation of memory references.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interest",
          "software",
          "techniques",
          "isolation",
          "memory",
          "references"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand V olume 14: 7 (September 1990). An example of a relocating",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 14",
          "september",
          "example",
          "relocating"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand From this paper: \u201cThe concepts of base-and-bound register and hardware-interp reted",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "from this paper",
          "concepts",
          "base",
          "bound",
          "register",
          "hardware",
          "interp",
          "reted"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Answer to footnote: \u201cIs there anything other than havoc that can be wre aked?\u201d by",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "answer to footnote",
          "anything",
          "havoc",
          "aked"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Wanjohi: \u201cIt\u2019s only since about 1970 that \u2019wreak havoc\u2019 has been more",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "wanjohi",
          "since",
          "wreak",
          "havoc"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Run with seeds 1, 2, and 3, and compute whether each virtual a d-",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. Run with seeds 1, 2, and 3, and compute whether each virtual a d-\ndress generated by the process is in or out of bounds. If in bounds,\ncompute the translation.\n2. Run with these \ufb02ags: -s 0 -n 10. What value do you have set\n-l (the bounds register) to in order to ensure that all the generat ed\nvirtual addresses are within bounds?\n3. Run with these \ufb02ags: -s 1 -n 10 -l 100. What is the maxi-\nmum value that base can be set to, such that the address space st ill\n\ufb01ts into physical memory in its entirety?",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Run with these \ufb02ags: -s 0 -n 10. What value do you have set",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "run with these \ufb02ags",
          "value"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Run with these \ufb02ags: -s 1 -n 10 -l 100. What is the maxi-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "run with these \ufb02ags",
          "maxi"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand l (the bounds register) to in order to ensure that all the generat ed",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "bounds",
          "register",
          "order",
          "ensure",
          "generat"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the maxi-\nmum value that base can be set to, such that the address space st ill\n\ufb01ts into physical memory in its entirety",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "maxi",
          "value",
          "base",
          "address",
          "space",
          "physical",
          "memory",
          "entirety"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Run some of the same problems above, but with larger address",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "4. Run some of the same problems above, but with larger address\nspaces ( -a) and physical memories ( -p).",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "What fraction of randomly-generated virtual addresses are v alid,",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "5. What fraction of randomly-generated virtual addresses are v alid,\nas a function of the value of the bounds register? Make a graph\nfrom running with different random seeds, with limit values ra ng-\ning from 0 up to the maximum size of the address space.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "1 Segmentation: Generalized Base/Bounds",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "16.1 Segmentation: Generalized Base/Bounds\nT o solve this problem, an idea was born, and it is called segmenta-\ntion. It is quite an old idea, going at least as far back as the very ear ly\n1960\u2019s [H61, G62]. The idea is simple: instead of having just one base\nand bounds pair in our MMU, why not have a base and bounds pair per\nlogical segment of the address space? A segment is just a contiguous\nportion of the address space of a particular length, and in our canon ical\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o solve this problem, an idea was born, and it is called segmenta-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "problem",
          "idea",
          "born",
          "called",
          "segmenta"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1 Segmentation: Generalized Base/Bounds",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1 segmentation",
          "generalized",
          "base",
          "bounds"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand The idea is simple: instead of having just one base",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the idea is simple",
          "instead",
          "base"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand segmentation: generalized base/bounds",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "segmentation",
          "generalized",
          "base",
          "bounds"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 SE G M E N TAT I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 SE G M E N TAT I O N\n16KB\n15KB\n14KB\n7KB\n6KB\n5KB\n4KB\n3KB\n2KB\n1KB\n0KB\nProgram Code\nHeap\n(free)\nStack\nFigure 16.1: An Address Space (Again)\naddress space, we have three logically-different segments: code, stack,\nand heap. What segmentation allows the OS to do is to place each on e\nof those segments in different parts of physical memory , and thus avoid\n\ufb01lling physical memory with unused virtual address space.\nLet\u2019s look at an example. Assume we want to place the address spac e\nfrom Figure 16.1 into physical memory . With a base and bounds pai r\nper segment, we can place each segment independently in physical mem-\nory . For example, see Figure 16.2 (page 3); there you see a 64KB ph ysical\nmemory with those three segments in it (and 16KB reserved for the OS).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: An Address Space (Again)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE G M E N TAT I O N 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE G M E N TAT I O N 3\n64KB\n48KB\n32KB\n16KB\n0KB\n(not in use)\n(not in use)\n(not in use)\nOperating System\nStack\nCode\nHeap\nFigure 16.2: Placing Segments In Physical Memory\nAs you can see in the diagram, only used memory is allocated space\nin physical memory , and thus large address spaces with large a mounts of\nunused address space (which we sometimes call sparse address spaces )\ncan be accommodated.\nThe hardware structure in our MMU required to support segmenta -\ntion is just what you\u2019d expect: in this case, a set of three base and bounds\nregister pairs. Figure 16.3 below shows the register values for the exam-\nple above; each bounds register holds the size of a segment.\nSegment Base Size\nCode 32K 2K\nHeap 34K 3K\nStack 28K 2K\nFigure 16.3: Segment Register V alues\nY ou can see from the \ufb01gure that the code segment is placed at physi cal\naddress 32KB and has a size of 2KB and the heap segment is placed at\n34KB and has a size of 3KB. The size segment here is exactly the s ame as\nthe bounds register introduced previously; it tells the hardwa re exactly\nhow many bytes are valid in this segment (and thus, enables the hard-\nware to determine when a program has made an illegal access outs ide of\nthose bounds).\nLet\u2019s do an example translation, using the address space in Fig ure 16.1.\nAssume a reference is made to virtual address 100 (which is in the code\nsegment, as you can see visually in Figure 16.1, page 2). When t he refer-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 2: Placing Segments In Physical Memory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "placing",
          "segments",
          "physical",
          "memory"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand d expect: in this case, a set of three base and bounds",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "d expect",
          "case",
          "three",
          "base",
          "bounds"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 3: Segment Register V alues",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "segment",
          "register",
          "alues"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "2 Which Segment Are W e Referring T o?",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "16.2 Which Segment Are W e Referring T o?\nThe hardware uses segment registers during translation. How d oes it\nknow the offset into a segment, and to which segment an address r efers?\nOne common approach, sometimes referred to as an explicit approach,\nis to chop up the address space into segments based on the top few b its\nof the virtual address; this technique was used in the V AX/VMS system\n[LL82]. In our example above, we have three segments; thus we ne ed two\nbits to accomplish our task. If we use the top two bits of our 14-bit v irtual\naddress to select the segment, our virtual address looks like th is:\n13 12 11 10 9 8 7 6 5 4 3 2 1 0\nSegment Offset\nIn our example, then, if the top two bits are 00, the hardware know s\nthe virtual address is in the code segment, and thus uses the cod e base\nand bounds pair to relocate the address to the correct physical l ocation.\nIf the top two bits are 01, the hardware knows the address is in th e heap,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "know the offset into a segment, and to which segment an address r efers?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "offset",
          "segment",
          "segment",
          "address",
          "efers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One common approach, sometimes referred to as an explicit approach,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "approach",
          "sometimes",
          "referred",
          "explicit",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of the virtual address; this technique was used in the V AX/VMS system",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "virtual",
          "address",
          "technique",
          "used",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "In our example, then, if the top two bits are 00, the hardware know s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "bits",
          "hardware",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "If the top two bits are 01, the hardware knows the address is in th e heap,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bits",
          "hardware",
          "knows",
          "address",
          "heap"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand which segment are w e referring t o?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "segment",
          "referring"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE G M E N TAT I O N 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE G M E N TAT I O N 5\nand thus uses the heap base and bounds. Let\u2019s take our example hea p\nvirtual address from above (4200) and translate it, just to mak e sure this\nis clear . The virtual address 4200, in binary form, can be seen here:\n13\n0\n12\n1\n11\n0\n10\n0\n9\n0\n8\n0\n7\n0\n6\n1\n5\n1\n4\n0\n3\n1\n2\n0\n1\n0\n0\n0\nSegment Offset\nAs you can see from the picture, the top two bits (01) tell the hard ware\nwhich segment we are referring to. The bottom 12 bits are the offset into\nthe segment: 0000 0110 1000, or hex 0x068, or 104 in decimal. Thu s, the\nhardware simply takes the \ufb01rst two bits to determine which se gment reg-\nister to use, and then takes the next 12 bits as the offset into t he segment.\nBy adding the base register to the offset, the hardware arrive s at the \ufb01-\nnal physical address. Note the offset eases the bounds check too: w e can\nsimply check if the offset is less than the bounds; if not, the add ress is ille-\ngal. Thus, if base and bounds were arrays (with one entry per seg ment),\nthe hardware would be doing something like this to obtain the desi red\nphysical address:\n1 // get top 2 bits of 14-bit VA\n2 Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT\n3 // now get offset\n4 Offset = VirtualAddress & OFFSET_MASK\n5 if (Offset >= Bounds[Segment])\n6 RaiseException(PROTECTION_FAULT)\n7 else\n8 PhysAddr = Base[Segment] + Offset\n9 Register = AccessMemory(PhysAddr)\nIn our running example, we can \ufb01ll in values for the constants abov e.\nSpeci\ufb01cally , SEG MASK would be set to 0x3000, SEG SHIFT to 12, and\nOFFSET MASK to 0xFFF.\nY ou may also have noticed that when we use the top two bits, and we\nonly have three segments (code, heap, stack), one segment of the a ddress\nspace goes unused. T o fully utilize the virtual address space (and avoid\nan unused segment), some systems put code in the same segment as the\nheap and thus use only one bit to select which segment to use [LL8 2].\nAnother issue with using the top so many bits to select a segment is\nthat it limits use of the virtual address space. Speci\ufb01cally , e ach segment\nis limited to a maximum size , which in our example is 4KB (using the top\ntwo bits to choose segments implies the 16KB address space gets chopped\ninto four pieces, or 4KB in this example). If a running program wi shes to\ngrow a segment (say the heap, or the stack) beyond that maximum, t he\nprogram is out of luck.\nThere are other ways for the hardware to determine which segmen t\na particular address is in. In the implicit approach, the hardware deter-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "a particular address is in. In the implicit approach, the hardware deter-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "particular",
          "address",
          "implicit",
          "approach",
          "hardware",
          "deter"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "3 What About The Stack?",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "16.3 What About The Stack?\nThus far , we\u2019ve left out one important component of the address space :\nthe stack. The stack has been relocated to physical address 28 KB in the\ndiagram above, but with one critical difference: it grows backwards (i.e.,\ntowards lower addresses). In physical memory , it \u201cstarts\u201d at 28 KB1 and\ngrows back to 26KB, corresponding to virtual addresses 16KB to 1 4KB;\ntranslation must proceed differently .\nThe \ufb01rst thing we need is a little extra hardware support. Inst ead of\njust base and bounds values, the hardware also needs to know whi ch way\nthe segment grows (a bit, for example, that is set to 1 when the se gment\ngrows in the positive direction, and 0 for negative). Our updated view of\nwhat the hardware tracks is seen in Figure 16.4:\nSegment Base Size (max 4K) Grows Positive?\nCode00 32K 2K 1\nHeap01 34K 3K 1\nStack11 28K 2K 0\nFigure 16.4: Segment Registers (With Negative-Growth Support)\nWith the hardware understanding that segments can grow in the neg-\native direction, the hardware must now translate such virtual addresses\nslightly differently . Let\u2019s take an example stack virtual ad dress and trans-\nlate it to understand the process.\nIn this example, assume we wish to access virtual address 15K B, which\nshould map to physical address 27KB. Our virtual address, in b inary\nform, thus looks like this: 11 1100 0000 0000 (hex 0x3C00). The ha rd-\nware uses the top two bits (11) to designate the segment, but th en we are\nleft with an offset of 3KB. T o obtain the correct negative offset, w e must\nsubtract the maximum segment size from 3KB: in this example, a seg-\nment can be 4KB, and thus the correct negative offset is 3KB minu s 4KB\nwhich equals -1KB. W e simply add the negative offset (-1KB) to the base\n(28KB) to arrive at the correct physical address: 27KB. The bou nds check\ncan be calculated by ensuring the absolute value of the negativ e offset is\nless than or equal to the segment\u2019s current size (in this case, 2 KB).\n1 Although we say , for simplicity , that the stack \u201cstarts\u201d at 28KB, thi s value is actually the\nbyte just below the location of the backward growing region; the \ufb01rst valid byte is act ually\n28KB minus 1. In contrast, forward-growing regions start at the addre ss of the \ufb01rst byte of the\nsegment. W e take this approach because it makes the math to compute t he physical address\nstraightforward: the physical address is just the base plus the negat ive offset.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus far , we\u2019ve left out one important component of the address space :",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "left",
          "important",
          "component",
          "address",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "diagram above, but with one critical difference: it grows backwards (i.e.,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "diagram",
          "critical",
          "difference",
          "grows",
          "backwards"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "just base and bounds values, the hardware also needs to know whi ch way",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "base",
          "bounds",
          "values",
          "hardware",
          "also",
          "needs",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "With the hardware understanding that segments can grow in the neg-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "understanding",
          "segments",
          "grow"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "late it to understand the process.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "late",
          "understand",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "ware uses the top two bits (11) to designate the segment, but th en we are",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ware",
          "uses",
          "bits",
          "designate",
          "segment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "KB minus 1. In contrast, forward-growing regions start at the addre ss of the \ufb01rst byte of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "minus",
          "contrast",
          "forward",
          "growing",
          "regions",
          "start",
          "addre",
          "byte"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "segment. W e take this approach because it makes the math to compute t he physical address",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "segment",
          "take",
          "approach",
          "makes",
          "math",
          "compute",
          "physical",
          "address"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 4: Segment Base Size (max 4K) Grows Positive?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "segment",
          "base",
          "size",
          "grows",
          "positive"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 4: Segment Registers (With Negative-Growth Support)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "segment",
          "registers",
          "negative",
          "growth",
          "support"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand thus looks like this: 11 1100 0000 0000 (hex 0x3C00). The ha rd-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "thus looks like this"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand what about the stack?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "stack"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "4 Support for Sharing",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "16.4 Support for Sharing\nAs support for segmentation grew , system designers soon realized that\nthey could realize new types of ef\ufb01ciencies with a little more ha rdware\nsupport. Speci\ufb01cally , to save memory , sometimes it is useful to share\ncertain memory segments between address spaces. In particul ar , code\nsharing is common and still in use in systems today .\nT o support sharing, we need a little extra support from the hardw are,\nin the form of protection bits . Basic support adds a few bits per segment,\nindicating whether or not a program can read or write a segment, or p er-\nhaps execute code that lies within the segment. By setting a cod e segment\nto read-only , the same code can be shared across multiple process es, with-\nout worry of harming isolation; while each process still thinks tha t it is ac-\ncessing its own private memory , the OS is secretly sharing memor y which\ncannot be modi\ufb01ed by the process, and thus the illusion is preserv ed.\nAn example of the additional information tracked by the hardware\n(and OS) is shown in Figure 16.5. As you can see, the code segment is\nset to read and execute, and thus the same physical segment in memory\ncould be mapped into multiple virtual address spaces.\nSegment Base Size (max 4K) Grows Positive? Protection\nCode00 32K 2K 1 Read-Execute\nHeap01 34K 3K 1 Read-W rite\nStack11 28K 2K 0 Read-W rite\nFigure 16.5: Segment Register V alues (with Protection)\nWith protection bits, the hardware algorithm described earlie r would\nalso have to change. In addition to checking whether a virtual address is\nwithin bounds, the hardware also has to check whether a partic ular access\nis permissible. If a user process tries to write to a read-only s egment, or\nexecute from a non-executable segment, the hardware should rai se an\nexception, and thus let the OS deal with the offending process.\n16.5 Fine-grained vs. Coarse-grained Segmentation\nMost of our examples thus far have focused on systems with just a\nfew segments (i.e., code, stack, heap); we can think of this seg mentation\nas coarse-grained, as it chops up the address space into relatively large,\ncoarse chunks. However , some early systems (e.g., Multics [CV6 5,DD68])\nwere more \ufb02exible and allowed for address spaces to consist of a lar ge\nnumber of smaller segments, referred to as \ufb01ne-grained segmentation.\nSupporting many segments requires even further hardware supp ort,\nwith a segment table of some kind stored in memory . Such segment ta-\nbles usually support the creation of a very large number of segmen ts, and\nthus enable a system to use segments in more \ufb02exible ways than w e have\nthus far discussed. For example, early machines like the Burr oughs B5000\nhad support for thousands of segments, and expected a compiler to c hop\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "As support for segmentation grew , system designers soon realized that",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "support",
          "segmentation",
          "grew",
          "system",
          "designers",
          "soon",
          "realized"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "With protection bits, the hardware algorithm described earlie r would",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "protection",
          "bits",
          "hardware",
          "algorithm",
          "described",
          "earlie",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Segment Register V alues (with Protection)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "segment",
          "register",
          "alues",
          "protection"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand support for sharing",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "sharing"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand fine-grained vs. coarse-grained segmentation",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fine",
          "grained",
          "coarse",
          "grained",
          "segmentation"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "6 OS Support",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "16.6 OS Support\nY ou now should have a basic idea as to how segmentation works.\nPieces of the address space are relocated into physical memory a s the\nsystem runs, and thus a huge savings of physical memory is achie ved\nrelative to our simpler approach with just a single base/bounds pair for\nthe entire address space. Speci\ufb01cally , all the unused space b etween the\nstack and the heap need not be allocated in physical memory , allow ing\nus to \ufb01t more address spaces into physical memory and support a la rge\nand sparse virtual address space per process.\nHowever , segmentation raises a number of new issues for the operat -\ning system. The \ufb01rst is an old one: what should the OS do on a context\nswitch? Y ou should have a good guess by now: the segment registers\nmust be saved and restored. Clearly , each process has its own vir tual ad-\ndress space, and the OS must make sure to set up these register s correctly\nbefore letting the process run again.\nThe second is OS interaction when segments grow (or perhaps shrin k).\nFor example, a program may call malloc() to allocate an object. In\nsome cases, the existing heap will be able to service the reque st, and thus\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "relative to our simpler approach with just a single base/bounds pair for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "relative",
          "simpler",
          "approach",
          "single",
          "base",
          "bounds",
          "pair"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "some cases, the existing heap will be able to service the reque st, and thus",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cases",
          "existing",
          "heap",
          "able",
          "service",
          "reque",
          "thus"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand os support",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "support"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE G M E N TAT I O N 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE G M E N TAT I O N 9\nTI P : I F 1000 S O L U T I O N S EX I S T, N O GR E AT ON E DO E S\nThe fact that so many different algorithms exist to try to mini mize exter-\nnal fragmentation is indicative of a stronger underlying truth : there is no\none \u201cbest\u201d way to solve the problem. Thus, we settle for something r ea-\nsonable and hope it is good enough. The only real solution (as we will\nsee in forthcoming chapters) is to avoid the problem altogether , b y never\nallocating memory in variable-sized chunks.\nmalloc() will \ufb01nd free space for the object and return a pointer to it to\nthe caller . In others, however , the heap segment itself may nee d to grow .\nIn this case, the memory-allocation library will perform a syste m call to\ngrow the heap (e.g., the traditional U N I X sbrk() system call). The OS\nwill then (usually) provide more space, updating the segment s ize reg-\nister to the new (bigger) size, and informing the library of suc cess; the\nlibrary can then allocate space for the new object and return suc cessfully\nto the calling program. Do note that the OS could reject the reque st, if no\nmore physical memory is available, or if it decides that the call ing process\nalready has too much.\nThe last, and perhaps most important, issue is managing free sp ace in\nphysical memory . When a new address space is created, the OS ha s to be\nable to \ufb01nd space in physical memory for its segments. Previousl y , we\nassumed that each address space was the same size, and thus ph ysical\nmemory could be thought of as a bunch of slots where processes would\n\ufb01t in. Now , we have a number of segments per process, and each segm ent\nmight be a different size.\nThe general problem that arises is that physical memory quickl y be-\ncomes full of little holes of free space, making it dif\ufb01cult to all ocate new\nsegments, or to grow existing ones. W e call this problem external frag-\nmentation [R69]; see Figure 16.6 (left).\nIn the example, a process comes along and wishes to allocate a 20KB\nsegment. In that example, there is 24KB free, but not in one conti guous\nsegment (rather , in three non-contiguous chunks). Thus, the OS cannot\nsatisfy the 20KB request. Similar problems could occur when a req uest to\ngrow a segment arrives; if the next so many bytes of physical spa ce are\nnot available, the OS will have to reject the request, even thou gh there\nmay be free bytes available elsewhere in physical memory .\nOne solution to this problem would be to compact physical memory\nby rearranging the existing segments. For example, the OS coul d stop\nwhichever processes are running, copy their data to one contiguou s re-\ngion of memory , change their segment register values to point to t he\nnew physical locations, and thus have a large free extent of memor y with\nwhich to work. By doing so, the OS enables the new allocation reques t\nto succeed. However , compaction is expensive, as copying segmen ts is\nmemory-intensive and generally uses a fair amount of processor ti me; see\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The fact that so many different algorithms exist to try to mini mize exter-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fact",
          "many",
          "different",
          "algorithms",
          "exist",
          "mini",
          "mize",
          "exter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "one \u201cbest\u201d way to solve the problem. Thus, we settle for something r ea-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "best",
          "solve",
          "problem",
          "thus",
          "settle",
          "something"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The last, and perhaps most important, issue is managing free sp ace in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "perhaps",
          "important",
          "issue",
          "managing",
          "free"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "physical memory . When a new address space is created, the OS ha s to be",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "physical",
          "memory",
          "address",
          "space",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "able to \ufb01nd space in physical memory for its segments. Previousl y , we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "space",
          "physical",
          "memory",
          "segments",
          "previousl"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "16",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "16.7 Summary\nSegmentation solves a number of problems, and helps us build a more\neffective virtualization of memory . Beyond just dynamic relocat ion, seg-\nmentation can better support sparse address spaces, by avoidin g the huge\npotential waste of memory between logical segments of the address space.\nIt is also fast, as doing the arithmetic segmentation requires is easy and\nwell-suited to hardware; the overheads of translation are mini mal. A\nfringe bene\ufb01t arises too: code sharing. If code is placed within a sepa-\nrate segment, such a segment could potentially be shared across multiple\nrunning programs.\nHowever , as we learned, allocating variable-sized segments i n mem-\nory leads to some problems that we\u2019d like to overcome. The \ufb01rst, as di s-\ncussed above, is external fragmentation. Because segments ar e variable-\nsized, free memory gets chopped up into odd-sized pieces, and th us sat-\nisfying a memory-allocation request can be dif\ufb01cult. One can tr y to use\nsmart algorithms [W+95] or periodically compact memory , but the p rob-\nlem is fundamental and hard to avoid.\nThe second and perhaps more important problem is that segmentati on\nstill isn\u2019t \ufb02exible enough to support our fully generalized, spa rse address\nspace. For example, if we have a large but sparsely-used heap a ll in one\nlogical segment, the entire heap must still reside in memory in order to be\naccessed. In other words, if our model of how the address space is bei ng\nused doesn\u2019t exactly match how the underlying segmentation has b een\ndesigned to support it, segmentation doesn\u2019t work very well. W e th us\nneed to \ufb01nd some new solutions. Ready to \ufb01nd them?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Segmentation solves a number of problems, and helps us build a more",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "segmentation",
          "solves",
          "number",
          "problems",
          "helps",
          "build"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "However , as we learned, allocating variable-sized segments i n mem-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "learned",
          "allocating",
          "variable",
          "sized",
          "segments"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "smart algorithms [W+95] or periodically compact memory , but the p rob-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "smart",
          "algorithms",
          "periodically",
          "compact",
          "memory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "lem is fundamental and hard to avoid.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "hard",
          "avoid"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The second and perhaps more important problem is that segmentati on",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "second",
          "perhaps",
          "important",
          "problem",
          "segmentati"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "designed to support it, segmentation doesn\u2019t work very well. W e th us",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "designed",
          "support",
          "segmentation",
          "work",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1968",
    "title": "Knuth is famous not only for his early books on the Art of Computer Programming but for his",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "1968. Knuth is famous not only for his early books on the Art of Computer Programming but for his\ntypesetting system T eX which is still a powerhouse typesetting tool used by professionals today, and\nindeed to typeset this very book. His tomes on algorithms are a great early refe rence to many of the\nalgorithms that underly computing systems today.\n[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems\nReview , 15:5, October 1983. A treasure-trove of sage advice on how to build systems. Hard to read in\none sitting; take it in a little at a time, like a \ufb01ne wine, or a reference manual .\n[LL82] \u201cVirtual Memory Management in the V AX/VMS Operating System\u201d by Henry M. Levy ,\nPeter H. Lipman. IEEE Computer , V olume 15:3, March 1982. A classic memory management\nsystem, with lots of common sense in its design. We\u2019ll study it in more detai l in a later chapter .\n[RK68] \u201cDynamic Storage Allocation Systems\u201d by B. Randell and C.J. Kuehner . Communica-\ntions of the ACM, V olume 11:5, May 1968. A nice overview of the differences between paging and\nsegmentation, with some historical discussion of various machines.\n[R69] \u201cA note on storage fragmentation and program segmentation\u201d by Brian Randell. Com-\nmunications of the ACM, V olume 12:7, July 1969. One of the earliest papers to discuss fragmenta-\ntion.\n[W+95] \u201cDynamic Storage Allocation: A Survey and Critical Review\u201d by Paul R. Wilson, Mark\nS. Johnstone, Michael Neely , David Boles. International W orkshop on Memo ry Management,\nScotland, UK, September 1995. A great survey paper on memory allocators.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "indeed to typeset this very book. His tomes on algorithms are a great early refe rence to many of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "indeed",
          "typeset",
          "book",
          "tomes",
          "algorithms",
          "great",
          "early",
          "refe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "algorithms that underly computing systems today.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "underly",
          "computing",
          "systems",
          "today"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hints",
          "computer",
          "systems",
          "design",
          "butler",
          "lampson",
          "erating",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "system, with lots of common sense in its design. We\u2019ll study it in more detai l in a later chapter .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "lots",
          "common",
          "sense",
          "design",
          "study",
          "detai",
          "later"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[W+95] \u201cDynamic Storage Allocation: A Survey and Critical Review\u201d by Paul R. Wilson, Mark",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dynamic",
          "storage",
          "allocation",
          "survey",
          "critical",
          "review",
          "paul",
          "wilson"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 15: 5, October 1983. A treasure-trove of sage advice on how to build systems. Hard to read in",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "15",
          "october",
          "treasure",
          "trove",
          "sage",
          "advice",
          "build",
          "systems",
          "hard"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand V olume 15: 3, March 1982. A classic memory management",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 15",
          "march",
          "classic",
          "memory",
          "management"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand V olume 11: 5, May 1968. A nice overview of the differences between paging and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 11",
          "nice",
          "overview",
          "differences",
          "paging"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 12: 7, July 1969. One of the earliest papers to discuss fragmenta-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 12",
          "july",
          "earliest",
          "papers",
          "discuss",
          "fragmenta"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "Now , let\u2019s see if we understand this tiny address space we\u2019ve c on-",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "2. Now , let\u2019s see if we understand this tiny address space we\u2019ve c on-\nstructed (using the parameters from the question above). What i s\nthe highest legal virtual address in segment 0? What about the low-\nest legal virtual address in segment 1? What are the lowest and\nhighest illegal addresses in this entire address space? Finally , how\nwould you run segmentation.py with the -A \ufb02ag to test if you\nare right?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now , let\u2019s see if we understand this tiny address space we\u2019ve c on-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "tiny",
          "address",
          "space"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Let\u2019s say we have a tiny 16-byte address space in a 128-byte p hysical",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "3. Let\u2019s say we have a tiny 16-byte address space in a 128-byte p hysical\nmemory . What base and bounds would you set up so as to get\nthe simulator to generate the following translation results for t he\nspeci\ufb01ed address stream: valid, valid, violation, ..., violat ion, valid,\nvalid? Assume the following parameters:\nsegmentation.py -a 16 -p 128\n-A 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n--b0 ? --l0 ? --b1 ? --l1 ?",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand Assume the following parameters: segmentation.py -a 16 -p 128",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "assume the following parameters",
          "segmentation"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand -b0 ? --l0 ? --b1 ? --l1 ?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Assume we want to generate a problem where roughly 90% of the",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "4. Assume we want to generate a problem where roughly 90% of the\nrandomly-generated virtual addresses are valid (not segment ation\nviolations). How should you con\ufb01gure the simulator to do so?\nWhich parameters are important to getting this outcome?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Which parameters are important to getting this outcome?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "parameters",
          "important",
          "getting",
          "outcome"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "5",
    "title": "Can you run the simulator such that no virtual addresses are v alid?",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "5. Can you run the simulator such that no virtual addresses are v alid?\nHow?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "17\nFree-Space Management\nIn this chapter , we take a small detour from our discussion of virtu al-\nizing memory to discuss a fundamental aspect of any memory manag e-\nment system, whether it be a malloc library (managing pages of a pro-\ncess\u2019s heap) or the OS itself (managing portions of the address spa ce of a\nprocess). Speci\ufb01cally , we will discuss the issues surrounding free-space\nmanagement.\nLet us make the problem more speci\ufb01c. Managing free space can ce r-\ntainly be easy , as we will see when we discuss the concept of paging. It is\neasy when the space you are managing is divided into \ufb01xed-size d units;\nin such a case, you just keep a list of these \ufb01xed-sized units; wh en a client\nrequests one of them, return the \ufb01rst entry .\nWhere free-space management becomes more dif\ufb01cult (and inter est-\ning) is when the free space you are managing consists of variable -sized\nunits; this arises in a user-level memory-allocation library ( as in malloc()\nand free()) and in an OS managing physical memory when using seg-\nmentation to implement virtual memory . In either case, the problem that\nexists is known as external fragmentation : the free space gets chopped\ninto little pieces of different sizes and is thus fragmented; subsequent re-\nquests may fail because there is no single contiguous space tha t can sat-\nisfy the request, even though the total amount of free space excee ds the\nsize of the request.\nfree used free\n0 10 20 30\nThe \ufb01gure shows an example of this problem. In this case, the total\nfree space available is 20 bytes; unfortunately , it is fragme nted into two\nchunks of size 10 each. As a result, a request for 15 bytes will fa il even\nthough there are 20 bytes free. And thus we arrive at the problem ad-\ndressed in this chapter .\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "izing memory to discuss a fundamental aspect of any memory manag e-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "izing",
          "memory",
          "discuss",
          "fundamental",
          "aspect",
          "memory",
          "manag"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tainly be easy , as we will see when we discuss the concept of paging. It is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tainly",
          "easy",
          "discuss",
          "concept",
          "paging"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "mentation to implement virtual memory . In either case, the problem that",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "mentation",
          "implement",
          "virtual",
          "memory",
          "either",
          "case",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "exists is known as external fragmentation : the free space gets chopped",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "exists",
          "known",
          "external",
          "fragmentation",
          "free",
          "space",
          "gets",
          "chopped"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "17",
    "title": "1 Assumptions",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "17.1 Assumptions\nMost of this discussion will focus on the great history of allocators\nfound in user-level memory-allocation libraries. W e draw on Wils on\u2019s\nexcellent survey [W+95] but encourage interested readers to go to the\nsource document itself for more details 1 .\nW e assume a basic interface such as that provided by malloc() and\nfree(). Speci\ufb01cally , void *malloc(size t size) takes a single pa-\nrameter , size, which is the number of bytes requested by the applica-\ntion; it hands back a pointer (of no particular type, or a void pointer in\nC lingo) to a region of that size (or greater). The complementary rou tine\nvoid free(void *ptr) takes a pointer and frees the corresponding\nchunk. Note the implication of the interface: the user , when fre eing the\nspace, does not inform the library of its size; thus, the library m ust be able\nto \ufb01gure out how big a chunk of memory is when handed just a pointer\nto it. W e\u2019ll discuss how to do this a bit later on in the chapter .\nThe space that this library manages is known historically as th e heap,\nand the generic data structure used to manage free space in th e heap is\nsome kind of free list . This structure contains references to all of the free\nchunks of space in the managed region of memory . Of course, this dat a\nstructure need not be a list per se, but just some kind of data structure to\ntrack free space.\nW e further assume that primarily we are concerned with external frag-\nmentation, as described above. Allocators could of course also have the\nproblem of internal fragmentation ; if an allocator hands out chunks of\nmemory bigger than that requested, any unasked for (and thus un used)\nspace in such a chunk is considered internal fragmentation (because the\nwaste occurs inside the allocated unit) and is another example of space\nwaste. However , for the sake of simplicity , and because it is the more in-\nteresting of the two types of fragmentation, we\u2019ll mostly focus on ex ternal\nfragmentation.\nW e\u2019ll also assume that once memory is handed out to a client, it can not\nbe relocated to another location in memory . For example, if a program\ncalls malloc() and is given a pointer to some space within the heap,\nthat memory region is essentially \u201cowned\u201d by the program (and can not\nbe moved by the library) until the program returns it via a corres pond-\ning call to free(). Thus, no compaction of free space is possible, which\n1 It is nearly 80 pages long; thus, you really have to be interested!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The space that this library manages is known historically as th e heap,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "space",
          "library",
          "manages",
          "known",
          "historically",
          "heap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "mentation, as described above. Allocators could of course also have the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mentation",
          "described",
          "allocators",
          "could",
          "course",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "that memory region is essentially \u201cowned\u201d by the program (and can not",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "region",
          "essentially",
          "owned",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand assumptions",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assumptions"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "17",
    "title": "2 Low-level Mechanisms",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "17.2 Low-level Mechanisms\nBefore delving into some policy details, we\u2019ll \ufb01rst cover some com-\nmon mechanisms used in most allocators. First, we\u2019ll discuss the b asics of\nsplitting and coalescing, common techniques in most any allocator . Sec-\nond, we\u2019ll show how one can track the size of allocated regions quickly\nand with relative ease. Finally , we\u2019ll discuss how to build a si mple list\ninside the free space to keep track of what is free and what isn\u2019t .\nSplitting and Coalescing\nA free list contains a set of elements that describe the free spa ce still re-\nmaining in the heap. Thus, assume the following 30-byte heap:\nfree used free\n0 10 20 30\nThe free list for this heap would have two elements on it. One entr y de-\nscribes the \ufb01rst 10-byte free segment (bytes 0-9), and one ent ry describes\nthe other free segment (bytes 20-29):\nhead addr:0\nlen:10\naddr:20\nlen:10 NULL\nAs described above, a request for anything greater than 10 byte s will\nfail (returning NULL); there just isn\u2019t a single contiguous chu nk of mem-\nory of that size available. A request for exactly that size (10 by tes) could\nbe satis\ufb01ed easily by either of the free chunks. But what happe ns if the\nrequest is for something smaller than 10 bytes?\nAssume we have a request for just a single byte of memory . In this\ncase, the allocator will perform an action known as splitting: it will \ufb01nd\n2 Once you hand a pointer to a chunk of memory to a C program, it is generally d if\ufb01cult\nto determine all references (pointers) to that region, which may be stor ed in other variables\nor even in registers at a given point in execution. This may not be the ca se in more strongly-\ntyped, garbage-collected languages, which would thus enable compacti on as a technique to\ncombat fragmentation.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "splitting and coalescing, common techniques in most any allocator . Sec-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "splitting",
          "coalescing",
          "common",
          "techniques",
          "allocator"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A free list contains a set of elements that describe the free spa ce still re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "list",
          "contains",
          "elements",
          "describe",
          "free",
          "still"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "scribes the \ufb01rst 10-byte free segment (bytes 0-9), and one ent ry describes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "scribes",
          "byte",
          "free",
          "segment",
          "bytes",
          "describes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "As described above, a request for anything greater than 10 byte s will",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "request",
          "anything",
          "greater",
          "byte"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "case, the allocator will perform an action known as splitting: it will \ufb01nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "case",
          "allocator",
          "perform",
          "action",
          "known",
          "splitting"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "typed, garbage-collected languages, which would thus enable compacti on as a technique to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "typed",
          "garbage",
          "collected",
          "languages",
          "would",
          "thus",
          "enable",
          "compacti"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand low-level mechanisms",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "level",
          "mechanisms"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand free and what isn\u2019t .\nSplitting and Coalescing\nA free list contains a set of elements that describe the free spa ce still re-\nmaining in the heap. Thus, assume the following 30-byte heap:\nfree used free\n0 10 20 30\nThe free list for this heap would have two elements on it. One entr y de-\nscribes the \ufb01rst 10-byte free segment (bytes 0-9), and one ent ry describes\nthe other free segment (bytes 20-29):\nhead addr:0\nlen:10\naddr:20\nlen:10 NULL\nAs described above, a request for anything greater than 10 byte s will\nfail (returning NULL); there just isn\u2019t a single contiguous chu nk of mem-\nory of that size available. A request for exactly that size (10 by tes) could\nbe satis\ufb01ed easily by either of the free chunks. But what happe ns if the\nrequest is for something smaller than 10 bytes",
        "type": "question_concept",
        "difficulty": "advanced",
        "keywords": [
          "free",
          "splitting",
          "coalescing",
          "free",
          "list",
          "contains",
          "elements",
          "describe"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 FR E E -S PA C E MA N A G E M E N T\na free chunk of memory that can satisfy the request and split it i nto two.\nThe \ufb01rst chunk it will return to the caller; the second chunk wi ll remain\non the list. Thus, in our example above, if a request for 1 byte were made,\nand the allocator decided to use the second of the two elements on th e list\nto satisfy the request, the call to malloc() would return 20 (th e address of\nthe 1-byte allocated region) and the list would end up looking like this:\nhead addr:0\nlen:10\naddr:21\nlen:9 NULL\nIn the picture, you can see the list basically stays intact; th e only change\nis that the free region now starts at 21 instead of 20, and the leng th of that\nfree region is now just 9 3 . Thus, the split is commonly used in allocators\nwhen requests are smaller than the size of any particular free chunk.\nA corollary mechanism found in many allocators is known as coalesc-\ning of free space. T ake our example from above once more (free 10 bytes,\nused 10 bytes, and another free 10 bytes).\nGiven this (tiny) heap, what happens when an application call s free(10),\nthus returning the space in the middle of the heap? If we simply add this\nfree space back into our list without too much thinking, we might end up\nwith a list that looks like this:\nhead addr:10\nlen:10\naddr:0\nlen:10\naddr:20\nlen:10 NULL\nNote the problem: while the entire heap is now free, it is seeming ly\ndivided into three chunks of 10 bytes each. Thus, if a user requ ests 20\nbytes, a simple list traversal will not \ufb01nd such a free chunk, a nd return\nfailure.\nWhat allocators do in order to avoid this problem is coalesce free sp ace\nwhen a chunk of memory is freed. The idea is simple: when returni ng a\nfree chunk in memory , look carefully at the addresses of the chunk you\nare returning as well as the nearby chunks of free space; if the newly-\nfreed space sits right next to one (or two, as in this example) exi sting free\nchunks, merge them into a single larger free chunk. Thus, wit h coalesc-\ning, our \ufb01nal list should look like this:\nhead addr:0\nlen:30 NULL\nIndeed, this is what the heap list looked like at \ufb01rst, before any allo-\ncations were made. With coalescing, an allocator can better ensu re that\nlarge free extents are available for the application.\n3 This discussion assumes that there are no headers, an unrealistic but simplifying assump-\ntion we make for now .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A corollary mechanism found in many allocators is known as coalesc-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "corollary",
          "mechanism",
          "found",
          "many",
          "allocators",
          "known",
          "coalesc"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_11",
        "text": "understand Note the problem: while the entire heap is now free, it is seeming ly",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "note the problem",
          "entire",
          "heap",
          "free",
          "seeming"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FR E E -S PA C E MA N A G E M E N T 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FR E E -S PA C E MA N A G E M E N T 5\nptr\nThe header used by malloc library\nThe 20 bytes returned to caller\nFigure 17.1: An Allocated Region Plus Header\nsize: 20\nmagic: 1234567\nhptr\nptr\nThe 20 bytes returned to caller\nFigure 17.2: Speci\ufb01c Contents Of The Header\nT racking The Size Of Allocated Regions\nY ou might have noticed that the interface to free(void *ptr) does\nnot take a size parameter; thus it is assumed that given a pointe r , the\nmalloc library can quickly determine the size of the region of mem ory\nbeing freed and thus incorporate the space back into the free li st.\nT o accomplish this task, most allocators store a little bit of extra infor-\nmation in a header block which is kept in memory , usually just before\nthe handed-out chunk of memory . Let\u2019s look at an example again (Fig-\nure 17.1). In this example, we are examining an allocated block of size 20\nbytes, pointed to by ptr; imagine the user called malloc() and stored\nthe results in ptr, e.g., ptr = malloc(20);.\nThe header minimally contains the size of the allocated region (i n this\ncase, 20); it may also contain additional pointers to speed up de alloca-\ntion, a magic number to provide additional integrity checking, and other\ninformation. Let\u2019s assume a simple header which contains the siz e of the\nregion and a magic number , like this:\ntypedef struct {\nint size;\nint magic;\n} header_t;\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: An Allocated Region Plus Header",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "allocated",
          "region",
          "plus",
          "header"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 2: Speci\ufb01c Contents Of The Header",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "contents",
          "header"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 FR E E -S PA C E MA N A G E M E N T\nThe example above would look like what you see in Figure 17.2. When\nthe user calls free(ptr), the library then uses simple pointer arithmetic\nto \ufb01gure out where the header begins:\nvoid free(void *ptr) {\nheader_t *hptr = (header_t *) ptr - 1;\n...\nAfter obtaining such a pointer to the header , the library can ea sily de-\ntermine whether the magic number matches the expected value as a san-\nity check ( assert(hptr->magic == 1234567)) and calculate the to-\ntal size of the newly-freed region via simple math (i.e., addin g the size of\nthe header to size of the region). Note the small but critical det ail in the\nlast sentence: the size of the free region is the size of the heade r plus the\nsize of the space allocated to the user . Thus, when a user reques ts N bytes\nof memory , the library does not search for a free chunk of size N; rather ,\nit searches for a free chunk of size N plus the size of the header .\nEmbedding A Free List\nThus far we have treated our simple free list as a conceptual ent ity; it is\njust a list describing the free chunks of memory in the heap. But how do\nwe build such a list inside the free space itself?\nIn a more typical list, when allocating a new node, you would just ca ll\nmalloc() when you need space for the node. Unfortunately , within the\nmemory-allocation library , you can\u2019t do this! Instead, you need to build\nthe list inside the free space itself. Don\u2019t worry if this sounds a little weird;\nit is, but not so weird that you can\u2019t do it!\nAssume we have a 4096-byte chunk of memory to manage (i.e., the\nheap is 4KB). T o manage this as a free list, we \ufb01rst have to init ialize said\nlist; initially , the list should have one entry , of size 4096 (mi nus the header\nsize). Here is the description of a node of the list:\ntypedef struct __node_t {\nint size;\nstruct __node_t *next;\n} node_t;\nNow let\u2019s look at some code that initializes the heap and puts the \ufb01rs t\nelement of the free list inside that space. W e are assuming tha t the heap is\nbuilt within some free space acquired via a call to the system c all mmap();\nthis is not the only way to build such a heap but serves us well in t his\nexample. Here is the code:\n// mmap() returns a pointer to a chunk of free space\nnode_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE,\nMAP_ANON|MAP_PRIVATE, -1, 0);\nhead->size = 4096 - sizeof(node_t);\nhead->next = NULL;\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the header to size of the region). Note the small but critical det ail in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "header",
          "size",
          "region",
          "note",
          "small",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Thus far we have treated our simple free list as a conceptual ent ity; it is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "treated",
          "simple",
          "free",
          "list",
          "conceptual"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand Here is the code: // mmap() returns a pointer to a chunk of free space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "here is the code",
          "mmap",
          "returns",
          "pointer",
          "chunk",
          "free",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FR E E -S PA C E MA N A G E M E N T 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FR E E -S PA C E MA N A G E M E N T 7\nsize: 4088\nnext: 0\n...\nhead [virtual address: 16KB]\nheader: size field\nheader: next field (NULL is 0)\nthe rest of the 4KB chunk\nFigure 17.3: A Heap With One Free Chunk\nsize: 100\nmagic: 1234567\n. . .\nsize: 3980\nnext: 0\n. . .\nptr\n[virtual address: 16KB]\nhead\nThe 100 bytes now allocated\nThe free 3980 byte chunk\nFigure 17.4: A Heap: After One Allocation\nAfter running this code, the status of the list is that it has a si ngle entry ,\nof size 4088. Y es, this is a tiny heap, but it serves as a \ufb01ne exam ple for us\nhere. The head pointer contains the beginning address of this range; let\u2019s\nassume it is 16KB (though any virtual address would be \ufb01ne). Vis ually ,\nthe heap thus looks like what you see in Figure 17.3.\nNow , let\u2019s imagine that a chunk of memory is requested, say of size\n100 bytes. T o service this request, the library will \ufb01rst \ufb01nd a chunk that is\nlarge enough to accommodate the request; because there is only one free\nchunk (size: 4088), this chunk will be chosen. Then, the chunk will be\nsplit into two: one chunk big enough to service the request (and header ,\nas described above), and the remaining free chunk. Assuming a n 8-byte\nheader (an integer size and an integer magic number), the spa ce in the\nheap now looks like what you see in Figure 17.4.\nThus, upon the request for 100 bytes, the library allocated 108 b ytes\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "as described above), and the remaining free chunk. Assuming a n 8-byte",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "remaining",
          "free",
          "chunk",
          "assuming",
          "byte"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand header: next field (NULL is 0)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "header",
          "next",
          "field",
          "null"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 3: A Heap With One Free Chunk",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "heap",
          "free",
          "chunk"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand 4: A Heap: After One Allocation",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "heap",
          "allocation"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_13",
        "text": "understand size: 4088), this chunk will be chosen. Then, the chunk will be",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "size",
          "chunk",
          "chosen",
          "chunk"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_14",
        "text": "understand split into two: one chunk big enough to service the request (and header ,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "split into two",
          "chunk",
          "enough",
          "service",
          "request",
          "header"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 FR E E -S PA C E MA N A G E M E N T\nsize: 100\nmagic: 1234567\n. . .\nsize: 100\nmagic: 1234567\n. . .\nsize: 100\nmagic: 1234567\n. . .\nsize: 3764\nnext: 0\n. . .\nsptr\n[virtual address: 16KB]\nhead\n100 bytes still allocated\n100 bytes still allocated\n (but about to be freed)\n100-bytes still allocated\nThe free 3764-byte chunk\nFigure 17.5: Free Space With Three Chunks Allocated\nout of the existing one free chunk, returns a pointer (marked ptr in the\n\ufb01gure above) to it, stashes the header information immediately before the\nallocated space for later use upon free(), and shrinks the one free node\nin the list to 3980 bytes (4088 minus 108).\nNow let\u2019s look at the heap when there are three allocated regions, ea ch\nof 100 bytes (or 108 including the header). A visualization of thi s heap is\nshown in Figure 17.5.\nAs you can see therein, the \ufb01rst 324 bytes of the heap are now allo-\ncated, and thus we see three headers in that space as well as th ree 100-\nbyte regions being used by the calling program. The free list re mains\nuninteresting: just a single node (pointed to by head), but now only 3764\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_10",
        "text": "understand 5: Free Space With Three Chunks Allocated",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "free",
          "space",
          "three",
          "chunks",
          "allocated"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FR E E -S PA C E MA N A G E M E N T 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FR E E -S PA C E MA N A G E M E N T 9\nsize: 100\nmagic: 1234567\n. . .\nsize: 100\nnext: 16708\n. . .\nsize: 100\nmagic: 1234567\n. . .\nsize: 3764\nnext: 0\n. . .\n[virtual address: 16KB]\nhead\nsptr\n100 bytes still allocated\n(now a free chunk of memory)\n100-bytes still allocated\nThe free 3764-byte chunk\nFigure 17.6: Free Space With T wo Chunks Allocated\nbytes in size after the three splits. But what happens when th e calling\nprogram returns some memory via free()?\nIn this example, the application returns the middle chunk of al located\nmemory , by calling free(16500) (the value 16500 is arrived upon by\nadding the start of the memory region, 16384, to the 108 of the prev ious\nchunk and the 8 bytes of the header for this chunk). This value is shown\nin the previous diagram by the pointer sptr.\nThe library immediately \ufb01gures out the size of the free region, a nd\nthen adds the free chunk back onto the free list. Assuming we in sert at\nthe head of the free list, the space now looks like this (Figure 17. 6).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_10",
        "text": "understand 6: Free Space With T wo Chunks Allocated",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "free",
          "space",
          "chunks",
          "allocated"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 FR E E -S PA C E MA N A G E M E N T\nsize: 100\nnext: 16492\n. . .\nsize: 100\nnext: 16708\n. . .\nsize: 100\nnext: 16384\n. . .\nsize: 3764\nnext: 0\n. . .\n[virtual address: 16KB]\nhead\n(now free)\n(now free)\n(now free)\nThe free 3764-byte chunk\nFigure 17.7: A Non-Coalesced Free List\nNow we have a list that starts with a small free chunk (100 bytes ,\npointed to by the head of the list) and a large free chunk (3764 by tes).\nOur list \ufb01nally has more than one element on it! And yes, the free s pace\nis fragmented, an unfortunate but common occurrence.\nOne last example: let\u2019s assume now that the last two in-use chun ks are\nfreed. Without coalescing, you end up with fragmentation (Figur e 17.7).\nAs you can see from the \ufb01gure, we now have a big mess! Why? Simple,\nwe forgot to coalesce the list. Although all of the memory is free, it is\nchopped up into pieces, thus appearing as a fragmented memory d espite\nnot being one. The solution is simple: go through the list and merge\nneighboring chunks; when \ufb01nished, the heap will be whole again .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_10",
        "text": "understand 7: A Non-Coalesced Free List",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "coalesced",
          "free",
          "list"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand One last example: let\u2019s assume now that the last two in-use chun ks are",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last example",
          "assume",
          "last",
          "chun"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand The solution is simple: go through the list and merge",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the solution is simple",
          "list",
          "merge"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "17",
    "title": "3 Basic Strategies",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "17.3 Basic Strategies\nNow that we have some machinery under our belt, let\u2019s go over some\nbasic strategies for managing free space. These approaches ar e mostly\nbased on pretty simple policies that you could think up yourself; t ry it\nbefore reading and see if you come up with all of the alternatives ( or\nmaybe some new ones!).\nThe ideal allocator is both fast and minimizes fragmentation. Un fortu-\nnately , because the stream of allocation and free requests can b e arbitrary\n(after all, they are determined by the programmer), any parti cular strat-\negy can do quite badly given the wrong set of inputs. Thus, we wil l not\ndescribe a \u201cbest\u201d approach, but rather talk about some basics an d discuss\ntheir pros and cons.\nBest Fit\nThe best \ufb01t strategy is quite simple: \ufb01rst, search through the free list a nd\n\ufb01nd chunks of free memory that are as big or bigger than the reques ted\nsize. Then, return the one that is the smallest in that group of ca ndidates;\nthis is the so called best-\ufb01t chunk (it could be called smalles t \ufb01t too). One\npass through the free list is enough to \ufb01nd the correct block to ret urn.\nThe intuition behind best \ufb01t is simple: by returning a block tha t is close\nto what the user asks, best \ufb01t tries to reduce wasted space. How ever , there\nis a cost; naive implementations pay a heavy performance penalt y when\nperforming an exhaustive search for the correct free block.\nW orst Fit\nThe worst \ufb01t approach is the opposite of best \ufb01t; \ufb01nd the largest chunk\nand return the requested amount; keep the remaining (large) c hunk on\nthe free list. W orst \ufb01t tries to thus leave big chunks free inst ead of lots of\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "basic strategies for managing free space. These approaches ar e mostly",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "strategies",
          "managing",
          "free",
          "space",
          "approaches",
          "mostly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "describe a \u201cbest\u201d approach, but rather talk about some basics an d discuss",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describe",
          "best",
          "approach",
          "rather",
          "talk",
          "basics",
          "discuss"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The best \ufb01t strategy is quite simple: \ufb01rst, search through the free list a nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "best",
          "strategy",
          "quite",
          "simple",
          "search",
          "free",
          "list"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "is a cost; naive implementations pay a heavy performance penalt y when",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "cost",
          "naive",
          "implementations",
          "heavy",
          "performance",
          "penalt"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The worst \ufb01t approach is the opposite of best \ufb01t; \ufb01nd the largest chunk",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "worst",
          "approach",
          "opposite",
          "best",
          "largest",
          "chunk"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand basic strategies",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "strategies"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 FR E E -S PA C E MA N A G E M E N T\nsmall chunks that can arise from a best-\ufb01t approach. Once again , how-\never , a full search of free space is required, and thus this app roach can be\ncostly . W orse, most studies show that it performs badly , leading t o excess\nfragmentation while still having high overheads.\nFirst Fit\nThe \ufb01rst \ufb01t method simply \ufb01nds the \ufb01rst block that is big enough and\nreturns the requested amount to the user . As before, the remain ing free\nspace is kept free for subsequent requests.\nFirst \ufb01t has the advantage of speed \u2014 no exhaustive search of all the\nfree spaces are necessary \u2014 but sometimes pollutes the beginni ng of the\nfree list with small objects. Thus, how the allocator manages the free list\u2019s\norder becomes an issue. One approach is to use address-based ordering ;\nby keeping the list ordered by the address of the free space, coal escing\nbecomes easier , and fragmentation tends to be reduced.\nNext Fit\nInstead of always beginning the \ufb01rst-\ufb01t search at the beginni ng of the list,\nthe next \ufb01t algorithm keeps an extra pointer to the location within the\nlist where one was looking last. The idea is to spread the searche s for\nfree space throughout the list more uniformly , thus avoiding spli ntering\nof the beginning of the list. The performance of such an approach is quite\nsimilar to \ufb01rst \ufb01t, as an exhaustive search is once again avoide d.\nExamples\nHere are a few examples of the above strategies. Envision a free l ist with\nthree elements on it, of sizes 10, 30, and 20 (we\u2019ll ignore headers and other\ndetails here, instead just focusing on how strategies operate):\nhead 10 30 20 NULL\nAssume an allocation request of size 15. A best-\ufb01t approach would\nsearch the entire list and \ufb01nd that 20 was the best \ufb01t, as it is t he smallest\nfree space that can accommodate the request. The resulting fre e list:\nhead 10 30 5 NULL\nAs happens in this example, and often happens with a best-\ufb01t ap -\nproach, a small free chunk is now left over . A worst-\ufb01t approach is s imilar\nbut instead \ufb01nds the largest chunk, in this example 30. The re sulting list:\nhead 10 15 20 NULL\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "small chunks that can arise from a best-\ufb01t approach. Once again , how-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "small",
          "chunks",
          "arise",
          "best",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The \ufb01rst \ufb01t method simply \ufb01nds the \ufb01rst block that is big enough and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "method",
          "simply",
          "block",
          "enough"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "order becomes an issue. One approach is to use address-based ordering ;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "order",
          "becomes",
          "issue",
          "approach",
          "address",
          "based",
          "ordering"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "the next \ufb01t algorithm keeps an extra pointer to the location within the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "next",
          "algorithm",
          "keeps",
          "extra",
          "pointer",
          "location",
          "within"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "of the beginning of the list. The performance of such an approach is quite",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "beginning",
          "list",
          "performance",
          "approach",
          "quite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Assume an allocation request of size 15. A best-\ufb01t approach would",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "assume",
          "allocation",
          "request",
          "size",
          "best",
          "approach",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "proach, a small free chunk is now left over . A worst-\ufb01t approach is s imilar",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proach",
          "small",
          "free",
          "chunk",
          "left",
          "worst",
          "approach",
          "imilar"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "17",
    "title": "4 Other Approaches",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "17.4 Other Approaches\nBeyond the basic approaches described above, there have been a h ost\nof suggested techniques and algorithms to improve memory allocat ion in\nsome way . W e list a few of them here for your consideration (i.e., to m ake\nyou think about a little more than just best-\ufb01t allocation).\nSegregated Lists\nOne interesting approach that has been around for some time is the use\nof segregated lists . The basic idea is simple: if a particular application\nhas one (or a few) popular-sized request that it makes, keep a sep arate\nlist just to manage objects of that size; all other requests are f orwarded to\na more general memory allocator .\nThe bene\ufb01ts of such an approach are obvious. By having a chunk of\nmemory dedicated for one particular size of requests, fragmenta tion is\nmuch less of a concern; moreover , allocation and free requests can b e\nserved quite quickly when they are of the right size, as no compl icated\nsearch of a list is required.\nJust like any good idea, this approach introduces new complication s\ninto a system as well. For example, how much memory should one ded-\nicate to the pool of memory that serves specialized requests of a gi ven\nsize, as opposed to the general pool? One particular allocator , the slab\nallocator by uber-engineer Jeff Bonwick (which was designed for use in\nthe Solaris kernel), handles this issue in a rather nice way [B9 4].\nSpeci\ufb01cally , when the kernel boots up, it allocates a number of object\ncaches for kernel objects that are likely to be requested frequently ( such as\nlocks, \ufb01le-system inodes, etc.); the object caches thus are eac h segregated\nfree lists of a given size and serve memory allocation and free req uests\nquickly . When a given cache is running low on free space, it requ ests\nsome slabs of memory from a more general memory allocator (the to-\ntal amount requested being a multiple of the page size and the obj ect in\nquestion). Conversely , when the reference counts of the objects w ithin\na given slab all go to zero, the general allocator can reclaim the m from\nthe specialized allocator , which is often done when the VM system needs\nmore memory .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Other Approaches",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Beyond the basic approaches described above, there have been a h ost",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "beyond",
          "basic",
          "approaches",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of suggested techniques and algorithms to improve memory allocat ion in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "suggested",
          "techniques",
          "algorithms",
          "improve",
          "memory",
          "allocat"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "One interesting approach that has been around for some time is the use",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "interesting",
          "approach",
          "around",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The bene\ufb01ts of such an approach are obvious. By having a chunk of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "obvious",
          "chunk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Just like any good idea, this approach introduces new complication s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "like",
          "good",
          "idea",
          "approach",
          "introduces",
          "complication"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "allocator by uber-engineer Jeff Bonwick (which was designed for use in",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "allocator",
          "uber",
          "engineer",
          "jeff",
          "bonwick",
          "designed"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand other approaches",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "approaches"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 FR E E -S PA C E MA N A G E M E N T\nAS I D E : G R E AT EN G I N E E R S AR E RE A L LY GR E AT\nEngineers like Jeff Bonwick (who not only wrote the slab allocator m en-\ntioned herein but also was the lead of an amazing \ufb01le system, ZFS) are\nthe heart of Silicon V alley . Behind almost any great product or tech nol-\nogy is a human (or small group of humans) who are way above average\nin their talents, abilities, and dedication. As Mark Zuckerb erg (of Face-\nbook) says: \u201cSomeone who is exceptional in their role is not just a litt le\nbetter than someone who is pretty good. They are 100 times better . \u201d This\nis why , still today , one or two people can start a company that chang es\nthe face of the world forever (think Google, Apple, or Facebook). W ork\nhard and you might become such a \u201c100x\u201d person as well. Failing th at,\nwork with such a person; you\u2019ll learn more in a day than most learn in a\nmonth. Failing that, feel sad.\nThe slab allocator also goes beyond most segregated list approache s\nby keeping free objects on the lists in a pre-initialized state . Bonwick\nshows that initialization and destruction of data structures is costly [B94];\nby keeping freed objects in a particular list in their initial ized state, the\nslab allocator thus avoids frequent initialization and destruc tion cycles\nper object and thus lowers overheads noticeably .\nBuddy Allocation\nBecause coalescing is critical for an allocator , some approaches h ave been\ndesigned around making coalescing simple. One good example is fou nd\nin the binary buddy allocator [K65].\nIn such a system, free memory is \ufb01rst conceptually thought of as one\nbig space of size 2N . When a request for memory is made, the search for\nfree space recursively divides free space by two until a block that is big\nenough to accommodate the request is found (and a further split in to two\nwould result in a space that is too small). At this point, the requ ested\nblock is returned to the user . Here is an example of a 64KB free sp ace\ngetting divided in the search for a 7KB block (Figure 17.8, page 15).\nIn the example, the leftmost 8KB block is allocated (as indicate d by the\ndarker shade of gray) and returned to the user; note that this sc heme can\nsuffer from internal fragmentation , as you are only allowed to give out\npower-of-two-sized blocks.\nThe beauty of buddy allocation is found in what happens when that\nblock is freed. When returning the 8KB block to the free list, th e allocator\nchecks whether the \u201cbuddy\u201d 8KB is free; if so, it coalesces the t wo blocks\ninto a 16KB block. The allocator then checks if the buddy of the 16K B\nblock is still free; if so, it coalesces those two blocks. This recu rsive coa-\nlescing process continues up the tree, either restoring the ent ire free space\nor stopping when a buddy is found to be in use.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "work with such a person; you\u2019ll learn more in a day than most learn in a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "work",
          "person",
          "learn",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The slab allocator also goes beyond most segregated list approache s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "slab",
          "allocator",
          "also",
          "goes",
          "beyond",
          "segregated",
          "list",
          "approache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Because coalescing is critical for an allocator , some approaches h ave been",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "coalescing",
          "critical",
          "allocator",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "designed around making coalescing simple. One good example is fou nd",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "designed",
          "around",
          "making",
          "coalescing",
          "simple",
          "good",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "In such a system, free memory is \ufb01rst conceptually thought of as one",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "free",
          "memory",
          "conceptually",
          "thought"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand says: \u201cSomeone who is exceptional in their role is not just a litt le",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "says",
          "someone",
          "exceptional",
          "role",
          "litt"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "17",
    "title": "5 Summary",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "17.5 Summary\nIn this chapter , we\u2019ve discussed the most rudimentary forms of me m-\nory allocators. Such allocators exist everywhere, linked into eve ry C pro-\ngram you write, as well as in the underlying OS which is managin g mem-\nory for its own data structures. As with many systems, there are m any\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 FR E E -S PA C E MA N A G E M E N T",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 FR E E -S PA C E MA N A G E M E N T\ntrade-offs to be made in building such a system, and the more you k now\nabout the exact workload presented to an allocator , the more you could do\nto tune it to work better for that workload. Making a fast, space-e f\ufb01cient,\nscalable allocator that works well for a broad range of workloads rema ins\nan on-going challenge in modern computer systems.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FR E E -S PA C E MA N A G E M E N T 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FR E E -S PA C E MA N A G E M E N T 17\nReferences\n[B+00] \u201cHoard: A Scalable Memory Allocator for Multithreaded Appli cations\u201d by Emery D.\nBerger , Kathryn S. McKinley , Robert D. Blumofe, Paul R. Wilson. ASPLOS -IX, November 2000.\nBerger and company\u2019s excellent allocator for multiprocessor systems. Beyond just being a fun paper , also\nused in practice!\n[B94] \u201cThe Slab Allocator: An Object-Caching Kernel Memory Allocator \u201d by Je ff Bonwick.\nUSENIX \u201994. A cool paper about how to build an allocator for an operating system kernel, and a great\nexample of how to specialize for particular common object sizes.\n[E06] \u201cA Scalable Concurrent malloc(3) Implementation for FreeBSD\u201d b y Jason Evans. April,\n2006. http://people.freebsd.org/\u02dcjasone/jemalloc/bsdcan2006 /jemalloc.pdf. A detailed look at\nhow to build a real modern allocator for use in multiprocessors. The \u201cjemalloc\u201d allocator is in widespread\nuse today, within FreeBSD, NetBSD, Mozilla Firefox, and within Facebook.\n[K65] \u201cA Fast Storage Allocator \u201d by Kenneth C. Knowlton. Communicati ons of the ACM,\nV olume 8:10, October 1965. The common reference for buddy allocation. Random strange fact: Knuth\ngives credit for the idea not to Knowlton but to Harry Markowitz, a Nobel-prize wi nning economist.\nAnother strange fact: Knuth communicates all of his emails via a secretary; he doesn\u2019t send email\nhimself, rather he tells his secretary what email to send and then the secretary does the work of emailing.\nLast Knuth fact: he created T eX, the tool used to typeset this book. It is an amazing piece of software4 .\n[S15] \u201cUnderstanding glibc malloc\u201d by Sploitfun. February , 2015. s ploitfun.wordpress.com/\n2015/02/10/understanding-glibc-malloc/. A deep dive into how glibc malloc works. Amazingly\ndetailed and a very cool read.\n[W+95] \u201cDynamic Storage Allocation: A Survey and Critical Review\u201d by Paul R. Wilson, Mark\nS. Johnstone, Michael Neely , David Boles. International W orkshop on Memo ry Management,\nScotland, UK, September 1995. An excellent and far-reaching survey of many facets of memory\nallocation. Far too much detail to go into in this tiny chapter!\n4 Actually we use LaT eX, which is based on Lamport\u2019s additions to T e X, but close enough.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[E06] \u201cA Scalable Concurrent malloc(3) Implementation for FreeBSD\u201d b y Jason Evans. April,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "scalable",
          "concurrent",
          "malloc",
          "implementation",
          "freebsd",
          "jason",
          "evans",
          "april"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[K65] \u201cA Fast Storage Allocator \u201d by Kenneth C. Knowlton. Communicati ons of the ACM,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fast",
          "storage",
          "allocator",
          "kenneth",
          "knowlton",
          "communicati"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "gives credit for the idea not to Knowlton but to Harry Markowitz, a Nobel-prize wi nning economist.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "gives",
          "credit",
          "idea",
          "knowlton",
          "harry",
          "markowitz",
          "nobel",
          "prize"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Last Knuth fact: he created T eX, the tool used to typeset this book. It is an amazing piece of software4 .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "knuth",
          "fact",
          "created",
          "tool",
          "used",
          "typeset",
          "book"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[S15] \u201cUnderstanding glibc malloc\u201d by Sploitfun. February , 2015. s ploitfun.wordpress.com/",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "glibc",
          "malloc",
          "sploitfun",
          "february",
          "ploitfun",
          "wordpress"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "/02/10/understanding-glibc-malloc/. A deep dive into how glibc malloc works. Amazingly",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "glibc",
          "malloc",
          "deep",
          "dive",
          "glibc",
          "malloc",
          "works"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "[W+95] \u201cDynamic Storage Allocation: A Survey and Critical Review\u201d by Paul R. Wilson, Mark",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dynamic",
          "storage",
          "allocation",
          "survey",
          "critical",
          "review",
          "paul",
          "wilson"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Hoard: A Scalable Memory Allocator for Multithreaded Appli cations\u201d by Emery D.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hoard",
          "scalable",
          "memory",
          "allocator",
          "multithreaded",
          "appli",
          "cations",
          "emery"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand The Slab Allocator: An Object-Caching Kernel Memory Allocator \u201d by Je ff Bonwick.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the slab allocator",
          "object",
          "caching",
          "kernel",
          "memory",
          "allocator",
          "bonwick"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand http: //people.freebsd.org/\u02dcjasone/jemalloc/bsdcan2006 /jemalloc.pdf. A detailed look at",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "people",
          "freebsd",
          "jasone",
          "jemalloc",
          "jemalloc",
          "detailed",
          "look"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 8: 10, October 1965. The common reference for buddy allocation. Random strange fact: Knuth",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 8",
          "october",
          "common",
          "reference",
          "buddy",
          "allocation",
          "random",
          "strange",
          "fact"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Another strange fact: Knuth communicates all of his emails via a secretary; he doesn\u2019t send email",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "another strange fact",
          "knuth",
          "communicates",
          "emails",
          "secretary",
          "send",
          "email"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "First run with the \ufb02ags -n 10 -H 0 -p BEST -s 0 to gener-",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. First run with the \ufb02ags -n 10 -H 0 -p BEST -s 0 to gener-\nate a few random allocations and frees. Can you predict what al-\nloc()/free() will return? Can you guess the state of the free lis t after\neach request? What do you notice about the free list over time?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "How are the results different when using a WORST \ufb01t policy to",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "2. How are the results different when using a WORST \ufb01t policy to\nsearch the free list ( -p WORST)? What changes?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "What about when using FIRST \ufb01t ( -p FIRST)? What speeds up",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "3. What about when using FIRST \ufb01t ( -p FIRST)? What speeds up\nwhen you use \ufb01rst \ufb01t?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "For the above questions, how the list is kept ordered can affect t he",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "4. For the above questions, how the list is kept ordered can affect t he\ntime it takes to \ufb01nd a free location for some of the policies. Use\nthe different free list orderings ( -l ADDRSORT, -l SIZESORT+,\n-l SIZESORT-) to see how the policies and the list orderings in-\nteract.\n5. Coalescing of a free list can be quite important. Increase the number\nof random allocations (say to -n 1000). What happens to larger\nallocation requests over time? Run with and without coalescing\n(i.e., without and with the -C \ufb02ag). What differences in outcome do\nyou see? How big is the free list over time in each case? Does the\nordering of the list matter in this case?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Coalescing of a free list can be quite important. Increase the number",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "coalescing",
          "free",
          "list",
          "quite",
          "important",
          "increase",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(i.e., without and with the -C \ufb02ag). What differences in outcome do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "without",
          "differences",
          "outcome"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand l sizesort-) to see how the policies and the list orderings in-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "sizesort",
          "policies",
          "list",
          "orderings"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "6",
    "title": "What happens when you change the percent allocated fraction -P",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "6. What happens when you change the percent allocated fraction -P\nto higher than 50? What happens to allocations as it nears 100?\nWhat about as the percent nears 0?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "7",
    "title": "What kind of speci\ufb01c requests can you make to generate a highl y-",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "7. What kind of speci\ufb01c requests can you make to generate a highl y-\nfragmented free space? Use the -A \ufb02ag to create fragmented free\nlists, and see how different policies and options change the organ i-\nzation of the free list.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "fragmented free space? Use the -A \ufb02ag to create fragmented free",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fragmented",
          "free",
          "space",
          "create",
          "fragmented",
          "free"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "1 A Simple Example And Overview",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "18.1 A Simple Example And Overview\nT o help make this approach more clear , let\u2019s illustrate it with a simple\nexample. Figure 18.1 (page 2) presents an example of a tiny add ress space,\nonly 64 bytes total in size, with four 16-byte pages (virtual pag es 0, 1, 2,\nand 3). Real address spaces are much bigger , of course, commonly 3 2 bits\nand thus 4-GB of address space, or even 64 bits 1 ; in the book, we\u2019ll often\nuse tiny examples to make them easier to digest.\n1 A 64-bit address space is hard to imagine, it is so amazingly large. An analogy might\nhelp: if you think of a 32-bit address space as the size of a tennis court, a 64-bit address space\nis about the size of Europe(!).\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o help make this approach more clear , let\u2019s illustrate it with a simple",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "help",
          "make",
          "approach",
          "clear",
          "illustrate",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand An analogy might\nhelp: if you think of a 32-bit address space as the size of a tennis court, a 64-bit address space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "an analogy might\nhelp",
          "think",
          "address",
          "space",
          "size",
          "tennis",
          "court",
          "address",
          "space"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a simple example and overview",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "example",
          "overview"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 PA G I N G : I N T R O D U C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 PA G I N G : I N T R O D U C T I O N\n64\n48\n32\n16\n0\n(page 3)\n(page 2)\n(page 1)\n(page 0 of the address space)\nFigure 18.1: A Simple 64-byte Address Space\nPhysical memory , as shown in Figure 18.2, also consists of a numbe r\nof \ufb01xed-sized slots, in this case eight page frames (making for a 128-byte\nphysical memory , also ridiculously small). As you can see in the diagram,\nthe pages of the virtual address space have been placed at diff erent loca-\ntions throughout physical memory; the diagram also shows the OS us ing\nsome of physical memory for itself.\nPaging, as we will see, has a number of advantages over our previou s\napproaches. Probably the most important improvement will be \ufb02exibil-\nity: with a fully-developed paging approach, the system will be ab le to\nsupport the abstraction of an address space effectively , regar dless of how\na process uses the address space; we won\u2019t, for example, make assu mp-\ntions about the direction the heap and stack grow and how they are us ed.\n128\n112\n96\n80\n64\n48\n32\n16\n0\npage frame 7\npage frame 6\npage frame 5\npage frame 4\npage frame 3\npage frame 2\npage frame 1\npage frame 0 of physical memoryreserved for OS\n(unused)\npage 3 of AS\npage 0 of AS\n(unused)\npage 2 of AS\n(unused)\npage 1 of AS\nFigure 18.2: A 64-Byte Address Space In A 128-Byte Physical Memory\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "approaches. Probably the most important improvement will be \ufb02exibil-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches",
          "probably",
          "important",
          "improvement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ity: with a fully-developed paging approach, the system will be ab le to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "fully",
          "developed",
          "paging",
          "approach",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1: A Simple 64-byte Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "simple",
          "byte",
          "address",
          "space"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 2: A 64-Byte Address Space In A 128-Byte Physical Memory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "byte",
          "address",
          "space",
          "byte",
          "physical",
          "memory"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : I N T R O D U C T I O N 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : I N T R O D U C T I O N 3\nAnother advantage is the simplicity of free-space management that pag-\ning affords. For example, when the OS wishes to place our tiny 64- byte\naddress space into our eight-page physical memory , it simply \ufb01 nds four\nfree pages; perhaps the OS keeps a free list of all free pages for this, and\njust grabs the \ufb01rst four free pages off of this list. In the exampl e, the OS\nhas placed virtual page 0 of the address space (AS) in physical f rame 3,\nvirtual page 1 of the AS in physical frame 7, page 2 in frame 5, an d page\n3 in frame 2. Page frames 1, 4, and 6 are currently free.\nT o record where each virtual page of the address space is placed in\nphysical memory , the operating system usually keeps a per-process data\nstructure known as a page table . The major role of the page table is to\nstore address translations for each of the virtual pages of the address\nspace, thus letting us know where in physical memory each page r esides.\nFor our simple example (Figure 18.2, page 2), the page table woul d thus\nhave the following four entries: (Virtual Page 0 \u2192 Physical Frame 3),\n(VP 1 \u2192 PF 7), (VP 2 \u2192 PF 5), and (VP 3 \u2192 PF 2).\nIt is important to remember that this page table is a per-process data\nstructure (most page table structures we discuss are per-proc ess struc-\ntures; an exception we\u2019ll touch on is the inverted page table). If another\nprocess were to run in our example above, the OS would have to manag e\na different page table for it, as its virtual pages obviously map to different\nphysical pages (modulo any sharing going on).\nNow , we know enough to perform an address-translation example.\nLet\u2019s imagine the process with that tiny address space (64 byte s) is per-\nforming a memory access:\nmovl <virtual address>, %eax\nSpeci\ufb01cally , let\u2019s pay attention to the explicit load of the data f rom\naddress <virtual address> into the register eax (and thus ignore the\ninstruction fetch that must have happened prior).\nT o translate this virtual address that the process generated, we have\nto \ufb01rst split it into two components: the virtual page number (VPN), and\nthe offset within the page. For this example, because the virtual addres s\nspace of the process is 64 bytes, we need 6 bits total for our virtual address\n(26 = 64). Thus, our virtual address can be conceptualized as follows:\nVa5 Va4 Va3 Va2 Va1 Va0\nIn this diagram, V a5 is the highest-order bit of the virtual add ress, and\nV a0 the lowest-order bit. Because we know the page size (16 bytes ), we\ncan further divide the virtual address as follows:\nVa5 Va4 Va3 Va2 Va1 Va0\nVPN offset\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "structure known as a page table . The major role of the page table is to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "structure",
          "known",
          "page",
          "table",
          "major",
          "role",
          "page",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "space, thus letting us know where in physical memory each page r esides.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "space",
          "thus",
          "letting",
          "know",
          "physical",
          "memory",
          "page",
          "esides"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "It is important to remember that this page table is a per-process data",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "remember",
          "page",
          "table",
          "process",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Now , we know enough to perform an address-translation example.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "enough",
          "perform",
          "address",
          "translation",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "(26 = 64). Thus, our virtual address can be conceptualized as follows:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "virtual",
          "address",
          "conceptualized",
          "follows"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "V a0 the lowest-order bit. Because we know the page size (16 bytes ), we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lowest",
          "order",
          "know",
          "page",
          "size",
          "bytes"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand forming a memory access: movl <virtual address>, %eax",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "forming a memory access",
          "movl",
          "virtual",
          "address"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 PA G I N G : I N T R O D U C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 PA G I N G : I N T R O D U C T I O N\nThe page size is 16 bytes in a 64-byte address space; thus we ne ed to\nbe able to select 4 pages, and the top 2 bits of the address do just that.\nThus, we have a 2-bit virtual page number (VPN). The remainin g bits tell\nus which byte of the page we are interested in, 4 bits in this cas e; we call\nthis the offset.\nWhen a process generates a virtual address, the OS and hardwar e\nmust combine to translate it into a meaningful physical addre ss. For ex-\nample, let us assume the load above was to virtual address 21:\nmovl 21, %eax\nT urning \u201c21\u201d into binary form, we get \u201c010101\u201d, and thus we can ex-\namine this virtual address and see how it breaks down into a virt ual page\nnumber (VPN) and offset:\n0 1 0 1 0 1\nVPN offset\nThus, the virtual address \u201c21\u201d is on the 5th (\u201c0101\u201dth) byte of v irtual\npage \u201c01\u201d (or 1). With our virtual page number , we can now index our\npage table and \ufb01nd which physical frame virtual page 1 reside s within. In\nthe page table above the physical frame number (PFN) (also sometimes\ncalled the physical page number or PPN) is 7 (binary 111). Thus, we can\ntranslate this virtual address by replacing the VPN with the PFN and then\nissue the load to physical memory (Figure 18.3).\n0 1 0 1 0 1\nVPN offset\n1 1 1 0 1 0 1\nAddress\nTranslation\nPFN offset\nVirtual\nAddress\nPhysical\nAddress\nFigure 18.3: The Address T ranslation Process\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "be able to select 4 pages, and the top 2 bits of the address do just that.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "select",
          "pages",
          "bits",
          "address"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 3: The Address T ranslation Process",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "address",
          "ranslation",
          "process"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "2 Where Are Page T ables Stored?",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "18.2 Where Are Page T ables Stored?\nPage tables can get terribly large, much bigger than the smal l segment\ntable or base/bounds pair we have discussed previously . For exam ple,\nimagine a typical 32-bit address space, with 4KB pages. This virtual ad-\ndress splits into a 20-bit VPN and 12-bit offset (recall that 1 0 bits would\nbe needed for a 1KB page size, and just add two more to get to 4KB).\nA 20-bit VPN implies that there are 220 translations that the OS would\nhave to manage for each process (that\u2019s roughly a million); assumi ng we\nneed 4 bytes per page table entry (PTE) to hold the physical translation\nplus any other useful stuff, we get an immense 4MB of memory neede d\nfor each page table! That is pretty large. Now imagine there are 100\nprocesses running: this means the OS would need 400MB of memory\njust for all those address translations! Even in the modern era, w here\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand this: the OS would need 400MB of memory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this",
          "would",
          "need",
          "memory"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand where are page t ables stored?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "ables",
          "stored"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "3 What\u2019s Actually In The Page T able?",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "18.3 What\u2019s Actually In The Page T able?\nLet\u2019s talk a little about page table organization. The page table is just\na data structure that is used to map virtual addresses (or real ly , virtual\npage numbers) to physical addresses (physical frame number s). Thus,\nany data structure could work. The simplest form is called a linear page\ntable, which is just an array . The OS indexes the array by the virtual page\nnumber (VPN), and looks up the page-table entry (PTE) at that in dex in\norder to \ufb01nd the desired physical frame number (PFN). For now , we will\nassume this simple linear structure; in later chapters, we w ill make use of\nmore advanced data structures to help solve some problems with pa ging.\nAs for the contents of each PTE, we have a number of different bits\nin there worth understanding at some level. A valid bit is common to\nindicate whether the particular translation is valid; for exa mple, when\na program starts running, it will have code and heap at one end of it s\naddress space, and the stack at the other . All the unused space in-between\nwill be marked invalid, and if the process tries to access such memory , it\nwill generate a trap to the OS which will likely terminate the process.\nThus, the valid bit is crucial for supporting a sparse address s pace; by\nsimply marking all the unused pages in the address space inva lid, we\nremove the need to allocate physical frames for those pages and th us save\na great deal of memory .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "more advanced data structures to help solve some problems with pa ging.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "advanced",
          "data",
          "structures",
          "help",
          "solve",
          "problems",
          "ging"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in there worth understanding at some level. A valid bit is common to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "worth",
          "understanding",
          "level",
          "valid",
          "common"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand what\u2019s actually in the page t able?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "actually",
          "page",
          "able"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : I N T R O D U C T I O N 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : I N T R O D U C T I O N 7\n31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\nPFN\nG\nPAT\nD\nA\nPCD\nPWT\nU/S\nR/W\nP\nFigure 18.5: An x86 Page T able Entry (PTE)\nW e also might have protection bits, indicating whether the page could\nbe read from, written to, or executed from. Again, accessing a pag e in a\nway not allowed by these bits will generate a trap to the OS.\nThere are a couple of other bits that are important but we won\u2019t talk\nabout much for now . A present bit indicates whether this page is in phys-\nical memory or on disk (i.e., it has been swapped out ). W e will under-\nstand this machinery further when we study how to swap parts of the\naddress space to disk to support address spaces that are large r than phys-\nical memory; swapping allows the OS to free up physical memory by\nmoving rarely-used pages to disk. A dirty bit is also common, indicating\nwhether the page has been modi\ufb01ed since it was brought into memor y .\nA reference bit (a.k.a. accessed bit) is sometimes used to track whether\na page has been accessed, and is useful in determining which p ages are\npopular and thus should be kept in memory; such knowledge is criti cal\nduring page replacement, a topic we will study in great detail in subse-\nquent chapters.\nFigure 18.5 shows an example page table entry from the x86 archi tec-\nture [I09]. It contains a present bit (P); a read/write bit (R/ W) which\ndetermines if writes are allowed to this page; a user/supervi sor bit (U/S)\nwhich determines if user-mode processes can access the page; a few bits\n(PWT , PCD, P A T , and G) that determine how hardware caching work s for\nthese pages; an accessed bit (A) and a dirty bit (D); and \ufb01nall y , the page\nframe number (PFN) itself.\nRead the Intel Architecture Manuals [I09] for more details on x8 6 pag-\ning support. Be forewarned, however; reading manuals such as th ese,\nwhile quite informative (and certainly necessary for those who write code\nto use such page tables in the OS), can be challenging at \ufb01rst. A little pa-\ntience, and a lot of desire, is required.\nAS I D E : W H Y NO VA L I D BI T ?\nY ou may notice that in the Intel example, there are no separate v alid and\npresent bits, but rather just a present bit (P). If that bit is set (P=1), it\nmeans the page is both present and valid. If not (P=0), it means t hat\nthe page may not be present in memory (but is valid), or may not be\nvalid. An access to a page with P=0 will trigger a trap to the OS; the\nOS must then use additional structures it keeps to determine w hether\nthe page is valid (and thus perhaps should be swapped back in) or not\n(and thus the program is attempting to access memory illegally ). This\nsort of judiciousness is common in hardware, which often just provid e\nthe minimal set of features upon which the OS can build a full ser vice.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "There are a couple of other bits that are important but we won\u2019t talk",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "couple",
          "bits",
          "important",
          "talk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "popular and thus should be kept in memory; such knowledge is criti cal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "popular",
          "thus",
          "kept",
          "memory",
          "knowledge",
          "criti"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand it: the page is both present and valid. If not (P=0), it means t hat",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it",
          "page",
          "present",
          "valid",
          "means"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 5: An x86 Page T able Entry (PTE)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "page",
          "able",
          "entry"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand AS I D E: W H Y NO VA L I D BI T ?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "4 Paging: Also T oo Slow",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "18.4 Paging: Also T oo Slow\nWith page tables in memory , we already know that they might be too\nbig. As it turns out, they can slow things down too. For example, take\nour simple instruction:\nmovl 21, %eax\nAgain, let\u2019s just examine the explicit reference to address 2 1 and not\nworry about the instruction fetch. In this example, we\u2019ll assume the hard-\nware performs the translation for us. T o fetch the desired data, the system\nmust \ufb01rst translate the virtual address (21) into the correct physical ad-\ndress (117). Thus, before fetching the data from address 117, t he system\nmust \ufb01rst fetch the proper page table entry from the process\u2019s pag e table,\nperform the translation, and then load the data from physical mem ory .\nT o do so, the hardware must know where the page table is for the\ncurrently-running process. Let\u2019s assume for now that a single page-table\nbase register contains the physical address of the starting location of the\npage table. T o \ufb01nd the location of the desired PTE, the hardware w ill thus\nperform the following functions:\nVPN = (VirtualAddress & VPN_MASK) >> SHIFT\nPTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))\nIn our example, VPN\nMASK would be set to 0x30 (hex 30, or binary\n110000) which picks out the VPN bits from the full virtual addre ss; SHIFT\nis set to 4 (the number of bits in the offset), such that we move the VPN\nbits down to form the correct integer virtual page number . For exa m-\nple, with virtual address 21 (010101), and masking turns thi s value into\n010000; the shift turns it into 01, or virtual page 1, as desire d. W e then use\nthis value as an index into the array of PTEs pointed to by the pag e table\nbase register .\nOnce this physical address is known, the hardware can fetch th e PTE\nfrom memory , extract the PFN, and concatenate it with the offset f rom the\nvirtual address to form the desired physical address. Speci\ufb01c ally , you can\nthink of the PFN being left-shifted by SHIFT, and then bitwise OR\u2019d with\nthe offset to form the \ufb01nal address as follows:\noffset = VirtualAddress & OFFSET_MASK\nPhysAddr = (PFN << SHIFT) | offset\nFinally , the hardware can fetch the desired data from memory an d put\nit into register eax. The program has now succeeded at loading a value\nfrom memory!\nT o summarize, we now describe the initial protocol for what happen s\non each memory reference. Figure 18.6 (page 9) shows the approach . For\nevery memory reference (whether an instruction fetch or an expl icit load\nor store), paging requires us to perform one extra memory referenc e in\norder to \ufb01rst fetch the translation from the page table. That is a lot of\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "With page tables in memory , we already know that they might be too",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "tables",
          "memory",
          "already",
          "know",
          "might"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T o do so, the hardware must know where the page table is for the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "must",
          "know",
          "page",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Once this physical address is known, the hardware can fetch th e PTE",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "physical",
          "address",
          "known",
          "hardware",
          "fetch"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o summarize, we now describe the initial protocol for what happen s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "summarize",
          "describe",
          "initial",
          "protocol",
          "happen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "on each memory reference. Figure 18.6 (page 9) shows the approach . For",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "reference",
          "figure",
          "page",
          "shows",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand paging: also t oo slow",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "paging",
          "also",
          "slow"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "5 A Memory T race",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "18.5 A Memory T race\nBefore closing, we now trace through a simple memory access exam-\nple to demonstrate all of the resulting memory accesses that occu r when\nusing paging. The code snippet (in C, in a \ufb01le called array.c) that we\nare interested in is as follows:\nint array[1000];\n...\nfor (i = 0; i < 1000; i++)\narray[i] = 0;\nW e compile array.c and run it with the following commands:\nprompt> gcc -o array array.c -Wall -O\nprompt> ./array\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ple to demonstrate all of the resulting memory accesses that occu r when",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "demonstrate",
          "resulting",
          "memory",
          "accesses",
          "occu"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a memory t race",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "race"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 PA G I N G : I N T R O D U C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 PA G I N G : I N T R O D U C T I O N\nOf course, to truly understand what memory accesses this code sn ip-\npet (which simply initializes an array) will make, we\u2019ll have to know (or\nassume) a few more things. First, we\u2019ll have to disassemble the result-\ning binary (using objdump on Linux, or otool on a Mac) to see what\nassembly instructions are used to initialize the array in a loop . Here is the\nresulting assembly code:\n1024 movl $0x0,(%edi,%eax,4)\n1028 incl %eax\n1032 cmpl $0x03e8,%eax\n1036 jne 0x1024\nThe code, if you know a little x86, is actually quite easy to understand 2 .\nThe \ufb01rst instruction moves the value zero (shown as $0x0) into the vir-\ntual memory address of the location of the array; this address is com puted\nby taking the contents of %edi and adding %eax multiplied by four to it.\nThus, %edi holds the base address of the array , whereas %eax holds the\narray index ( i); we multiply by four because the array is an array of inte-\ngers, each of size four bytes.\nThe second instruction increments the array index held in %eax, and\nthe third instruction compares the contents of that register to t he hex\nvalue 0x03e8, or decimal 1000. If the comparison shows that two val-\nues are not yet equal (which is what the jne instruction tests), the fourth\ninstruction jumps back to the top of the loop.\nT o understand which memory accesses this instruction sequenc e makes\n(at both the virtual and physical levels), we\u2019ll have to assume something\nabout where in virtual memory the code snippet and array are found , as\nwell as the contents and location of the page table.\nFor this example, we assume a virtual address space of size 64KB (un-\nrealistically small). W e also assume a page size of 1KB.\nAll we need to know now are the contents of the page table, and its\nlocation in physical memory . Let\u2019s assume we have a linear (array -based)\npage table and that it is located at physical address 1KB (1024 ).\nAs for its contents, there are just a few virtual pages we need to worry\nabout having mapped for this example. First, there is the virtu al page the\ncode lives on. Because the page size is 1KB, virtual address 102 4 resides\non the second page of the virtual address space (VPN=1, as VPN=0 i s\nthe \ufb01rst page). Let\u2019s assume this virtual page maps to physica l frame 4\n(VPN 1 \u2192 PFN 4).\nNext, there is the array itself. Its size is 4000 bytes (1000 i ntegers),\nand we assume that it resides at virtual addresses 40000 throu gh 44000\n(not including the last byte). The virtual pages for this decim al range are\nVPN=39 ... VPN=42. Thus, we need mappings for these pages. Let \u2019s as-\nsume these virtual-to-physical mappings for the example: (VPN 39 \u2192 PFN 7),\n(VPN 40 \u2192 PFN 8), (VPN 41 \u2192 PFN 9), (VPN 42 \u2192 PFN 10).\n2 W e are cheating a little bit here, assuming each instruction is four byt es in size for sim-\nplicity; in actuality , x86 instructions are variable-sized.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Of course, to truly understand what memory accesses this code sn ip-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "truly",
          "understand",
          "memory",
          "accesses",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "pet (which simply initializes an array) will make, we\u2019ll have to know (or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simply",
          "initializes",
          "array",
          "make",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The code, if you know a little x86, is actually quite easy to understand 2 .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "know",
          "little",
          "actually",
          "quite",
          "easy",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "the third instruction compares the contents of that register to t he hex",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "third",
          "instruction",
          "compares",
          "contents",
          "register"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "T o understand which memory accesses this instruction sequenc e makes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "memory",
          "accesses",
          "instruction",
          "sequenc",
          "makes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "All we need to know now are the contents of the page table, and its",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "know",
          "contents",
          "page",
          "table"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : I N T R O D U C T I O N 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : I N T R O D U C T I O N 11\n0 10 20 30 40 50\n1024\n1074\n1124\nMemory Access\nCode (VA)\n40000\n40050\n40100Array (VA)\n1024\n1074\n1124\n1174\n1224\nPage Table (PA)\n4096\n4146\n4196\nCode (PA)\n7232\n7282\n7332\nArray (PA)\nmov\ninc\ncmp\njne\nmov\nPageTable[1]\nPageTable[39]\nFigure 18.7: A Virtual (And Physical) Memory T race\nW e are now ready to trace the memory references of the program.\nWhen it runs, each instruction fetch will generate two memory r eferences:\none to the page table to \ufb01nd the physical frame that the instruc tion resides\nwithin, and one to the instruction itself to fetch it to the CPU f or process-\ning. In addition, there is one explicit memory reference in the f orm of\nthe mov instruction; this adds another page table access \ufb01rst (to tran slate\nthe array virtual address to the correct physical one) and then the array\naccess itself.\nThe entire process, for the \ufb01rst \ufb01ve loop iterations, is depicted i n Fig-\nure 18.7 (page 11). The bottom most graph shows the instruction mem ory\nreferences on the y-axis in black (with virtual addresses on th e left, and\nthe actual physical addresses on the right); the middle graph shows array\naccesses in dark gray (again with virtual on left and physical on right); \ufb01-\nnally , the topmost graph shows page table memory accesses in ligh t gray\n(just physical, as the page table in this example resides in p hysical mem-\nory). The x-axis, for the entire trace, shows memory accesses acr oss the\n\ufb01rst \ufb01ve iterations of the loop; there are 10 memory accesses per loop ,\nwhich includes four instruction fetches, one explicit update of memory ,\nand \ufb01ve page table accesses to translate those four fetches and one explicit\nupdate.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "one to the page table to \ufb01nd the physical frame that the instruc tion resides",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "table",
          "physical",
          "frame",
          "instruc",
          "tion",
          "resides"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 7: A Virtual (And Physical) Memory T race",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "virtual",
          "physical",
          "memory",
          "race"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "18",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "18.6 Summary\nW e have introduced the concept of paging as a solution to our chal-\nlenge of virtualizing memory . Paging has many advantages over p revi-\nous approaches (such as segmentation). First, it does not lead to e xternal\nfragmentation, as paging (by design) divides memory into \ufb01xed -sized\nunits. Second, it is quite \ufb02exible, enabling the sparse use of vi rtual ad-\ndress spaces.\nHowever , implementing paging support without care will lead to a\nslower machine (with many extra memory accesses to access the p age\ntable) as well as memory waste (with memory \ufb01lled with page tabl es in-\nstead of useful application data). W e\u2019ll thus have to think a lit tle harder\nto come up with a paging system that not only works, but works well.\nThe next two chapters, fortunately , will show us how to do so.\n3 W e\u2019re not really sorry . But, we are sorry about not being sorry , i f that makes sense.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have introduced the concept of paging as a solution to our chal-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "introduced",
          "concept",
          "paging",
          "solution",
          "chal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ous approaches (such as segmentation). First, it does not lead to e xternal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches",
          "segmentation",
          "first",
          "lead",
          "xternal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "fragmentation, as paging (by design) divides memory into \ufb01xed -sized",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "fragmentation",
          "paging",
          "design",
          "divides",
          "memory",
          "sized"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "However , implementing paging support without care will lead to a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "however",
          "implementing",
          "paging",
          "support",
          "without",
          "care",
          "lead"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : I N T R O D U C T I O N 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : I N T R O D U C T I O N 13\nReferences\n[KE+62] \u201cOne-level Storage System\u201d by T . Kilburn, D.B.G. Edwards , M.J. Lanigan, F .H. Sum-\nner . IRE T rans. EC-11, 2, 1962. Reprinted in Bell and Newell, \u201cComp uter Structures: Readings\nand Examples\u201d. McGraw-Hill, New Y ork, 1971. The Atlas pioneered the idea of dividing memory\ninto \ufb01xed-sized pages and in many senses was an early form of the memory-managem ent ideas we see\nin modern computer systems.\n[I09] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manuals\u201d Intel, 2009. A vailable:\nhttp://www .intel.com/products/processor/manuals. In particular , pay attention to \u201cV olume\n3A: System Programming Guide Part 1\u201d and \u201cV olume 3B: System Programmin g Guide Part 2\u201d.\n[L78] \u201cThe Manchester Mark I and Atlas: A Historical Perspective\u201d by S. H. L avington. Com-\nmunications of the ACM, V olume 21:1, January 1978. This paper is a great retrospective of some of\nthe history of the development of some important computer systems. As we someti mes forget in the US,\nmany of these new ideas came from overseas.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[I09] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manuals\u201d Intel, 2009. A vailable:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "intel",
          "architectures",
          "software",
          "developer",
          "manuals",
          "intel",
          "vailable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the history of the development of some important computer systems. As we someti mes forget in the US,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "history",
          "development",
          "important",
          "computer",
          "systems",
          "someti",
          "forget"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable: http://www .intel.com/products/processor/manuals. In particular , pay attention to \u201cV olume",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "intel",
          "products",
          "processor",
          "manuals",
          "particular",
          "attention",
          "olume"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 3A: System Programming Guide Part 1\u201d and \u201cV olume 3B: System Programmin g Guide Part 2\u201d.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3a",
          "system",
          "programming",
          "guide",
          "part",
          "olume",
          "system",
          "programmin",
          "guide"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand V olume 21: 1, January 1978. This paper is a great retrospective of some of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 21",
          "january",
          "paper",
          "great",
          "retrospective"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Before doing any translations, let\u2019s use the simulator to study how",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1. Before doing any translations, let\u2019s use the simulator to study how\nlinear page tables change size given different parameters. Compute\nthe size of linear page tables as different parameters change . Some\nsuggested inputs are below; by using the -v flag, you can see\nhow many page-table entries are \ufb01lled. First, to understand h ow\nlinear page table size changes as the address space grows, run with\nthese \ufb02ags:\n-P 1k -a 1m -p 512m -v -n 0\n-P 1k -a 2m -p 512m -v -n 0\n-P 1k -a 4m -p 512m -v -n 0\nThen, to understand how linear page table size changes as page size\ngrows:\n-P 1k -a 1m -p 512m -v -n 0\n-P 2k -a 1m -p 512m -v -n 0\n-P 4k -a 1m -p 512m -v -n 0\nBefore running any of these, try to think about the expected tren ds.\nHow should page-table size change as the address space grows? As\nthe page size grows? Why not use big pages in general?\n2. Now let\u2019s do some translations. Start with some small examples,\nand change the number of pages that are allocated to the address\nspace with the -u flag. For example:\n-P 1k -a 16k -p 32k -v -u 0\n-P 1k -a 16k -p 32k -v -u 25\n-P 1k -a 16k -p 32k -v -u 50\n-P 1k -a 16k -p 32k -v -u 75\n-P 1k -a 16k -p 32k -v -u 100\nWhat happens as you increase the percentage of pages that are al -\nlocated in each address space?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "how many page-table entries are \ufb01lled. First, to understand h ow",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "page",
          "table",
          "entries",
          "first",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Then, to understand how linear page table size changes as page size",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "linear",
          "page",
          "table",
          "size",
          "changes",
          "page",
          "size"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand run with\nthese \ufb02ags: -P 1k -a 1m -p 512m -v -n 0",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "run with\nthese \ufb02ags"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand For example: -P 1k -a 16k -p 32k -v -u 0",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "for example"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand p 1k -a 1m -p 512m -v -n 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand p 1k -a 2m -p 512m -v -n 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand p 1k -a 4m -p 512m -v -n 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand p 2k -a 1m -p 512m -v -n 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand p 4k -a 1m -p 512m -v -n 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Now let\u2019s try some different random seeds, and some different (a nd",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "3. Now let\u2019s try some different random seeds, and some different (a nd\nsometimes quite crazy) address-space parameters, for variet y:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : I N T R O D U C T I O N 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : I N T R O D U C T I O N 15\n-P 8 -a 32 -p 1024 -v -s 1\n-P 8k -a 32k -p 1m -v -s 2\n-P 1m -a 256m -p 512m -v -s 3\nWhich of these parameter combinations are unrealistic? Why?\n4. Use the program to try out some other problems. Can you \ufb01nd the\nlimits of where the program doesn\u2019t work anymore? For example,\nwhat happens if the address-space size is bigger than physical mem-\nory?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand p 8 -a 32 -p 1024 -v -s 1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand p 8k -a 32k -p 1m -v -s 2",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand p 1m -a 256m -p 512m -v -s 3",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "19\nPaging: Faster Translations (TLBs)\nUsing paging as the core mechanism to support virtual memory can lead\nto high performance overheads. By chopping the address space in to small,\n\ufb01xed-sized units (i.e., pages), paging requires a large amou nt of mapping\ninformation. Because that mapping information is generally stor ed in\nphysical memory , paging logically requires an extra memory looku p for\neach virtual address generated by the program. Going to memory f or\ntranslation information before every instruction fetch or explic it load or\nstore is prohibitively slow . And thus our problem:\nTH E CR U X :\nHO W TO SP E E D UP AD D R E S S TR A N S L AT I O N\nHow can we speed up address translation, and generally avoid the\nextra memory reference that paging seems to require? What har dware\nsupport is required? What OS involvement is needed?\nWhen we want to make things fast, the OS usually needs some help .\nAnd help often comes from the OS\u2019s old friend: the hardware. T o speed\naddress translation, we are going to add what is called (for hist orical rea-\nsons [CP78]) a translation-lookaside buffer , or TLB [CG68, C95]. A TLB\nis part of the chip\u2019s memory-management unit (MMU), and is simply a\nhardware cache of popular virtual-to-physical address translations; thus,\na better name would be an address-translation cache . Upon each virtual\nmemory reference, the hardware \ufb01rst checks the TLB to see if th e desired\ntranslation is held therein; if so, the translation is performed (quickly)\nwithout having to consult the page table (which has all translations). Be-\ncause of their tremendous performance impact, TLBs in a real sen se make\nvirtual memory possible [C95].\n1",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 19\nPaging: Faster Translations (TLBs)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "19\npaging",
          "faster",
          "translations",
          "tlbs"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand s old friend: the hardware. T o speed",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s old friend",
          "hardware",
          "speed"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "1 TLB Basic Algorithm",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "19.1 TLB Basic Algorithm\nFigure 19.1 shows a rough sketch of how hardware might handle a\nvirtual address translation, assuming a simple linear page table (i.e., the\npage table is an array) and a hardware-managed TLB (i.e., the hardware\nhandles much of the responsibility of page table accesses; we\u2019ll explain\nmore about this below).\nThe algorithm the hardware follows works like this: \ufb01rst, extrac t the\nvirtual page number (VPN) from the virtual address (Line 1 in F igure 19.1),\nand check if the TLB holds the translation for this VPN (Line 2). I f it does,\nwe have a TLB hit , which means the TLB holds the translation. Success!\nW e can now extract the page frame number (PFN) from the relevant TLB\nentry , concatenate that onto the offset from the original virtual address,\nand form the desired physical address (P A), and access memory ( Lines\n5\u20137), assuming protection checks do not fail (Line 4).\nIf the CPU does not \ufb01nd the translation in the TLB (a TLB miss ), we\nhave some more work to do. In this example, the hardware accesses t he\npage table to \ufb01nd the translation (Lines 11\u201312), and, assumin g that the\nvirtual memory reference generated by the process is valid and accessi-\nble (Lines 13, 15), updates the TLB with the translation (Line 18). These\nset of actions are costly , primarily because of the extra memory re ference\nneeded to access the page table (Line 12). Finally , once the TL B is up-\ndated, the hardware retries the instruction; this time, the t ranslation is\nfound in the TLB, and the memory reference is processed quickly .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "TLB Basic Algorithm",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "handles much of the responsibility of page table accesses; we\u2019ll explain",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "handles",
          "much",
          "responsibility",
          "page",
          "table",
          "accesses",
          "explain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The algorithm the hardware follows works like this: \ufb01rst, extrac t the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "hardware",
          "follows",
          "works",
          "like",
          "extrac"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "page table to \ufb01nd the translation (Lines 11\u201312), and, assumin g that the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "table",
          "translation",
          "lines",
          "assumin"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand which: the TLB holds the translation. Success!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which",
          "holds",
          "translation",
          "success"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand tlb basic algorithm",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "algorithm"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "2 Example: Accessing An Array",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "19.2 Example: Accessing An Array\nT o make clear the operation of a TLB, let\u2019s examine a simple virtua l\naddress trace and see how a TLB can improve its performance. In th is\nexample, let\u2019s assume we have an array of 10 4-byte integers in m emory ,\nstarting at virtual address 100. Assume further that we have a small 8-bit\nvirtual address space, with 16-byte pages; thus, a virtual a ddress breaks\ndown into a 4-bit VPN (there are 16 virtual pages) and a 4-bit off set (there\nare 16 bytes on each of those pages).\nFigure 19.2 (page 4) shows the array laid out on the 16 16-byte pages\nof the system. As you can see, the array\u2019s \ufb01rst entry ( a[0]) begins on\n(VPN=06, offset=04); only three 4-byte integers \ufb01t onto that pa ge. The\narray continues onto the next page (VPN=07), where the next four entries\n(a[3] ... a[6]) are found. Finally , the last three entries of the 10-entry\narray ( a[7] ... a[9]) are located on the next page of the address space\n(VPN=08).\nNow let\u2019s consider a simple loop that accesses each array element,\nsomething that would look like this in C:\nint sum = 0;\nfor (i = 0; i < 10; i++) {\nsum += a[i];\n}\nFor the sake of simplicity , we will pretend that the only memory ac -\ncesses the loop generates are to the array (ignoring the variabl es i and\nsum, as well as the instructions themselves). When the \ufb01rst array element\n(a[0]) is accessed, the CPU will see a load to virtual address 100. Th e\nhardware extracts the VPN from this (VPN=06), and uses that to check\nthe TLB for a valid translation. Assuming this is the \ufb01rst time t he pro-\ngram accesses the array , the result will be a TLB miss.\nThe next access is to a[1], and there is some good news here: a TLB\nhit! Because the second element of the array is packed next to th e \ufb01rst, it\nlives on the same page; because we\u2019ve already accessed this pag e when\naccessing the \ufb01rst element of the array , the translation is alr eady loaded\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand example: accessing an array",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "accessing",
          "array"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 P A G I N G : F A S T E R TR A N S L AT I O N S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 P A G I N G : F A S T E R TR A N S L AT I O N S (TLB S)\nVPN = 15\nVPN = 14\nVPN = 13\nVPN = 12\nVPN = 11\nVPN = 10\nVPN = 09\nVPN = 08\nVPN = 07\nVPN = 06\nVPN = 05\nVPN = 04\nVPN = 03\nVPN = 02\nVPN = 01\nVPN = 00\n00 04 08 12 16\nOffset\na[0] a[1] a[2]\na[3] a[4] a[5] a[6]\na[7] a[8] a[9]\nFigure 19.2: Example: An Array In A Tiny Address Space\ninto the TLB. And hence the reason for our success. Access to a[2] en-\ncounters similar success (another hit), because it too lives on t he same\npage as a[0] and a[1].\nUnfortunately , when the program accesses a[3], we encounter an-\nother TLB miss. However , once again, the next entries ( a[4] ... a[6])\nwill hit in the TLB, as they all reside on the same page in memory .\nFinally , access to a[7] causes one last TLB miss. The hardware once\nagain consults the page table to \ufb01gure out the location of this virt ual page\nin physical memory , and updates the TLB accordingly . The \ufb01nal t wo ac-\ncesses ( a[8] and a[9]) receive the bene\ufb01ts of this TLB update; when the\nhardware looks in the TLB for their translations, two more hits res ult.\nLet us summarize TLB activity during our ten accesses to the ar ray:\nmiss, hit, hit, miss, hit, hit, hit, miss, hit, hit. Thus, our TLB hit rate ,\nwhich is the number of hits divided by the total number of accesse s, is\n70%. Although this is not too high (indeed, we desire hit rates th at ap-\nproach 100%), it is non-zero, which may be a surprise. Even though this\nis the \ufb01rst time the program accesses the array , the TLB improve s per-\nformance due to spatial locality . The elements of the array are packed\ntightly into pages (i.e., they are close to one another in space), and thus\nonly the \ufb01rst access to an element on a page yields a TLB miss.\nAlso note the role that page size plays in this example. If the pa ge size\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "again consults the page table to \ufb01gure out the location of this virt ual page",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consults",
          "page",
          "table",
          "location",
          "virt",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 2: Example: An Array In A Tiny Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "example",
          "array",
          "tiny",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : F A S T E R TR A N S L AT I O N S (TL...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : F A S T E R TR A N S L AT I O N S (TLB S) 5\nTI P : U S E CA C H I N G WH E N PO S S I B L E\nCaching is one of the most fundamental performance techniques in com-\nputer systems, one that is used again and again to make the \u201ccomm on-\ncase fast\u201d [HP06]. The idea behind hardware caches is to take advantage\nof locality in instruction and data references. There are usually two typ es\nof locality: temporal locality and spatial locality . With temporal locality ,\nthe idea is that an instruction or data item that has been recent ly accessed\nwill likely be re-accessed soon in the future. Think of loop variab les or in-\nstructions in a loop; they are accessed repeatedly over time. Wit h spatial\nlocality , the idea is that if a program accesses memory at addres s x, it will\nlikely soon access memory near x. Imagine here streaming through an\narray of some kind, accessing one element and then the next. Of cou rse,\nthese properties depend on the exact nature of the program, and th us are\nnot hard-and-fast laws but more like rules of thumb.\nHardware caches, whether for instructions, data, or address tr anslations\n(as in our TLB) take advantage of locality by keeping copies of memor y in\nsmall, fast on-chip memory . Instead of having to go to a (slow) mem ory\nto satisfy a request, the processor can \ufb01rst check if a nearby cop y exists\nin a cache; if it does, the processor can access it quickly (i.e., in a few\nCPU cycles) and avoid spending the costly time it takes to acces s memory\n(many nanoseconds).\nY ou might be wondering: if caches (like the TLB) are so great, wh y don\u2019t\nwe just make bigger caches and keep all of our data in them? Unfor-\ntunately , this is where we run into more fundamental laws like those of\nphysics. If you want a fast cache, it has to be small, as issues l ike the\nspeed-of-light and other physical constraints become relevant . Any large\ncache by de\ufb01nition is slow , and thus defeats the purpose. Thus, w e are\nstuck with small, fast caches; the question that remains is how to best use\nthem to improve performance.\nhad simply been twice as big (32 bytes, not 16), the array acces s would\nsuffer even fewer misses. As typical page sizes are more like 4 KB, these\ntypes of dense, array-based accesses achieve excellent TLB p erformance,\nencountering only a single miss per page of accesses.\nOne last point about TLB performance: if the program, soon after thi s\nloop completes, accesses the array again, we\u2019d likely see an even bet-\nter result, assuming that we have a big enough TLB to cache the n eeded\ntranslations: hit, hit, hit, hit, hit, hit, hit, hit, hit, hit . In this case, the\nTLB hit rate would be high because of temporal locality , i.e., the quick\nre-referencing of memory items in time. Like any cache, TLBs rely upon\nboth spatial and temporal locality for success, which are program proper-\nties. If the program of interest exhibits such locality (and man y programs\ndo), the TLB hit rate will likely be high.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Caching is one of the most fundamental performance techniques in com-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "caching",
          "fundamental",
          "performance",
          "techniques"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tunately , this is where we run into more fundamental laws like those of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tunately",
          "fundamental",
          "laws",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: U S E CA C H I N G WH E N PO S S I B L E",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "3 Who Handles The TLB Miss?",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "19.3 Who Handles The TLB Miss?\nOne question that we must answer: who handles a TLB miss? T wo an -\nswers are possible: the hardware, or the software (OS). In the olde n days,\nthe hardware had complex instruction sets (sometimes called CISC, for\ncomplex-instruction set computers) and the people who built the hard-\nware didn\u2019t much trust those sneaky OS people. Thus, the hardwar e\nwould handle the TLB miss entirely . T o do this, the hardware ha s to\nknow exactly where the page tables are located in memory (via a page-\ntable base register , used in Line 11 in Figure 19.1), as well as their exact\nformat; on a miss, the hardware would \u201cwalk\u201d the page table, \ufb01nd the cor-\nrect page-table entry and extract the desired translation, u pdate the TLB\nwith the translation, and retry the instruction. An example of a n \u201colder \u201d\narchitecture that has hardware-managed TLBs is the Intel x86 architec-\nture, which uses a \ufb01xed multi-level page table (see the next chapter for\ndetails); the current page table is pointed to by the CR3 regis ter [I09].\nMore modern architectures (e.g., MIPS R10k [H93] or Sun\u2019s SP ARC v9\n[WG00], both RISC or reduced-instruction set computers) have what is\nknown as a software-managed TLB . On a TLB miss, the hardware sim-\nply raises an exception (line 11 in Figure 19.3), which pauses the current\ninstruction stream, raises the privilege level to kernel mode , and jumps\nto a trap handler . As you might guess, this trap handler is code within\nthe OS that is written with the express purpose of handling TLB m isses.\nWhen run, the code will lookup the translation in the page table, u se spe-\ncial \u201cprivileged\u201d instructions to update the TLB, and return from the trap;\nat this point, the hardware retries the instruction (resultin g in a TLB hit).\nLet\u2019s discuss a couple of important details. First, the return-f rom-trap\ninstruction needs to be a little different than the return-fr om-trap we saw\nbefore when servicing a system call. In the latter case, the re turn-from-\ntrap should resume execution at the instruction after the trap into the OS,\njust as a return from a procedure call returns to the instruction imme-\ndiately following the call into the procedure. In the former case , when\nreturning from a TLB miss-handling trap, the hardware must re sume ex-\necution at the instruction that caused the trap; this retry thus lets the in-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "know exactly where the page tables are located in memory (via a page-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "exactly",
          "page",
          "tables",
          "located",
          "memory",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "known as a software-managed TLB . On a TLB miss, the hardware sim-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "software",
          "managed",
          "miss",
          "hardware"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Let\u2019s discuss a couple of important details. First, the return-f rom-trap",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "discuss",
          "couple",
          "important",
          "details",
          "first",
          "return",
          "trap"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand swers are possible: the hardware, or the software (OS). In the olde n days,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "swers are possible",
          "hardware",
          "software",
          "olde",
          "days"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand who handles the tlb miss?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "handles",
          "miss"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : F A S T E R TR A N S L AT I O N S (TL...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : F A S T E R TR A N S L AT I O N S (TLB S) 7\nAS I D E : RISC V S. CISC\nIn the 1980\u2019s, a great battle took place in the computer architect ure com-\nmunity . On one side was the CISC camp, which stood for Complex\nInstruction Set Computing ; on the other side was RISC, for Reduced\nInstruction Set Computing [PS81]. The RISC side was spear-headed by\nDavid Patterson at Berkeley and John Hennessy at Stanford (who ar e also\nco-authors of some famous books [HP06]), although later John Cocke was\nrecognized with a T uring award for his earliest work on RISC [CM00] .\nCISC instruction sets tend to have a lot of instructions in them, an d each\ninstruction is relatively powerful. For example, you might see a string\ncopy , which takes two pointers and a length and copies bytes from s ource\nto destination. The idea behind CISC was that instructions shoul d be\nhigh-level primitives, to make the assembly language itsel f easier to use,\nand to make code more compact.\nRISC instruction sets are exactly the opposite. A key observation b ehind\nRISC is that instruction sets are really compiler targets, and a ll compil-\ners really want are a few simple primitives that they can use t o gener-\nate high-performance code. Thus, RISC proponents argued, let\u2019s ri p out\nas much from the hardware as possible (especially the microcode) , and\nmake what\u2019s left simple, uniform, and fast.\nIn the early days, RISC chips made a huge impact, as they were not iceably\nfaster [BC91]; many papers were written; a few companies were formed\n(e.g., MIPS and Sun). However , as time progressed, CISC manufact urers\nsuch as Intel incorporated many RISC techniques into the core of th eir\nprocessors, for example by adding early pipeline stages that tr ansformed\ncomplex instructions into micro-instructions which could then b e pro-\ncessed in a RISC-like manner . These innovations, plus a growing n umber\nof transistors on each chip, allowed CISC to remain competitive. Th e end\nresult is that the debate died down, and today both types of process ors\ncan be made to run fast.\nstruction run again, this time resulting in a TLB hit. Thus, de pending on\nhow a trap or exception was caused, the hardware must save a diffe rent\nPC when trapping into the OS, in order to resume properly when the time\nto do so arrives.\nSecond, when running the TLB miss-handling code, the OS needs to be\nextra careful not to cause an in\ufb01nite chain of TLB misses to occur . Many\nsolutions exist; for example, you could keep TLB miss handlers in p hysi-\ncal memory (where they are unmapped and not subject to address trans-\nlation), or reserve some entries in the TLB for permanently-vali d transla-\ntions and use some of those permanent translation slots for the handl er\ncode itself; these wired translations always hit in the TLB.\nThe primary advantage of the software-managed approach is \ufb02exibil-\nity: the OS can use any data structure it wants to implement the pa ge\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "such as Intel incorporated many RISC techniques into the core of th eir",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "intel",
          "incorporated",
          "many",
          "risc",
          "techniques",
          "core"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The primary advantage of the software-managed approach is \ufb02exibil-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "primary",
          "advantage",
          "software",
          "managed",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ity: the OS can use any data structure it wants to implement the pa ge",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "data",
          "structure",
          "wants",
          "implement"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "3, in contrast",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "19.3, in contrast\nto lines 11\u201319 in Figure 19.1). The hardware doesn\u2019t do much on a miss:\njust raise an exception and let the OS TLB miss handler do the re st.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": ", in contrast",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand , in contrast",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "contrast"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "19",
    "title": "4 TLB Contents: What\u2019s In There?",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "19.4 TLB Contents: What\u2019s In There?\nLet\u2019s look at the contents of the hardware TLB in more detail. A typic al\nTLB might have 32, 64, or 128 entries and be what is called fully associa-\ntive. Basically , this just means that any given translation can be anywhere\nin the TLB, and that the hardware will search the entire TLB in parallel to\n\ufb01nd the desired translation. A TLB entry might look like this:\nVPN PFN other bits\nNote that both the VPN and PFN are present in each entry , as a tran s-\nlation could end up in any of these locations (in hardware terms, th e TLB\nis known as a fully-associative cache). The hardware searches the entries\nin parallel to see if there is a match.\nMore interesting are the \u201cother bits\u201d. For example, the TLB common ly\nhas a valid bit, which says whether the entry has a valid translation or\nnot. Also common are protection bits, which determine how a page can\nbe accessed (as in the page table). For example, code pages migh t be\nmarked read and execute , whereas heap pages might be marked read and\nwrite. There may also be a few other \ufb01elds, including an address-space\nidenti\ufb01er , a dirty bit , and so forth; see below for more information.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "is known as a fully-associative cache). The hardware searches the entries",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "fully",
          "associative",
          "cache",
          "hardware",
          "searches",
          "entries"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand this just: that any given translation can be anywhere",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this just",
          "given",
          "translation",
          "anywhere"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand tlb contents: what\u2019s in there?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "contents"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "5 TLB Issue: Context Switches",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "19.5 TLB Issue: Context Switches\nWith TLBs, some new issues arise when switching between proces ses\n(and hence address spaces). Speci\ufb01cally , the TLB contains vir tual-to-physical\ntranslations that are only valid for the currently running proce ss; these\ntranslations are not meaningful for other processes. As a result, when\nswitching from one process to another , the hardware or OS (or both) mu st\nbe careful to ensure that the about-to-be-run process does not acc identally\nuse translations from some previously run process.\nT o understand this situation better , let\u2019s look at an example. Wh en one\nprocess (P1) is running, it assumes the TLB might be caching tr anslations\nthat are valid for it, i.e., that come from P1\u2019s page table. Assume , for this\nexample, that the 10th virtual page of P1 is mapped to physical frame 100.\nIn this example, assume another process (P2) exists, and the OS soon\nmight decide to perform a context switch and run it. Assume here that\nthe 10th virtual page of P2 is mapped to physical frame 170. If e ntries for\nboth processes were in the TLB, the contents of the TLB would be:\nVPN PFN valid prot\n10 100 1 rwx\n\u2014 \u2014 0 \u2014\n10 170 1 rwx\n\u2014 \u2014 0 \u2014\nIn the TLB above, we clearly have a problem: VPN 10 translates to\neither PFN 100 (P1) or PFN 170 (P2), but the hardware can\u2019t disti nguish\nwhich entry is meant for which process. Thus, we need to do some mor e\nwork in order for the TLB to correctly and ef\ufb01ciently support virtu aliza-\ntion across multiple processes. And thus, a crux:\nTH E CR U X :\nHO W TO MA N A G E TLB C O N T E N T S ON A C O N T E X T SW I T C H\nWhen context-switching between processes, the translations i n the TLB\nfor the last process are not meaningful to the about-to-be-run proc ess.\nWhat should the hardware or OS do in order to solve this problem?\nThere are a number of possible solutions to this problem. One ap-\nproach is to simply \ufb02ush the TLB on context switches, thus emptying\nit before running the next process. On a software-based system, this\ncan be accomplished with an explicit (and privileged) hardwa re instruc-\ntion; with a hardware-managed TLB, the \ufb02ush could be enacted wh en the\npage-table base register is changed (note the OS must change t he PTBR\non a context switch anyhow). In either case, the \ufb02ush operation sim ply\nsets all valid bits to 0, essentially clearing the contents of t he TLB.\nBy \ufb02ushing the TLB on each context switch, we now have a working\nsolution, as a process will never accidentally encounter the wron g trans-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand this situation better , let\u2019s look at an example. Wh en one",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "situation",
          "better",
          "look",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "What should the hardware or OS do in order to solve this problem?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "order",
          "solve",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "sets all valid bits to 0, essentially clearing the contents of t he TLB.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sets",
          "valid",
          "bits",
          "essentially",
          "clearing",
          "contents"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand tlb issue: context switches",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "issue",
          "context",
          "switches"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 P A G I N G : F A S T E R TR A N S L AT I O N S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 P A G I N G : F A S T E R TR A N S L AT I O N S (TLB S)\nlations in the TLB. However , there is a cost: each time a process ru ns, it\nmust incur TLB misses as it touches its data and code pages. If th e OS\nswitches between processes frequently , this cost may be high.\nT o reduce this overhead, some systems add hardware support to en -\nable sharing of the TLB across context switches. In particular , some hard-\nware systems provide an address space identi\ufb01er (ASID) \ufb01eld in the\nTLB. Y ou can think of the ASID as a process identi\ufb01er (PID), but usu-\nally it has fewer bits (e.g., 8 bits for the ASID versus 32 bits for a PID).\nIf we take our example TLB from above and add ASIDs, it is clear\nprocesses can readily share the TLB: only the ASID \ufb01eld is needed to dif-\nferentiate otherwise identical translations. Here is a depic tion of a TLB\nwith the added ASID \ufb01eld:\nVPN PFN valid prot ASID\n10 100 1 rwx 1\n\u2014 \u2014 0 \u2014 \u2014\n10 170 1 rwx 2\n\u2014 \u2014 0 \u2014 \u2014\nThus, with address-space identi\ufb01ers, the TLB can hold transl ations\nfrom different processes at the same time without any confusion. O f\ncourse, the hardware also needs to know which process is current ly run-\nning in order to perform translations, and thus the OS must, on a con text\nswitch, set some privileged register to the ASID of the current p rocess.\nAs an aside, you may also have thought of another case where two\nentries of the TLB are remarkably similar . In this example, th ere are two\nentries for two different processes with two different VPNs th at point to\nthe same physical page:\nVPN PFN valid prot ASID\n10 101 1 r-x 1\n\u2014 \u2014 0 \u2014 \u2014\n50 101 1 r-x 2\n\u2014 \u2014 0 \u2014 \u2014\nThis situation might arise, for example, when two processes share a\npage (a code page, for example). In the example above, Process 1 is shar-\ning physical page 101 with Process 2; P1 maps this page into the 10th\npage of its address space, whereas P2 maps it to the 50th page of i ts ad-\ndress space. Sharing of code pages (in binaries, or shared librar ies) is\nuseful as it reduces the number of physical pages in use, thus r educing\nmemory overheads.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "course, the hardware also needs to know which process is current ly run-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "hardware",
          "also",
          "needs",
          "know",
          "process",
          "current"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand there is a cost: each time a process ru ns, it",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "there is a cost",
          "time",
          "process"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "6 Issue: Replacement Policy",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "19.6 Issue: Replacement Policy\nAs with any cache, and thus also with the TLB, one more issue that we\nmust consider is cache replacement . Speci\ufb01cally , when we are installing\na new entry in the TLB, we have to replace an old one, and thus the\nquestion: which one to replace?\nTH E CR U X : H O W TO DE S I G N TLB R E P L A C E M E N T PO L I C Y\nWhich TLB entry should be replaced when we add a new TLB entry?\nThe goal, of course, being to minimize the miss rate (or increase hit rate )\nand thus improve performance.\nW e will study such policies in some detail when we tackle the prob lem\nof swapping pages to disk; here we\u2019ll just highlight a few typic al policies.\nOne common approach is to evict the least-recently-used or LRU entry .\nLRU tries to take advantage of locality in the memory-reference stream,\nassuming it is likely that an entry that has not recently been u sed is a good\ncandidate for eviction. Another typical approach is to use a random pol-\nicy , which evicts a TLB mapping at random. Such a policy is useful due\nto its simplicity and ability to avoid corner-case behaviors; f or example,\na \u201creasonable\u201d policy such as LRU behaves quite unreasonably wh en a\nprogram loops over n + 1pages with a TLB of size n; in this case, LRU\nmisses upon every access, whereas random does much better .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The goal, of course, being to minimize the miss rate (or increase hit rate )",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goal",
          "course",
          "minimize",
          "miss",
          "rate",
          "increase",
          "rate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One common approach is to evict the least-recently-used or LRU entry .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "approach",
          "evict",
          "least",
          "recently",
          "used",
          "entry"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "candidate for eviction. Another typical approach is to use a random pol-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "candidate",
          "eviction",
          "another",
          "typical",
          "approach",
          "random"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand and thus the\nquestion: which one to replace?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and thus the\nquestion",
          "replace"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand issue: replacement policy",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "issue",
          "replacement",
          "policy"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "19",
    "title": "7 A Real TLB Entry",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "19.7 A Real TLB Entry\nFinally , let\u2019s brie\ufb02y look at a real TLB. This example is from the M IPS\nR4000 [H93], a modern system that uses software-managed TLBs; a slightly\nsimpli\ufb01ed MIPS TLB entry can be seen in Figure 19.4.\nThe MIPS R4000 supports a 32-bit address space with 4KB pages. Thus,\nwe would expect a 20-bit VPN and 12-bit offset in our typical virt ual ad-\ndress. However , as you can see in the TLB, there are only 19 bits for the\nVPN; as it turns out, user addresses will only come from half the ad dress\nspace (the rest reserved for the kernel) and hence only 19 bits of VPN\nare needed. The VPN translates to up to a 24-bit physical fram e number\n(PFN), and hence can support systems with up to 64GB of (physica l) main\nmemory ( 224 4KB pages).\nThere are a few other interesting bits in the MIPS TLB. W e see a global\nbit (G), which is used for pages that are globally-shared among p rocesses.\nThus, if the global bit is set, the ASID is ignored. W e also see the 8-bit\nASID, which the OS can use to distinguish between address spaces ( as\n0\n0\n0\n1\n0\n2\n0\n3\n0\n4\n0\n5\n0\n6\n0\n7\n0\n8\n0\n9\n1\n0\n1\n1\n1\n2\n1\n3\n1\n4\n1\n5\n1\n6\n1\n7\n1\n8\n1\n9\n2\n0\n2\n1\n2\n2\n2\n3\n2\n4\n2\n5\n2\n6\n2\n7\n2\n8\n2\n9\n3\n0\n3\n1\nVPN G ASID\nPFN C D V\nFigure 19.4: A MIPS TLB Entry\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand a real tlb entry",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "real",
          "entry"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "19",
    "title": "8 Summary",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "19.8 Summary\nW e have seen how hardware can help us make address translation\nfaster . By providing a small, dedicated on-chip TLB as an addre ss-translation\ncache, most memory references will hopefully be handled without having\nto access the page table in main memory . Thus, in the common case,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : F A S T E R TR A N S L AT I O N S (TL...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : F A S T E R TR A N S L AT I O N S (TLB S) 13\nthe performance of the program will be almost as if memory isn\u2019t bein g\nvirtualized at all, an excellent achievement for an operating system, and\ncertainly essential to the use of paging in modern systems.\nHowever , TLBs do not make the world rosy for every program that\nexists. In particular , if the number of pages a program accesse s in a short\nperiod of time exceeds the number of pages that \ufb01t into the TLB, th e pro-\ngram will generate a large number of TLB misses, and thus run qu ite a\nbit more slowly . W e refer to this phenomenon as exceeding the TLB cov-\nerage, and it can be quite a problem for certain programs. One solution,\nas we\u2019ll discuss in the next chapter , is to include support for la rger page\nsizes; by mapping key data structures into regions of the progra m\u2019s ad-\ndress space that are mapped by larger pages, the effective cov erage of the\nTLB can be increased. Support for large pages is often exploited by pro-\ngrams such as a database management system (a DBMS), which have\ncertain data structures that are both large and randomly-acce ssed.\nOne other TLB issue worth mentioning: TLB access can easily be-\ncome a bottleneck in the CPU pipeline, in particular with what i s called a\nphysically-indexed cache . With such a cache, address translation has to\ntake place before the cache is accessed, which can slow things down quite\na bit. Because of this potential problem, people have looked into al l sorts\nof clever ways to access caches with virtual addresses, thus avoiding the\nexpensive step of translation in the case of a cache hit. Such a virtually-\nindexed cache solves some performance problems, but introduces new\nissues into hardware design as well. See Wiggins\u2019s \ufb01ne survey f or more\ndetails [W03].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "certainly essential to the use of paging in modern systems.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "certainly",
          "essential",
          "paging",
          "modern",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "indexed cache solves some performance problems, but introduces new",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "indexed",
          "cache",
          "solves",
          "performance",
          "problems",
          "introduces"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "issues into hardware design as well. See Wiggins\u2019s \ufb01ne survey f or more",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "issues",
          "hardware",
          "design",
          "well",
          "wiggins",
          "survey"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 P A G I N G : F A S T E R TR A N S L AT I O N S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 P A G I N G : F A S T E R TR A N S L AT I O N S (TLB S)\nReferences\n[BC91] \u201cPerformance from Architecture: Comparing a RISC and a CISC with S imilar Hard-\nware Organization\u201d by D. Bhandarkar and Douglas W . Clark. Communicat ions of the ACM,\nSeptember 1991. A great and fair comparison between RISC and CISC. The bottom line: on similar\nhardware, RISC was about a factor of three better in performance.\n[CM00] \u201cThe evolution of RISC technology at IBM\u201d by John Cocke, V . Markstei n. IBM Journal\nof Research and Development, 44:1/2. A summary of the ideas and work behind the IBM 801, which\nmany consider the \ufb01rst true RISC microprocessor .\n[C95] \u201cThe Core of the Black Canyon Computer Corporation\u201d by John Coule ur . IEEE Annals\nof History of Computing, 17:4, 1995. In this fascinating historical note, Couleur talks about how he\ninvented the TLB in 1964 while working for GE, and the fortuitous collaboration th at thus ensued with\nthe Project MAC folks at MIT .\n[CG68] \u201cShared-access Data Processing System\u201d by John F . Couleur , Edwa rd L. Glaser . Patent\n3412382, November 1968. The patent that contains the idea for an associative memory to store address\ntranslations. The idea, according to Couleur , came in 1964.\n[CP78] \u201cThe architecture of the IBM System/370\u201d by R.P . Case, A. Padegs . Communications of\nthe ACM. 21:1, 73-96, January 1978. Perhaps the \ufb01rst paper to use the term translation lookaside\nbuffer. The name arises from the historical name for a cache, which was a lookaside buffer as called by\nthose developing the Atlas system at the University of Manchester; a cache of ad dress translations thus\nbecame a translation lookaside buffer. Even though the term lookaside buffer fell out of favor , TLB\nseems to have stuck, for whatever reason.\n[H93] \u201cMIPS R4000 Microprocessor User \u2019s Manual\u201d. by Joe Heinrich. Prentice-H all, June 1993.\nA vailable: http://cag.csail.mit.edu/raw/ . documents/R4400\nUman book Ed2.pdf A manual,\none that is surprisingly readable. Or is it?\n[HP06] \u201cComputer Architecture: A Quantitative Approach\u201d by John Hennessy and David Pat-\nterson. Morgan-Kaufmann, 2006. A great book about computer architecture. We have a particular\nattachment to the classic \ufb01rst edition.\n[I09] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manuals\u201d by Intel, 2009. A vail-\nable: http://www .intel.com/products/processor/manuals. In particular , pay attention to \u201cV ol-\nume 3A: System Programming Guide\u201d Part 1 and \u201cV olume 3B: System Programming Guide Part\n2\u201d.\n[PS81] \u201cRISC-I: A Reduced Instruction Set VLSI Computer \u201d by D.A. Pat terson and C.H. Se-\nquin. ISCA \u201981, Minneapolis, May 1981. The paper that introduced the term RISC, and started the\navalanche of research into simplifying computer chips for performance.\n[SB92] \u201cCPU Performance Evaluation and Execution Time Prediction Using Narrow Spectrum\nBenchmarking\u201d by Rafael H. Saavedra-Barrera. EECS Department, Univ ersity of California,\nBerkeley . T echnical Report No. UCB/CSD-92-684, February 1992.. A great dissertation about how\nto predict execution time of applications by breaking them down into constituen t pieces and knowing the\ncost of each piece. Probably the most interesting part that comes out of this work is the tool to measure\ndetails of the cache hierarchy (described in Chapter 5). Make sure to check ou t the wonderful diagrams\ntherein.\n[W03] \u201cA Survey on the Interaction Between Caching, T ranslation and Pro tection\u201d by Adam\nWiggins. University of New South W ales TR UNSW-CSE-TR-0321, August , 2003. An excellent\nsurvey of how TLBs interact with other parts of the CPU pipeline, namely hard ware caches.\n[WG00] \u201cThe SP ARC Architecture Manual: V ersion 9\u201d by David L. W eaver a nd T om Germond.\nSP ARC International, San Jose, California, September 2000. A vail able: www.sparc.org/\nstandards/SPARCV9.pdf. Another manual. I bet you were hoping for a more fun citation to\nend this chapter .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "of Research and Development, 44:1/2. A summary of the ideas and work behind the IBM 801, which",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "research",
          "development",
          "summary",
          "ideas",
          "work",
          "behind"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "those developing the Atlas system at the University of Manchester; a cache of ad dress translations thus",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developing",
          "atlas",
          "system",
          "university",
          "manchester",
          "cache",
          "dress",
          "translations"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[HP06] \u201cComputer Architecture: A Quantitative Approach\u201d by John Hennessy and David Pat-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "computer",
          "architecture",
          "quantitative",
          "approach",
          "john",
          "hennessy",
          "david"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[I09] \u201cIntel 64 and IA-32 Architectures Software Developer \u2019s Manuals\u201d by Intel, 2009. A vail-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "intel",
          "architectures",
          "software",
          "developer",
          "manuals",
          "intel",
          "vail"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "to predict execution time of applications by breaking them down into constituen t pieces and knowing the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "predict",
          "execution",
          "time",
          "applications",
          "breaking",
          "constituen",
          "pieces",
          "knowing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "details of the cache hierarchy (described in Chapter 5). Make sure to check ou t the wonderful diagrams",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "details",
          "cache",
          "hierarchy",
          "described",
          "chapter",
          "make",
          "sure",
          "check"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Performance from Architecture: Comparing a RISC and a CISC with S imilar Hard-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "performance from architecture",
          "comparing",
          "risc",
          "cisc",
          "imilar",
          "hard"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 44: 1/2. A summary of the ideas and work behind the IBM 801, which",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "44",
          "summary",
          "ideas",
          "work",
          "behind"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 17: 4, 1995. In this fascinating historical note, Couleur talks about how he",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "17",
          "fascinating",
          "historical",
          "note",
          "couleur",
          "talks"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 21: 1, 73-96, January 1978. Perhaps the \ufb01rst paper to use the term translation lookaside",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "21",
          "january",
          "perhaps",
          "paper",
          "term",
          "translation",
          "lookaside"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand A vailable: http://cag.csail.mit.edu/raw/ . documents/R4400",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "csail",
          "documents"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand able: http://www .intel.com/products/processor/manuals. In particular , pay attention to \u201cV ol-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "http",
          "intel",
          "products",
          "processor",
          "manuals",
          "particular",
          "attention"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand ume 3A: System Programming Guide\u201d Part 1 and \u201cV olume 3B: System Programming Guide Part",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ume 3a",
          "system",
          "programming",
          "guide",
          "part",
          "olume",
          "system",
          "programming",
          "guide"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : F A S T E R TR A N S L AT I O N S (TL...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : F A S T E R TR A N S L AT I O N S (TLB S) 15\nHomework (Measurement)\nIn this homework, you are to measure the size and cost of accessing\na TLB. The idea is based on work by Saavedra-Barrera [SB92], who de -\nveloped a simple but beautiful method to measure numerous aspec ts of\ncache hierarchies, all with a very simple user-level program . Read his\nwork for more details.\nThe basic idea is to access some number of pages within a large da ta\nstructure (e.g., an array) and to time those accesses. For exam ple, let\u2019s say\nthe TLB size of a machine happens to be 4 (which would be very smal l,\nbut useful for the purposes of this discussion). If you write a progr am\nthat touches 4 or fewer pages, each access should be a TLB hit, and thus\nrelatively fast. However , once you touch 5 pages or more, repeatedl y in a\nloop, each access will suddenly jump in cost, to that of a TLB miss.\nThe basic code to loop through an array once should look like this:\nint jump = PAGESIZE / sizeof(int);\nfor (i = 0; i < NUMPAGES * jump; i += jump)\na[i] += 1;\nIn this loop, one integer per page of the array a is updated, up to the\nnumber of pages speci\ufb01ed by NUMPAGES. By timing such a loop repeat-\nedly (say , a few hundred million times in another loop around this on e, or\nhowever many loops are needed to run for a few seconds), you can time\nhow long each access takes (on average). By looking for jumps in cost a s\nNUMPAGES increases, you can roughly determine how big the \ufb01rst-level\nTLB is, determine whether a second-level TLB exists (and how bi g it is if\nit does), and in general get a good sense of how TLB hits and misses ca n\naffect performance.\n1 4 16 64 256 1024\n0\n20\n40\n60\n80\nTLB Size Measurement\nNumber Of Pages\nTime Per Access (ns)\nFigure 19.5: Discovering TLB Sizes and Miss Costs\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "veloped a simple but beautiful method to measure numerous aspec ts of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "veloped",
          "simple",
          "beautiful",
          "method",
          "measure",
          "numerous",
          "aspec"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 5: Discovering TLB Sizes and Miss Costs",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "discovering",
          "sizes",
          "miss",
          "costs"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "3",
    "title": "Now write a script in your favorite scripting language (bash? ) to",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "3. Now write a script in your favorite scripting language (bash? ) to\nrun this program, while varying the number of pages accessed fr om\n1 up to a few thousand, perhaps incrementing by a factor of two\nper iteration. Run the script on different machines and gather some\ndata. How many trials are needed to get reliable measurements ?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Next, graph the results, making a graph that looks similar to the",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "4. Next, graph the results, making a graph that looks similar to the\none above. Use a good tool like ploticus or even zplot. Visual-\nization usually makes the data much easier to digest; why do you\nthink that is?\n5. One thing to watch out for is compiler optimization. Compilers\ndo all sorts of clever things, including removing loops which incr e-\nment values that no other part of the program subsequently uses.\nHow can you ensure the compiler does not remove the main loop\nabove from your TLB size estimator?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "6",
    "title": "Another thing to watch out for is the fact that most systems today",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "6. Another thing to watch out for is the fact that most systems today\nship with multiple CPUs, and each CPU, of course, has its own TLB\nhierarchy . T o really get good measurements, you have to run your\ncode on just one CPU, instead of letting the scheduler bounce it\nfrom one CPU to the next. How can you do that? (hint: look up\n\u201cpinning a thread\u201d on Google for some clues) What will happen if\nyou don\u2019t do this, and the code moves from one CPU to the other?\n7. Another issue that might arise relates to initialization. I f you don\u2019t\ninitialize the array a above before accessing it, the \ufb01rst time you\naccess it will be very expensive, due to initial access costs s uch as\ndemand zeroing. Will this affect your code and its timing? What\ncan you do to counterbalance these potential costs?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "20",
    "title": "1 Simple Solution: Bigger Pages",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "20.1 Simple Solution: Bigger Pages\nW e could reduce the size of the page table in one simple way: use\nbigger pages. T ake our 32-bit address space again, but this ti me assume\n16KB pages. W e would thus have an 18-bit VPN plus a 14-bit offset . As-\nsuming the same size for each PTE (4 bytes), we now have 218 entries in\nour linear page table and thus a total size of 1MB per page table, a factor\n1 Or indeed, you might not; this paging thing is getting out of control, no? That said,\nalways make sure you understand the problem you are solving before moving onto the solution;\nindeed, if you understand the problem, you can often derive the solut ion yourself. Here, the\nproblem should be clear: simple linear (array-based) page tables are too big.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "always make sure you understand the problem you are solving before moving onto the solution;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "always",
          "make",
          "sure",
          "understand",
          "problem",
          "solving",
          "moving",
          "onto"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "indeed, if you understand the problem, you can often derive the solut ion yourself. Here, the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "indeed",
          "understand",
          "problem",
          "often",
          "derive",
          "solut"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand simple solution: bigger pages",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "solution",
          "bigger",
          "pages"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "20",
    "title": "2 Hybrid Approach: Paging and Segments",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "20.2 Hybrid Approach: Paging and Segments\nWhenever you have two reasonable but different approaches to som e-\nthing in life, you should always examine the combination of the two to\nsee if you can obtain the best of both worlds. W e call such a combinati on a\nhybrid. For example, why eat just chocolate or plain peanut butter when\nyou can instead combine the two in a lovely hybrid known as the Rees e\u2019s\nPeanut Butter Cup [M28]?\nY ears ago, the creators of Multics (in particular Jack Dennis) c hanced\nupon such an idea in the construction of the Multics virtual memory sys-\ntem [M07]. Speci\ufb01cally , Dennis had the idea of combining paging and\nsegmentation in order to reduce the memory overhead of page tables .\nW e can see why this might work by examining a typical linear pag e ta-\nble in more detail. Assume we have an address space in which the used\nportions of the heap and stack are small. For the example, we use a t iny\n16KB address space with 1KB pages (Figure",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Hybrid Approach: Paging and Segments",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hybrid",
          "approach",
          "paging",
          "segments"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Whenever you have two reasonable but different approaches to som e-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "whenever",
          "reasonable",
          "different",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "you can instead combine the two in a lovely hybrid known as the Rees e\u2019s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "instead",
          "combine",
          "lovely",
          "hybrid",
          "known",
          "rees"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "20",
    "title": "1); the page table for this",
    "document_source": "book.pdf",
    "start_line": 41,
    "type": "chapter",
    "content": "20.1); the page table for this\naddress space is in Figure 20.2.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand ); the page table for this",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "table"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : S M A L L E R TA B L E S 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : S M A L L E R TA B L E S 3\ncode\nheap\nstack\nVirtual Address Space Physical Memory\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\nFigure 20.1: A 16KB Address Space With 1KB Pages\nPFN valid prot present dirty\n10 1 r-x 1 0\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n23 1 rw- 1 1\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n- 0 \u2014 - -\n28 1 rw- 1 1\n4 1 rw- 1 1\nFigure 20.2: A Page T able For 16KB Address Space\nThis example assumes the single code page (VPN 0) is mapped to\nphysical page 10, the single heap page (VPN 4) to physical pag e 23, and\nthe two stack pages at the other end of the address space (VPNs 14 and\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 1: A 16KB Address Space With 1KB Pages",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "address",
          "space",
          "pages"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2: A Page T able For 16KB Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "page",
          "able",
          "address",
          "space"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand 0 \u2014 - -",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 PA G I N G : S M A L L E R TA B L E S\n15) are mapped to physical pages 28 and 4, respectively . As you can see\nfrom the picture, most of the page table is unused, full of invalid entries.\nWhat a waste! And this is for a tiny 16KB address space. Imagine the\npage table of a 32-bit address space and all the potential waste d space in\nthere! Actually , don\u2019t imagine such a thing; it\u2019s far too gruesome .\nThus, our hybrid approach: instead of having a single page table for\nthe entire address space of the process, why not have one per logica l seg-\nment? In this example, we might thus have three page tables, on e for the\ncode, heap, and stack parts of the address space.\nNow , remember with segmentation, we had a base register that told\nus where each segment lived in physical memory , and a bound or limit\nregister that told us the size of said segment. In our hybrid, we s till have\nthose structures in the MMU; here, we use the base not to point to t he\nsegment itself but rather to hold the physical address of the page table of that\nsegment. The bounds register is used to indicate the end of the p age table\n(i.e., how many valid pages it has).\nLet\u2019s do a simple example to clarify . Assume a 32-bit virtual a ddress\nspace with 4KB pages, and an address space split into four segm ents.\nW e\u2019ll only use three segments for this example: one for code, one for\nheap, and one for stack.\nT o determine which segment an address refers to, we\u2019ll use the t op\ntwo bits of the address space. Let\u2019s assume 00 is the unused segm ent,\nwith 01 for code, 10 for the heap, and 11 for the stack. Thus, a virtu al\naddress looks like this:\n3\n1 3\n0 2\n9 2\n8 2\n7 2\n6 2\n5 2\n4 2\n3 2\n2 2\n1 2\n0 1\n9 1\n8 1\n7 1\n6 1\n5 1\n4 1\n3 1\n2 1\n1 1\n0 0\n9 0\n8 0\n7 0\n6 0\n5 0\n4 0\n3 0\n2 0\n1 0\n0\nSeg VPN Offset\nIn the hardware, assume that there are thus three base/bounds pairs,\none each for code, heap, and stack. When a process is running, the b ase\nregister for each of these segments contains the physical addre ss of a lin-\near page table for that segment; thus, each process in the syste m now has\nthree page tables associated with it. On a context switch, these regi sters\nmust be changed to re\ufb02ect the location of the page tables of the new ly-\nrunning process.\nOn a TLB miss (assuming a hardware-managed TLB, i.e., where t he\nhardware is responsible for handling TLB misses), the hardwar e uses the\nsegment bits ( SN) to determine which base and bounds pair to use. The\nhardware then takes the physical address therein and combine s it with\nthe VPN as follows to form the address of the page table entry (PTE) :\nSN = (VirtualAddress & SEG_MASK) >> SN_SHIFT\nVPN = (VirtualAddress & VPN_MASK) >> VPN_SHIFT\nAddressOfPTE = Base[SN] + (VPN * sizeof(PTE))\nThis sequence should look familiar; it is virtually identical t o what we\nsaw before with linear page tables. The only difference, of cours e, is the\nuse of one of three segment base registers instead of the single pa ge table\nbase register .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus, our hybrid approach: instead of having a single page table for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "hybrid",
          "approach",
          "instead",
          "single",
          "page",
          "table"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "20",
    "title": "3 Multi-level Page T ables",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "20.3 Multi-level Page T ables\nA different approach doesn\u2019t rely on segmentation but attacks the same\nproblem: how to get rid of all those invalid regions in the page tabl e in-\nstead of keeping them all in memory? W e call this approach a multi-level\npage table, as it turns the linear page table into something like a tree. T his\napproach is so effective that many modern systems employ it (e.g ., x86\n[BOH10]). W e now describe this approach in detail.\nThe basic idea behind a multi-level page table is simple. Fir st, chop up\nthe page table into page-sized units; then, if an entire page of page-table\nentries (PTEs) is invalid, don\u2019t allocate that page of the page ta ble at all.\nT o track whether a page of the page table is valid (and if valid, where it\nis in memory), use a new structure, called the page directory. The page\ndirectory thus either can be used to tell you where a page of the pa ge\ntable is, or that the entire page of the page table contains no val id pages.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A different approach doesn\u2019t rely on segmentation but attacks the same",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "approach",
          "rely",
          "segmentation",
          "attacks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "stead of keeping them all in memory? W e call this approach a multi-level",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "stead",
          "keeping",
          "memory",
          "call",
          "approach",
          "multi",
          "level"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "approach is so effective that many modern systems employ it (e.g ., x86",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "effective",
          "many",
          "modern",
          "systems",
          "employ"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[BOH10]). W e now describe this approach in detail.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describe",
          "approach",
          "detail"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand multi-level page t ables",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "multi",
          "level",
          "page",
          "ables"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 PA G I N G : S M A L L E R TA B L E S\nvalid\nprotPFN\n1 rx 12\n1 rx 13\n0 - -\n1 rw 100\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n0 - -\n1 rw 86\n1 rw 15\nLinear Page Table\nPTBR 201\nPFN 201PFN 202PFN 203PFN 204\nvalid\nprotPFN\n1 rx 12\n1 rx 13\n0 - -\n1 rw 100\n0 - -\n0 - -\n1 rw 86\n1 rw 15\n[Page 1 of PT: Not Allocated]\n[Page 2 of PT: Not Allocated]\nPFN 201PFN 204\nMulti-level Page Table\nPDBR 200\nvalid PFN\n1 201\n0 -\n0 -\n1 204\nPFN 200\nThe Page Directory\nFigure 20.3: Linear (Left) And Multi-Level (Right) Page T ables\nFigure 20.3 shows an example. On the left of the \ufb01gure is the classic\nlinear page table; even though most of the middle regions of the add ress\nspace are not valid, we still require page-table space allocat ed for those\nregions (i.e., the middle two pages of the page table). On the ri ght is a\nmulti-level page table. The page directory marks just two pag es of the\npage table as valid (the \ufb01rst and last); thus, just those two pa ges of the\npage table reside in memory . And thus you can see one way to visual ize\nwhat a multi-level table is doing: it just makes parts of the lin ear page\ntable disappear (freeing those frames for other uses), and trac ks which\npages of the page table are allocated with the page directory .\nThe page directory , in a simple two-level table, contains one ent ry per\npage of the page table. It consists of a number of page directory entries\n(PDE). A PDE (minimally) has a valid bit and a page frame number\n(PFN), similar to a PTE. However , as hinted at above, the meanin g of\nthis valid bit is slightly different: if the PDE is valid, it m eans that at least\none of the pages of the page table that the entry points to (via the P FN)\nis valid, i.e., in at least one PTE on that page pointed to by this P DE, the\nvalid bit in that PTE is set to one. If the PDE is not valid (i.e., e qual to\nzero), the rest of the PDE is not de\ufb01ned.\nMulti-level page tables have some obvious advantages over approa ches\nwe\u2019ve seen thus far . First, and perhaps most obviously , the multi -level ta-\nble only allocates page-table space in proportion to the amount of ad dress\nspace you are using; thus it is generally compact and supports sp arse ad-\ndress spaces.\nSecond, if carefully constructed, each portion of the page table \ufb01t s\nneatly within a page, making it easier to manage memory; the OS can\nsimply grab the next free page when it needs to allocate or grow a p age\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_4",
        "text": "understand 3: Linear (Left) And Multi-Level (Right) Page T ables",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "linear",
          "left",
          "multi",
          "level",
          "right",
          "page",
          "ables"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand level table is doing: it just makes parts of the lin ear page",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "level table is doing",
          "makes",
          "parts",
          "page"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "20",
    "title": "4 (page 8)",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "20.4 (page 8)\npresents one example of such an address space.\nIn this example, virtual pages 0 and 1 are for code, virtual page s 4 and\n5 for the heap, and virtual pages 254 and 255 for the stack; the re st of the\npages of the address space are unused.\nT o build a two-level page table for this address space, we start with\nour full linear page table and break it up into page-sized unit s. Recall our\nfull table (in this example) has 256 entries; assume each PTE is 4 bytes\n2 W e are making some assumptions here, i.e., that all page tables re side in their entirety in\nphysical memory (i.e., they are not swapped to disk); we\u2019ll soon rel ax this assumption.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand (page 8)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 PA G I N G : S M A L L E R TA B L E S\nstack\nstack\n(free)\n(free)\n... all free ...\n(free)\n(free)\nheap\nheap\n(free)\n(free)\ncode\ncode\n1111 1111\n1111 1110\n1111 1101\n1111 1100\n0000 0111\n0000 0110\n0000 0101\n0000 0100\n0000 0011\n0000 0010\n0000 0001\n0000 0000\n................\nFigure 20.4: A 16KB Address Space With 64-byte Pages\nin size. Thus, our page table is 1KB (256 \u00d7 4 bytes) in size. Given that\nwe have 64-byte pages, the 1KB page table can be divided into 1 6 64-byte\npages; each page can hold 16 PTEs.\nWhat we need to understand now is how to take a VPN and use it to\nindex \ufb01rst into the page directory and then into the page of the p age table.\nRemember that each is an array of entries; thus, all we need to \ufb01 gure out\nis how to construct the index for each from pieces of the VPN.\nLet\u2019s \ufb01rst index into the page directory . Our page table in this example\nis small: 256 entries, spread across 16 pages. The page direct ory needs one\nentry per page of the page table; thus, it has 16 entries. As a re sult, we\nneed four bits of the VPN to index into the directory; we use the top four\nbits of the VPN, as follows:\n13 12 11 10 9 8 7 6 5 4 3 2 1 0\nVPN offset\nPage Directory Index\nOnce we extract the page-directory index (PDIndex for short) from\nthe VPN, we can use it to \ufb01nd the address of the page-directory en try\n(PDE) with a simple calculation: PDEAddr = PageDirBase + (PDIndex\n* sizeof(PDE)). This results in our page directory , which we now ex-\namine to make further progress in our translation.\nIf the page-directory entry is marked invalid, we know that the access\nis invalid, and thus raise an exception. If, however , the PDE is valid,\nwe have more work to do. Speci\ufb01cally , we now have to fetch the page-\ntable entry (PTE) from the page of the page table pointed to by thi s page-\ndirectory entry . T o \ufb01nd this PTE, we have to index into the porti on of the\npage table using the remaining bits of the VPN:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "What we need to understand now is how to take a VPN and use it to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "understand",
          "take"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "If the page-directory entry is marked invalid, we know that the access",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "directory",
          "entry",
          "marked",
          "invalid",
          "know",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 4: A 16KB Address Space With 64-byte Pages",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "address",
          "space",
          "byte",
          "pages"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand as follows: 13 12 11 10 9 8 7 6 5 4 3 2 1 0",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as follows"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand with a simple calculation: PDEAddr = PageDirBase + (PDIndex",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "with a simple calculation",
          "pdeaddr",
          "pagedirbase",
          "pdindex"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand sizeof(pde)). this results in our page directory , which we now ex-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "sizeof",
          "results",
          "page",
          "directory"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : S M A L L E R TA B L E S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : S M A L L E R TA B L E S 9\n13 12 11 10 9 8 7 6 5 4 3 2 1 0\nVPN offset\nPage Directory Index Page Table Index\nThis page-table index (PTIndex for short) can then be used to index\ninto the page table itself, giving us the address of our PTE:\nPTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))\nNote that the page-frame number (PFN) obtained from the page-di rectory\nentry must be left-shifted into place before combining it with the page-\ntable index to form the address of the PTE.\nT o see if this all makes sense, we\u2019ll now \ufb01ll in a multi-level pag e ta-\nble with some actual values, and translate a single virtual ad dress. Let\u2019s\nbegin with the page directory for this example (left side of Figure\n20.5).\nIn the \ufb01gure, you can see that each page directory entry (PDE) de -\nscribes something about a page of the page table for the address sp ace.\nIn this example, we have two valid regions in the address space (at the\nbeginning and end), and a number of invalid mappings in-betwe en.\nIn physical page 100 (the physical frame number of the 0th page of the\npage table), we have the \ufb01rst page of 16 page table entries for th e \ufb01rst 16\nVPNs in the address space. See Figure 20.5 (middle part) for the contents\nof this portion of the page table.\nThis page of the page table contains the mappings for the \ufb01rst 16\nVPNs; in our example, VPNs 0 and 1 are valid (the code segment), a s\nPage Directory Page of PT (@PFN:100) Page of PT (@PFN:101)\nPFN valid? PFN valid prot PFN valid prot\n100 1 10 1 r-x \u2014 0 \u2014\n\u2014 0 23 1 r-x \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 80 1 rw- \u2014 0 \u2014\n\u2014 0 59 1 rw- \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 \u2014 0 \u2014\n\u2014 0 \u2014 0 \u2014 55 1 rw-\n101 1 \u2014 0 \u2014 45 1 rw-\nFigure 20.5: A Page Directory , And Pieces Of Page T able\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand PFN: 100) Page of PT (@PFN:101)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pfn",
          "page"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 5: A Page Directory , And Pieces Of Page T able",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "page",
          "directory",
          "pieces",
          "page",
          "able"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 PA G I N G : S M A L L E R TA B L E S\nTI P : B E WA RY OF CO M P L E X I T Y\nSystem designers should be wary of adding complexity into their s ys-\ntem. What a good systems builder does is implement the least compl ex\nsystem that achieves the task at hand. For example, if disk spa ce is abun-\ndant, you shouldn\u2019t design a \ufb01le system that works hard to use as fe w\nbytes as possible; similarly , if processors are fast, it is bett er to write a\nclean and understandable module within the OS than perhaps th e most\nCPU-optimized, hand-assembled code for the task at hand. Be war y of\nneedless complexity , in prematurely-optimized code or other form s; such\napproaches make systems harder to understand, maintain, and debug.\nAs Antoine de Saint-Exupery famously wrote: \u201cPerfection is \ufb01nall y at-\ntained not when there is no longer anything to add, but when ther e is no\nlonger anything to take away .\u201d What he didn\u2019t write: \u201cIt\u2019s a lot ea sier to\nsay something about perfection than to actually achieve it.\u201d\nare 4 and 5 (the heap). Thus, the table has mapping information f or each\nof those pages. The rest of the entries are marked invalid.\nThe other valid page of the page table is found inside PFN 101. Thi s\npage contains mappings for the last 16 VPNs of the address space; see\nFigure\n20.5 (right) for details.\nIn the example, VPNs 254 and 255 (the stack) have valid mappin gs.\nHopefully , what we can see from this example is how much space sav ings\nare possible with a multi-level indexed structure. In this ex ample, instead\nof allocating the full sixteen pages for a linear page table, we allocate only\nthree: one for the page directory , and two for the chunks of the page table\nthat have valid mappings. The savings for large (32-bit or 64-b it) address\nspaces could obviously be much greater .\nFinally , let\u2019s use this information in order to perform a translat ion.\nHere is an address that refers to the 0th byte of VPN 254: 0x3F80, or\n11 1111 1000 0000 in binary .\nRecall that we will use the top 4 bits of the VPN to index into the\npage directory . Thus, 1111 will choose the last (15th, if you start at the\n0th) entry of the page directory above. This points us to a valid pa ge\nof the page table located at address 101. W e then use the next 4 bits\nof the VPN ( 1110) to index into that page of the page table and \ufb01nd\nthe desired PTE. 1110 is the next-to-last (14th) entry on the pa ge, and\ntells us that page 254 of our virtual address space is mapped at p hysi-\ncal page 55. By concatenating PFN=55 (or hex 0x37) with offset=000000,\nwe can thus form our desired physical address and issue the requ est to\nthe memory system: PhysAddr = (PTE.PFN << SHIFT) + offset\n= 00 1101 1100 0000 = 0x0DC0.\nY ou should now have some idea of how to construct a two-level page\ntable, using a page directory which points to pages of the page ta ble. Un-\nfortunately , however , our work is not done. As we\u2019ll now discuss, some-\ntimes two levels of page table is not enough!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "System designers should be wary of adding complexity into their s ys-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "designers",
          "wary",
          "adding",
          "complexity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tem. What a good systems builder does is implement the least compl ex",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "good",
          "systems",
          "builder",
          "implement",
          "least",
          "compl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "dant, you shouldn\u2019t design a \ufb01le system that works hard to use as fe w",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "dant",
          "design",
          "system",
          "works",
          "hard"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "clean and understandable module within the OS than perhaps th e most",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "clean",
          "understandable",
          "module",
          "within",
          "perhaps"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "approaches make systems harder to understand, maintain, and debug.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches",
          "make",
          "systems",
          "harder",
          "understand",
          "maintain",
          "debug"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand TI P: B E WA RY OF CO M P L E X I T Y",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Exupery famously wrote: \u201cPerfection is \ufb01nall y at-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "exupery famously wrote",
          "perfection"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand t write: \u201cIt\u2019s a lot ea sier to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t write",
          "sier"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand we allocate only\nthree: one for the page directory , and two for the chunks of the page table",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "we allocate only\nthree",
          "page",
          "directory",
          "chunks",
          "page",
          "table"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand (right) for details.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "right",
          "details"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "PA G I N G : S M A L L E R TA B L E S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "PA G I N G : S M A L L E R TA B L E S 11\nMore Than T wo Levels\nIn our example thus far , we\u2019ve assumed that multi-level page ta bles only\nhave two levels: a page directory and then pieces of the page tab le. In\nsome cases, a deeper tree is possible (and indeed, needed).\nLet\u2019s take a simple example and use it to show why a deeper multi-\nlevel table can be useful. In this example, assume we have a 30 -bit virtual\naddress space, and a small (512 byte) page. Thus our virtual ad dress has\na 21-bit virtual page number component and a 9-bit offset.\nRemember our goal in constructing a multi-level page table: to m ake\neach piece of the page table \ufb01t within a single page. Thus far , w e\u2019ve only\nconsidered the page table itself; however , what if the page dir ectory gets\ntoo big?\nT o determine how many levels are needed in a multi-level table to\nmake all pieces of the page table \ufb01t within a page, we start by de termining\nhow many page-table entries \ufb01t within a page. Given our page siz e of 512\nbytes, and assuming a PTE size of 4 bytes, you should see that you ca n \ufb01t\n128 PTEs on a single page. When we index into a page of the page tab le,\nwe can thus conclude we\u2019ll need the least signi\ufb01cant 7 bits ( log2128) of\nthe VPN as an index:\n29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\nVPN offset\nPage Directory Index Page Table Index\nWhat you also might notice from the diagram above is how many bits\nare left into the (large) page directory: 14. If our page direct ory has 214\nentries, it spans not one page but 128, and thus our goal of making ev ery\npiece of the multi-level page table \ufb01t into a page vanishes.\nT o remedy this problem, we build a further level of the tree, by s plit-\nting the page directory itself into multiple pages, and then a dding another\npage directory on top of that, to point to the pages of the page direct ory .\nW e can thus split up our virtual address as follows:\n29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\nVPN offset\nPD Index 0 PD Index 1 Page Table Index\nNow , when indexing the upper-level page directory , we use the v ery\ntop bits of the virtual address ( PD Index 0 in the diagram); this index\ncan be used to fetch the page-directory entry from the top-level page di-\nrectory . If valid, the second level of the page directory is consul ted by\ncombining the physical frame number from the top-level PDE and t he\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Remember our goal in constructing a multi-level page table: to m ake",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "remember",
          "goal",
          "constructing",
          "multi",
          "level",
          "page",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T o determine how many levels are needed in a multi-level table to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "determine",
          "many",
          "levels",
          "needed",
          "multi",
          "level",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "entries, it spans not one page but 128, and thus our goal of making ev ery",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "entries",
          "spans",
          "page",
          "thus",
          "goal",
          "making"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand page directory: 14. If our page direct ory has 214",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "page directory",
          "page",
          "direct"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 PA G I N G : S M A L L E R TA B L E S\n1 VPN = (VirtualAddress & VPN_MASK) >> SHIFT\n2 (Success, TlbEntry) = TLB_Lookup(VPN)\n3 if (Success == True) // TLB Hit\n4 if (CanAccess(TlbEntry.ProtectBits) == True)\n5 Offset = VirtualAddress & OFFSET_MASK\n6 PhysAddr = (TlbEntry.PFN << SHIFT) | Offset\n7 Register = AccessMemory(PhysAddr)\n8 else\n9 RaiseException(PROTECTION_FAULT)\n10 else // TLB Miss\n11 // first, get page directory entry\n12 PDIndex = (VPN & PD_MASK) >> PD_SHIFT\n13 PDEAddr = PDBR + (PDIndex * sizeof(PDE))\n14 PDE = AccessMemory(PDEAddr)\n15 if (PDE.Valid == False)\n16 RaiseException(SEGMENTATION_FAULT)\n17 else\n18 // PDE is valid: now fetch PTE from page table\n19 PTIndex = (VPN & PT_MASK) >> PT_SHIFT\n20 PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))\n21 PTE = AccessMemory(PTEAddr)\n22 if (PTE.Valid == False)\n23 RaiseException(SEGMENTATION_FAULT)\n24 else if (CanAccess(PTE.ProtectBits) == False)\n25 RaiseException(PROTECTION_FAULT)\n26 else\n27 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)\n28 RetryInstruction()\nFigure 20.6: Multi-level Page T able Control Flow\nnext part of the VPN ( PD Index 1). Finally , if valid, the PTE address\ncan be formed by using the page-table index combined with the ad dress\nfrom the second-level PDE. Whew! That\u2019s a lot of work. And all just to\nlook something up in a multi-level table.\nThe T ranslation Process: Remember the TLB\nT o summarize the entire process of address translation using a t wo-level\npage table, we once again present the control \ufb02ow in algorithmic for m\n(Figure\n20.6). The \ufb01gure shows what happens in hardware (assuming a\nhardware-managed TLB) upon every memory reference.\nAs you can see from the \ufb01gure, before any of the complicated multi-\nlevel page table access occurs, the hardware \ufb01rst checks the T LB; upon\na hit, the physical address is formed directly without accessing the page\ntable at all, as before. Only upon a TLB miss does the hardware nee d to\nperform the full multi-level lookup. On this path, you can see the cost of\nour traditional two-level page table: two additional memory acce sses to\nlook up a valid translation.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "page table, we once again present the control \ufb02ow in algorithmic for m",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "table",
          "present",
          "control",
          "algorithmic"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand PDE is valid: now fetch PTE from page table",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pde is valid",
          "fetch",
          "page",
          "table"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 6: Multi-level Page T able Control Flow",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "multi",
          "level",
          "page",
          "able",
          "control",
          "flow"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand level page table: two additional memory acce sses to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "level page table",
          "additional",
          "memory",
          "acce",
          "sses"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand ). the \ufb01gure shows what happens in hardware (assuming a",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "happens",
          "hardware",
          "assuming"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "20",
    "title": "4 Inverted Page T ables",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "20.4 Inverted Page T ables\nAn even more extreme space savings in the world of page tables is\nfound with inverted page tables . Here, instead of having many page\ntables (one per process of the system), we keep a single page tabl e that\nhas an entry for each physical page of the system. The entry tells us which\nprocess is using this page, and which virtual page of that proces s maps to\nthis physical page.\nFinding the correct entry is now a matter of searching through thi s\ndata structure. A linear scan would be expensive, and thus a ha sh table\nis often built over the base structure to speed up lookups. The Powe rPC\nis one example of such an architecture [JM98].\nMore generally , inverted page tables illustrate what we\u2019ve sa id from\nthe beginning: page tables are just data structures. Y ou can d o lots of\ncrazy things with data structures, making them smaller or big ger , making\nthem slower or faster . Multi-level and inverted page tables ar e just two\nexamples of the many things one could do.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand inverted page t ables",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "inverted",
          "page",
          "ables"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "20",
    "title": "5 Swapping the Page T ables to Disk",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "20.5 Swapping the Page T ables to Disk\nFinally , we discuss the relaxation of one \ufb01nal assumption. Thus f ar ,\nwe have assumed that page tables reside in kernel-owned physi cal mem-\nory . Even with our many tricks to reduce the size of page tables, i t is still\npossible, however , that they may be too big to \ufb01t into memory all at once.\nThus, some systems place such page tables in kernel virtual memory ,\nthereby allowing the system to swap some of these page tables to disk\nwhen memory pressure gets a little tight. W e\u2019ll talk more about th is in\na future chapter (namely , the case study on V AX/VMS), once we und er-\nstand how to move pages in and out of memory in more detail.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand swapping the page t ables to disk",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "swapping",
          "page",
          "ables",
          "disk"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "20",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "20.6 Summary\nW e have now seen how real page tables are built; not necessarily j ust\nas linear arrays but as more complex data structures. The trade -offs such\ntables present are in time and space \u2014 the bigger the table, th e faster a\nTLB miss can be serviced, as well as the converse \u2014 and thus the r ight\nchoice of structure depends strongly on the constraints of the give n envi-\nronment.\nIn a memory-constrained system (like many older systems), smal l struc-\ntures make sense; in a system with a reasonable amount of memory an d\nwith workloads that actively use a large number of pages, a bigge r ta-\nble that speeds up TLB misses might be the right choice. With sof tware-\nmanaged TLBs, the entire space of data structures opens up to th e delight\nof the operating system innovator (hint: that\u2019s you). What new stru c-\ntures can you come up with? What problems do they solve? Think of\nthese questions as you fall asleep, and dream the big dreams tha t only\noperating-system developers can dream.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tures can you come up with? What problems do they solve? Think of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tures",
          "come",
          "problems",
          "solve",
          "think"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "operating-system developers can dream.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "operating",
          "system",
          "developers",
          "dream"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand hint: that\u2019s you). What new stru c-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hint",
          "stru"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 PA G I N G : S M A L L E R TA B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 PA G I N G : S M A L L E R TA B L E S\nReferences\n[BOH10] \u201cComputer Systems: A Programmer \u2019s Perspective\u201d by Randal E. Bryant and David\nR. O\u2019Hallaron. Addison-W esley , 2010. We have yet to \ufb01nd a good \ufb01rst reference to the multi-level\npage table. However , this great textbook by Bryant and O\u2019Hallaron dives into the details of x86, which\nat least is an early system that used such structures. It\u2019s also just a great b ook to have.\n[JM98] \u201cVirtual Memory: Issues of Implementation\u201d by Bruce Jacob, T re vor Mudge. IEEE\nComputer , June 1998. An excellent survey of a number of different systems and their approac h to\nvirtualizing memory. Plenty of details on x86, PowerPC, MIPS, and other archi tectures.\n[LL82] \u201cVirtual Memory Management in the V AX/VMS Operating System\u201d by Hank Levy , P .\nLipman. IEEE Computer , V ol. 15, No. 3, March 1982. A terri\ufb01c paper about a real virtual memory\nmanager in a classic operating system, VMS. So terri\ufb01c, in fact, that we\u2019ll use it to review everything\nwe\u2019ve learned about virtual memory thus far a few chapters from now.\n[M28] \u201cReese\u2019s Peanut Butter Cups\u201d by Mars Candy Corporation. Publis hed at stores near\nyou. Apparently these \ufb01ne confections were invented in 1928 by Harry Burne tt Reese, a former dairy\nfarmer and shipping foreman for one Milton S. Hershey. At least, that is what it says on Wikipedia. If\ntrue, Hershey and Reese probably hate each other\u2019s guts, as any two chocolate baron s should.\n[N+02] \u201cPractical, T ransparent Operating System Support for Superpa ges\u201d by Juan Navarro,\nSitaram Iyer , Peter Druschel, Alan Cox. OSDI \u201902, Boston, Massachuse tts, October 2002. A nice\npaper showing all the details you have to get right to incorporate large pages, or superpages, into a\nmodern OS. Not as easy as you might think, alas.\n[M07] \u201cMultics: History\u201d A vailable: http://www.multicians.org/history.html. This\namazing web site provides a huge amount of history on the Multics system, certai nly one of the most\nin\ufb02uential systems in OS history. The quote from therein: \u201cJack Dennis of M IT contributed in\ufb02uential\narchitectural ideas to the beginning of Multics, especially the idea of com bining paging and segmenta-\ntion.\u201d (from Section 1.2.1)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[JM98] \u201cVirtual Memory: Issues of Implementation\u201d by Bruce Jacob, T re vor Mudge. IEEE",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "virtual",
          "memory",
          "issues",
          "implementation",
          "bruce",
          "jacob",
          "mudge",
          "ieee"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "we\u2019ve learned about virtual memory thus far a few chapters from now.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learned",
          "virtual",
          "memory",
          "thus",
          "chapters"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Computer Systems: A Programmer \u2019s Perspective\u201d by Randal E. Bryant and David",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "computer systems",
          "programmer",
          "perspective",
          "randal",
          "bryant",
          "david"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Multics: History\u201d A vailable: http://www.multicians.org/history.html. This",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "multics",
          "history",
          "vailable",
          "http",
          "multicians",
          "history",
          "html"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand The quote from therein: \u201cJack Dennis of M IT contributed in\ufb02uential",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the quote from therein",
          "jack",
          "dennis",
          "contributed"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "With a linear page table, you need a single register to locate the",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "1. With a linear page table, you need a single register to locate the\npage table, assuming that hardware does the lookup upon a TLB\nmiss. How many registers do you need to locate a two-level page\ntable? A three-level table?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Use the simulator to perform translations given random seeds 0 ,",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "2. Use the simulator to perform translations given random seeds 0 ,\n1, and 2, and check your answers using the -c \ufb02ag. How many\nmemory references are needed to perform each lookup?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Given your understanding of how cache memory works, how do",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "3. Given your understanding of how cache memory works, how do\nyou think memory references to the page table will behave in the\ncache? Will they lead to lots of cache hits (and thus fast access es?)\nOr lots of misses (and thus slow accesses)?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Given your understanding of how cache memory works, how do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "given",
          "understanding",
          "cache",
          "memory",
          "works"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "21\nBeyond Physical Memory: Mechanisms\nThus far , we\u2019ve assumed that an address space is unrealistica lly small\nand \ufb01ts into physical memory . In fact, we\u2019ve been assuming that every\naddress space of every running process \ufb01ts into memory . W e will n ow\nrelax these big assumptions, and assume that we wish to support many\nconcurrently-running large address spaces.\nT o do so, we require an additional level in the memory hierarchy .\nThus far , we have assumed that all pages reside in physical me mory .\nHowever , to support large address spaces, the OS will need a pla ce to\nstash away portions of address spaces that currently aren\u2019t in gr eat de-\nmand. In general, the characteristics of such a location are tha t it should\nhave more capacity than memory; as a result, it is generally slow er (if it\nwere faster , we would just use it as memory , no?). In modern system s,\nthis role is usually served by a hard disk drive . Thus, in our memory\nhierarchy , big and slow hard drives sit at the bottom, with memory just\nabove. And thus we arrive at the crux of the problem:\nTH E CR U X : H O W TO GO BE Y O N D PH Y S I C A L ME M O RY\nHow can the OS make use of a larger , slower device to transparentl y pro-\nvide the illusion of a large virtual address space?\nOne question you might have: why do we want to support a single\nlarge address space for a process? Once again, the answer is conv enience\nand ease of use. With a large address space, you don\u2019t have to worry\nabout if there is room enough in memory for your program\u2019s data struc-\ntures; rather , you just write the program naturally , allocatin g memory as\nneeded. It is a powerful illusion that the OS provides, and makes your\nlife vastly simpler . Y ou\u2019re welcome! A contrast is found in older sy stems\nthat used memory overlays , which required programmers to manually\nmove pieces of code or data in and out of memory as they were needed\n[D97]. T ry imagining what this would be like: before calling a f unction or\naccessing some data, you need to \ufb01rst arrange for the code or data to be\nin memory; yuck!\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "life vastly simpler . Y ou\u2019re welcome! A contrast is found in older sy stems",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "life",
          "vastly",
          "simpler",
          "welcome",
          "contrast",
          "found",
          "older",
          "stems"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "1 Swap Space",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "21.1 Swap Space\nThe \ufb01rst thing we will need to do is to reserve some space on the di sk\nfor moving pages back and forth. In operating systems, we general ly refer\nto such space as swap space, because we swap pages out of memory to it\nand swap pages into memory from it. Thus, we will simply assume that\nthe OS can read from and write to the swap space, in page-sized u nits. T o\ndo so, the OS will need to remember the disk address of a given page.\nThe size of the swap space is important, as ultimately it determ ines\nthe maximum number of memory pages that can be in use by a system a t\na given time. Let us assume for simplicity that it is very large for now .\nIn the tiny example (Figure 21.1), you can see a little example of a 4-\npage physical memory and an 8-page swap space. In the example, three\nprocesses (Proc 0, Proc 1, and Proc 2) are actively sharing physic al mem-\nory; each of the three, however , only have some of their valid pages i n\nmemory , with the rest located in swap space on disk. A fourth proces s\n(Proc 3) has all of its pages swapped out to disk, and thus clearly isn\u2019t\ncurrently running. One block of swap remains free. Even from thi s tiny\nexample, hopefully you can see how using swap space allows the sys tem\nto pretend that memory is larger than it actually is.\nW e should note that swap space is not the only on-disk location for\nswapping traf\ufb01c. For example, assume you are running a program b inary\n(e.g., ls, or your own compiled main program). The code pages from this\nbinary are initially found on disk, and when the program runs, th ey are\nloaded into memory (either all at once when the program starts exe cution,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.00] W W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The size of the swap space is important, as ultimately it determ ines",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "size",
          "swap",
          "space",
          "important",
          "ultimately",
          "determ",
          "ines"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand swap space",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "swap",
          "space"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "2 The Present Bit",
    "document_source": "book.pdf",
    "start_line": 45,
    "type": "chapter",
    "content": "21.2 The Present Bit\nNow that we have some space on the disk, we need to add some ma-\nchinery higher up in the system in order to support swapping pag es to\nand from the disk. Let us assume, for simplicity , that we have a s ystem\nwith a hardware-managed TLB.\nRecall \ufb01rst what happens on a memory reference. The running pro-\ncess generates virtual memory references (for instruction fet ches, or data\naccesses), and, in this case, the hardware translates them i nto physical\naddresses before fetching the desired data from memory .\nRemember that the hardware \ufb01rst extracts the VPN from the virt ual\naddress, checks the TLB for a match (a TLB hit), and if a hit, produces the\nresulting physical address and fetches it from memory . This is hopefully\nthe common case, as it is fast (requiring no additional memory acc esses).\nIf the VPN is not found in the TLB (i.e., a TLB miss ), the hardware\nlocates the page table in memory (using the page table base register )\nand looks up the page table entry (PTE) for this page using the VPN\nas an index. If the page is valid and present in physical memory , the\nhardware extracts the PFN from the PTE, installs it in the TLB, and retries\nthe instruction, this time generating a TLB hit; so far , so good.\nIf we wish to allow pages to be swapped to disk, however , we must\nadd even more machinery . Speci\ufb01cally , when the hardware looks in the\nPTE, it may \ufb01nd that the page is not present in physical memory . The way\nthe hardware (or the OS, in a software-managed TLB approach) dete r-\nmines this is through a new piece of information in each page-tabl e entry ,\nknown as the present bit . If the present bit is set to one, it means the\npage is present in physical memory and everything proceeds as a bove; if\nit is set to zero, the page is not in memory but rather on disk somewhere.\nThe act of accessing a page that is not in physical memory is commonl y\nreferred to as a page fault.\nc\u20dd 2008\u201318, A R PA C I-D U S S E A U\nTH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the hardware (or the OS, in a software-managed TLB approach) dete r-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hardware",
          "software",
          "managed",
          "approach",
          "dete"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "known as the present bit . If the present bit is set to one, it means the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "present",
          "present",
          "means"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the present bit",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "present"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "3 The Page Fault",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "21.3 The Page Fault\nRecall that with TLB misses, we have two types of systems: hard ware-\nmanaged TLBs (where the hardware looks in the page table to \ufb01nd t he\ndesired translation) and software-managed TLBs (where the OS does). In\neither type of system, if a page is not present, the OS is put in ch arge to\nhandle the page fault. The appropriately-named OS page-fault handler\nruns to determine what to do. Virtually all systems handle pag e faults in\nsoftware; even with a hardware-managed TLB, the hardware tru sts the\nOS to manage this important duty .\nIf a page is not present and has been swapped to disk, the OS will need\nto swap the page into memory in order to service the page fault. T hus, a\nquestion arises: how will the OS know where to \ufb01nd the desired pag e? In\nmany systems, the page table is a natural place to store such in formation.\nThus, the OS could use the bits in the PTE normally used for data su ch as\nthe PFN of the page for a disk address. When the OS receives a page fault\nfor a page, it looks in the PTE to \ufb01nd the address, and issues the re quest\nto disk to fetch the page into memory .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.00] W W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "managed TLBs (where the hardware looks in the page table to \ufb01nd t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "managed",
          "tlbs",
          "hardware",
          "looks",
          "page",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "OS to manage this important duty .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "manage",
          "important",
          "duty"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "question arises: how will the OS know where to \ufb01nd the desired pag e? In",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "question",
          "arises",
          "know",
          "desired"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the page fault",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "fault"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "4 What If Memory Is Full?",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "21.4 What If Memory Is Full?\nIn the process described above, you may notice that we assumed the re\nis plenty of free memory in which to page in a page from swap space.\nOf course, this may not be the case; memory may be full (or close to it ).\nThus, the OS might like to \ufb01rst page out one or more pages to make room\nfor the new page(s) the OS is about to bring in. The process of picki ng a\npage to kick out, or replace is known as the page-replacement policy.\nAs it turns out, a lot of thought has been put into creating a good page -\nreplacement policy , as kicking out the wrong page can exact a gre at cost\non program performance. Making the wrong decision can cause a pro-\ngram to run at disk-like speeds instead of memory-like speeds; in cur-\nrent technology that means a program could run 10,000 or 100,000 ti mes\nslower . Thus, such a policy is something we should study in some det ail;\nindeed, that is exactly what we will do in the next chapter . For now , it is\ngood enough to understand that such a policy exists, built on top of th e\nmechanisms described here.\nc\u20dd 2008\u201318, A R PA C I-D U S S E A U\nTH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In the process described above, you may notice that we assumed the re",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "process",
          "described",
          "notice",
          "assumed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "page to kick out, or replace is known as the page-replacement policy.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "kick",
          "replace",
          "known",
          "page",
          "replacement",
          "policy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "good enough to understand that such a policy exists, built on top of th e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "good",
          "enough",
          "understand",
          "policy",
          "exists",
          "built"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "mechanisms described here.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mechanisms",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand rent technology that: a program could run 10,000 or 100,000 ti mes",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rent technology that",
          "program",
          "could"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand what if memory is full?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "full"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "5 Page Fault Control Flow",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "21.5 Page Fault Control Flow\nWith all of this knowledge in place, we can now roughly sketch the\ncomplete control \ufb02ow of memory access. In other words, when some-\nbody asks you \u201cwhat happens when a program fetches some data from\nmemory?\u201d, you should have a pretty good idea of all the different pos-\nsibilities. See the control \ufb02ow in Figures 21.2 and 21.3 for more det ails;\nthe \ufb01rst \ufb01gure shows what the hardware does during translation, and the\nsecond what the OS does upon a page fault.\nFrom the hardware control \ufb02ow diagram in Figure 21.2, notice that\nthere are now three important cases to understand when a TLB mis s oc-\ncurs. First, that the page was both present and valid (Lines 18\u201321); in\nthis case, the TLB miss handler can simply grab the PFN from the PTE,\nretry the instruction (this time resulting in a TLB hit), and t hus continue\nas described (many times) before. In the second case (Lines 22\u2013 23), the\npage fault handler must be run; although this was a legitimate page for\nthe process to access (it is valid, after all), it is not present in physical\nmemory . Third (and \ufb01nally), the access could be to an invalid pa ge, due\nfor example to a bug in the program (Lines 13\u201314). In this case, n o other\nbits in the PTE really matter; the hardware traps this invali d access, and\nthe OS trap handler runs, likely terminating the offending pr ocess.\nFrom the software control \ufb02ow in Figure 21.3, we can see what the OS\nroughly must do in order to service the page fault. First, the OS must \ufb01nd\na physical frame for the soon-to-be-faulted-in page to reside wi thin; if\nthere is no such page, we\u2019ll have to wait for the replacement alg orithm to\nrun and kick some pages out of memory , thus freeing them for use here .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.00] W W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "With all of this knowledge in place, we can now roughly sketch the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowledge",
          "place",
          "roughly",
          "sketch"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "there are now three important cases to understand when a TLB mis s oc-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "three",
          "important",
          "cases",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "as described (many times) before. In the second case (Lines 22\u2013 23), the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "many",
          "times",
          "second",
          "case",
          "lines"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand page fault control flow",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "fault",
          "control",
          "flow"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "6 When Replacements Really Occur",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "21.6 When Replacements Really Occur\nThus far , the way we\u2019ve described how replacements occur assume s\nthat the OS waits until memory is entirely full, and only then re places\n(evicts) a page to make room for some other page. As you can imagine,\nthis is a little bit unrealistic, and there are many reasons for the OS to keep\na small portion of memory free more proactively .\nT o keep a small amount of memory free, most operating systems thus\nhave some kind of high watermark (HW ) and low watermark (LW ) to\nhelp decide when to start evicting pages from memory . How this wor ks is\nas follows: when the OS notices that there are fewer than LW pages avail-\nable, a background thread that is responsible for freeing memory runs.\nThe thread evicts pages until there are HW pages available. The back-\nground thread, sometimes called the swap daemon or page daemon 1 ,\nthen goes to sleep, happy that it has freed some memory for running pro-\ncesses and the OS to use.\nBy performing a number of replacements at once, new performance\noptimizations become possible. For example, many systems will cluster\nor group a number of pages and write them out at once to the swap parti-\ntion, thus increasing the ef\ufb01ciency of the disk [LL82]; as we wi ll see later\nwhen we discuss disks in more detail, such clustering reduces seek and\nrotational overheads of a disk and thus increases performance noti ceably .\nT o work with the background paging thread, the control \ufb02ow in Figur e",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus far , the way we\u2019ve described how replacements occur assume s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "described",
          "replacements",
          "occur",
          "assume"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand when replacements really occur",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "replacements",
          "really",
          "occur"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "21",
    "title": "3 should be modi\ufb01ed slightly; instead of performing a replace ment",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "21.3 should be modi\ufb01ed slightly; instead of performing a replace ment\ndirectly , the algorithm would instead simply check if there ar e any free\npages available. If not, it would inform the background paging th read\nthat free pages are needed; when the thread frees up some pages , it would\nre-awaken the original thread, which could then page in the des ired page\nand go about its work.\n1 The word \u201cdaemon\u201d, usually pronounced \u201cdemon\u201d, is an old term for a back ground\nthread or process that does something useful. T urns out (once again!) that the source of the\nterm is Multics [CS94].\nc\u20dd 2008\u201318, A R PA C I-D U S S E A U\nTH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "directly , the algorithm would instead simply check if there ar e any free",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directly",
          "algorithm",
          "would",
          "instead",
          "simply",
          "check",
          "free"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand should be modi\ufb01ed slightly; instead of performing a replace ment",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "slightly",
          "instead",
          "performing",
          "replace",
          "ment"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "21",
    "title": "7 Summary",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "21.7 Summary\nIn this brief chapter , we have introduced the notion of accessing more\nmemory than is physically present within a system. T o do so req uires\nmore complexity in page-table structures, as a present bit (of some kind)\nmust be included to tell us whether the page is present in memor y or not.\nWhen not, the operating system page-fault handler runs to service the\npage fault , and thus arranges for the transfer of the desired page from\ndisk to memory , perhaps \ufb01rst replacing some pages in memory to ma ke\nroom for those soon to be swapped in.\nRecall, importantly (and amazingly!), that these actions all t ake place\ntransparently to the process. As far as the process is concerned, it is just\naccessing its own private, contiguous virtual memory . Behind th e scenes,\npages are placed in arbitrary (non-contiguous) locations in phys ical mem-\nory , and sometimes they are not even present in memory , requiring a fetch\nfrom disk. While we hope that in the common case a memory access is\nfast, in some cases it will take multiple disk operations to serv ice it; some-\nthing as simple as performing a single instruction can, in the w orst case,\ntake many milliseconds to complete.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.00] W W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Recall, importantly (and amazingly!), that these actions all t ake place",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "recall",
          "importantly",
          "amazingly",
          "actions",
          "place"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "BE Y O N D PH Y S I C A L ME M O RY: M E C H A N I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "BE Y O N D PH Y S I C A L ME M O RY: M E C H A N I S M S 9\nReferences\n[CS94] \u201cT ake Our W ord For It\u201d by F . Corbato, R. Steinberg. www.takeourword.com/TOW146\n(Page 4). Richard Steinberg writes: \u201cSomeone has asked me the origin of the word daemon as it applies\nto computing. Best I can tell based on my research, the word was \ufb01rst used by people on your team at\nProject MAC using the IBM 7094 in 1963.\u201d Professor Corbato replies: \u201cO ur use of the word daemon\nwas inspired by the Maxwell\u2019s daemon of physics and thermodynamics (my bac kground is in physics).\nMaxwell\u2019s daemon was an imaginary agent which helped sort molecules of di fferent speeds and worked\ntirelessly in the background. We fancifully began to use the word daemon to d escribe background pro-\ncesses which worked tirelessly to perform system chores.\u201d\n[D97] \u201cBefore Memory W as Virtual\u201d by Peter Denning. In the Beginning: Reco llections of\nSoftware Pioneers, Wiley , November 1997. An excellent historical piece by one of the pioneers of\nvirtual memory and working sets.\n[G+95] \u201cIdleness is not sloth\u201d by Richard Golding, Peter Bosch, Carl Sta elin, Tim Sullivan, John\nWilkes. USENIX A TC \u201995, New Orleans, Louisiana. A fun and easy-to-read discussion of how idle\ntime can be better used in systems, with lots of good examples.\n[LL82] \u201cVirtual Memory Management in the V AX/VMS Operating System\u201d by Hank Levy , P .\nLipman. IEEE Computer , V ol. 15, No. 3, March 1982. Not the \ufb01rst place where page clustering was\nused, but a clear and simple explanation of how such a mechanism works. We s ure cite this paper a lot!\nc\u20dd 2008\u201318, A R PA C I-D U S S E A U\nTH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand Richard Steinberg writes: \u201cSomeone has asked me the origin of the word daemon as it applies",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "richard steinberg writes",
          "someone",
          "asked",
          "origin",
          "word",
          "daemon",
          "applies"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor Corbato replies: \u201cO ur use of the word daemon",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor corbato replies",
          "word",
          "daemon"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "First, open two separate terminal connections to the same machine, so that",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1. First, open two separate terminal connections to the same machine, so that\nyou can easily run something in one window and the other .\nNow , in one window , run vmstat 1, which shows statistics about machine\nusage every second. Read the man page, the associated README, an d any\nother information you need so that you can understand its output. Leave\nthis window running vmstat for the rest of the exercises below .\nNow , we will run the program mem.c but with very little memory usage.\nThis can be accomplished by typing ./mem 1 (which uses only 1 MB of\nmemory). How do the CPU usage statistics change when running mem? Do\nthe numbers in the user time column make sense? How does this change\nwhen running more than one instance of mem at once?\n2. Let\u2019s now start looking at some of the memory statistics while running mem.\nW e\u2019ll focus on two columns: swpd (the amount of virtual memory used) and\nfree (the amount of idle memory). Run ./mem 1024 (which allocates 1024\nMB) and watch how these values change. Then kill the running pro gram\n(by typing control-c) and watch again how the values change. W hat do you\nnotice about the values? In particular , how does the free column change\nwhen the program exits? Does the amount of free memory increase by t he\nexpected amount when mem exits?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "other information you need so that you can understand its output. Leave",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "information",
          "need",
          "understand",
          "output",
          "leave"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand this change\nwhen running more than one instance of mem at once",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "change",
          "running",
          "instance"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the free column change\nwhen the program exits",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "column",
          "change",
          "program",
          "exits"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "W e\u2019ll next look at the swap columns ( si and so), which indicate how much",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "3. W e\u2019ll next look at the swap columns ( si and so), which indicate how much\nswapping is taking place to and from the disk. Of course, to act ivate these,\nyou\u2019ll need to run mem with large amounts of memory . First, examine how\nmuch free memory is on your Linux system (for example, by typing cat\n/proc/meminfo; type man proc for details on the /proc \ufb01le system and\nthe types of information you can \ufb01nd there). One of the \ufb01rst ent ries in\n/proc/meminfo is the total amount of memory in your system. Let\u2019s as-\nsume it\u2019s something like 8 GB of memory; if so, start by running mem 4000\n(about 4 GB) and watching the swap in/out columns. Do they ever giv e\nnon-zero values? Then, try with 5000, 6000, etc. What happens to these\nvalues as the program enters the second loop (and beyond), as c ompared to\nthe \ufb01rst loop? How much data (total) are swapped in and out during t he\nsecond, third, and subsequent loops? (do the numbers make sense?)",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Do the same experiments as above, but now watch the other statis tics (such",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "4. Do the same experiments as above, but now watch the other statis tics (such\nas CPU utilization, and block I/O statistics). How do they cha nge when\nmem is running?\n5. Now let\u2019s examine performance. Pick an input for mem that comfortably\n\ufb01ts in memory (say 4000 if the amount of memory on the system is 8 GB).\nHow long does loop 0 take (and subsequent loops 1, 2, etc.)? Now p ick a size\ncomfortably beyond the size of memory (say 12000 again assuming 8 GB of\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.00] W W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "Finally , if you\u2019re advanced, you can con\ufb01gure your system to us e different",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "7. Finally , if you\u2019re advanced, you can con\ufb01gure your system to us e different\nswap devices using swapon and swapoff. Read the man pages for details.\nIf you have access to different hardware, see how the performa nce of swap-\nping changes when swapping to a classic hard drive, a \ufb02ash-ba sed SSD, and\neven a RAID array . How much can swapping performance be improved vi a\nnewer devices? How close can you get to in-memory performance?\nc\u20dd 2008\u201318, A R PA C I-D U S S E A U\nTH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "1 Cache Management",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "22.1 Cache Management\nBefore diving into policies, we \ufb01rst describe the problem we are trying\nto solve in more detail. Given that main memory holds some subset of\nall the pages in the system, it can rightly be viewed as a cache for virtual\nmemory pages in the system. Thus, our goal in picking a replaceme nt\npolicy for this cache is to minimize the number of cache misses , i.e., to\nminimize the number of times that we have to fetch a page from dis k.\nAlternately , one can view our goal as maximizing the number of cache\nhits, i.e., the number of times a page that is accessed is found in mem ory .\nKnowing the number of cache hits and misses let us calculate the av-\nerage memory access time (AMA T) for a program (a metric computer\narchitects compute for hardware caches [HP06]). Speci\ufb01cally , given these\nvalues, we can compute the AMA T of a program as follows:\nAMAT = TM + (PMiss \u00b7 TD) (22.1)\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Before diving into policies, we \ufb01rst describe the problem we are trying",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "diving",
          "policies",
          "describe",
          "problem",
          "trying"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to solve in more detail. Given that main memory holds some subset of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "detail",
          "given",
          "main",
          "memory",
          "holds",
          "subset"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "memory pages in the system. Thus, our goal in picking a replaceme nt",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "pages",
          "system",
          "thus",
          "goal",
          "picking",
          "replaceme"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Alternately , one can view our goal as maximizing the number of cache",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "alternately",
          "view",
          "goal",
          "maximizing",
          "number",
          "cache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Knowing the number of cache hits and misses let us calculate the av-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowing",
          "number",
          "cache",
          "hits",
          "misses",
          "calculate"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand cache management",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "cache",
          "management"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "2 The Optimal Replacement Policy",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "22.2 The Optimal Replacement Policy\nT o better understand how a particular replacement policy works , it\nwould be nice to compare it to the best possible replacement polic y . As it\nturns out, such an optimal policy was developed by Belady many years\nago [B66] (he originally called it MIN). The optimal replaceme nt policy\nleads to the fewest number of misses overall. Belady showed that a sim-\nple (but, unfortunately , dif\ufb01cult to implement!) approach tha t replaces\nthe page that will be accessed furthest in the future is the optimal policy ,\nresulting in the fewest-possible cache misses.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o better understand how a particular replacement policy works , it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "better",
          "understand",
          "particular",
          "replacement",
          "policy",
          "works"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "would be nice to compare it to the best possible replacement polic y . As it",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "would",
          "nice",
          "compare",
          "best",
          "possible",
          "replacement",
          "polic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "turns out, such an optimal policy was developed by Belady many years",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "turns",
          "optimal",
          "policy",
          "developed",
          "belady",
          "many",
          "years"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ple (but, unfortunately , dif\ufb01cult to implement!) approach tha t replaces",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "unfortunately",
          "implement",
          "approach",
          "replaces"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the optimal replacement policy",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "optimal",
          "replacement",
          "policy"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E S 3\nTI P : C O M PA R I N G AG A I N S T OP T I M A L IS US E F U L\nAlthough optimal is not very practical as a real policy , it is incr edibly\nuseful as a comparison point in simulation or other studies. Saying t hat\nyour fancy new algorithm has a 80% hit rate isn\u2019t meaningful in is olation;\nsaying that optimal achieves an 82% hit rate (and thus your new a pproach\nis quite close to optimal) makes the result more meaningful and g ives it\ncontext. Thus, in any study you perform, knowing what the optimal i s\nlets you perform a better comparison, showing how much improvement\nis still possible, and also when you can stop making your policy better ,\nbecause it is close enough to the ideal [AD03].\nHopefully , the intuition behind the optimal policy makes sense. Think\nabout it like this: if you have to throw out some page, why not throw\nout the one that is needed the furthest from now? By doing so, you are\nessentially saying that all the other pages in the cache are mor e important\nthan the one furthest out. The reason this is true is simple: you wi ll refer\nto the other pages before you refer to the one furthest out.\nLet\u2019s trace through a simple example to understand the decision s the\noptimal policy makes. Assume a program accesses the following str eam\nof virtual pages: 0, 1, 2, 0, 1, 3, 0, 3, 1, 2, 1. Figure 22.1 shows t he behavior\nof optimal, assuming a cache that \ufb01ts three pages.\nIn the \ufb01gure, you can see the following actions. Not surprisingly , the\n\ufb01rst three accesses are misses, as the cache begins in an empt y state; such\na miss is sometimes referred to as a cold-start miss (or compulsory miss ).\nThen we refer again to pages 0 and 1, which both hit in the cache. Finally ,\nwe reach another miss (to page 3), but this time the cache is ful l; a re-\nplacement must take place! Which begs the question: which pag e should\nwe replace? With the optimal policy , we examine the future for ea ch page\ncurrently in the cache (0, 1, and 2), and see that 0 is accessed almost imme-\ndiately , 1 is accessed a little later , and 2 is accessed furth est in the future.\nThus the optimal policy has an easy choice: evict page 2, resulti ng in\nResulting\nAccess Hit/Miss? Evict Cache State\n0 Miss 0\n1 Miss 0, 1\n2 Miss 0, 1, 2\n0 Hit 0, 1, 2\n1 Hit 0, 1, 2\n3 Miss 2 0, 1, 3\n0 Hit 0, 1, 3\n3 Hit 0, 1, 3\n1 Hit 0, 1, 3\n2 Miss 3 0, 1, 2\n1 Hit 0, 1, 2\nFigure 22.1: T racing The Optimal Policy\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "your fancy new algorithm has a 80% hit rate isn\u2019t meaningful in is olation;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fancy",
          "algorithm",
          "rate",
          "meaningful",
          "olation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "context. Thus, in any study you perform, knowing what the optimal i s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "context",
          "thus",
          "study",
          "perform",
          "knowing",
          "optimal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "essentially saying that all the other pages in the cache are mor e important",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "essentially",
          "saying",
          "pages",
          "cache",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Let\u2019s trace through a simple example to understand the decision s the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trace",
          "simple",
          "example",
          "understand",
          "decision"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand TI P: C O M PA R I N G AG A I N S T OP T I M A L IS US E F U L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 1: T racing The Optimal Policy",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "racing",
          "optimal",
          "policy"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "3 A Simple Policy: FIFO",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "22.3 A Simple Policy: FIFO\nMany early systems avoided the complexity of trying to approach\noptimal and employed very simple replacement policies. For exam ple,\nsome systems used FIFO (\ufb01rst-in, \ufb01rst-out) replacement, where pages\nwere simply placed in a queue when they enter the system; when a re-\nplacement occurs, the page on the tail of the queue (the \u201c\ufb01rst-in \u201d page) is\nevicted. FIFO has one great strength: it is quite simple to imp lement.\nLet\u2019s examine how FIFO does on our example reference stream (Figur e\n22.2, page 5). W e again begin our trace with three compulsory mis ses to\n1 If you can, let us know! W e can become rich together . Or , like the scientist s who \u201cdiscov-\nered\u201d cold fusion, widely scorned and mocked [FP89].\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Many early systems avoided the complexity of trying to approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "early",
          "systems",
          "avoided",
          "complexity",
          "trying",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "If you can, let us know! W e can become rich together . Or , like the scientist s who \u201cdiscov-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "become",
          "rich",
          "together",
          "like",
          "scientist",
          "discov"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a simple policy: fifo",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "policy",
          "fifo"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand , page 5). w e again begin our trace with three compulsory mis ses to",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "begin",
          "trace",
          "three",
          "compulsory"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E S 5\nResulting\nAccess Hit/Miss? Evict Cache State\n0 Miss First-in \u2192 0\n1 Miss First-in \u2192 0, 1\n2 Miss First-in \u2192 0, 1, 2\n0 Hit First-in \u2192 0, 1, 2\n1 Hit First-in \u2192 0, 1, 2\n3 Miss 0 First-in \u2192 1, 2, 3\n0 Miss 1 First-in \u2192 2, 3, 0\n3 Hit First-in \u2192 2, 3, 0\n1 Miss 2 First-in \u2192 3, 0, 1\n2 Miss 3 First-in \u2192 0, 1, 2\n1 Hit First-in \u2192 0, 1, 2\nFigure 22.2: T racing The FIFO Policy\npages 0, 1, and 2, and then hit on both 0 and 1. Next, page 3 is refer enced,\ncausing a miss; the replacement decision is easy with FIFO: pi ck the page\nthat was the \u201c\ufb01rst one\u201d in (the cache state in the \ufb01gure is kept i n FIFO\norder , with the \ufb01rst-in page on the left), which is page 0. Unfort unately ,\nour next access is to page 0, causing another miss and replaceme nt (of\npage 1). W e then hit on page 3, but miss on 1 and 2, and \ufb01nally hit on 3 .\nComparing FIFO to optimal, FIFO does notably worse: a 36.4% hit\nrate (or 57.1% excluding compulsory misses). FIFO simply can\u2019t d eter-\nmine the importance of blocks: even though page 0 had been accesse d\na number of times, FIFO still kicks it out, simply because it was the \ufb01rst\none brought into memory .\nAS I D E : B E L A D Y \u2019 S AN O M A LY\nBelady (of the optimal policy) and colleagues found an interestin g refer-\nence stream that behaved a little unexpectedly [BNS69]. The m emory-\nreference stream: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5. The replacem ent policy\nthey were studying was FIFO. The interesting part: how the cac he hit\nrate changed when moving from a cache size of 3 to 4 pages.\nIn general, you would expect the cache hit rate to increase (get better)\nwhen the cache gets larger . But in this case, with FIFO, it get s worse! Cal-\nculate the hits and misses yourself and see. This odd behavior is generally\nreferred to as Belady\u2019s Anomaly (to the chagrin of his co-authors).\nSome other policies, such as LRU, don\u2019t suffer from this problem. Can\nyou guess why? As it turns out, LRU has what is known as a stack prop-\nerty [M+70]. For algorithms with this property , a cache of size N + 1\nnaturally includes the contents of a cache of size N. Thus, when increas-\ning the cache size, hit rate will either stay the same or improve . FIFO and\nRandom (among others) clearly do not obey the stack property , and th us\nare susceptible to anomalous behavior .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "you guess why? As it turns out, LRU has what is known as a stack prop-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "guess",
          "turns",
          "known",
          "stack",
          "prop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "erty [M+70]. For algorithms with this property , a cache of size N + 1",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "erty",
          "algorithms",
          "property",
          "cache",
          "size"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 2: T racing The FIFO Policy",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "racing",
          "fifo",
          "policy"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand AS I D E: B E L A D Y \u2019 S AN O M A LY",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand reference stream: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5. The replacem ent policy",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "reference stream",
          "replacem",
          "policy"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "4 Another Simple Policy: Random",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "22.4 Another Simple Policy: Random\nAnother similar replacement policy is Random, which simply pic ks a\nrandom page to replace under memory pressure. Random has propert ies\nsimilar to FIFO; it is simple to implement, but it doesn\u2019t reall y try to be\ntoo intelligent in picking which blocks to evict. Let\u2019s look at how R andom\ndoes on our famous example reference stream (see Figure 22.3).\nOf course, how Random does depends entirely upon how lucky (or\nunlucky) Random gets in its choices. In the example above, Random does\na little better than FIFO, and a little worse than optimal. In fa ct, we can\nrun the Random experiment thousands of times and determine how it\ndoes in general. Figure 22.4 shows how many hits Random achieves ov er\n10,000 trials, each with a different random seed. As you can see , some-\ntimes (just over 40% of the time), Random is as good as optimal, achie ving\n6 hits on the example trace; sometimes it does much worse, achievi ng 2\nhits or fewer . How Random does depends on the luck of the draw .\n0 1 2 3 4 5 6 7\n0\n10\n20\n30\n40\n50\nNumber of Hits\nFrequency\nFigure 22.4: Random Performance Over 10,000 T rials\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "similar to FIFO; it is simple to implement, but it doesn\u2019t reall y try to be",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "similar",
          "fifo",
          "simple",
          "implement",
          "reall"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 4: Random Performance Over 10,000 T rials",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "random",
          "performance",
          "rials"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand another simple policy: random",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "simple",
          "policy",
          "random"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "5 Using History: LRU",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "22.5 Using History: LRU\nUnfortunately , any policy as simple as FIFO or Random is likely to\nhave a common problem: it might kick out an important page, one that\nis about to be referenced again. FIFO kicks out the page that was \ufb01rst\nbrought in; if this happens to be a page with important code or data\nstructures upon it, it gets thrown out anyhow , even though it will s oon be\npaged back in. Thus, FIFO, Random, and similar policies are not l ikely to\napproach optimal; something smarter is needed.\nAs we did with scheduling policy , to improve our guess at the futu re,\nwe once again lean on the past and use history as our guide. For example,\nif a program has accessed a page in the near past, it is likely to access it\nagain in the near future.\nOne type of historical information a page-replacement policy coul d\nuse is frequency; if a page has been accessed many times, perhaps it\nshould not be replaced as it clearly has some value. A more commonly-\nused property of a page is its recency of access; the more recently a page\nhas been accessed, perhaps the more likely it will be accessed again.\nThis family of policies is based on what people refer to as the prin-\nciple of locality [D70], which basically is just an observation about pro-\ngrams and their behavior . What this principle says, quite sim ply , is that\nprograms tend to access certain code sequences (e.g., in a loop) a nd data\nstructures (e.g., an array accessed by the loop) quite frequen tly; we should\nthus try to use history to \ufb01gure out which pages are important, an d keep\nthose pages in memory when it comes to eviction time.\nAnd thus, a family of simple historically-based algorithms are born.\nThe Least-Frequently-Used (LFU) policy replaces the least-frequently-\nused page when an eviction must take place. Similarly , the Least-Recently-\nUsed (LRU) policy replaces the least-recently-used page. These algo-\nrithms are easy to remember: once you know the name, you know exactl y\nwhat it does, which is an excellent property for a name.\nT o better understand LRU, let\u2019s examine how LRU does on our exam-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "have a common problem: it might kick out an important page, one that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "problem",
          "might",
          "kick",
          "important",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "brought in; if this happens to be a page with important code or data",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "brought",
          "happens",
          "page",
          "important",
          "code",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "approach optimal; something smarter is needed.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "optimal",
          "something",
          "smarter",
          "needed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "grams and their behavior . What this principle says, quite sim ply , is that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "grams",
          "behavior",
          "principle",
          "says",
          "quite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "thus try to use history to \ufb01gure out which pages are important, an d keep",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "history",
          "pages",
          "important",
          "keep"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "And thus, a family of simple historically-based algorithms are born.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "family",
          "simple",
          "historically",
          "based",
          "algorithms",
          "born"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "rithms are easy to remember: once you know the name, you know exactl y",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rithms",
          "easy",
          "remember",
          "know",
          "name",
          "know",
          "exactl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "T o better understand LRU, let\u2019s examine how LRU does on our exam-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "better",
          "understand",
          "examine",
          "exam"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand using history: lru",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "history"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "6 W orkload Examples",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "22.6 W orkload Examples\nLet\u2019s look at a few more examples in order to better understand how\nsome of these policies behave. Here, we\u2019ll examine more complex work-\nloads instead of small traces. However , even these workloads are great ly\nsimpli\ufb01ed; a better study would include application traces.\nOur \ufb01rst workload has no locality , which means that each referen ce\nis to a random page within the set of accessed pages. In this simp le ex-\nample, the workload accesses 100 unique pages over time, choosing the\nnext page to refer to at random; overall, 10,000 pages are acces sed. In the\nexperiment, we vary the cache size from very small (1 page) to e nough\nto hold all the unique pages (100 page), in order to see how each pol icy\nbehaves over the range of cache sizes.\n2 OK, we cooked the results. But sometimes cooking is necessary to prov e a point.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s look at a few more examples in order to better understand how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "look",
          "examples",
          "order",
          "better",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand w orkload examples",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "orkload",
          "examples"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "BE Y O N D PH Y S I C A L ME M O RY: P O L I C I E S 9\n0 20 40 60 80 100\n0%\n20%\n40%\n60%\n80%\n100%\nThe No-Locality Workload\nCache Size (Blocks)\nHit Rate\nOPT\nLRU\nFIFO\nRAND\nFigure 22.6: The No-Locality W orkload\nFigure 22.6 plots the results of the experiment for optimal, LRU, Ran-\ndom, and FIFO. The y-axis of the \ufb01gure shows the hit rate that each policy\nachieves; the x-axis varies the cache size as described above .\nW e can draw a number of conclusions from the graph. First, when\nthere is no locality in the workload, it doesn\u2019t matter much which r ealistic\npolicy you are using; LRU, FIFO, and Random all perform the same, w ith\nthe hit rate exactly determined by the size of the cache. Second, when\nthe cache is large enough to \ufb01t the entire workload, it also doesn\u2019t matter\nwhich policy you use; all policies (even Random) converge to a 100% hit\nrate when all the referenced blocks \ufb01t in cache. Finally , you ca n see that\noptimal performs noticeably better than the realistic policies ; peeking into\nthe future, if it were possible, does a much better job of replacem ent.\nThe next workload we examine is called the \u201c80-20\u201d workload, whic h\nexhibits locality: 80% of the references are made to 20% of the pa ges (the\n\u201chot\u201d pages); the remaining 20% of the references are made to th e re-\nmaining 80% of the pages (the \u201ccold\u201d pages). In our workload, there are\na total 100 unique pages again; thus, \u201chot\u201d pages are referred t o most of\nthe time, and \u201ccold\u201d pages the remainder . Figure 22.7 (page 10 ) shows\nhow the policies perform with this workload.\nAs you can see from the \ufb01gure, while both random and FIFO do rea-\nsonably well, LRU does better , as it is more likely to hold onto the h ot\npages; as those pages have been referred to frequently in the p ast, they\nare likely to be referred to again in the near future. Optimal once again\ndoes better , showing that LRU\u2019s historical information is not perfe ct.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "achieves; the x-axis varies the cache size as described above .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "achieves",
          "axis",
          "varies",
          "cache",
          "size",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 6: The No-Locality W orkload",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "locality",
          "orkload"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand whic h\nexhibits locality: 80% of the references are made to 20% of the pa ges (the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "whic h\nexhibits locality",
          "references",
          "made"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 B E Y O N D PH Y S I C A L ME M O RY: P O L I C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 B E Y O N D PH Y S I C A L ME M O RY: P O L I C I E S\n0 20 40 60 80 100\n0%\n20%\n40%\n60%\n80%\n100%\nThe 80-20 Workload\nCache Size (Blocks)\nHit Rate\nOPT\nLRU\nFIFO\nRAND\nFigure 22.7: The 80-20 W orkload\nY ou might now be wondering: is LRU\u2019s improvement over Random\nand FIFO really that big of a deal? The answer , as usual, is \u201cit d epends.\u201d If\neach miss is very costly (not uncommon), then even a small increas e in hit\nrate (reduction in miss rate) can make a huge difference on perf ormance.\nIf misses are not so costly , then of course the bene\ufb01ts possible wit h LRU\nare not nearly as important.\nLet\u2019s look at one \ufb01nal workload. W e call this one the \u201clooping sequen-\ntial\u201d workload, as in it, we refer to 50 pages in sequence, start ing at 0,\nthen 1, ..., up to page 49, and then we loop, repeating those acces ses, for a\ntotal of 10,000 accesses to 50 unique pages. The last graph in Fi gure 22.8\nshows the behavior of the policies under this workload.\nThis workload, common in many applications (including important\ncommercial applications such as databases [CD85]), represen ts a worst-\ncase for both LRU and FIFO. These algorithms, under a looping-sequ ential\nworkload, kick out older pages; unfortunately , due to the looping na ture\nof the workload, these older pages are going to be accessed sooner tha n\nthe pages that the policies prefer to keep in cache. Indeed, ev en with\na cache of size 49, a looping-sequential workload of 50 pages result s in\na 0% hit rate. Interestingly , Random fares notably better , not q uite ap-\nproaching optimal, but at least achieving a non-zero hit rate. T urns out\nthat random has some nice properties; one such property is not havin g\nweird corner-case behaviors.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "are not nearly as important.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "nearly",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "This workload, common in many applications (including important",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "workload",
          "common",
          "many",
          "applications",
          "including",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "case for both LRU and FIFO. These algorithms, under a looping-sequ ential",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "case",
          "fifo",
          "algorithms",
          "looping",
          "sequ",
          "ential"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "7 Implementing Historical Algorithms",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "22.7 Implementing Historical Algorithms\nAs you can see, an algorithm such as LRU can generally do a better\njob than simpler policies like FIFO or Random, which may throw out\nimportant pages. Unfortunately , historical policies present u s with a new\nchallenge: how do we implement them?\nLet\u2019s take, for example, LRU. T o implement it perfectly , we nee d to\ndo a lot of work. Speci\ufb01cally , upon each page access (i.e., each memory\naccess, whether an instruction fetch or a load or store), we must up date\nsome data structure to move this page to the front of the list (i.e. , the\nMRU side). Contrast this to FIFO, where the FIFO list of pages is only\naccessed when a page is evicted (by removing the \ufb01rst-in page) or when a\nnew page is added to the list (to the last-in side). T o keep tra ck of which\npages have been least- and most-recently used, the system has to do some\naccounting work on every memory reference. Clearly , without great care,\nsuch accounting could greatly reduce performance.\nOne method that could help speed this up is to add a little bit of ha rd-\nware support. For example, a machine could update, on each page ac cess,\na time \ufb01eld in memory (for example, this could be in the per-proces s page\ntable, or just in some separate array in memory , with one entry per phys-\nical page of the system). Thus, when a page is accessed, the tim e \ufb01eld\nwould be set, by hardware, to the current time. Then, when repl acing a\npage, the OS could simply scan all the time \ufb01elds in the system t o \ufb01nd the\nleast-recently-used page.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Implementing Historical Algorithms",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "historical",
          "algorithms"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "As you can see, an algorithm such as LRU can generally do a better",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "generally",
          "better"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "important pages. Unfortunately , historical policies present u s with a new",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "pages",
          "unfortunately",
          "historical",
          "policies",
          "present"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "challenge: how do we implement them?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "challenge",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Let\u2019s take, for example, LRU. T o implement it perfectly , we nee d to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "take",
          "example",
          "implement",
          "perfectly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "MRU side). Contrast this to FIFO, where the FIFO list of pages is only",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "side",
          "contrast",
          "fifo",
          "fifo",
          "list",
          "pages"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "One method that could help speed this up is to add a little bit of ha rd-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "method",
          "could",
          "help",
          "speed",
          "little"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand implementing historical algorithms",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "historical",
          "algorithms"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "8 Approximating LRU",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "22.8 Approximating LRU\nAs it turns out, the answer is yes: approximating LRU is more fea-\nsible from a computational-overhead standpoint, and indeed it is what\nmany modern systems do. The idea requires some hardware support,\nin the form of a use bit (sometimes called the reference bit ), the \ufb01rst of\nwhich was implemented in the \ufb01rst system with paging, the Atl as one-\nlevel store [KE+62]. There is one use bit per page of the system, a nd the\nuse bits live in memory somewhere (they could be in the per-proces s page\ntables, for example, or just in an array somewhere). Whenever a p age is\nreferenced (i.e., read or written), the use bit is set by hardw are to 1. The\nhardware never clears the bit, though (i.e., sets it to 0); tha t is the respon-\nsibility of the OS.\nHow does the OS employ the use bit to approximate LRU? W ell, there\ncould be a lot of ways, but with the clock algorithm [C69], one simple\napproach was suggested. Imagine all the pages of the system arr anged in\na circular list. A clock hand points to some particular page to begin with\n(it doesn\u2019t really matter which). When a replacement must occur , the OS\nchecks if the currently-pointed to page P has a use bit of 1 or 0. If 1, this\nimplies that page P was recently used and thus is not a good candidate\nfor replacement. Thus, the use bit for P set to 0 (cleared), and the clock\nhand is incremented to the next page ( P + 1). The algorithm continues\nuntil it \ufb01nds a use bit that is set to 0, implying this page has n ot been\nrecently used (or , in the worst case, that all pages have been an d that we\nhave now searched through the entire set of pages, clearing all t he bits).\nNote that this approach is not the only way to employ a use bit to\napproximate LRU. Indeed, any approach which periodically clea rs the\nuse bits and then differentiates between which pages have us e bits of 1\nversus 0 to decide which to replace would be \ufb01ne. The clock algori thm of\nCorbato\u2019s was just one early approach which met with some success, a nd\nhad the nice property of not repeatedly scanning through all of mem ory\nlooking for an unused page.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "which was implemented in the \ufb01rst system with paging, the Atl as one-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implemented",
          "system",
          "paging"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "could be a lot of ways, but with the clock algorithm [C69], one simple",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "could",
          "ways",
          "clock",
          "algorithm",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "approach was suggested. Imagine all the pages of the system arr anged in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "suggested",
          "imagine",
          "pages",
          "system",
          "anged"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "hand is incremented to the next page ( P + 1). The algorithm continues",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hand",
          "incremented",
          "next",
          "page",
          "algorithm",
          "continues"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Note that this approach is not the only way to employ a use bit to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "note",
          "approach",
          "employ"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "approximate LRU. Indeed, any approach which periodically clea rs the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approximate",
          "indeed",
          "approach",
          "periodically",
          "clea"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "Corbato\u2019s was just one early approach which met with some success, a nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "corbato",
          "early",
          "approach",
          "success"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand the answer is yes: approximating LRU is more fea-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the answer is yes",
          "approximating"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand approximating lru",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "approximating"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the OS employ the use bit to approximate LRU",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "employ",
          "approximate"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "9 Considering Dirty Pages",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "22.9 Considering Dirty Pages\nOne small modi\ufb01cation to the clock algorithm (also originally sug -\ngested by Corbato [C69]) that is commonly made is the additional c on-\nsideration of whether a page has been modi\ufb01ed or not while in memory .\nThe reason for this: if a page has been modi\ufb01ed and is thus dirty, it must\nbe written back to disk to evict it, which is expensive. If it h as not been\nmodi\ufb01ed (and is thus clean), the eviction is free; the physical frame can\nsimply be reused for other purposes without additional I/O. Thus, some\nVM systems prefer to evict clean pages over dirty pages.\nT o support this behavior , the hardware should include a modi\ufb01ed bit\n(a.k.a. dirty bit ). This bit is set any time a page is written, and thus can be\nincorporated into the page-replacement algorithm. The clock al gorithm,\nfor example, could be changed to scan for pages that are both unuse d\nand clean to evict \ufb01rst; failing to \ufb01nd those, then for unused pa ges that\nare dirty , and so forth.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One small modi\ufb01cation to the clock algorithm (also originally sug -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "small",
          "clock",
          "algorithm",
          "also",
          "originally"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "incorporated into the page-replacement algorithm. The clock al gorithm,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "incorporated",
          "page",
          "replacement",
          "algorithm",
          "clock",
          "gorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand The reason for this: if a page has been modi\ufb01ed and is thus dirty, it must",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the reason for this",
          "page",
          "thus",
          "dirty",
          "must"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand considering dirty pages",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "considering",
          "dirty",
          "pages"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "10 Other VM Policies",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "22.10 Other VM Policies\nPage replacement is not the only policy the VM subsystem employs\n(though it may be the most important). For example, the OS also has to\ndecide when to bring a page into memory . This policy , sometimes called\nthe page selection policy (as it was called by Denning [D70]), presents\nthe OS with some different options.\nFor most pages, the OS simply uses demand paging , which means the\nOS brings the page into memory when it is accessed, \u201con demand\u201d a s\nit were. Of course, the OS could guess that a page is about to be use d,\nand thus bring it in ahead of time; this behavior is known as prefetching\nand should only be done when there is reasonable chance of success. For\nexample, some systems will assume that if a code page P is brought into\nmemory , that code page P +1 will likely soon be accessed and thus should\nbe brought into memory too.\nAnother policy determines how the OS writes pages out to disk. Of\ncourse, they could simply be written out one at a time; however , man y\nsystems instead collect a number of pending writes together in m emory\nand write them to disk in one (more ef\ufb01cient) write. This behavi or is\nusually called clustering or simply grouping of writes, and is effective\nbecause of the nature of disk drives, which perform a single larg e write\nmore ef\ufb01ciently than many small ones.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "(though it may be the most important). For example, the OS also has to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "though",
          "important",
          "example",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "and thus bring it in ahead of time; this behavior is known as prefetching",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "bring",
          "ahead",
          "time",
          "behavior",
          "known",
          "prefetching"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand other vm policies",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "policies"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "22",
    "title": "11 Thrashing",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "22.11 Thrashing\nBefore closing, we address one \ufb01nal question: what should the OS do\nwhen memory is simply oversubscribed, and the memory demands of t he\nset of running processes simply exceeds the available physica l memory?\nIn this case, the system will constantly be paging, a condition s ometimes\nreferred to as thrashing [D70].\nSome earlier operating systems had a fairly sophisticated set of m ech-\nanisms to both detect and cope with thrashing when it took place. F or\nexample, given a set of processes, a system could decide not to run a sub-\nset of processes, with the hope that the reduced set of processes\u2019 working\nsets (the pages that they are using actively) \ufb01t in memory and thus c an\nmake progress. This approach, generally known as admission control ,\nstates that it is sometimes better to do less work well than to tr y to do\neverything at once poorly , a situation we often encounter in real li fe as\nwell as in modern computer systems (sadly).\nSome current systems take more a draconian approach to memory\noverload. For example, some versions of Linux run an out-of-memory\nkiller when memory is oversubscribed; this daemon chooses a memory-\nintensive process and kills it, thus reducing memory in a none-t oo-subtle\nmanner . While successful at reducing memory pressure, this a pproach\ncan have problems, if, for example, it kills the X server and thu s renders\nany applications requiring the display unusable.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "make progress. This approach, generally known as admission control ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "progress",
          "approach",
          "generally",
          "known",
          "admission",
          "control"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Some current systems take more a draconian approach to memory",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "current",
          "systems",
          "take",
          "draconian",
          "approach",
          "memory"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand thrashing",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "thrashing"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "22",
    "title": "12 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "22.12 Summary\nW e have seen the introduction of a number of page-replacement (an d\nother) policies, which are part of the VM subsystem of all modern ope rat-\ning systems. Modern systems add some tweaks to straightforward LRU\napproximations like clock; for example, scan resistance is an important\npart of many modern algorithms, such as ARC [MM03]. Scan-resista nt al-\ngorithms are usually LRU-like but also try to avoid the worst-ca se behav-\nior of LRU, which we saw with the looping-sequential workload. Thus ,\nthe evolution of page-replacement algorithms continues.\nHowever , in many cases the importance of said algorithms has de-\ncreased, as the discrepancy between memory-access and disk- access times\nhas increased. Because paging to disk is so expensive, the cos t of frequent\npaging is prohibitive. Thus, the best solution to excessive pag ing is often\na simple (if intellectually unsatisfying) one: buy more memory .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "approximations like clock; for example, scan resistance is an important",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approximations",
          "like",
          "clock",
          "example",
          "scan",
          "resistance",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "part of many modern algorithms, such as ARC [MM03]. Scan-resista nt al-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "part",
          "many",
          "modern",
          "algorithms",
          "scan",
          "resista"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the evolution of page-replacement algorithms continues.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "evolution",
          "page",
          "replacement",
          "algorithms",
          "continues"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "However , in many cases the importance of said algorithms has de-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "many",
          "cases",
          "importance",
          "said",
          "algorithms"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1989",
    "title": "The famous paper that would have revolutionized the world in providing an easy w ay to generate",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "1989. The famous paper that would have revolutionized the world in providing an easy w ay to generate\nnearly-in\ufb01nite power from jars of water with a little metal in them. Unfortunately , the results pub-\nlished (and widely publicized) by Pons and Fleischmann were impossi ble to reproduce, and thus these\ntwo well-meaning scientists were discredited (and certainly, mocked). Th e only guy really happy about\nthis result was Marvin Hawkins, whose name was left off this paper even thoug h he participated in the\nwork, thus avoiding association with one of the biggest scienti\ufb01c goofs of the 20th c entury.\n[HP06] \u201cComputer Architecture: A Quantitative Approach\u201d by John Hennessy and David\nPatterson. Morgan-Kaufmann, 2006. A marvelous book about computer architecture. Read it!\n[H87] \u201cAspects of Cache Memory and Instruction Buffer Performance\u201d by Mark D . Hill. Ph.D.\nDissertation, U.C. Berkeley , 1987. Mark Hill, in his dissertation work, introduced the Three C\u2019s,\nwhich later gained wide popularity with its inclusion in H&P [HP06]. The q uote from therein: \u201cI have\nfound it useful to partition misses ... into three components intuitively b ased on the cause of the misses\n(page 49).\u201d\n[KE+62] \u201cOne-level Storage System\u201d by T . Kilburn, D.B.G. Edwards , M.J. Lanigan, F .H. Sum-\nner . IRE T rans. EC-11:2, 1962. Although Atlas had a use bit, it only had a very small number of pages,\nand thus the scanning of the use bits in large memories was not a problem the auth ors solved.\n[M+70] \u201cEvaluation T echniques for Storage Hierarchies\u201d by R. L. Matts on, J. Gecsei, D. R.\nSlutz, I. L. T raiger . IBM Systems Journal, V olume 9:2, 1970. A paper that is mostly about how to\nsimulate cache hierarchies ef\ufb01ciently; certainly a classic in that reg ard, as well for its excellent discussion\nof some of the properties of various replacement algorithms. Can you \ufb01gure out w hy the stack property\nmight be useful for simulating a lot of different-sized caches at once?\n[MM03] \u201cARC: A Self-T uning, Low Overhead Replacement Cache\u201d by Nimrod Megid do and\nDharmendra S. Modha. F AST 2003, February 2003, San Jose, California . An excellent modern\npaper about replacement algorithms, which includes a new policy, ARC , that is now used in some\nsystems. Recognized in 2014 as a \u201cT est of Time\u201d award winner by the storage systems community at\nthe F AST \u201914 conference.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[HP06] \u201cComputer Architecture: A Quantitative Approach\u201d by John Hennessy and David",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "computer",
          "architecture",
          "quantitative",
          "approach",
          "john",
          "hennessy",
          "david"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "and thus the scanning of the use bits in large memories was not a problem the auth ors solved.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "scanning",
          "bits",
          "large",
          "memories",
          "problem",
          "auth",
          "solved"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of some of the properties of various replacement algorithms. Can you \ufb01gure out w hy the stack property",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "properties",
          "various",
          "replacement",
          "algorithms",
          "stack",
          "property"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "paper about replacement algorithms, which includes a new policy, ARC , that is now used in some",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "paper",
          "replacement",
          "algorithms",
          "includes",
          "policy",
          "used"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 11: 2, 1962. Although Atlas had a use bit, it only had a very small number of pages,",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "11",
          "although",
          "atlas",
          "small",
          "number",
          "pages"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 9: 2, 1970. A paper that is mostly about how to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 9",
          "paper",
          "mostly"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand ARC: A Self-T uning, Low Overhead Replacement Cache\u201d by Nimrod Megid do and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "arc",
          "self",
          "uning",
          "overhead",
          "replacement",
          "cache",
          "nimrod",
          "megid"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Generate random addresses with the following arguments: -s 0",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "1. Generate random addresses with the following arguments: -s 0\n-n 10, -s 1 -n 10, and -s 2 -n 10. Change the policy from\nFIFO, to LRU, to OPT . Compute whether each access in said addre ss\ntraces are hits or misses.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand n 10, -s 1 -n 10, and -s 2 -n 10. change the policy from",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "change",
          "policy"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "For a cache of size 5, generate worst-case address reference s treams",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "2. For a cache of size 5, generate worst-case address reference s treams\nfor each of the following policies: FIFO, LRU, and MRU (worst-case\nreference streams cause the most misses possible. For the worst c ase\nreference streams, how much bigger of a cache is needed to improv e\nperformance dramatically and approach OPT?\n3. Generate a random trace (use python or perl). How would you\nexpect the different policies to perform on such a trace?\n4. Now generate a trace with some locality . How can you generate\nsuch a trace? How does LRU perform on it? How much better than\nRAND is LRU? How does CLOCK do? How about CLOCK with\ndifferent numbers of clock bits?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "performance dramatically and approach OPT?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "dramatically",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand LRU perform on it",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "perform"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Use a program like valgrind to instrument a real application and",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "5. Use a program like valgrind to instrument a real application and\ngenerate a virtual page reference stream. For example, runni ng\nvalgrind --tool=lackey --trace-mem=yes ls will output\na nearly-complete reference trace of every instruction and dat a ref-\nerence made by the program ls. T o make this useful for the sim-\nulator above, you\u2019ll have to \ufb01rst transform each virtual memory\nreference into a virtual page-number reference (done by mask ing\noff the offset and shifting the resulting bits downward). How big\nof a cache is needed for your application trace in order to satisfy a\nlarge fraction of requests? Plot a graph of its working set as the si ze\nof the cache increases.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "23\nComplete Virtual Memory Systems\nBefore we end our study of virtualizing memory , let us take a closer look\nat how entire virtual memory systems are put together . W e\u2019ve seen key\nelements of such systems, including numerous page-table desi gns, inter-\nactions with the TLB (sometimes, even handled by the OS itself) , and\nstrategies for deciding which pages to keep in memory and which to kick\nout. However , there are many other features that comprise a comple te\nvirtual memory system, including numerous features for perform ance,\nfunctionality , and security . And thus, our crux:\nTH E CR U X : H O W TO BU I L D A C O M P L E T E VM S Y S T E M\nWhat features are needed to realize a complete virtual memory s ys-\ntem? How do they improve performance, increase security , or other wise\nimprove the system?\nW e\u2019ll do this by covering two systems. The \ufb01rst is one of the earli-\nest examples of a \u201cmodern\u201d virtual memory manager , that found in t he\nV AX/VMSoperating system [LL82], as developed in the 1970\u2019s and early\n1980\u2019s; a surprising number of techniques and approaches from th is sys-\ntem survive to this day , and thus it is well worth studying. Some i deas,\neven those that are 50 years old, are still worth knowing, a thought that\nis well known to those in most other \ufb01elds (e.g., Physics), but has to be\nstated in technology-driven disciplines (e.g., Computer Scien ce).\nThe second is that of Linux, for reasons that should be obvious. Linux\nis a widely used system, and runs effectively on systems as sma ll and\nunderpowered as phones to the most scalable multicore systems fou nd\nin modern datacenters. Thus, its VM system must be \ufb02exible enou gh to\nrun successfully in all of those scenarios. W e will discuss each system to\nillustrate how concepts brought forth in earlier chapters come tog ether in\na complete memory manager .\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "V AX/VMSoperating system [LL82], as developed in the 1970\u2019s and early",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "vmsoperating",
          "system",
          "developed",
          "early"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "\u2019s; a surprising number of techniques and approaches from th is sys-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "surprising",
          "number",
          "techniques",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "even those that are 50 years old, are still worth knowing, a thought that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "even",
          "years",
          "still",
          "worth",
          "knowing",
          "thought"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "is well known to those in most other \ufb01elds (e.g., Physics), but has to be",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "well",
          "known",
          "physics"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "illustrate how concepts brought forth in earlier chapters come tog ether in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "illustrate",
          "concepts",
          "brought",
          "forth",
          "earlier",
          "chapters",
          "come",
          "ether"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand our crux: TH E CR U X : H O W TO BU I L D A C O M P L E T E VM S Y S T E M",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "our crux"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "23",
    "title": "1 V AX/VMS Virtual Memory",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "23.1 V AX/VMS Virtual Memory\nThe V AX-11 minicomputer architecture was introduced in the la te 1970\u2019s\nby Digital Equipment Corporation (DEC). DEC was a massive player\nin the computer industry during the era of the mini-computer; un fortu-\nnately , a series of bad decisions and the advent of the PC slowly (b ut\nsurely) led to their demise [C03]. The architecture was real ized in a num-\nber of implementations, including the V AX-11/780 and the less powerful\nV AX-11/750.\nThe OS for the system was known as V AX/VMS (or just plain VMS),\none of whose primary architects was Dave Cutler , who later led th e effort\nto develop Microsoft\u2019s Windows NT [C93]. VMS had the general prob-\nlem that it would be run on a broad range of machines, including ver y\ninexpensive V AXen (yes, that is the proper plural) to extreme ly high-end\nand powerful machines in the same architecture family . Thus, the OS had\nto have mechanisms and policies that worked (and worked well) ac ross\nthis huge range of systems.\nAs an additional issue, VMS is an excellent example of software i nno-\nvations used to hide some of the inherent \ufb02aws of the architecture . Al-\nthough the OS often relies on the hardware to build ef\ufb01cient abst ractions\nand illusions, sometimes the hardware designers don\u2019t quite get every-\nthing right; in the V AX hardware, we\u2019ll see a few examples of thi s, and\nwhat the VMS operating system does to build an effective, workin g sys-\ntem despite these hardware \ufb02aws.\nMemory Management Hardware\nThe V AX-11 provided a 32-bit virtual address space per process , divided\ninto 512-byte pages. Thus, a virtual address consisted of a 23- bit VPN\nand a 9-bit offset. Further , the upper two bits of the VPN were us ed to\ndifferentiate which segment the page resided within; thus, the system\nwas a hybrid of paging and segmentation, as we saw previously .\nThe lower-half of the address space was known as \u201cprocess space\u201d a nd\nis unique to each process. In the \ufb01rst half of process space (known as P0),\nthe user program is found, as well as a heap which grows downward.\nIn the second half of process space ( P1), we \ufb01nd the stack, which grows\nupwards. The upper-half of the address space is known as system space\n(S), although only half of it is used. Protected OS code and data resid e\nhere, and the OS is in this way shared across processes.\nOne major concern of the VMS designers was the incredibly small s ize\nof pages in the V AX hardware (512 bytes). This size, chosen for hi storical\nreasons, has the fundamental problem of making simple linear pa ge ta-\nbles excessively large. Thus, one of the \ufb01rst goals of the VMS desi gners\nwas to ensure that VMS would not overwhelm memory with page tables .\nThe system reduced the pressure page tables place on memory in t wo\nways. First, by segmenting the user address space into two, th e V AX-11\nprovides a page table for each of these regions ( P0 and P1) per process;\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ber of implementations, including the V AX-11/780 and the less powerful",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementations",
          "including",
          "less",
          "powerful"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The OS for the system was known as V AX/VMS (or just plain VMS),",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "known",
          "plain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "to develop Microsoft\u2019s Windows NT [C93]. VMS had the general prob-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "develop",
          "microsoft",
          "windows",
          "general",
          "prob"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "and illusions, sometimes the hardware designers don\u2019t quite get every-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "illusions",
          "sometimes",
          "hardware",
          "designers",
          "quite",
          "every"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The lower-half of the address space was known as \u201cprocess space\u201d a nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lower",
          "half",
          "address",
          "space",
          "known",
          "process",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "is unique to each process. In the \ufb01rst half of process space (known as P0),",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unique",
          "process",
          "half",
          "process",
          "space",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "upwards. The upper-half of the address space is known as system space",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "upwards",
          "upper",
          "half",
          "address",
          "space",
          "known",
          "system",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "One major concern of the VMS designers was the incredibly small s ize",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "major",
          "concern",
          "designers",
          "incredibly",
          "small"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "reasons, has the fundamental problem of making simple linear pa ge ta-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reasons",
          "fundamental",
          "problem",
          "making",
          "simple",
          "linear"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "bles excessively large. Thus, one of the \ufb01rst goals of the VMS desi gners",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bles",
          "excessively",
          "large",
          "thus",
          "goals",
          "desi",
          "gners"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand v ax/vms virtual memory",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "virtual",
          "memory"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 3\nAS I D E : T H E CU R S E OF GE N E R A L I T Y\nOperating systems often have a problem known as the curse of gener-\nality, where they are tasked with general support for a broad class of\napplications and systems. The fundamental result of the curse is that the\nOS is not likely to support any one installation very well. In the c ase of\nVMS, the curse was very real, as the V AX-11 architecture was re alized\nin a number of different implementations. It is no less real toda y , where\nLinux is expected to run well on your phone, a TV set-top box, a laptop\ncomputer , desktop computer , and a high-end server running thous ands\nof processes in a cloud-based datacenter .\nthus, no page-table space is needed for the unused portion of the a ddress\nspace between the stack and the heap. The base and bounds regis ters\nare used as you would expect; a base register holds the address of t he\npage table for that segment, and the bounds holds its size (i.e., number of\npage-table entries).\nSecond, the OS reduces memory pressure even further by placing u ser\npage tables (for P0 and P1, thus two per process) in kernel virtual mem-\nory . Thus, when allocating or growing a page table, the kernel all ocates\nspace out of its own virtual memory , in segment S. If memory comes un-\nder severe pressure, the kernel can swap pages of these page ta bles out to\ndisk, thus making physical memory available for other uses.\nPutting page tables in kernel virtual memory means that addre ss trans-\nlation is even further complicated. For example, to translate a virtual ad-\ndress in P0 or P1, the hardware has to \ufb01rst try to look up the page-table\nentry for that page in its page table (the P0 or P1 page table for that pro-\ncess); in doing so, however , the hardware may \ufb01rst have to consult the\nsystem page table (which lives in physical memory); with that transla-\ntion complete, the hardware can learn the address of the page of th e page\ntable, and then \ufb01nally learn the address of the desired memory a ccess.\nAll of this, fortunately , is made faster by the V AX\u2019s hardware-m anaged\nTLBs, which usually (hopefully) circumvent this laborious looku p.\nA Real Address Space\nOne neat aspect of studying VMS is that we can see how a real addre ss\nspace is constructed (Figure 23.1. Thus far , we have assumed a simple\naddress space of just user code, user data, and user heap, but as we can\nsee above, a real address space is notably more complex.\nFor example, the code segment never begins at page 0. This page,\ninstead, is marked inaccessible, in order to provide some suppor t for de-\ntecting null-pointer accesses. Thus, one concern when designing an ad-\ndress space is support for debugging, which the inaccessible z ero page\nprovides here in some form.\nPerhaps more importantly , the kernel virtual address space (i .e., its\ndata structures and code) is a part of each user address space. O n a con-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Operating systems often have a problem known as the curse of gener-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "systems",
          "often",
          "problem",
          "known",
          "curse",
          "gener"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "applications and systems. The fundamental result of the curse is that the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "applications",
          "systems",
          "fundamental",
          "result",
          "curse"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "in a number of different implementations. It is no less real toda y , where",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "number",
          "different",
          "implementations",
          "less",
          "real",
          "toda"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "tion complete, the hardware can learn the address of the page of th e page",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "complete",
          "hardware",
          "learn",
          "address",
          "page",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "table, and then \ufb01nally learn the address of the desired memory a ccess.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "table",
          "learn",
          "address",
          "desired",
          "memory",
          "ccess"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "tecting null-pointer accesses. Thus, one concern when designing an ad-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tecting",
          "null",
          "pointer",
          "accesses",
          "thus",
          "concern",
          "designing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "Perhaps more importantly , the kernel virtual address space (i .e., its",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "perhaps",
          "importantly",
          "kernel",
          "virtual",
          "address",
          "space"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 C O M P L E T E VI RT U A L ME M O RY SY S T E M...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nPage 0: Invalid\nUser Code\nUser Heap\nUser Stack\nTrap Tables\nKernel Data\nKernel Code\nKernel Heap\nUnused\nSystem (S)\nUser (P1)\nUser (P0)\n0\n230\n231\n232\nFigure 23.1: The V AX/VMS Address Space\ntext switch, the OS changes the P0 and P1 registers to point to the ap-\npropriate page tables of the soon-to-be-run process; however , it doe s not\nchange the S base and bound registers, and as a result the \u201csame\u201d kernel\nstructures are mapped into each user address space.\nThe kernel is mapped into each address space for a number of reas ons.\nThis construction makes life easier for the kernel; when, for exa mple, the\nOS is handed a pointer from a user program (e.g., on a write() system\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 1: The V AX/VMS Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 5\nAS I D E : W H Y NU L L PO I N T E R AC C E S S E S CA U S E SE G FA U LT S\nY ou should now have a good understanding of exactly what happens on\na null-pointer dereference. A process generates a virtual add ress of 0, by\ndoing something like this:\nint *p = NULL; // set p = 0\n*p = 10; // try to store 10 to virtual addr 0\nThe hardware tries to look up the VPN (also 0 here) in the TLB, and suf-\nfers a TLB miss. The page table is consulted, and the entry for VP N 0\nis found to be marked invalid. Thus, we have an invalid access, which\ntransfers control to the OS, which likely terminates the process (on U N I X\nsystems, processes are sent a signal which allows them to react to such a\nfault; if uncaught, however , the process is killed).\ncall), it is easy to copy data from that pointer to its own structur es. The\nOS is naturally written and compiled, without worry of where the d ata\nit is accessing comes from. If in contrast the kernel were located entirely\nin physical memory , it would be quite hard to do things like swap pages\nof the page table to disk; if the kernel were given its own addres s space,\nmoving data between user applications and the kernel would agai n be\ncomplicated and painful. With this construction (now used widel y), the\nkernel appears almost as a library to applications, albeit a pr otected one.\nOne last point about this address space relates to protection. Cl early ,\nthe OS does not want user applications reading or writing OS data or\ncode. Thus, the hardware must support different protection leve ls for\npages to enable this. The V AX did so by specifying, in protecti on bits\nin the page table, what privilege level the CPU must be at in ord er to\naccess a particular page. Thus, system data and code are set to a higher\nlevel of protection than user data and code; an attempted access t o such\ninformation from user code will generate a trap into the OS, and (you\nguessed it) the likely termination of the offending process.\nPage Replacement\nThe page table entry (PTE) in V AX contains the following bits: a v alid\nbit, a protection \ufb01eld (4 bits), a modify (or dirty) bit, a \ufb01eld res erved for\nOS use (5 bits), and \ufb01nally a physical frame number (PFN) to st ore the\nlocation of the page in physical memory . The astute reader might n ote:\nno reference bit ! Thus, the VMS replacement algorithm must make do\nwithout hardware support for determining which pages are activ e.\nThe developers were also concerned about memory hogs , programs\nthat use a lot of memory and make it hard for other programs to run.\nMost of the policies we have looked at thus far are susceptible to su ch\nhogging; for example, LRU is a global policy that doesn\u2019t share memory\nfairly among processes.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Y ou should now have a good understanding of exactly what happens on",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "good",
          "understanding",
          "exactly",
          "happens"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "it is accessing comes from. If in contrast the kernel were located entirely",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "accessing",
          "comes",
          "contrast",
          "kernel",
          "located",
          "entirely"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of the page table to disk; if the kernel were given its own addres s space,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "page",
          "table",
          "disk",
          "kernel",
          "given",
          "addres",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "no reference bit ! Thus, the VMS replacement algorithm must make do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reference",
          "thus",
          "replacement",
          "algorithm",
          "must",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The developers were also concerned about memory hogs , programs",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developers",
          "also",
          "concerned",
          "memory",
          "hogs",
          "programs"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand p = 10; // try to store 10 to virtual addr 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "store",
          "virtual",
          "addr"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 C O M P L E T E VI RT U A L ME M O RY SY S T E M...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nAS I D E : E M U L AT I N G RE F E R E N C E BI T S\nAs it turns out, you don\u2019t need a hardware reference bit in order to g et\nsome notion of which pages are in use in a system. In fact, in the ear ly\n1980\u2019s, Babaoglu and Joy showed that protection bits on the V AX can be\nused to emulate reference bits [BJ81]. The basic idea: if you w ant to gain\nsome understanding of which pages are actively being used in a s ystem,\nmark all of the pages in the page table as inaccessible (but kee p around\nthe information as to which pages are really accessible by the p rocess,\nperhaps in the \u201creserved OS \ufb01eld\u201d portion of the page table entry ). When\na process accesses a page, it will generate a trap into the OS; th e OS will\nthen check if the page really should be accessible, and if so, re vert the\npage to its normal protections (e.g., read-only , or read-write). At the time\nof a replacement, the OS can check which pages remain marked in acces-\nsible, and thus get an idea of which pages have not been recently used.\nThe key to this \u201cemulation\u201d of reference bits is reducing overhe ad while\nstill obtaining a good idea of page usage. The OS must not be too aggre s-\nsive in marking pages inaccessible, or overhead would be too high . The\nOS also must not be too passive in such marking, or all pages will e nd up\nreferenced; the OS will again have no good idea which page to evi ct.\nT o address these two problems, the developers came up with the seg-\nmented FIFO replacement policy [RL81]. The idea is simple: each process\nhas a maximum number of pages it can keep in memory , known as its res-\nident set size (RSS). Each of these pages is kept on a FIFO list; when a\nprocess exceeds its RSS, the \u201c\ufb01rst-in\u201d page is evicted. FIFO cle arly does\nnot need any support from the hardware, and is thus easy to implem ent.\nOf course, pure FIFO does not perform particularly well, as we saw\nearlier . T o improve FIFO\u2019s performance, VMS introduced two second-\nchance lists where pages are placed before getting evicted from memory ,\nspeci\ufb01cally a global clean-page free list and dirty-page list . When a process\nP exceeds its RSS, a page is removed from its per-process FIFO; if cle an\n(not modi\ufb01ed), it is placed on the end of the clean-page list; if di rty (mod-\ni\ufb01ed), it is placed on the end of the dirty-page list.\nIf another process Q needs a free page, it takes the \ufb01rst free page off\nof the global clean list. However , if the original process P faults on that\npage before it is reclaimed, P reclaims it from the free (or dirty) list, thus\navoiding a costly disk access. The bigger these global second-ch ance lists\nare, the closer the segmented FIFO algorithm performs to LRU [RL 81].\nAnother optimization used in VMS also helps overcome the small pag e\nsize in VMS. Speci\ufb01cally , with such small pages, disk I/O durin g swap-\nping could be highly inef\ufb01cient, as disks do better with large transfers.\nT o make swapping I/O more ef\ufb01cient, VMS adds a number of optimiza -\ntions, but most important is clustering. With clustering, VMS groups\nlarge batches of pages together from the global dirty list, and wr ites them\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "some understanding of which pages are actively being used in a s ystem,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "pages",
          "actively",
          "used",
          "ystem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T o address these two problems, the developers came up with the seg-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "address",
          "problems",
          "developers",
          "came"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "has a maximum number of pages it can keep in memory , known as its res-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "maximum",
          "number",
          "pages",
          "keep",
          "memory",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "are, the closer the segmented FIFO algorithm performs to LRU [RL 81].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "closer",
          "segmented",
          "fifo",
          "algorithm",
          "performs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "tions, but most important is clustering. With clustering, VMS groups",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tions",
          "important",
          "clustering",
          "clustering",
          "groups"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 7\nto disk in one fell swoop (thus making them clean). Clustering is used\nin most modern systems, as the freedom to place pages anywhere wi thin\nswap space lets the OS group pages, perform fewer and bigger wri tes,\nand thus improve performance.\nOther Neat T ricks\nVMS had two other now-standard tricks: demand zeroing and copy-on -\nwrite. W e now describe these lazy optimizations. One form of laziness\nin VMS (and most modern systems) is demand zeroing of pages. T o un-\nderstand this better , let\u2019s consider the example of adding a pag e to your\naddress space, say in your heap. In a naive implementation, the OS re-\nsponds to a request to add a page to your heap by \ufb01nding a page in ph ys-\nical memory , zeroing it (required for security; otherwise you\u2019d be able to\nsee what was on the page from when some other process used it!), and\nthen mapping it into your address space (i.e., setting up the p age table to\nrefer to that physical page as desired). But the naive implem entation can\nbe costly , particularly if the page does not get used by the proces s.\nWith demand zeroing, the OS instead does very little work when th e\npage is added to your address space; it puts an entry in the page table that\nmarks the page inaccessible. If the process then reads or write s the page,\na trap into the OS takes place. When handling the trap, the OS n otices\n(usually through some bits marked in the \u201creserved for OS\u201d portion of the\npage table entry) that this is actually a demand-zero page; a t this point,\nthe OS does the needed work of \ufb01nding a physical page, zeroing it, a nd\nmapping it into the process\u2019s address space. If the process neve r accesses\nthe page, all such work is avoided, and thus the virtue of demand z eroing.\nAnother cool optimization found in VMS (and again, in virtually eve ry\nmodern OS) is copy-on-write (COW for short). The idea, which goes at\nleast back to the TENEX operating system [BB+72], is simple: w hen the\nOS needs to copy a page from one address space to another , instead of\ncopying it, it can map it into the target address space and mark it read-\nonly in both address spaces. If both address spaces only read the p age, no\nfurther action is taken, and thus the OS has realized a fast copy without\nactually moving any data.\nIf, however , one of the address spaces does indeed try to write to t he\npage, it will trap into the OS. The OS will then notice that the pa ge is a\nCOW page, and thus (lazily) allocate a new page, \ufb01ll it with the data, and\nmap this new page into the address space of the faulting process . The\nprocess then continues and now has its own private copy of the page.\nCOW is useful for a number of reasons. Certainly any sort of shared\nlibrary can be mapped copy-on-write into the address spaces of m any\nprocesses, saving valuable memory space. In U N I X systems, COW is\neven more critical, due to the semantics of fork() and exec(). As\nyou might recall, fork() creates an exact copy of the address space of\nthe caller; with a large address space, making such a copy is sl ow and\ndata intensive. Even worse, most of the address space is immedia tely\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "write. W e now describe these lazy optimizations. One form of laziness",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "write",
          "describe",
          "lazy",
          "optimizations",
          "form",
          "laziness"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "address space, say in your heap. In a naive implementation, the OS re-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "address",
          "space",
          "heap",
          "naive",
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ical memory , zeroing it (required for security; otherwise you\u2019d be able to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ical",
          "memory",
          "zeroing",
          "required",
          "security",
          "otherwise",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "then mapping it into your address space (i.e., setting up the p age table to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mapping",
          "address",
          "space",
          "setting",
          "table"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "even more critical, due to the semantics of fork() and exec(). As",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "even",
          "critical",
          "semantics",
          "fork",
          "exec"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "you might recall, fork() creates an exact copy of the address space of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "might",
          "recall",
          "fork",
          "creates",
          "exact",
          "copy",
          "address",
          "space"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand standard tricks: demand zeroing and copy-on -",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "standard tricks",
          "demand",
          "zeroing",
          "copy"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "23",
    "title": "2 The Linux Virtual Memory System",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "23.2 The Linux Virtual Memory System\nW e\u2019ll now discuss some of the more interesting aspects of the Linux\nVM system. Linux development has been driven forward by real en gi-\nneers solving real problems encountered in production, and thus a large\nnumber of features have slowly been incorporated into what is now a\nfully functional, feature-\ufb01lled virtual memory system.\nWhile we won\u2019t be able to discuss every aspect of Linux VM, we\u2019ll\ntouch on the most important ones, especially where it has gone beyond\nwhat is found in classic VM systems such as V AX/VMS. W e\u2019ll also tr y to\nhighlight commonalities between Linux and older systems.\nFor this discussion, we\u2019ll focus on Linux for Intel x86. While Linux can\nand does run on many different processor architectures, Linux on x 86 is\nits most dominant and important deployment, and thus the focus of our\nattention.\nThe Linux Address Space\nMuch like other modern operating systems, and also like V AX/VMS,\na Linux virtual address space 1 consists of a user portion (where user\n1 Until recent changes, due to security threats, that is. Read the subsecti ons below about\nLinux security for details on this modi\ufb01cation.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "VM system. Linux development has been driven forward by real en gi-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "linux",
          "development",
          "driven",
          "forward",
          "real"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "While we won\u2019t be able to discuss every aspect of Linux VM, we\u2019ll",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "discuss",
          "every",
          "aspect",
          "linux"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "touch on the most important ones, especially where it has gone beyond",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "touch",
          "important",
          "ones",
          "especially",
          "gone",
          "beyond"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "its most dominant and important deployment, and thus the focus of our",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dominant",
          "important",
          "deployment",
          "thus",
          "focus"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the linux virtual memory system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "linux",
          "virtual",
          "memory",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 9\nPage 0: Invalid\nUser Code\nUser Heap\nUser Stack\nKernel (Logical)\nKernel (Virtual)\nUser\nKernel\n0x00000000\n0xC0000000\nFigure 23.2: The Linux Address Space\nprogram code, stack, heap, and other parts reside) and a kernel p ortion\n(where kernel code, stacks, heap, and other parts reside). Lik e those other\nsystems, upon a context switch, the user portion of the currently- running\naddress space changes; the kernel portion is the same across proc esses.\nLike those other systems, a program running in user mode cannot acc ess\nkernel virtual pages; only by trapping into the kernel and tra nsitioning to\nprivileged mode can such memory be accessed.\nIn classic 32-bit Linux (i.e., Linux with a 32-bit virtual ad dress space),\nthe split between user and kernel portions of the address space t akes\nplace at address 0xC0000000, or three-quarters of the way through the\naddress space. Thus, virtual addresses 0 through 0xBFFFFFFF are user\nvirtual addresses; the remaining virtual addresses ( 0xC0000000 through\n0xFFFFFFFF) are in the kernel\u2019s virtual address space. 64-bit Linux has a\nsimilar split but at slightly different points. Figure 23.2 s hows a depiction\nof a typical (simpli\ufb01ed) address space.\nOne slightly interesting aspect of Linux is that it contains tw o types of\nkernel virtual addresses. The \ufb01rst are known as kernel logical addresses\n[O16]. This is what you would consider the normal virtual address space\nof the kernel; to get more memory of this type, kernel code merely ne eds\nto call kmalloc. Most kernel data structures live here, such as page ta-\nbles, per-process kernel stacks, and so forth. Unlike most other memory\nin the system, kernel logical memory cannot be swapped to disk.\nThe most interesting aspect of kernel logical addresses is thei r con-\nnection to physical memory . Speci\ufb01cally , there is a direct mapp ing be-\ntween kernel logical addresses and the \ufb01rst portion of physical m emory .\nThus, kernel logical address 0xC0000000 translates to physical address\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "kernel virtual addresses. The \ufb01rst are known as kernel logical addresses",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "kernel",
          "virtual",
          "addresses",
          "known",
          "kernel",
          "logical",
          "addresses"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 2: The Linux Address Space",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "linux",
          "address",
          "space"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 C O M P L E T E VI RT U A L ME M O RY SY S T E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\n0x00000000, 0xC0000FFF to 0x00000FFF, and so forth. This direct\nmapping has two implications. The \ufb01rst is that it is simple to t ranslate\nback and forth between kernel logical addresses and physical a ddresses;\nas a result, these addresses are often treated as if they are in deed physi-\ncal. The second is that if a chunk of memory is contiguous in kernel l og-\nical address space, it is also contiguous in physical memory . Th is makes\nmemory allocated in this part of the kernel\u2019s address space suita ble for\noperations which need contiguous physical memory to work correctly ,\nsuch as I/O transfers to and from devices via directory memory access\n(DMA) (something we\u2019ll learn about in the third part of this book).\nThe other type of kernel address is a kernel virtual address . T o get\nmemory of this type, kernel code calls a different allocator , vmalloc,\nwhich returns a pointer to a virtually contiguous region of the des ired\nsize. Unlike kernel logical memory , kernel virtual memory is us ually not\ncontiguous; each kernel virtual page may map to non-contiguous ph ysi-\ncal pages (and is thus not suitable for DMA). However , such memory is\neasier to allocate as a result, and thus used for large buffers w here \ufb01nding\na contiguous large chunk of physical memory would be challenging.\nIn 32-bit Linux, one other reason for the existence of kernel virtu al\naddresses is that they enable the kernel to address more than ( roughly) 1\nGB of memory . Y ears ago, machines had much less memory than this, a nd\nenabling access to more than 1 GB was not an issue. However , techn ology\nprogressed, and soon there was a need to enable the kernel to use l arger\namounts of memory . Kernel virtual addresses, and their disconne ction\nfrom a strict one-to-one mapping to physical memory , make this poss ible.\nHowever , with the move to 64-bit Linux, the need is less urgent, because\nthe kernel is not con\ufb01ned to only the last 1 GB of the virtual addres s space.\nPage T able Structure\nBecause we are focused on Linux for x86, our discussion will center on\nthe type of page-table structure provided by x86, as it determi nes what\nLinux can and cannot do. As mentioned before, x86 provides a hardwa re-\nmanaged, multi-level page table structure, with one page tab le per pro-\ncess; the OS simply sets up mappings in its memory , points a priv ileged\nregister at the start of the page directory , and the hardware ha ndles the\nrest. The OS gets involved, as expected, at process creation, de letion, and\nupon context switches, making sure in each case that the correct page\ntable is being used by the hardware MMU to perform translations .\nProbably the biggest change in recent years is the move from 32-b it\nx86 to 64-bit x86, as brie\ufb02y mentioned above. As seen in the V AX/ VMS\nsystem, 32-bit address spaces have been around for a long time, a nd as\ntechnology changed, they were \ufb01nally starting to become a real l imit for\nprograms. Virtual memory makes it easy to program systems, but w ith\nmodern systems containing many GB of memory , 32 bits were no longer\nenough to refer to each of them. Thus, the next leap became neces sary .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "(DMA) (something we\u2019ll learn about in the third part of this book).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "something",
          "learn",
          "third",
          "part",
          "book"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 11\nMoving to a 64-bit address affects page table structure in x86 in the\nexpected manner . Because x86 uses a multi-level page table, current 64-\nbit systems use a four-level table. The full 64-bit nature of th e virtual\naddress space is not yet in use, however , rather only the bottom 48 b its.\nThus, a virtual address can be viewed as follows:\n63 47 31 15 0\nUnused P1 P2 P3 P4 Offset\nAs you can see in the picture, the top 16 bits of a virtual address a re\nunused (and thus play no role in translation), the bottom 12 bits ( due to\nthe 4-KB page size) are used as the offset (and hence just used d irectly ,\nand not translated), leaving the middle 36 bits of virtual addr ess to take\npart in the translation. The P1 portion of the address is used to in dex into\nthe topmost page directory , and the translation proceeds from ther e, one\nlevel at a time, until the actual page of the page table is index ed by P4,\nyielding the desired page table entry .\nAs system memories grow even larger , more parts of this voluminous\naddress space will become enabled, leading to \ufb01ve-level and e ventually\nsix-level page-table tree structures. Imagine that: a simp le page table\nlookup requiring six levels of translation, just to \ufb01gure out wher e in mem-\nory a certain piece of data resides.\nLarge Page Support\nIntel x86 allows for the use of multiple page sizes, not just the st andard 4-\nKB page. Speci\ufb01cally , recent designs support 2-MB and even 1-G B pages\nin hardware. Thus, over time, Linux has evolved to allow applica tions to\nutilize these huge pages (as they are called in the world of Linux).\nUsing huge pages, as hinted at earlier , leads to numerous bene \ufb01ts. As\nseen in V AX/VMS, doing so reduces the number of mappings that are\nneeded in the page table; the larger the pages, the fewer the m appings.\nHowever , fewer page-table entries is not the driving force behi nd huge\npages; rather , it\u2019s better TLB behavior and related performanc e gains.\nWhen a process actively uses a large amount of memory , it quickly\n\ufb01lls up the TLB with translations. If those translations are for 4 -KB pages,\nonly a small amount of total memory can be accessed without inducing\nTLB misses. The result, for modern \u201cbig memory\u201d workloads running on\nmachines with many GBs of memory , is a noticeable performance cost ;\nrecent research shows that some applications spend 10% of their c ycles\nservicing TLB misses [B+13].\nHuge pages allow a process to access a large tract of memory with-\nout TLB misses, by using fewer slots in the TLB, and thus is the ma in\nadvantage. However , there are other bene\ufb01ts to huge pages: the re is a\nshorter TLB-miss path, meaning that when a TLB miss does occur , i t is\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "KB page. Speci\ufb01cally , recent designs support 2-MB and even 1-G B pages",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "page",
          "recent",
          "designs",
          "support",
          "even",
          "pages"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 C O M P L E T E VI RT U A L ME M O RY SY S T E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nTI P : C O N S I D E R IN C R E M E N TA L I S M\nMany times in life, you are encouraged to be a revolutionary . \u201cThi nk\nbig!\u201d, they say . \u201cChange the world!\u201d, they scream. And you can see why\nit is appealing; in some cases, big changes are needed, and thu s pushing\nhard for them makes a lot of sense. And, if you try it this way , at lea st\nthey might stop yelling at you.\nHowever , in many cases, a slower , more incremental approach migh t be\nthe right thing to do. The Linux huge page example in this chapt er is\nan example of engineering incrementalism; instead of taking t he stance\nof a fundamentalist and insisting large pages were the way of th e future,\ndevelopers took the measured approach of \ufb01rst introducing special ized\nsupport for it, learning more about its upsides and downsides, and , only\nwhen there was real reason for it, adding more generic support for a ll\napplications.\nIncrementalism, while sometimes scorned, often leads to slow , t hought-\nful, and sensible progress. When building systems, such an ap proach\nmight just be the thing you need. Indeed, this may be true in lif e as well.\nserviced more quickly . In addition, allocation can be quite fast (in certain\nscenarios), a small but sometimes important bene\ufb01t.\nOne interesting aspect of Linux support for huge pages is how it wa s\ndone incrementally . At \ufb01rst, Linux developers knew such suppor t was\nonly important for a few applications, such as large databases wi th strin-\ngent performance demands. Thus, the decision was made to allow a ppli-\ncations to explicitly request memory allocations with large pag es (either\nthrough the mmap() or shmget() calls). In this way , most applications\nwould be unaffected (and continue to use only 4-KB pages; a few de -\nmanding applications would have to be changed to use these inte rfaces,\nbut for them it would be worth the pain.\nMore recently , as the need for better TLB behavior is more common\namong many applications, Linux developers have added transparent huge\npage support. When this feature is enabled, the operating syst em auto-\nmatically looks for opportunities to allocate huge pages (usually 2 MB,\nbut on some systems, 1 GB) without requiring application modi\ufb01cat ion.\nHuge pages are not without their costs. The biggest potential cost is\ninternal fragmentation , i.e., a page that is large but sparsely used. This\nform of waste can \ufb01ll memory with large but little used pages. Swap ping,\nif enabled, also does not work well with huge pages, sometimes gre atly\namplifying the amount of I/O a system does. Overhead of allocation\ncan also be bad (in some other cases). Overall, one thing is clear : the 4-\nKB page size which served systems so well for so many years is not the\nuniversal solution it once was; growing memory sizes demand that w e\nconsider large pages and other solutions as part of a necessary evol ution\nof VM systems. Linux\u2019s slow adoption of this hardware-based technol ogy\nis evidence of the coming change.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "However , in many cases, a slower , more incremental approach migh t be",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "many",
          "cases",
          "slower",
          "incremental",
          "approach",
          "migh"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of a fundamentalist and insisting large pages were the way of th e future,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamentalist",
          "insisting",
          "large",
          "pages",
          "future"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "developers took the measured approach of \ufb01rst introducing special ized",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developers",
          "took",
          "measured",
          "approach",
          "introducing",
          "special",
          "ized"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "support for it, learning more about its upsides and downsides, and , only",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "learning",
          "upsides",
          "downsides"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": ", a small but sometimes important bene\ufb01t.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "small",
          "sometimes",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "done incrementally . At \ufb01rst, Linux developers knew such suppor t was",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "done",
          "incrementally",
          "linux",
          "developers",
          "knew",
          "suppor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "only important for a few applications, such as large databases wi th strin-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "applications",
          "large",
          "databases",
          "strin"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "among many applications, Linux developers have added transparent huge",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "among",
          "many",
          "applications",
          "linux",
          "developers",
          "added",
          "transparent",
          "huge"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 13\nThe Page Cache\nT o reduce costs of accessing persistent storage (the focus of the t hird part\nof this book), most systems use aggressive caching subsystems to keep\npopular data items in memory . Linux, in this regard, is no diffe rent than\ntraditional operating systems.\nThe Linux page cache is uni\ufb01ed, keeping pages in memory from three\nprimary sources: memory-mapped \ufb01les , \ufb01le data and metadata from de-\nvices (usually accessed by directing read() and write() calls to the \ufb01le\nsystem), and heap and stack pages that comprise each process (s ometimes\ncalled anonymous memory , because there is no named \ufb01le underneath of\nit, but rather swap space). These entities are kept in a page cache hash\ntable, allowing for quick lookup when said data is needed.\nThe page cache tracks if entries are clean (read but not updated) or\ndirty (a.k.a., modi\ufb01ed ). Dirty data is periodically written to the back-\ning store (i.e., to a speci\ufb01c \ufb01le for \ufb01le data, or to swap space for a nony-\nmous regions) by background threads (called pdflush), thus ensuring\nthat modi\ufb01ed data eventually is written back to persistent st orage. This\nbackground activity either takes place after a certain time p eriod or if too\nmany pages are considered dirty (both con\ufb01gurable parameters) .\nIn some cases, a system runs low on memory , and Linux has to decide\nwhich pages to kick out of memory to free up space. T o do so, Linux us es\na modi\ufb01ed form of 2Q replacement [JS94], which we describe here.\nThe basic idea is simple: standard LRU replacement is effect ive, but\ncan be subverted by certain common access patterns. For example , if a\nprocess repeatedly accesses a large \ufb01le (especially one that i s nearly the\nsize of memory , or larger), LRU will kick every other \ufb01le out of memory .\nEven worse: retaining portions of this \ufb01le in memory isn\u2019t useful, a s they\nare never re-referenced before getting kicked out of memory .\nThe Linux version of the 2Q replacement algorithm solves this prob -\nlem by keeping two lists, and dividing memory between them. Wh en\naccessed for the \ufb01rst time, a page is placed on one queue (called A1 in the\noriginal paper , but the inactive list in Linux); when it is re-referenced, the\npage is promoted to the other queue (called Aq in the original, but the ac-\ntive list in Linux). When replacement needs to take place, the candida te\nfor replacement is taken from the inactive list. Linux also per iodically\nmoves pages from the bottom of the active list to the inactive list, keeping\nthe active list to about two-thirds of the total page cache size [G 04].\nLinux would ideally manage these lists in perfect LRU order , bu t, as\ndiscussed in earlier chapters, doing so is costly . Thus, as wit h many OSes,\nan approximation of LRU (similar to clock replacement) is used.\nThis 2Q approach generally behaves quite a bit like LRU, but not ably\nhandles the case where a cyclic large-\ufb01le access occurs by con\ufb01 ning the\npages of that cyclic access to the inactive list. Because said pages are never\nre-referenced before getting kicked out of memory , they do not \ufb02us h out\nother useful pages found in the active list.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "a modi\ufb01ed form of 2Q replacement [JS94], which we describe here.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "form",
          "replacement",
          "describe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The Linux version of the 2Q replacement algorithm solves this prob -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "linux",
          "version",
          "replacement",
          "algorithm",
          "solves",
          "prob"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "This 2Q approach generally behaves quite a bit like LRU, but not ably",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "generally",
          "behaves",
          "quite",
          "like",
          "ably"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Even worse: retaining portions of this \ufb01le in memory isn\u2019t useful, a s they",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "even worse",
          "retaining",
          "portions",
          "memory",
          "useful"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 C O M P L E T E VI RT U A L ME M O RY SY S T E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nAS I D E : T H E UB I Q U I T Y OF ME M O RY-M A P P I N G\nMemory mapping predates Linux by some years, and is used in many\nplaces within Linux and other modern systems. The idea is simpl e: by\ncalling mmap() on an already opened \ufb01le descriptor , a process is returned\na pointer to the beginning of a region of virtual memory where the con -\ntents of the \ufb01le seem to be located. By then using that pointer , a p rocess\ncan access any part of the \ufb01le with a simple pointer dereference .\nAccesses to parts of a memory-mapped \ufb01le that have not yet been br ought\ninto memory trigger page faults , at which point the OS will page in the\nrelevant data and make it accessible by updating the page tab le of the\nprocess accordingly (i.e., demand paging ).\nEvery regular Linux process uses memory-mapped \ufb01les, even the code\nin main() does not call mmap() directly , because of how Linux loads\ncode from the executable and shared library code into memory . Bel ow\nis the (highly abbreviated) output of the pmap command line tool, which\nshows what different mapping comprise the virtual address spa ce of a\nrunning program (the shell, in this example, tcsh). The output shows\nfour columns: the virtual address of the mapping, its size, the p rotection\nbits of the region, and the source of the mapping:\n0000000000400000 372K r-x-- tcsh\n00000000019d5000 1780K rw--- [anon ]\n00007f4e7cf06000 1792K r-x-- libc-2.23.so\n00007f4e7d2d0000 36K r-x-- libcrypt-2.23.so\n00007f4e7d508000 148K r-x-- libtinfo.so.5.9\n00007f4e7d731000 152K r-x-- ld-2.23.so\n00007f4e7d932000 16K rw--- [stack ]\nAs you can see from this output, the code from the tcsh binary , as well\nas code from libc, libcrypt, libtinfo, and code from the dynamic\nlinker itself ( ld.so) are all mapped into the address space. Also present\nare two anonymous regions, the heap (the second entry , labeled anon)\nand the stack (labeled stack). Memory-mapped \ufb01les provide a straight-\nforward and ef\ufb01cient way for the OS to construct a modern address s pace.\nSecurity And Buffer Over\ufb02ows\nProbably the biggest difference between modern VM systems (Li nux, So-\nlaris, or one of the BSD variants) and ancient ones (V AX/VMS) is the\nemphasis on security in the modern era. Protection has always bee n\na serious concern for operating systems, but with machines more in ter-\nconnected than ever , it is no surprise that developers have imp lemented\na variety of defensive countermeasures to halt those wily hacke rs from\ngaining control of systems.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "connected than ever , it is no surprise that developers have imp lemented",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "connected",
          "ever",
          "surprise",
          "developers",
          "lemented"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 15\nOne major threat is found in buffer over\ufb02ow attacks2 , which can be\nused against normal user programs and even the kernel itself. T he idea\nof these attacks is to \ufb01nd a bug in the target system which lets t he attacker\ninject arbitrary data into the target\u2019s address space. Such vu lnerabilities\nsometime arise because the developer assumes (erroneously) tha t an in-\nput will not be overly long, and thus (trustingly) copies the inpu t into a\nbuffer; because the input is in fact too long, it over\ufb02ows the buff er , thus\noverwriting memory of the target. Code as innocent as the below can b e\nthe source of the problem:\nint some_function(char *input) {\nchar dest_buffer[100];\nstrcpy(dest_buffer, input); // oops, unbounded copy!\n}\nIn many cases, such an over\ufb02ow is not catastrophic, e.g., bad inpu t\ninnocently given to a user program or even the OS will probably cau se it\nto crash, but no worse. However , malicious programmers can caref ully\ncraft the input that over\ufb02ows the buffer so as to inject their own code\ninto the targeted system, essentially allowing them to take i t over and\ndo their own bidding. If successful upon a network-connected use r pro-\ngram, attackers can run arbitrary computations or even rent out c ycles on\nthe compromised system; if successful upon the operating system itself,\nthe attack can access even more resources, and is a form of what is c alled\nprivilege escalation (i.e., user code gaining kernel access rights). If you\ncan\u2019t guess, these are all Bad Things.\nThe \ufb01rst and most simple defense against buffer over\ufb02ow is to pre vent\nexecution of any code found within certain regions of an address spa ce\n(e.g., within the stack). The NX bit (for No-eXecute), introduced by AMD\ninto their version of x86 (a similar XD bit is now available on Inte l\u2019s), is\none such defense; it just prevents execution from any page which has this\nbit set in its corresponding page table entry . The approach prev ents code,\ninjected by an attacker into the target\u2019s stack, from being exe cuted, and\nthus mitigates the problem.\nHowever , clever attackers are ... clever , and even when injec ted code\ncannot be added explicitly by the attacker , arbitrary code seq uences can\nbe executed by malicious code. The idea is known, in its most gener al\nform, as a return-oriented programming (ROP) [S07], and really it is\nquite brilliant. The observation behind ROP is that there are l ots of bits of\ncode ( gadgets, in ROP terminology) within any program\u2019s address space,\nespecially C programs that link with the voluminous C library . T hus,\nan attacker can overwrite the stack such that the return addre ss in the\ncurrently executing function points to a desired malicious ins truction (or\n2 See https://en.wikipedia.org/wiki/Buffer_overflow for some details and\nlinks about this topic, including a reference to the famous article by the se curity hacker Elias\nLevy , also known as \u201cAleph One\u201d.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "sometime arise because the developer assumes (erroneously) tha t an in-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "sometime",
          "arise",
          "developer",
          "assumes",
          "erroneously"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "into the targeted system, essentially allowing them to take i t over and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "targeted",
          "system",
          "essentially",
          "allowing",
          "take"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "bit set in its corresponding page table entry . The approach prev ents code,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "corresponding",
          "page",
          "table",
          "entry",
          "approach",
          "prev",
          "ents",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "be executed by malicious code. The idea is known, in its most gener al",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "executed",
          "malicious",
          "code",
          "idea",
          "known",
          "gener"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Levy , also known as \u201cAleph One\u201d.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "levy",
          "also",
          "known",
          "aleph"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand or\n2 See https: //en.wikipedia.org/wiki/Buffer_overflow for some details and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "or\n2 see https",
          "wikipedia",
          "wiki",
          "details"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 C O M P L E T E VI RT U A L ME M O RY SY S T E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nseries of instructions), followed by a return instruction. By str inging to-\ngether a large number of gadgets (i.e., ensuring each return j umps to the\nnext gadget), the attacker can execute arbitrary code. Amazi ng!\nT o defend against ROP (including its earlier form, the return-to-libc\nattack [S+04]), Linux (and other systems) add another defense, known\nas address space layout randomization (ASLR). Instead of placing code,\nstack, and the heap at \ufb01xed locations within the virtual addres s space, the\nOS randomizes their placement, thus making it quite challeng ing to craft\nthe intricate code sequence required to implement this class of attacks.\nMost attacks on vulnerable user programs will thus cause crashe s, but\nnot be able to gain control of the running program.\nInterestingly , you can observe this randomness in practice rat her eas-\nily . Here\u2019s a piece of code that demonstrates it on a modern Linux sys tem:\nint main(int argc, char *argv[]) {\nint stack = 0;\nprintf(\"%p\\n\", &stack);\nreturn 0;\n}\nThis code just prints out the (virtual) address of a variable on th e stack.\nIn older non-ASLR systems, this value would be the same each time. But,\nas you can see below , the value changes with each run:\nprompt> ./random\n0x7ffd3e55d2b4\nprompt> ./random\n0x7ffe1033b8f4\nprompt> ./random\n0x7ffe45522e94\nASLR is such a useful defense for user-level programs that it has also\nbeen incorporated into the kernel, in a feature unimaginative ly called ker-\nnel address space layout randomization (KASLR). However , it turns out\nthe kernel may have even bigger problems to handle, as we discu ss next.\nOther Security Problems: Meltdown And Spectre\nAs we write these words (August, 2018), the world of systems secu rity\nhas been turned upside down by two new and related attacks. The \ufb01rst\nis called Meltdown, and the second Spectre. They were discovered at\nabout the same time by four different groups of researchers/engi neers,\nand have led to deep questioning of the fundamental protections of fered\nby computer hardware and the OS above. See meltdownattack.com\nand spectreattack.com for papers describing each attack in detail.\nSpectre is considered the more problematic of the two.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "attack [S+04]), Linux (and other systems) add another defense, known",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "attack",
          "linux",
          "systems",
          "another",
          "defense",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the intricate code sequence required to implement this class of attacks.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "intricate",
          "code",
          "sequence",
          "required",
          "implement",
          "class",
          "attacks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "not be able to gain control of the running program.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "gain",
          "control",
          "running",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ily . Here\u2019s a piece of code that demonstrates it on a modern Linux sys tem:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "piece",
          "code",
          "demonstrates",
          "modern",
          "linux"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "and have led to deep questioning of the fundamental protections of fered",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "deep",
          "questioning",
          "fundamental",
          "protections",
          "fered"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "23",
    "title": "3 Summary",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "23.3 Summary\nY ou have now seen a top-to-bottom review of two virtual memory sys-\ntems. Hopefully , most of the details were easy to follow , as you shoul d\nhave already had a good understanding of the basic mechanisms an d\npolicies. More detail on V AX/VMS is available in the excellent ( and short)\npaper by Levy and Lipman [LL82]. W e encourage you to read it, as i t is a\ngreat way to see what the source material behind these chapter s is like.\nY ou have also learned a bit about Linux. While a large and complex\nsystem, it inherits many good ideas from the past, many of which we\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "have already had a good understanding of the basic mechanisms an d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "already",
          "good",
          "understanding",
          "basic",
          "mechanisms"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Y ou have also learned a bit about Linux. While a large and complex",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "learned",
          "linux",
          "large",
          "complex"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "18 C O M P L E T E VI RT U A L ME M O RY SY S T E ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "18 C O M P L E T E VI RT U A L ME M O RY SY S T E M S\nhave not had room to discuss in detail. For example, Linux performs lazy\ncopy-on-write copying of pages upon fork(), thus lowering overheads\nby avoiding unnecessary copying. Linux also demand zeroes page s (us-\ning memory-mapping of the /dev/zero device), and has a background\nswap daemon ( swapd) that swaps pages to disk to reduce memory pres-\nsure. Indeed, the VM is \ufb01lled with good ideas taken from the past, and\nalso includes many of its own innovations.\nT o learn more, check out these reasonable (but, alas, outdated) b ooks\n[BC05,G04]. W e encourage you to read them on your own, as we can\nonly provide the merest drop from what is an ocean of complexity . But,\nyou\u2019ve got to start somewhere. What is any ocean, but a multitude of\ndrops? [M04]\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o learn more, check out these reasonable (but, alas, outdated) b ooks",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "check",
          "reasonable",
          "alas",
          "outdated",
          "ooks"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand an ocean of complexity . But,\nyou\u2019ve got to start somewhere. What is any ocean, but a multitude of\ndrops",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "ocean",
          "complexity",
          "start",
          "somewhere",
          "ocean",
          "multitude",
          "drops"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M P L E T E VI RT U A L ME M O RY SY S T E M S 19\nReferences\n[B+13] \u201cEf\ufb01cient Virtual Memory for Big Memory Servers\u201d by A. Basu, J. Gandhi, J. Chang,\nM. D. Hill, M. M. Swift. ISCA \u201913, June 2013, T el-A viv , Israel. A recent work showing that TLBs\nmatter , consuming 10% of cycles for large-memory workloads. The solution: one m assive segment to\nhold large data sets. We go backward, so that we can go forward!\n[BB+72] \u201cTENEX, A Paged Time Sharing System for the PDP-10\u201d by D. G. Bobro w , J. D. Burch-\n\ufb01el, D. L. Murphy , R. S. T omlinson. CACM, V olume 15, March 1972. An early time-sharing OS\nwhere a number of good ideas came from. Copy-on-write was just one of those; also an inspiration for\nother aspects of modern systems, including process management, virtual me mory, and \ufb01le systems.\n[BJ81] \u201cConverting a Swap-Based System to do Paging in an Architecture L acking Page-Reference\nBits\u201d by O. Babaoglu, W . N. Joy . SOSP \u201981, Paci\ufb01c Grove, California, D ecember 1981. How to\nexploit existing protection machinery to emulate reference bits, from a g roup at Berkeley working on\ntheir own version of UN I X: the Berkeley Systems Distribution (BSD). The group was in\ufb02uential in\nthe development of virtual memory, \ufb01le systems, and networking.\n[BC05] \u201cUnderstanding the Linux Kernel\u201d by D. P . Bovet, M. Cesati. O\u2019Re illy Media, Novem-\nber 2005. One of the many books you can \ufb01nd on Linux, which are out of date, but still worthwhi le.\n[C03] \u201cThe Innovator \u2019s Dilemma\u201d by Clayton M. Christenson. Harper Pape rbacks, January\n2003. A fantastic book about the disk-drive industry and how new innovations disrupt ex isting ones.\nA good read for business majors and computer scientists alike. Provides insi ght on how large and\nsuccessful companies completely fail.\n[C93] \u201cInside Windows NT\u201d by H. Custer , D. Solomon. Microsoft Press, 19 93. The book about\nWindows NT that explains the system top to bottom, in more detail than you might like. But seriously,\na pretty good book.\n[G04] \u201cUnderstanding the Linux Virtual Memory Manager \u201d by M. Gorman. Prent ice Hall,\n2004. An in-depth look at Linux VM, but alas a little out of date.\n[G+17] \u201cKASLR is Dead: Long Live KASLR\u201d by D. Gruss, M. Lipp, M. Schwa rz, R. Fell-\nner , C. Maurice, S. Mangard. Engineering Secure Software and Systems, 20 17. A vailable:\nhttps://gruss.cc/files/kaiser.pdf Excellent info on KASLR, KPTI, and beyond.\n[JS94] \u201c2Q: A Low Overhead High Performance Buffer Management Replacement Al gorithm\u201d\nby T . Johnson, D. Shasha. VLDB \u201994, Santiago, Chile. A simple but effective approach to building\npage replacement.\n[LL82] \u201cVirtual Memory Management in the V AX/VMS Operating System\u201d by H. Levy , P .\nLipman. IEEE Computer , V olume 15:3, March 1982. Read the original source of most of this\nmaterial. Particularly important if you wish to go to graduate school, where all y ou do is read papers,\nwork, read some more papers, work more, eventually write a paper , and then work some more.\n[M04] \u201cCloud Atlas\u201d by D. Mitchell. Random House, 2004. It\u2019s hard to pick a favorite book. There\nare too many! Each is great in its own unique way. But it\u2019d be hard for these author s not to pick \u201cCloud\nAtlas\u201d, a fantastic, sprawling epic about the human condition, from where the th e last quote of this\nchapter is lifted. If you are smart \u2013 and we think you are \u2013 you should stop reading obscure commentary\nin the references and instead read \u201cCloud Atlas\u201d; you\u2019ll thank us later .\n[O16] \u201cVirtual Memory and Linux\u201d by A. Ott. Embedded Linux Conference, Ap ril 2016.\nhttps://events.static.linuxfound.org/sites/events/\ufb01les/sli des/elc\n2016 mem.pdf . A useful\nset of slides which gives an overview of the Linux VM.\n[RL81] \u201cSegmented FIFO Page Replacement\u201d by R. T urner , H. Levy . SIG METRICS \u201981, Las\nV egas, Nevada, September 1981. A short paper that shows for some workloads, segmented FIFO can\napproach the performance of LRU.\n[S07] \u201cThe Geometry of Innocent Flesh on the Bone: Return-into-libc without Function Calls\n(on the x86)\u201d by H. Shacham. CCS \u201907, October 2007. A generalization of return-to-libc. Dr . Beth\nGarner said in Basic Instinct, \u201cShe\u2019s crazy! She\u2019s brilliant!\u201d We might s ay the same about ROP .\n[S+04] \u201cOn the Effectiveness of Address-space Randomization\u201d by H. Shacha m, M. Page, B.\nPfaff, E. J. Goh, N. Modadugu, D. Boneh. CCS \u201904, October 2004. A description of the return-to-\nlibc attack and its limits. Start reading, but be wary: the rabbit hole of system s security is deep...\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the development of virtual memory, \ufb01le systems, and networking.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "development",
          "virtual",
          "memory",
          "systems",
          "networking"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[BC05] \u201cUnderstanding the Linux Kernel\u201d by D. P . Bovet, M. Cesati. O\u2019Re illy Media, Novem-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "linux",
          "kernel",
          "bovet",
          "cesati",
          "illy",
          "media",
          "novem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Windows NT that explains the system top to bottom, in more detail than you might like. But seriously,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "windows",
          "explains",
          "system",
          "bottom",
          "detail",
          "might",
          "like",
          "seriously"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[G04] \u201cUnderstanding the Linux Virtual Memory Manager \u201d by M. Gorman. Prent ice Hall,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "linux",
          "virtual",
          "memory",
          "manager",
          "gorman",
          "prent",
          "hall"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "by T . Johnson, D. Shasha. VLDB \u201994, Santiago, Chile. A simple but effective approach to building",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "johnson",
          "shasha",
          "vldb",
          "santiago",
          "chile",
          "simple",
          "effective",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "material. Particularly important if you wish to go to graduate school, where all y ou do is read papers,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "material",
          "particularly",
          "important",
          "wish",
          "graduate",
          "school",
          "read",
          "papers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "approach the performance of LRU.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "performance"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand The solution: one m assive segment to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the solution",
          "assive",
          "segment"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand KASLR is Dead: Long Live KASLR\u201d by D. Gruss, M. Lipp, M. Schwa rz, R. Fell-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "kaslr is dead",
          "long",
          "live",
          "kaslr",
          "gruss",
          "lipp",
          "schwa",
          "fell"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A vailable: https://gruss.cc/files/kaiser.pdf Excellent info on KASLR, KPTI, and beyond.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "https",
          "gruss",
          "files",
          "kaiser",
          "excellent",
          "info",
          "kaslr",
          "kpti"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 2Q: A Low Overhead High Performance Buffer Management Replacement Al gorithm\u201d",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2q",
          "overhead",
          "high",
          "performance",
          "buffer",
          "management",
          "replacement",
          "gorithm"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand V olume 15: 3, March 1982. Read the original source of most of this",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 15",
          "march",
          "read",
          "original",
          "source"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand https: //events.static.linuxfound.org/sites/events/\ufb01les/sli des/elc",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "https",
          "events",
          "static",
          "linuxfound",
          "sites",
          "events"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand but be wary: the rabbit hole of system s security is deep...",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "but be wary",
          "rabbit",
          "hole",
          "system",
          "security",
          "deep"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "24\nSummary Dialogue on Memory Virtualization\nStudent: (Gulps) Wow, that was a lot of material.\nProfessor: Y es, and?\nStudent: Well, how am I supposed to remember it all? Y ou know, for the exam?\nProfessor: Goodness, I hope that\u2019s not why you are trying to remember it.\nStudent: Why should I then?\nProfessor: Come on, I thought you knew better . Y ou\u2019re trying to learn some-\nthing here, so that when you go off into the world, you\u2019ll understand how systems\nactually work.\nStudent: Hmm... can you give an example?\nProfessor: Sure! One time back in graduate school, my friends and I were\nmeasuring how long memory accesses took, and once in a while the num bers\nwere way higher than we expected; we thought all the data was \ufb01ttin g nicely into\nthe second-level hardware cache, you see, and thus should have been really fast\nto access.\nStudent: (nods)\nProfessor: We couldn\u2019t \ufb01gure out what was going on. So what do you do in such\na case? Easy, ask a professor! So we went and asked one of our pro fessors, who\nlooked at the graph we had produced, and simply said \u201cTLB\u201d. Aha! Of course,\nTLB misses! Why didn\u2019t we think of that? Having a good model of how v irtual\nmemory works helps diagnose all sorts of interesting performance p roblems.\nStudent: I think I see. I\u2019m trying to build these mental models of how things\nwork, so that when I\u2019m out there working on my own, I won\u2019t be surp rised when\na system doesn\u2019t quite behave as expected. I should even be able t o anticipate how\nthe system will work just by thinking about it.\nProfessor: Exactly. So what have you learned? What\u2019s in your mental model of\nhow virtual memory works?\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: Well, how am I supposed to remember it all? Y ou know, for the exam?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "supposed",
          "remember",
          "know",
          "exam"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Professor: Come on, I thought you knew better . Y ou\u2019re trying to learn some-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "come",
          "thought",
          "knew",
          "better",
          "trying",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "thing here, so that when you go off into the world, you\u2019ll understand how systems",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thing",
          "world",
          "understand",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Professor: Exactly. So what have you learned? What\u2019s in your mental model of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "exactly",
          "learned",
          "mental",
          "model"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Goodness, I hope that\u2019s not why you are trying to remember it.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "goodness",
          "hope",
          "trying",
          "remember"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: Hmm... can you give an example?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "give",
          "example"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Sure! One time back in graduate school, my friends and I were",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "sure",
          "time",
          "back",
          "graduate",
          "school",
          "friends"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Professor: We couldn\u2019t \ufb01gure out what was going on. So what do you do in such",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "going"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Student: I think I see. I\u2019m trying to build these mental models of how things",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "think",
          "trying",
          "build",
          "mental",
          "models",
          "things"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S U M M A RYDI A L O G U E O NME M O RYVI RT U A...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S U M M A RYDI A L O G U E O NME M O RYVI RT U A L I Z AT I O N\nStudent: Well, I think I now have a pretty good idea of what happens when\nmemory is referenced by a process, which, as you\u2019ve said many times, happens\non each instruction fetch as well as explicit loads and stores.\nProfessor: Sounds good \u2014 tell me more.\nStudent: Well, one thing I\u2019ll always remember is that the addresses we see in a\nuser program, written in C for example...\nProfessor: What other language is there?\nStudent: (continuing) ... Y es, I know you like C. So do I! Anyhow, as I was\nsaying, I now really know that all addresses that we can observe wit hin a program\nare virtual addresses; that I, as a programmer , am just given this illusion of where\ndata and code are in memory. I used to think it was cool that I could p rint the\naddress of a pointer , but now I \ufb01nd it frustrating \u2014 it\u2019s just a virtual a ddress! I\ncan\u2019t see the real physical address where the data lives.\nProfessor: Nope, the OS de\ufb01nitely hides that from you. What else?\nStudent: Well, I think the TLB is a really key piece, providing the system with\na small hardware cache of address translations. Page tables are u sually quite\nlarge and hence live in big and slow memories. Without that TLB, progra ms\nwould certainly run a great deal more slowly. Seems like the TLB truly m akes\nvirtualizing memory possible. I couldn\u2019t imagine building a system withou t one!\nAnd I shudder at the thought of a program with a working set that e xceeds the\ncoverage of the TLB: with all those TLB misses, it would be hard to wa tch.\nProfessor: Y es, cover the eyes of the children! Beyond the TLB, what did you\nlearn?\nStudent: I also now understand that the page table is one of those data stru ctures\nyou need to know about; it\u2019s just a data structure, though, and t hat means almost\nany structure could be used. We started with simple structures, lik e arrays (a.k.a.\nlinear page tables), and advanced all the way up to multi-level tables (which look\nlike trees), and even crazier things like pageable page tables in kerne l virtual\nmemory. All to save a little space in memory!\nProfessor: Indeed.\nStudent: And here\u2019s one more important thing: I learned that the address t rans-\nlation structures need to be \ufb02exible enough to support what progra mmers want\nto do with their address spaces. Structures like the multi-level tab le are perfect\nin this sense; they only create table space when the user needs a po rtion of the\naddress space, and thus there is little waste. Earlier attempts, like the simple base\nand bounds register , just weren\u2019t \ufb02exible enough; the structures need to match\nwhat users expect and want out of their virtual memory system.\nProfessor: That\u2019s a nice perspective. What about all of the stuff we learned\nabout swapping to disk?\nStudent: Well, it\u2019s certainly fun to study, and good to know how page replace-\nment works. Some of the basic policies are kind of obvious (like LRU, for ex-\nample), but building a real virtual memory system seems more intere sting, like\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: (continuing) ... Y es, I know you like C. So do I! Anyhow, as I was",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "student",
          "continuing",
          "know",
          "like",
          "anyhow"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "saying, I now really know that all addresses that we can observe wit hin a program",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "saying",
          "really",
          "know",
          "addresses",
          "observe",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Student: I also now understand that the page table is one of those data stru ctures",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "also",
          "understand",
          "page",
          "table",
          "data",
          "stru",
          "ctures"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "you need to know about; it\u2019s just a data structure, though, and t hat means almost",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "need",
          "know",
          "data",
          "structure",
          "though",
          "means",
          "almost"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Student: And here\u2019s one more important thing: I learned that the address t rans-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "important",
          "thing",
          "learned",
          "address",
          "rans"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "in this sense; they only create table space when the user needs a po rtion of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sense",
          "create",
          "table",
          "space",
          "user",
          "needs",
          "rtion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "Professor: That\u2019s a nice perspective. What about all of the stuff we learned",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "nice",
          "perspective",
          "stuff",
          "learned"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "Student: Well, it\u2019s certainly fun to study, and good to know how page replace-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "certainly",
          "study",
          "good",
          "know",
          "page",
          "replace"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: Sounds good \u2014 tell me more.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "sounds",
          "good",
          "tell"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: Well, one thing I\u2019ll always remember is that the addresses we see in a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "thing",
          "always",
          "remember",
          "addresses"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: What other language is there?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "language"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Professor: Nope, the OS de\ufb01nitely hides that from you. What else?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "nope",
          "hides",
          "else"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Student: Well, I think the TLB is a really key piece, providing the system with",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "think",
          "really",
          "piece",
          "providing",
          "system"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Professor: Y es, cover the eyes of the children! Beyond the TLB, what did you",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "cover",
          "eyes",
          "children",
          "beyond"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SU M M A RYDI A L O G U E O NME M O RYVI RT U A L ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SU M M A RYDI A L O G U E O NME M O RYVI RT U A L I Z AT I O N 3\nwe saw in the VMS case study. But somehow, I found the mechanisms m ore\ninteresting, and the policies less so.\nProfessor: Oh, why is that?\nStudent: Well, as you said, in the end the best solution to policy problems is\nsimple: buy more memory. But the mechanisms you need to understa nd to know\nhow stuff really works. Speaking of which...\nProfessor: Y es?\nStudent: Well, my machine is running a little slowly these days... and memory\ncertainly doesn\u2019t cost that much...\nProfessor: Oh \ufb01ne, \ufb01ne! Here\u2019s a few bucks. Go and get yourself some DRAM,\ncheapskate.\nStudent: Thanks professor! I\u2019ll never swap to disk again \u2014 or , if I do, at least\nI\u2019ll know what\u2019s actually going on!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "simple: buy more memory. But the mechanisms you need to understa nd to know",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "memory",
          "mechanisms",
          "need",
          "understa",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "I\u2019ll know what\u2019s actually going on!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "actually",
          "going"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: Well, as you said, in the end the best solution to policy problems is",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "said",
          "best",
          "solution",
          "policy",
          "problems"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Well, my machine is running a little slowly these days... and memory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "machine",
          "running",
          "little",
          "slowly",
          "days",
          "memory"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: Oh \ufb01ne, \ufb01ne! Here\u2019s a few bucks. Go and get yourself some DRAM,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "bucks",
          "dram"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: Thanks professor! I\u2019ll never swap to disk again \u2014 or , if I do, at least",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "thanks",
          "professor",
          "never",
          "swap",
          "disk",
          "least"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "Part II\nConcurrency\n1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "25\nA Dialogue on Concurrency\nProfessor: And thus we reach the second of our three pillars of operating sys-\ntems: concurrency.\nStudent: I thought there were four pillars...?\nProfessor: Nope, that was in an older version of the book.\nStudent: Umm... OK. So what is concurrency, oh wonderful professor?\nProfessor: Well, imagine we have a peach \u2014\nStudent: (interrupting) Peaches again! What is it with you and peaches?\nProfessor: Ever read T .S. Eliot? The Love Song of J. Alfred Prufrock, \u201cDo I dare\nto eat a peach\u201d, and all that fun stuff?\nStudent: Oh yes! In English class in high school. Great stuff! I really liked the\npart where \u2014\nProfessor: (interrupting) This has nothing to do with that \u2014 I just like peaches.\nAnyhow, imagine there are a lot of peaches on a table, and a lot of peo ple who\nwish to eat them. Let\u2019s say we did it this way: each eater \ufb01rst identi\ufb01es a peach\nvisually, and then tries to grab it and eat it. What is wrong with this app roach?\nStudent: Hmmm... seems like you might see a peach that somebody else also\nsees. If they get there \ufb01rst, when you reach out, no peach for you !\nProfessor: Exactly! So what should we do about it?\nStudent: Well, probably develop a better way of going about this. Maybe form a\nline, and when you get to the front, grab a peach and get on with it.\nProfessor: Good! But what\u2019s wrong with your approach?\nStudent: Sheesh, do I have to do all the work?\nProfessor: Y es.\nStudent: OK, let me think. Well, we used to have many people grabbing for\npeaches all at once, which is faster . But in my way, we just go one at a t ime,\nwhich is correct, but quite a bit slower . The best kind of approach wo uld be fast\nand correct, probably.\n3",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: Well, probably develop a better way of going about this. Maybe form a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "student",
          "well",
          "probably",
          "develop",
          "better",
          "going",
          "maybe",
          "form"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Professor: Good! But what\u2019s wrong with your approach?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good",
          "wrong",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "which is correct, but quite a bit slower . The best kind of approach wo uld be fast",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "correct",
          "quite",
          "slower",
          "best",
          "kind",
          "approach",
          "fast"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Student: I thought there were four pillars...?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "thought",
          "four",
          "pillars"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Nope, that was in an older version of the book.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "nope",
          "older",
          "version",
          "book"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Umm... OK. So what is concurrency, oh wonderful professor?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "concurrency",
          "wonderful",
          "professor"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: Well, imagine we have a peach \u2014",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "imagine",
          "peach"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: (interrupting) Peaches again! What is it with you and peaches?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "interrupting",
          "peaches",
          "peaches"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Ever read T .S. Eliot? The Love Song of J. Alfred Prufrock, \u201cDo I dare",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "ever",
          "read",
          "eliot",
          "love",
          "song",
          "alfred",
          "prufrock",
          "dare"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Student: Oh yes! In English class in high school. Great stuff! I really liked the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "english",
          "class",
          "high",
          "school",
          "great",
          "stuff",
          "really",
          "liked"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Professor: (interrupting) This has nothing to do with that \u2014 I just like peaches.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "interrupting",
          "nothing",
          "like",
          "peaches"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand concurrency, oh wonderful professor",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrency",
          "wonderful",
          "professor"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand it with you and peaches",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "peaches"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_3",
        "text": "understand wrong with this app roach",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "wrong",
          "roach"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 A D I A L O G U E O NCO N C U R R E N C Y",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 A D I A L O G U E O NCO N C U R R E N C Y\nProfessor: Y ou are really starting to impress. In fact, you just told us everythin g\nwe need to know about concurrency! Well done.\nStudent: I did? I thought we were just talking about peaches. Remember , this\nis usually the part where you make it about computers again.\nProfessor: Indeed. My apologies! One must never forget the concrete. Well,\nas it turns out, there are certain types of programs that we call multi-threaded\napplications; each thread is kind of like an independent agent running around\nin this program, doing things on the program\u2019s behalf. But these thr eads access\nmemory, and for them, each spot of memory is kind of like one of those peaches. If\nwe don\u2019t coordinate access to memory between threads, the pro gram won\u2019t work\nas expected. Make sense?\nStudent: Kind of. But why do we talk about this in an OS class? Isn\u2019t that just\napplication programming?\nProfessor: Good question! A few reasons, actually. First, the OS must support\nmulti-threaded applications with primitives such as locks and condition vari-\nables, which we\u2019ll talk about soon. Second, the OS itself was the \ufb01rst concu rrent\nprogram \u2014 it must access its own memory very carefully or many stran ge and\nterrible things will happen. Really, it can get quite grisly.\nStudent: I see. Sounds interesting. There are more details, I imagine?\nProfessor: Indeed there are...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "we need to know about concurrency! Well done.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "know",
          "concurrency",
          "well",
          "done"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: I did? I thought we were just talking about peaches. Remember , this",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "thought",
          "talking",
          "peaches",
          "remember"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: Indeed. My apologies! One must never forget the concrete. Well,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "indeed",
          "apologies",
          "must",
          "never",
          "forget",
          "concrete",
          "well"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: Kind of. But why do we talk about this in an OS class? Isn\u2019t that just",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "kind",
          "talk",
          "class"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Good question! A few reasons, actually. First, the OS must support",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good",
          "question",
          "reasons",
          "actually",
          "first",
          "must",
          "support"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Student: I see. Sounds interesting. There are more details, I imagine?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "interesting",
          "details",
          "imagine"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "26\nConcurrency: An Introduction\nThus far , we have seen the development of the basic abstractions that the\nOS performs. W e have seen how to take a single physical CPU and tu rn\nit into multiple virtual CPUs, thus enabling the illusion of multiple pro-\ngrams running at the same time. W e have also seen how to create t he\nillusion of a large, private virtual memory for each process; this abstrac-\ntion of the address space enables each program to behave as if it has its\nown memory when indeed the OS is secretly multiplexing address spaces\nacross physical memory (and sometimes, disk).\nIn this note, we introduce a new abstraction for a single running p ro-\ncess: that of a thread. Instead of our classic view of a single point of\nexecution within a program (i.e., a single PC where instruction s are be-\ning fetched from and executed), a multi-threaded program has more than\none point of execution (i.e., multiple PCs, each of which is being f etched\nand executed from). Perhaps another way to think of this is that e ach\nthread is very much like a separate process, except for one diffe rence:\nthey share the same address space and thus can access the same data.\nThe state of a single thread is thus very similar to that of a proce ss.\nIt has a program counter (PC) that tracks where the program is fet ch-\ning instructions from. Each thread has its own private set of regi sters it\nuses for computation; thus, if there are two threads that are run ning on\na single processor , when switching from running one (T1) to runni ng the\nother (T2), a context switch must take place. The context switch between\nthreads is quite similar to the context switch between process es, as the\nregister state of T1 must be saved and the register state of T2 re stored\nbefore running T2. With processes, we saved state to a process control\nblock (PCB); now , we\u2019ll need one or more thread control blocks (TCBs)\nto store the state of each thread of a process. There is one major diff erence,\nthough, in the context switch we perform between threads as compa red\nto processes: the address space remains the same (i.e., there is no need to\nswitch which page table we are using).\nOne other major difference between threads and processes concer ns\nthe stack. In our simple model of the address space of a classic proc ess\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus far , we have seen the development of the basic abstractions that the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "thus",
          "seen",
          "development",
          "basic",
          "abstractions"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "grams running at the same time. W e have also seen how to create t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "grams",
          "running",
          "time",
          "also",
          "seen",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand cess: that of a thread. Instead of our classic view of a single point of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cess",
          "thread",
          "instead",
          "classic",
          "view",
          "single",
          "point"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "1 Why Use Threads?",
    "document_source": "book.pdf",
    "start_line": 50,
    "type": "chapter",
    "content": "26.1 Why Use Threads?\nBefore getting into the details of threads and some of the problems you\nmight have in writing multi-threaded programs, let\u2019s \ufb01rst ans wer a more\nsimple question. Why should you use threads at all?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand why use threads?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "threads"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "2 An Example: Thread Creation",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "26.2 An Example: Thread Creation\nLet\u2019s get into some of the details. Say we wanted to run a program\nthat creates two threads, each of which does some independent wor k, in\nthis case printing \u201cA \u201d or \u201cB\u201d. The code is shown in Figure 26.2 (pa ge 4).\nThe main program creates two threads, each of which will run the\nfunction mythread(), though with different arguments (the string A or\nB). Once a thread is created, it may start running right away (d epending\non the whims of the scheduler); alternately , it may be put in a \u201cr eady\u201d but\nnot \u201crunning\u201d state and thus not run yet. Of course, on a multiproce ssor ,\nthe threads could even be running at the same time, but let\u2019s not w orry\nabout this possibility quite yet.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "that creates two threads, each of which does some independent wor k, in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "threads",
          "independent"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The main program creates two threads, each of which will run the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "program",
          "creates",
          "threads"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": ". Once a thread is created, it may start running right away (d epending",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "created",
          "start",
          "running",
          "right",
          "away",
          "epending"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand an example: thread creation",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "thread",
          "creation"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 C O N C U R R E N C Y: A N IN T R O D U C T I O ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 C O N C U R R E N C Y: A N IN T R O D U C T I O N\n1 #include <stdio.h>\n2 #include <assert.h>\n3 #include <pthread.h>\n4 #include \"common.h\"\n5 #include \"common_threads.h\"\n6\n7 void *mythread(void *arg) {\n8 printf(\"%s\\n\", (char *) arg);\n9 return NULL;\n10 }\n11\n12 int\n13 main(int argc, char *argv[]) {\n14 pthread_t p1, p2;\n15 int rc;\n16 printf(\"main: begin\\n\");\n17 Pthread_create(&p1, NULL, mythread, \"A\");\n18 Pthread_create(&p2, NULL, mythread, \"B\");\n19 // join waits for the threads to finish\n20 Pthread_join(p1, NULL);\n21 Pthread_join(p2, NULL);\n22 printf(\"main: end\\n\");\n23 return 0;\n24 }\nFigure 26.2: Simple Thread Creation Code (t0.c)\nAfter creating the two threads (let\u2019s call them T1 and T2), the main\nthread calls pthread\njoin(), which waits for a particular thread to\ncomplete. It does so twice, thus ensuring T1 and T2 will run and c om-\nplete before \ufb01nally allowing the main thread to run again; when it does,\nit will print \u201cmain: end\u201d and exit. Overall, three threads we re employed\nduring this run: the main thread, T1, and T2.\nLet us examine the possible execution ordering of this little prog ram.\nIn the execution diagram (Figure 26.3, page 5), time increase s in the down-\nwards direction, and each column shows when a different thread ( the\nmain one, or Thread 1, or Thread 2) is running.\nNote, however , that this ordering is not the only possible ordering. In\nfact, given a sequence of instructions, there are quite a few , d epending on\nwhich thread the scheduler decides to run at a given point. For e xample,\nonce a thread is created, it may run immediately , which would le ad to the\nexecution shown in Figure 26.4 (page 5).\nW e also could even see \u201cB\u201d printed before \u201cA \u201d, if, say , the sched uler\ndecided to run Thread 2 \ufb01rst even though Thread 1 was created ea rlier;\nthere is no reason to assume that a thread that is created \ufb01rst w ill run \ufb01rst.\nFigure 26.5 (page 6) shows this \ufb01nal execution ordering, with Th read 2\ngetting to strut its stuff before Thread 1.\nAs you might be able to see, one way to think about thread creation\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pthread_create(&p1, NULL, mythread, \"A\");",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Pthread_create(&p2, NULL, mythread, \"B\");",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "once a thread is created, it may run immediately , which would le ad to the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "created",
          "immediately",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "decided to run Thread 2 \ufb01rst even though Thread 1 was created ea rlier;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "decided",
          "thread",
          "even",
          "though",
          "thread",
          "created",
          "rlier"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "there is no reason to assume that a thread that is created \ufb01rst w ill run \ufb01rst.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reason",
          "assume",
          "thread",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "As you might be able to see, one way to think about thread creation",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "might",
          "able",
          "think",
          "thread",
          "creation"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 2: Simple Thread Creation Code (t0.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "simple",
          "thread",
          "creation",
          "code"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand main: end\u201d and exit. Overall, three threads we re employed",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "exit",
          "overall",
          "three",
          "threads",
          "employed"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand during this run: the main thread, T1, and T2.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "during this run",
          "main",
          "thread"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 5...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 5\nmain Thread 1 Thread2\nstarts running\nprints \u201cmain: begin\u201d\ncreates Thread 1\ncreates Thread 2\nwaits for T1\nruns\nprints \u201cA \u201d\nreturns\nwaits for T2\nruns\nprints \u201cB\u201d\nreturns\nprints \u201cmain: end\u201d\nFigure 26.3: Thread T race (1)\nmain Thread 1 Thread2\nstarts running\nprints \u201cmain: begin\u201d\ncreates Thread 1\nruns\nprints \u201cA \u201d\nreturns\ncreates Thread 2\nruns\nprints \u201cB\u201d\nreturns\nwaits for T1\nreturns immediately; T1 is done\nwaits for T2\nreturns immediately; T2 is done\nprints \u201cmain: end\u201d\nFigure 26.4: Thread T race (2)\nis that it is a bit like making a function call; however , instead of \ufb01rst ex-\necuting the function and then returning to the caller , the sys tem instead\ncreates a new thread of execution for the routine that is being cal led, and\nit runs independently of the caller , perhaps before returning from the cre-\nate, but perhaps much later . What runs next is determined by t he OS\nscheduler, and although the scheduler likely implements some sensible\nalgorithm, it is hard to know what will run at any given moment in t ime.\nAs you also might be able to tell from this example, threads make life\ncomplicated: it is already hard to tell what will run when! Comp uters are\nhard enough to understand without concurrency . Unfortunately , with\nconcurrency , it simply gets worse. Much worse.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "creates Thread 1",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "creates Thread 2",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "creates a new thread of execution for the routine that is being cal led, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "thread",
          "execution",
          "routine"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "scheduler, and although the scheduler likely implements some sensible",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "scheduler",
          "although",
          "scheduler",
          "likely",
          "implements",
          "sensible"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "algorithm, it is hard to know what will run at any given moment in t ime.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "hard",
          "know",
          "given",
          "moment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "As you also might be able to tell from this example, threads make life",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "might",
          "able",
          "tell",
          "example",
          "threads",
          "make",
          "life"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "hard enough to understand without concurrency . Unfortunately , with",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hard",
          "enough",
          "understand",
          "without",
          "concurrency",
          "unfortunately"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_8",
        "text": "understand threads make life\ncomplicated: it is already hard to tell what will run when! Comp uters are",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "threads make life\ncomplicated",
          "already",
          "hard",
          "tell",
          "comp",
          "uters"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "3 Why It Gets W orse: Shared Data",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "26.3 Why It Gets W orse: Shared Data\nThe simple thread example we showed above was useful in showing\nhow threads are created and how they can run in different orders d epend-\ning on how the scheduler decides to run them. What it doesn\u2019t show you ,\nthough, is how threads interact when they access shared data.\nLet us imagine a simple example where two threads wish to upda te a\nglobal shared variable. The code we\u2019ll study is in Figure 26.6 (p age 7).\nHere are a few notes about the code. First, as Stevens suggests [SR0 5],\nwe wrap the thread creation and join routines to simply exit on fai lure;\nfor a program as simple as this one, we want to at least notice an err or\noccurred (if it did), but not do anything very smart about it (e.g ., just\nexit). Thus, Pthread\ncreate() simply calls pthread create() and\nmakes sure the return code is 0; if it isn\u2019t, Pthread create() just prints\na message and exits.\nSecond, instead of using two separate function bodies for the worker\nthreads, we just use a single piece of code, and pass the thread a n argu-\nment (in this case, a string) so we can have each thread print a different\nletter before its messages.\nFinally , and most importantly , we can now look at what each worker is\ntrying to do: add a number to the shared variable counter, and do so 10\nmillion times (1e7) in a loop. Thus, the desired \ufb01nal result is: 2 0,000,000.\nW e now compile and run the program, to see how it behaves. Some-\ntimes, everything works how we might expect:\nprompt> gcc -o main main.c -Wall -pthread; ./main\nmain: begin (counter = 0)\nA: begin\nB: begin\nA: done\nB: done\nmain: done with both (counter = 20000000)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "how threads are created and how they can run in different orders d epend-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "threads",
          "created",
          "different",
          "orders",
          "epend"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "create() simply calls pthread create() and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "simply",
          "calls",
          "pthread",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "makes sure the return code is 0; if it isn\u2019t, Pthread create() just prints",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "makes",
          "sure",
          "return",
          "code",
          "pthread",
          "create",
          "prints"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Finally , and most importantly , we can now look at what each worker is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "importantly",
          "look",
          "worker"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_10",
        "text": "understand main: done with both (counter = 20000000)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "done",
          "counter"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand why it gets w orse: shared data",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "gets",
          "orse",
          "shared",
          "data"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 7...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 7\n1 #include <stdio.h>\n2 #include <pthread.h>\n3 #include \"common.h\"\n4 #include \"common_threads.h\"\n5\n6 static volatile int counter = 0;\n7\n8 // mythread()\n9 //\n10 // Simply adds 1 to counter repeatedly, in a loop\n11 // No, this is not how you would add 10,000,000 to\n12 // a counter, but it shows the problem nicely.\n13 //\n14 void *mythread(void *arg) {\n15 printf(\"%s: begin\\n\", (char *) arg);\n16 int i;\n17 for (i = 0; i < 1e7; i++) {\n18 counter = counter + 1;\n19 }\n20 printf(\"%s: done\\n\", (char *) arg);\n21 return NULL;\n22 }\n23\n24 // main()\n25 //\n26 // Just launches two threads (pthread_create)\n27 // and then waits for them (pthread_join)\n28 //\n29 int main(int argc, char *argv[]) {\n30 pthread_t p1, p2;\n31 printf(\"main: begin (counter = %d)\\n\", counter);\n32 Pthread_create(&p1, NULL, mythread, \"A\");\n33 Pthread_create(&p2, NULL, mythread, \"B\");\n34\n35 // join waits for the threads to finish\n36 Pthread_join(p1, NULL);\n37 Pthread_join(p2, NULL);\n38 printf(\"main: done with both (counter = %d)\\n\",\n39 counter);\n40 return 0;\n41 }\nFigure 26.6: Sharing Data: Uh Oh (t1.c)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "// Just launches two threads (pthread_create)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "launches",
          "threads"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Pthread_create(&p1, NULL, mythread, \"A\");",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Pthread_create(&p2, NULL, mythread, \"B\");",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand s: begin\\n\", (char *) arg);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s",
          "begin",
          "char"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand s: done\\n\", (char *) arg);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s",
          "done",
          "char"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand main: begin (counter = %d)\\n\", counter);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "begin",
          "counter",
          "counter"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand main: done with both (counter = %d)\\n\",",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "done",
          "counter"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 6: Sharing Data: Uh Oh (t1.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "sharing",
          "data"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 C O N C U R R E N C Y: A N IN T R O D U C T I O ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 C O N C U R R E N C Y: A N IN T R O D U C T I O N\nUnfortunately , when we run this code, even on a single processor , w e\ndon\u2019t necessarily get the desired result. Sometimes, we get:\nprompt> ./main\nmain: begin (counter = 0)\nA: begin\nB: begin\nA: done\nB: done\nmain: done with both (counter = 19345221)\nLet\u2019s try it one more time, just to see if we\u2019ve gone crazy . After all ,\naren\u2019t computers supposed to produce deterministic results, as you have\nbeen taught?! Perhaps your professors have been lying to you? (gasp)\nprompt> ./main\nmain: begin (counter = 0)\nA: begin\nB: begin\nA: done\nB: done\nmain: done with both (counter = 19221041)\nNot only is each run wrong, but also yields a different result! A big\nquestion remains: why does this happen?\nTI P : K N O W AN D US E YO U R TO O L S\nY ou should always learn new tools that help you write, debug, and un -\nderstand computer systems. Here, we use a neat tool called a disassem-\nbler. When you run a disassembler on an executable, it shows you what\nassembly instructions make up the program. For example, if we wi sh to\nunderstand the low-level code to update a counter (as in our examp le),\nwe run objdump (Linux) to see the assembly code:\nprompt> objdump -d main\nDoing so produces a long listing of all the instructions in the progr am,\nneatly labeled (particularly if you compiled with the -g \ufb02ag), which in-\ncludes symbol information in the program. The objdump program is just\none of many tools you should learn how to use; a debugger like gdb,\nmemory pro\ufb01lers like valgrind or purify, and of course the compiler\nitself are others that you should spend time to learn more about; th e better\nyou are at using your tools, the better systems you\u2019ll be able to buil d.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Y ou should always learn new tools that help you write, debug, and un -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "always",
          "learn",
          "tools",
          "help",
          "write",
          "debug"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand the low-level code to update a counter (as in our examp le),",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "level",
          "code",
          "update",
          "counter",
          "examp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "one of many tools you should learn how to use; a debugger like gdb,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "tools",
          "learn",
          "debugger",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "itself are others that you should spend time to learn more about; th e better",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "others",
          "spend",
          "time",
          "learn",
          "better"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "you are at using your tools, the better systems you\u2019ll be able to buil d.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "tools",
          "better",
          "systems",
          "able",
          "buil"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_8",
        "text": "understand main: done with both (counter = 19345221)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "done",
          "counter"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_14",
        "text": "understand main: done with both (counter = 19221041)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "done",
          "counter"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_15",
        "text": "understand A big\nquestion remains: why does this happen?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a big\nquestion remains",
          "happen"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_16",
        "text": "understand TI P: K N O W AN D US E YO U R TO O L S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "4 The Heart Of The Problem: Uncontrolled Scheduling",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "26.4 The Heart Of The Problem: Uncontrolled Scheduling\nT o understand why this happens, we must understand the code se -\nquence that the compiler generates for the update to counter. In this\ncase, we wish to simply add a number (1) to counter. Thus, the code\nsequence for doing so might look something like this (in x86);\nmov 0x8049a1c, %eax\nadd $0x1, %eax\nmov %eax, 0x8049a1c\nThis example assumes that the variable counter is located at address\n0x8049a1c. In this three-instruction sequence, the x86 mov instruction is\nused \ufb01rst to get the memory value at the address and put it into r egister\neax. Then, the add is performed, adding 1 (0x1) to the contents of the\neax register , and \ufb01nally , the contents of eax are stored back into memory\nat the same address.\nLet us imagine one of our two threads (Thread 1) enters this region of\ncode, and is thus about to increment counter by one. It loads the value\nof counter (let\u2019s say it\u2019s 50 to begin with) into its register eax. Thus,\neax=50 for Thread 1. Then it adds one to the register; thus eax=51.\nNow , something unfortunate happens: a timer interrupt goes off; t hus,\nthe OS saves the state of the currently running thread (its PC, its registers\nincluding eax, etc.) to the thread\u2019s TCB.\nNow something worse happens: Thread 2 is chosen to run, and it en-\nters this same piece of code. It also executes the \ufb01rst instruct ion, getting\nthe value of counter and putting it into its eax (remember: each thread\nwhen running has its own private registers; the registers are virtualized\nby the context-switch code that saves and restores them). The va lue of\ncounter is still 50 at this point, and thus Thread 2 has eax=50. Let\u2019s\nthen assume that Thread 2 executes the next two instructions, increment-\ning eax by 1 (thus eax=51), and then saving the contents of eax into\ncounter (address 0x8049a1c). Thus, the global variable counter now\nhas the value 51.\nFinally , another context switch occurs, and Thread 1 resumes ru nning.\nRecall that it had just executed the mov and add, and is now about to\nperform the \ufb01nal mov instruction. Recall also that eax=51. Thus, the \ufb01nal\nmov instruction executes, and saves the value to memory; the counte r is\nset to 51 again.\nPut simply , what has happened is this: the code to increment counter\nhas been run twice, but counter, which started at 50, is now only equal\nto 51. A \u201ccorrect\u201d version of this program should have resulted in t he\nvariable counter equal to 52.\nLet\u2019s look at a detailed execution trace to understand the problem bet-\nter . Assume, for this example, that the above code is loaded at add ress\n100 in memory , like the following sequence (note for those of you used t o\nnice, RISC-like instruction sets: x86 has variable-length in structions; this\nmov instruction takes up 5 bytes of memory , and the add only 3):\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand why this happens, we must understand the code se -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "happens",
          "must",
          "understand",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Let\u2019s look at a detailed execution trace to understand the problem bet-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "look",
          "detailed",
          "execution",
          "trace",
          "understand",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand something unfortunate happens: a timer interrupt goes off; t hus,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "something unfortunate happens",
          "timer",
          "interrupt",
          "goes"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Now something worse happens: Thread 2 is chosen to run, and it en-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "now something worse happens",
          "thread",
          "chosen"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand like instruction sets: x86 has variable-length in structions; this",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "like instruction sets",
          "variable",
          "length",
          "structions"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the heart of the problem: uncontrolled scheduling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "heart",
          "problem",
          "uncontrolled",
          "scheduling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 C O N C U R R E N C Y: A N IN T R O D U C T I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 C O N C U R R E N C Y: A N IN T R O D U C T I O N\n(after instruction)\nOS Thread 1 Thread 2 PC eax counter\nbefore critical section 100 0 50\nmov 8049a1c,%eax 105 50 50\nadd $0x1,%eax 108 51 50\ninterrupt\nsave T1\nrestore T2 100 0 50\nmov 8049a1c,%eax 105 50 50\nadd $0x1,%eax 108 51 50\nmov %eax,8049a1c 113 51 51\ninterrupt\nsave T2\nrestore T1 108 51 51\nmov %eax,8049a1c 113 51 51\nFigure 26.7: The Problem: Up Close and Personal\n100 mov 0x8049a1c, %eax\n105 add $0x1, %eax\n108 mov %eax, 0x8049a1c\nWith these assumptions, what happens is shown in Figure 26.7 (p age\n10). Assume the counter starts at value 50, and trace through th is example\nto make sure you understand what is going on.\nWhat we have demonstrated here is called a race condition (or , more\nspeci\ufb01cally , a data race ): the results depend on the timing execution of\nthe code. With some bad luck (i.e., context switches that occur at un-\ntimely points in the execution), we get the wrong result. In fact , we may\nget a different result each time; thus, instead of a nice deterministic com-\nputation (which we are used to from computers), we call this resu lt inde-\nterminate, where it is not known what the output will be and it is indeed\nlikely to be different across runs.\nBecause multiple threads executing this code can result in a r ace con-\ndition, we call this code a critical section. A critical section is a piece of\ncode that accesses a shared variable (or more generally , a share d resource)\nand must not be concurrently executed by more than one thread.\nWhat we really want for this code is what we call mutual exclusion.\nThis property guarantees that if one thread is executing withi n the critical\nsection, the others will be prevented from doing so.\nVirtually all of these terms, by the way , were coined by Edsger D ijk-\nstra, who was a pioneer in the \ufb01eld and indeed won the T uring A war d\nbecause of this and other work; see his 1968 paper on \u201cCooperating Se-\nquential Processes\u201d [D68] for an amazingly clear description of the prob-\nlem. W e\u2019ll be hearing more about Dijkstra in this section of the book.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "before critical section 100 0 50",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to make sure you understand what is going on.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "sure",
          "understand",
          "going"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "What we have demonstrated here is called a race condition (or , more",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "demonstrated",
          "called",
          "race",
          "condition"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "terminate, where it is not known what the output will be and it is indeed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "terminate",
          "known",
          "output",
          "indeed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "dition, we call this code a critical section. A critical section is a piece of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dition",
          "call",
          "code",
          "critical",
          "section",
          "critical",
          "section",
          "piece"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "This property guarantees that if one thread is executing withi n the critical",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "property",
          "guarantees",
          "thread",
          "executing",
          "withi",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 7: The Problem: Up Close and Personal",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "problem",
          "close",
          "personal"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "5 The Wish For Atomicity",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "26.5 The Wish For Atomicity\nOne way to solve this problem would be to have more powerful in-\nstructions that, in a single step, did exactly whatever we nee ded done\nand thus removed the possibility of an untimely interrupt. For ex ample,\nwhat if we had a super instruction that looked like this:\nmemory-add 0x8049a1c, $0x1\nAssume this instruction adds a value to a memory location, and the\nhardware guarantees that it executes atomically; when the instruction\nexecuted, it would perform the update as desired. It could not be i nter-\nrupted mid-instruction, because that is precisely the guara ntee we receive\nfrom the hardware: when an interrupt occurs, either the instru ction has\nnot run at all, or it has run to completion; there is no in-between s tate.\nHardware can be a beautiful thing, no?\nAtomically , in this context, means \u201cas a unit\u201d, which sometimes we\ntake as \u201call or none.\u201d What we\u2019d like is to execute the three instr uction\nsequence atomically:\nmov 0x8049a1c, %eax\nadd $0x1, %eax\nmov %eax, 0x8049a1c\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One way to solve this problem would be to have more powerful in-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "problem",
          "would",
          "powerful"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the wish for atomicity",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "wish",
          "atomicity"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "6 One More Problem: W aiting For Another",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "26.6 One More Problem: W aiting For Another\nThis chapter has set up the problem of concurrency as if only one typ e\nof interaction occurs between threads, that of accessing shared variables\nand the need to support atomicity for critical sections. As it tur ns out,\nthere is another common interaction that arises, where one thread must\nwait for another to complete some action before it continues. This in ter-\naction arises, for example, when a process performs a disk I/O and is put\nto sleep; when the I/O completes, the process needs to be roused f rom its\nslumber so it can continue.\nThus, in the coming chapters, we\u2019ll be not only studying how to buil d\nsupport for synchronization primitives to support atomicity but a lso for\nmechanisms to support this type of sleeping/waking interacti on that is\ncommon in multi-threaded programs. If this doesn\u2019t make sense rig ht\nnow , that is OK! It will soon enough, when you read the chapter on con-\ndition variables . If it doesn\u2019t by then, well, then it is less OK, and you\nshould read that chapter again (and again) until it does make se nse.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and the need to support atomicity for critical sections. As it tur ns out,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "support",
          "atomicity",
          "critical",
          "sections"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand one more problem: w aiting for another",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "aiting",
          "another"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "26",
    "title": "7 Summary: Why in OS Class?",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "26.7 Summary: Why in OS Class?\nBefore wrapping up, one question that you might have is: why are we\nstudying this in OS class? \u201cHistory\u201d is the one-word answer; the OS was\nthe \ufb01rst concurrent program, and many techniques were created for use\nwithin the OS. Later , with multi-threaded processes, application prog ram-\nmers also had to consider such things.\nFor example, imagine the case where there are two processes run ning.\nAssume they both call write() to write to the \ufb01le, and both wish to\nappend the data to the \ufb01le (i.e., add the data to the end of the \ufb01l e, thus\nincreasing its length). T o do so, both must allocate a new block, r ecord\nin the inode of the \ufb01le where this block lives, and change the size of the\n\ufb01le to re\ufb02ect the new larger size (among other things; we\u2019ll lear n more\nabout \ufb01les in the third part of the book). Because an interrupt may occur\nat any time, the code that updates these shared structures (e. g., a bitmap\nfor allocation, or the \ufb01le\u2019s inode) are critical sections; thus, OS d esign-\ners, from the very beginning of the introduction of the interrupt, had to\nworry about how the OS updates internal structures. An untimely inter-\nrupt causes all of the problems described above. Not surprisingl y , page\ntables, process lists, \ufb01le system structures, and virtually every kernel data\nstructure has to be carefully accessed, with the proper synch ronization\nprimitives, to work correctly .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the \ufb01rst concurrent program, and many techniques were created for use",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "program",
          "many",
          "techniques",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "for allocation, or the \ufb01le\u2019s inode) are critical sections; thus, OS d esign-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "allocation",
          "inode",
          "critical",
          "sections",
          "thus",
          "esign"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "rupt causes all of the problems described above. Not surprisingl y , page",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rupt",
          "causes",
          "problems",
          "described",
          "surprisingl",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary: why in os class?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary",
          "class"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 C O N C U R R E N C Y: A N IN T R O D U C T I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 C O N C U R R E N C Y: A N IN T R O D U C T I O N\nReferences\n[D65] \u201cSolution of a problem in concurrent programming control\u201d by E. W . Dijkstra. Commu-\nnications of the ACM, 8(9):569, September 1965. Pointed to as the \ufb01rst paper of Dijkstra\u2019s where\nhe outlines the mutual exclusion problem and a solution. The solution, howeve r , is not widely used;\nadvanced hardware and OS support is needed, as we will see in the coming c hapters.\n[D68] \u201cCooperating sequential processes\u201d by Edsger W . Dijkstra . 1968. A vailable at this site:\nhttp://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. Dijkstra has an amaz-\ning number of his old papers, notes, and thoughts recorded (for posterity) on thi s website at the last\nplace he worked, the University of T exas. Much of his foundational work, howeve r , was done years\nearlier while he was at the T echnische Hochshule of Eindhoven (THE), in cluding this famous paper on\n\u201ccooperating sequential processes\u201d, which basically outlines all of the thi nking that has to go into writ-\ning multi-threaded programs. Dijkstra discovered much of this while worki ng on an operating system\nnamed after his school: the \u201cTHE\u201d operating system (said \u201cT\u201d, \u201cH\u201d, \u201cE\u201d, and n ot like the word \u201cthe\u201d).\n[GR92] \u201cT ransaction Processing: Concepts and T echniques\u201d by Jim Gray and And reas Reuter .\nMorgan Kaufmann, September 1992. This book is the bible of transaction processing, written by one\nof the legends of the \ufb01eld, Jim Gray. It is, for this reason, also considered Ji m Gray\u2019s \u201cbrain dump\u201d,\nin which he wrote down everything he knows about how database management system s work. Sadly,\nGray passed away tragically a few years back, and many of us lost a friend and gre at mentor , including\nthe co-authors of said book, who were lucky enough to interact with Gray during thei r graduate school\nyears.\n[L+93] \u201cAtomic T ransactions\u201d by Nancy Lynch, Michael Merritt, William W ei hl, Alan Fekete.\nMorgan Kaufmann, August 1993. A nice text on some of the theory and practice of atomic transac-\ntions for distributed systems. Perhaps a bit formal for some, but lots of good mate rial is found herein.\n[NM92] \u201cWhat Are Race Conditions? Some Issues and Formalizations\u201d by Robert H. B. Netzer\nand Barton P . Miller . ACM Letters on Programming Languages and Syst ems, V olume 1:1,\nMarch 1992. An excellent discussion of the different types of races found in concu rrent programs. In\nthis chapter (and the next few), we focus on data races, but later we will broaden to discuss general\nraces as well.\n[SR05] \u201cAdvanced Programming in the U N I X Environment\u201d by W . Richard Stevens and Stephen\nA. Rago. Addison-W esley , 2005. As we\u2019ve said many times, buy this book, and read it, in little\nchunks, preferably before going to bed. This way, you will actually fall as leep more quickly; more im-\nportantly, you learn a little more about how to become a serious UN I X programmer .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[GR92] \u201cT ransaction Processing: Concepts and T echniques\u201d by Jim Gray and And reas Reuter .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ransaction",
          "processing",
          "concepts",
          "echniques",
          "gray",
          "reas",
          "reuter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in which he wrote down everything he knows about how database management system s work. Sadly,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wrote",
          "everything",
          "knows",
          "database",
          "management",
          "system",
          "work",
          "sadly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Morgan Kaufmann, August 1993. A nice text on some of the theory and practice of atomic transac-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "morgan",
          "kaufmann",
          "august",
          "nice",
          "text",
          "theory",
          "practice",
          "atomic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "chunks, preferably before going to bed. This way, you will actually fall as leep more quickly; more im-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "chunks",
          "preferably",
          "going",
          "actually",
          "fall",
          "leep",
          "quickly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "portantly, you learn a little more about how to become a serious UN I X programmer .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "portantly",
          "learn",
          "little",
          "become",
          "serious",
          "programmer"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 1...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N C U R R E N C Y: A N IN T R O D U C T I O N 15\nHomework (Simulation)\nThis program, x86.py, allows you to see how different thread inter-\nleavings either cause or avoid race conditions. See the README for d e-\ntails on how the program works, then answer the questions below .\nQuestions\n1. Let\u2019s examine a simple program, \u201cloop.s\u201d. First, just read and un-\nderstand it. Then, run it with these arguments ( ./x86.py -p loop.s\n-t 1 -i 100 -R dx) This speci\ufb01es a single thread, an interrupt\nevery 100 instructions, and tracing of register %dx. What will %dx\nbe during the run? Use the -c \ufb02ag to check your answers; the an-\nswers, on the left, show the value of the register (or memory value)\nafter the instruction on the right has run.\n2. Same code, different \ufb02ags: ( ./x86.py -p loop.s -t 2 -i 100\n-a\ndx=3,dx=3 -R dx) This speci\ufb01es two threads, and initializes each\n%dx to 3. What values will %dx see? Run with -c to check. Does\nthe presence of multiple threads affect your calculations? Is t here a\nrace in this code?\n3. Run this: ./x86.py -p loop.s -t 2 -i 3 -r -a dx=3,dx=3\n-R dx This makes the interrupt interval small/random; use dif-\nferent seeds ( -s) to see different interleavings. Does the interrupt\nfrequency change anything?\n4. Now , a different program, looping-race-nolock.s, which ac-\ncesses a shared variable located at address 2000; we\u2019ll call th is vari-\nable value. Run it with a single thread to con\ufb01rm your under-\nstanding: ./x86.py -p\nlooping-race-nolock.s -t 1 -M 2000 What is value (i.e.,\nat memory address 2000) throughout the run? Use -c to check.\n5. Run with multiple iterations/threads: ./x86.py -p\nlooping-race-nolock.s -t 2 -a bx=3 -M 2000 Why does\neach thread loop three times? What is \ufb01nal value of value?\n6. Run with random interrupt intervals: ./x86.py -p\nlooping-race-nolock.s -t 2 -M 2000 -i 4 -r -s 0 with\ndifferent seeds ( -s 1, -s 2, etc.) Can you tell by looking at the\nthread interleaving what the \ufb01nal value of value will be? Does the\ntiming of the interrupt matter? Where can it safely occur? Wher e\nnot? In other words, where is the critical section exactly?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "not? In other words, where is the critical section exactly?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "words",
          "critical",
          "section",
          "exactly"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand different \ufb02ags: ( ./x86.py -p loop.s -t 2 -i 100",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "different \ufb02ags",
          "loop"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Run this: ./x86.py -p loop.s -t 2 -i 3 -r -a dx=3,dx=3",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "run this",
          "loop"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand t 1 -i 100 -r dx) this speci\ufb01es a single thread, an interrupt",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "thread",
          "interrupt"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand r dx this makes the interrupt interval small/random; use dif-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "makes",
          "interrupt",
          "interval",
          "small",
          "random"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand value (i.e.,\nat memory address 2000) throughout the run",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "value",
          "memory",
          "address",
          "throughout"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand \ufb01nal value of value",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "value",
          "value"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_3",
        "text": "understand the critical section exactly",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "exactly"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 C O N C U R R E N C Y: A N IN T R O D U C T I O...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 C O N C U R R E N C Y: A N IN T R O D U C T I O N\n7. Now examine \ufb01xed interrupt intervals: ./x86.py -p\nlooping-race-nolock.s -a bx=1 -t 2 -M 2000 -i 1 What\nwill the \ufb01nal value of the shared variable value be? What about\nwhen you change -i 2, -i 3, etc.? For which interrupt intervals\ndoes the program give the \u201ccorrect\u201d answer?\n8. Run the same for more loops (e.g., set -a bx=100). What inter-\nrupt intervals ( -i) lead to a correct outcome? Which intervals are\nsurprising?\n9. One last program: wait-for-me.s. Run: ./x86.py -p\nwait-for-me.s -a ax=1,ax=0 -R ax -M 2000 This sets the\n%ax register to 1 for thread 0, and 0 for thread 1, and watches %ax\nand memory location 2000. How should the code behave? How is\nthe value at location 2000 being used by the threads? What will i ts\n\ufb01nal value be?\n10. Now switch the inputs: ./x86.py -p wait-for-me.s -a\nax=0,ax=1 -R ax -M 2000 How do the threads behave? What\nis thread 0 doing? How would changing the interrupt interval (e. g.,\n-i 1000, or perhaps to use random intervals) change the trace out-\ncome? Is the program ef\ufb01ciently using the CPU?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "rupt intervals ( -i) lead to a correct outcome? Which intervals are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rupt",
          "intervals",
          "lead",
          "correct",
          "outcome",
          "intervals"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand One last program: wait-for-me.s. Run: ./x86.py -p",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last program",
          "wait"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Now switch the inputs: ./x86.py -p wait-for-me.s -a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "now switch the inputs",
          "wait"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand i 1000, or perhaps to use random intervals) change the trace out-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "perhaps",
          "random",
          "intervals",
          "change",
          "trace"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand thread 0 doing",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "thread"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "27",
    "title": "1 Thread Creation",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "27.1 Thread Creation\nThe \ufb01rst thing you have to be able to do to write a multi-threade d\nprogram is to create new threads, and thus some kind of thread cre ation\ninterface must exist. In POSIX, it is easy:\n#include <pthread.h>\nint\npthread_create(pthread_t *thread,\nconst pthread_attr_t *attr,\nvoid *(*start_routine)(void*),\nvoid *arg);\nThis declaration might look a little complex (particularly if you haven\u2019t\nused function pointers in C), but actually it\u2019s not too bad. There a re\nfour arguments: thread, attr, start\nroutine, and arg. The \ufb01rst,\nthread, is a pointer to a structure of type pthread t; we\u2019ll use this\nstructure to interact with this thread, and thus we need to pa ss it to\npthread create() in order to initialize it.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The \ufb01rst thing you have to be able to do to write a multi-threade d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thing",
          "able",
          "write",
          "multi",
          "threade"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "program is to create new threads, and thus some kind of thread cre ation",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "create",
          "threads",
          "thus",
          "kind",
          "thread",
          "ation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "pthread_create(pthread_t *thread,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "pthread create() in order to initialize it.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pthread",
          "create",
          "order",
          "initialize"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand thread creation",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "creation"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "27",
    "title": "2 Thread Completion",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "27.2 Thread Completion\nThe example above shows how to create a thread. However , what\nhappens if you want to wait for a thread to complete? Y ou need to do\nsomething special in order to wait for completion; in particular , you must\ncall the routine pthread\njoin().\nint pthread_join(pthread_t thread, void **value_ptr);\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The example above shows how to create a thread. However , what",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "shows",
          "create",
          "thread",
          "however"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand thread completion",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "completion"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : T H R E A D API 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : T H R E A D API 3\n1 #include <stdio.h>\n2 #include <pthread.h>\n3\n4 typedef struct {\n5 int a;\n6 int b;\n7 } myarg_t;\n8\n9 void *mythread(void *arg) {\n10 myarg_t *args = (myarg_t *) arg;\n11 printf(\"%d %d\\n\", args->a, args->b);\n12 return NULL;\n13 }\n14\n15 int main(int argc, char *argv[]) {\n16 pthread_t p;\n17 myarg_t args = { 10, 20 };\n18\n19 int rc = pthread_create(&p, NULL, mythread, &args);\n20 ...\n21 }\nFigure 27.1: Creating a Thread\nThis routine takes two arguments. The \ufb01rst is of type pthread\nt, and\nis used to specify which thread to wait for . This variable is in itialized by\nthe thread creation routine (when you pass a pointer to it as an arg ument\nto pthread create()); if you keep it around, you can use it to wait for\nthat thread to terminate.\nThe second argument is a pointer to the return value you expect to get\nback. Because the routine can return anything, it is de\ufb01ned to return a\npointer to void; because the pthread join() routine changes the value\nof the passed in argument, you need to pass in a pointer to that val ue, not\njust the value itself.\nLet\u2019s look at another example (Figure 27.2, page 4). In the code, a\nsingle thread is again created, and passed a couple of argument s via the\nmyarg t structure. T o return values, the myret t type is used. Once\nthe thread is \ufb01nished running, the main thread, which has bee n waiting\ninside of the pthread join() routine1 , then returns, and we can access\nthe values returned from the thread, namely whatever is in myret t.\nA few things to note about this example. First, often times we don\u2019t\nhave to do all of this painful packing and unpacking of argument s. For\nexample, if we just create a thread with no arguments, we can p ass NULL\nin as an argument when the thread is created. Similarly , we can pass NULL\ninto pthread join() if we don\u2019t care about the return value.\n1 Note we use wrapper functions here; speci\ufb01cally , we call Malloc(), Pthread join(), and\nPthread create(), which just call their similarly-named lower-case versions and m ake sure the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "int rc = pthread_create(&p, NULL, mythread, &args);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread",
          "args"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to pthread create()); if you keep it around, you can use it to wait for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pthread",
          "create",
          "keep",
          "around",
          "wait"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "single thread is again created, and passed a couple of argument s via the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "thread",
          "created",
          "passed",
          "couple",
          "argument"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "example, if we just create a thread with no arguments, we can p ass NULL",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "create",
          "thread",
          "arguments",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "in as an argument when the thread is created. Similarly , we can pass NULL",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "argument",
          "thread",
          "created",
          "similarly",
          "pass",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Pthread create(), which just call their similarly-named lower-case versions and m ake sure the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pthread",
          "create",
          "call",
          "similarly",
          "named",
          "lower",
          "case",
          "versions"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 IN T E R L U D E : T H R E A D API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 IN T E R L U D E : T H R E A D API\n1 typedef struct { int a; int b; } myarg_t;\n2 typedef struct { int x; int y; } myret_t;\n3\n4 void *mythread(void *arg) {\n5 myret_t *rvals = Malloc(sizeof(myret_t));\n6 rvals->x = 1;\n7 rvals->y = 2;\n8 return (void *) rvals;\n9 }\n10\n11 int main(int argc, char *argv[]) {\n12 pthread_t p;\n13 myret_t *rvals;\n14 myarg_t args = { 10, 20 };\n15 Pthread_create(&p, NULL, mythread, &args);\n16 Pthread_join(p, (void **) &rvals);\n17 printf(\"returned %d %d\\n\", rvals->x, rvals->y);\n18 free(rvals);\n19 return 0;\n20 }\nFigure 27.2: W aiting for Thread Completion\nSecond, if we are just passing in a single value (e.g., a long long\nint), we don\u2019t have to package it up as an argument. Figure 27.3 (pag e\n5) shows an example. In this case, life is a bit simpler , as we don \u2019t have to\npackage arguments and return values inside of structures.\nThird, we should note that one has to be extremely careful with how\nvalues are returned from a thread. Speci\ufb01cally , never return a pointer\nwhich refers to something allocated on the thread\u2019s call stack. I f you do,\nwhat do you think will happen? (think about it!) Here is an exampl e of a\ndangerous piece of code, modi\ufb01ed from the example in Figure 27.2.\n1 void *mythread(void *arg) {\n2 myarg_t *args = (myarg_t *) arg;\n3 printf(\"%d %d\\n\", args->a, args->b);\n4 myret_t oops; // ALLOCATED ON STACK: BAD!\n5 oops.x = 1;\n6 oops.y = 2;\n7 return (void *) &oops;\n8 }\nIn this case, the variable oops is allocated on the stack of mythread.\nHowever , when it returns, the value is automatically deallocat ed (that\u2019s\nwhy the stack is so easy to use, after all!), and thus, passing b ack a pointer\nroutines did not return anything unexpected.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pthread_create(&p, NULL, mythread, &args);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "mythread",
          "args"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 2: W aiting for Thread Completion",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "aiting",
          "thread",
          "completion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "27",
    "title": "3 Locks",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "27.3 Locks\nBeyond thread creation and join, probably the next most useful set of\nfunctions provided by the POSIX threads library are those for provi ding\nmutual exclusion to a critical section via locks. The most basic pair of\nroutines to use for this purpose is provided by the following:\nint pthread_mutex_lock(pthread_mutex_t *mutex);\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n2 Fortunately the compiler gcc will likely complain when you write code like this, which\nis yet another reason to pay attention to compiler warnings.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "mutual exclusion to a critical section via locks. The most basic pair of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mutual",
          "exclusion",
          "critical",
          "section",
          "locks",
          "basic",
          "pair"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 IN T E R L U D E : T H R E A D API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 IN T E R L U D E : T H R E A D API\nThe routines should be easy to understand and use. When you have a\nregion of code that is a critical section, and thus needs to be protected to\nensure correct operation, locks are quite useful. Y ou can probably imag-\nine what the code looks like:\npthread_mutex_t lock;\npthread_mutex_lock(&lock);\nx = x + 1; // or whatever your critical section is\npthread_mutex_unlock(&lock);\nThe intent of the code is as follows: if no other thread holds the lock\nwhen pthread\nmutex lock() is called, the thread will acquire the lock\nand enter the critical section. If another thread does indeed hol d the lock,\nthe thread trying to grab the lock will not return from the call un til it has\nacquired the lock (implying that the thread holding the lock has released\nit via the unlock call). Of course, many threads may be stuck wai ting\ninside the lock acquisition function at a given time; only the thr ead with\nthe lock acquired, however , should call unlock.\nUnfortunately , this code is broken, in two important ways. The \ufb01r st\nproblem is a lack of proper initialization . All locks must be properly\ninitialized in order to guarantee that they have the correct va lues to begin\nwith and thus work as desired when lock and unlock are called.\nWith POSIX threads, there are two ways to initialize locks. One way\nto do this is to use PTHREAD MUTEX INITIALIZER, as follows:\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\nDoing so sets the lock to the default values and thus makes the loc k\nusable. The dynamic way to do it (i.e., at run time) is to make a call to\npthread mutex init(), as follows:\nint rc = pthread_mutex_init(&lock, NULL);\nassert(rc == 0); // always check success!\nThe \ufb01rst argument to this routine is the address of the lock itsel f, whereas\nthe second is an optional set of attributes. Read more about the attr ibutes\nyourself; passing NULL in simply uses the defaults. Either way works, but\nwe usually use the dynamic (latter) method. Note that a correspon ding\ncall to pthread\nmutex destroy() should also be made, when you are\ndone with the lock; see the manual page for all of details.\nThe second problem with the code above is that it fails to check err or\ncodes when calling lock and unlock. Just like virtually any libr ary rou-\ntine you call in a U N I X system, these routines can also fail! If your code\ndoesn\u2019t properly check error codes, the failure will happen silen tly , which\nin this case could allow multiple threads into a critical secti on. Minimally ,\nuse wrappers, which assert that the routine succeeded, as show n in Fig-\nure 27.4 (page 7); more sophisticated (non-toy) programs, which c an\u2019t\nsimply exit when something goes wrong, should check for failure an d do\nsomething appropriate when a call does not succeed.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The routines should be easy to understand and use. When you have a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "routines",
          "easy",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "region of code that is a critical section, and thus needs to be protected to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "region",
          "code",
          "critical",
          "section",
          "thus",
          "needs",
          "protected"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "x = x + 1; // or whatever your critical section is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "whatever",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "and enter the critical section. If another thread does indeed hol d the lock,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "enter",
          "critical",
          "section",
          "another",
          "thread",
          "indeed",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Unfortunately , this code is broken, in two important ways. The \ufb01r st",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unfortunately",
          "code",
          "broken",
          "important",
          "ways"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "we usually use the dynamic (latter) method. Note that a correspon ding",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "usually",
          "dynamic",
          "latter",
          "method",
          "note",
          "correspon",
          "ding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "in this case could allow multiple threads into a critical secti on. Minimally ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "case",
          "could",
          "allow",
          "multiple",
          "threads",
          "critical",
          "secti",
          "minimally"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand as follows: pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as follows",
          "lock"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand as follows: int rc = pthread_mutex_init(&lock, NULL);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as follows",
          "lock",
          "null"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "27",
    "title": "4 Condition V ariables",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "27.4 Condition V ariables\nThe other major component of any threads library , and certainly th e\ncase with POSIX threads, is the presence of a condition variable . Con-\ndition variables are useful when some kind of signaling must tak e place\nbetween threads, if one thread is waiting for another to do someth ing be-\nfore it can continue. T wo primary routines are used by programs wi shing\nto interact in this way:\nint pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);\nint pthread_cond_signal(pthread_cond_t *cond);\nT o use a condition variable, one has to in addition have a lock that i s\nassociated with this condition. When calling either of the above r outines,\nthis lock should be held.\nThe \ufb01rst routine, pthread\ncond wait(), puts the calling thread to\nsleep, and thus waits for some other thread to signal it, usually when\nsomething in the program has changed that the now-sleeping thre ad might\ncare about. A typical usage looks like this:\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nPthread_mutex_lock(&lock);\nwhile (ready == 0)\nPthread_cond_wait(&cond, &lock);\nPthread_mutex_unlock(&lock);\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand condition v ariables",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "condition",
          "ariables"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 IN T E R L U D E : T H R E A D API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 IN T E R L U D E : T H R E A D API\nIn this code, after initialization of the relevant lock and condit ion3 , a\nthread checks to see if the variable ready has yet been set to something\nother than zero. If not, the thread simply calls the wait routine i n order to\nsleep until some other thread wakes it.\nThe code to wake a thread, which would run in some other thread,\nlooks like this:\nPthread_mutex_lock(&lock);\nready = 1;\nPthread_cond_signal(&cond);\nPthread_mutex_unlock(&lock);\nA few things to note about this code sequence. First, when signal ing\n(as well as when modifying the global variable ready), we always make\nsure to have the lock held. This ensures that we don\u2019t accidental ly intro-\nduce a race condition into our code.\nSecond, you might notice that the wait call takes a lock as its second\nparameter , whereas the signal call only takes a condition. The r eason\nfor this difference is that the wait call, in addition to puttin g the call-\ning thread to sleep, releases the lock when putting said caller to sleep.\nImagine if it did not: how could the other thread acquire the lock an d\nsignal it to wake up? However , before returning after being woken, the\npthread\ncond wait() re-acquires the lock, thus ensuring that any time\nthe waiting thread is running between the lock acquire at the b eginning\nof the wait sequence, and the lock release at the end, it holds the lock.\nOne last oddity: the waiting thread re-checks the condition in a while\nloop, instead of a simple if statement. W e\u2019ll discuss this issue i n detail\nwhen we study condition variables in a future chapter , but in ge neral,\nusing a while loop is the simple and safe thing to do. Although it re checks\nthe condition (perhaps adding a little overhead), there are some pthread\nimplementations that could spuriously wake up a waiting thread ; in such\na case, without rechecking, the waiting thread will continue t hinking that\nthe condition has changed even though it has not. It is safer thus t o view\nwaking up as a hint that something might have changed, rather t han an\nabsolute fact.\nNote that sometimes it is tempting to use a simple \ufb02ag to signal b e-\ntween two threads, instead of a condition variable and associate d lock.\nFor example, we could rewrite the waiting code above to look more like\nthis in the waiting code:\nwhile (ready == 0)\n; // spin\nThe associated signaling code would look like this:\nready = 1;\n3 One can use pthread cond init() (and pthread cond destroy()) instead of the\nstatic initializer PTHREAD COND INITIALIZER. Sound like more work? It is.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "implementations that could spuriously wake up a waiting thread ; in such",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementations",
          "could",
          "spuriously",
          "wake",
          "waiting",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand looks like this: Pthread_mutex_lock(&lock);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "looks like this",
          "lock"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand One last oddity: the waiting thread re-checks the condition in a while",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last oddity",
          "waiting",
          "thread",
          "checks",
          "condition"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "27",
    "title": "5 Compiling and Running",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "27.5 Compiling and Running\nAll of the code examples in this chapter are relatively easy to g et up\nand running. T o compile them, you must include the header pthread.h\nin your code. On the link line, you must also explicitly link with the\npthreads library , by adding the -pthread \ufb02ag.\nFor example, to compile a simple multi-threaded program, all you\nhave to do is the following:\nprompt> gcc -o main main.c -Wall -pthread\nAs long as main.c includes the pthreads header , you have now suc-\ncessfully compiled a concurrent program. Whether it works or not, a s\nusual, is a different matter entirely .",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand compiling and running",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "compiling",
          "running"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "27",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "27.6 Summary\nW e have introduced the basics of the pthread library , includin g thread\ncreation, building mutual exclusion via locks, and signaling a nd waiting\nvia condition variables. Y ou don\u2019t need much else to write robust an d\nef\ufb01cient multi-threaded code, except patience and a great de al of care!\nW e now end the chapter with a set of tips that might be useful to you\nwhen you write multi-threaded code (see the aside on the following page\nfor details). There are other aspects of the API that are interes ting; if you\nwant more information, type man -k pthread on a Linux system to\nsee over one hundred APIs that make up the entire interface. Howe ver ,\nthe basics discussed herein should enable you to build sophisti cated (and\nhopefully , correct and performant) multi-threaded programs. T he hard\npart with threads is not the APIs, but rather the tricky logic of h ow you\nbuild concurrent programs. Read on to learn more.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "build concurrent programs. Read on to learn more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "build",
          "concurrent",
          "programs",
          "read",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 IN T E R L U D E : T H R E A D API",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 IN T E R L U D E : T H R E A D API\nAS I D E : T H R E A D API G U I D E L I N E S\nThere are a number of small but important things to remember whe n\nyou use the POSIX thread library (or really , any thread library) to build a\nmulti-threaded program. They are:\n\u2022 Keep it simple. Above all else, any code to lock or signal between\nthreads should be as simple as possible. T ricky thread interac tions\nlead to bugs.\n\u2022 Minimize thread interactions. T ry to keep the number of ways\nin which threads interact to a minimum. Each interaction shoul d\nbe carefully thought out and constructed with tried and true ap-\nproaches (many of which we will learn about in the coming chap-\nters).\n\u2022 Initialize locks and condition variables. Failure to do so will lead\nto code that sometimes works and sometimes fails in very strange\nways.\n\u2022 Check your return codes. Of course, in any C and U N I X program-\nming you do, you should be checking each and every return code,\nand it\u2019s true here as well. Failure to do so will lead to bizarre and\nhard to understand behavior , making you likely to (a) scream, ( b)\npull some of your hair out, or (c) both.\n\u2022 Be careful with how you pass arguments to, and return values\nfrom, threads. In particular , any time you are passing a reference to\na variable allocated on the stack, you are probably doing something\nwrong.\n\u2022 Each thread has its own stack. As related to the point above, please\nremember that each thread has its own stack. Thus, if you have a\nlocally-allocated variable inside of some function a thread is ex e-\ncuting, it is essentially private to that thread; no other thread can\n(easily) access it. T o share data between threads, the value s must be\nin the heap or otherwise some locale that is globally accessible.\n\u2022 Always use condition variables to signal between threads. While\nit is often tempting to use a simple \ufb02ag, don\u2019t do it.\n\u2022 Use the manual pages. On Linux, in particular , the pthread man\npages are highly informative and discuss much of the nuances pr e-\nsented here, often in even more detail. Read them carefully!\n.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "There are a number of small but important things to remember whe n",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "number",
          "small",
          "important",
          "things",
          "remember"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "proaches (many of which we will learn about in the coming chap-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proaches",
          "many",
          "learn",
          "coming",
          "chap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "hard to understand behavior , making you likely to (a) scream, ( b)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hard",
          "understand",
          "behavior",
          "making",
          "likely",
          "scream"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "cuting, it is essentially private to that thread; no other thread can",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cuting",
          "essentially",
          "private",
          "thread",
          "thread"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: T H R E A D API G U I D E L I N E S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand They are: \u2022 Keep it simple. Above all else, any code to lock or signal between",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "they are",
          "keep",
          "simple",
          "else",
          "code",
          "lock",
          "signal"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand minimize thread interactions. t ry to keep the number of ways",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "minimize",
          "thread",
          "interactions",
          "keep",
          "number",
          "ways"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand initialize locks and condition variables. failure to do so will lead",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "initialize",
          "locks",
          "condition",
          "variables",
          "failure",
          "lead"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand check your return codes. of course, in any c and u n i x program-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "check",
          "return",
          "codes",
          "course",
          "program"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand be careful with how you pass arguments to, and return values",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "careful",
          "pass",
          "arguments",
          "return",
          "values"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand each thread has its own stack. as related to the point above, please",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "stack",
          "related",
          "point",
          "please"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : T H R E A D API 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : T H R E A D API 11\nReferences\n[B89] \u201cAn Introduction to Programming with Threads\u201d by Andrew D. Birr ell. DEC T echni-\ncal Report, January , 1989. A vailable: https://birrell.org/and rew/papers/035-Threads.pdf A\nclassic but older introduction to threaded programming. Still a worthwhile read, and freely available.\n[B97] \u201cProgramming with POSIX Threads\u201d by David R. Butenhof. Addison-W es ley , May 1997.\nAnother one of these books on threads.\n[B+96] \u201cPThreads Programming: by A POSIX Standard for Better Multiproces sing. \u201d Dick\nButtlar , Jacqueline Farrell, Bradford Nichols. O\u2019Reilly , Septemb er 1996 A reasonable book from the\nexcellent, practical publishing house O\u2019Reilly. Our bookshelves ce rtainly contain a great deal of books\nfrom this company, including some excellent offerings on Perl, Python , and Javascript (particularly\nCrockford\u2019s \u201cJavascript: The Good Parts\u201d.)\n[K+96] \u201cProgramming With Threads\u201d by Steve Kleiman, Devang Shah, Bart Smaalders. Pren-\ntice Hall, January 1996. Probably one of the better books in this space. Get it at your local library. Or\nsteal it from your mother . More seriously, just ask your mother for it \u2013 she\u2019l l let you borrow it, don\u2019t\nworry.\n[X+10] \u201cAd Hoc Synchronization Considered Harmful\u201d by W eiwei Xiong, Soyeon Park, Jiaqi\nZhang, Y uanyuan Zhou, Zhiqiang Ma. OSDI 2010, V ancouver , Canada. This paper shows how\nseemingly simple synchronization code can lead to a surprising numberof bugs. Use condition variables\nand do the signaling correctly!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand A vailable: https://birrell.org/and rew/papers/035-Threads.pdf A",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "https",
          "birrell",
          "papers",
          "threads"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand PThreads Programming: by A POSIX Standard for Better Multiproces sing. \u201d Dick",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "pthreads programming",
          "posix",
          "standard",
          "better",
          "multiproces",
          "sing",
          "dick"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "What happens when you remove one of the offending lines of co de? Now",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "2. What happens when you remove one of the offending lines of co de? Now\nadd a lock around one of the updates to the shared variable, and t hen around\nboth. What does helgrind report in each of these cases?\n3. Now let\u2019s look at main-deadlock.c. Examine the code. This code has a\nproblem known as deadlock (which we discuss in much more depth in a\nforthcoming chapter). Can you see what problem it might have?\n4. Now run helgrind on this code. What does helgrind report?\n5. Now run helgrind on main-deadlock-global.c. Examine the code;\ndoes it have the same problem that main-deadlock.c has? Should helgrind\nbe reporting the same error? What does this tell you about tools like helgrind?\n6. Let\u2019s next look at main-signal.c. This code uses a variable ( done) to\nsignal that the child is done and that the parent can now conti nue. Why is\nthis code inef\ufb01cient? (what does the parent end up spending it s time doing,\nparticularly if the child thread takes a long time to complete?)\n7. Now run helgrind on this program. What does it report? Is the code\ncorrect?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "problem known as deadlock (which we discuss in much more depth in a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "known",
          "deadlock",
          "discuss",
          "much",
          "depth"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand this code inef\ufb01cient",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "code"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "8",
    "title": "Now look at a slightly modi\ufb01ed version of the code, which is f ound in",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "8. Now look at a slightly modi\ufb01ed version of the code, which is f ound in\nmain-signal-cv.c. This version uses a condition variable to do the sig-\nnaling (and associated lock). Why is this code preferred to t he previous\nversion? Is it correctness, or performance, or both?\n9. Once again run helgrind on main-signal-cv. Does it report any errors?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "main-signal-cv.c. This version uses a condition variable to do the sig-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "signal",
          "version",
          "uses",
          "condition",
          "variable"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand this code preferred to t he previous\nversion",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "preferred",
          "previous",
          "version"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "1 Locks: The Basic Idea",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "28.1 Locks: The Basic Idea\nAs an example, assume our critical section looks like this, the ca nonical\nupdate of a shared variable:\nbalance = balance + 1;\nOf course, other critical sections are possible, such as adding a n ele-\nment to a linked list or other more complex updates to shared struc tures,\nbut we\u2019ll just keep to this simple example for now . T o use a lock, we add\nsome code around the critical section like this:\n1 lock_t mutex; // some globally-allocated lock \u2019mutex\u2019\n2 ...\n3 lock(&mutex);\n4 balance = balance + 1;\n5 unlock(&mutex);\nA lock is just a variable, and thus to use one, you must declare a lock\nvariable of some kind (such as mutex above). This lock variable (or just\n\u201clock\u201d for short) holds the state of the lock at any instant in time. I t is ei-\nther available (or unlocked or free) and thus no thread holds the lock, or\nacquired (or locked or held), and thus exactly one thread holds the lock\nand presumably is in a critical section. W e could store other infor mation\nin the data type as well, such as which thread holds the lock, or a q ueue\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "As an example, assume our critical section looks like this, the ca nonical",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "assume",
          "critical",
          "section",
          "looks",
          "like",
          "nonical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Of course, other critical sections are possible, such as adding a n ele-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "critical",
          "sections",
          "possible",
          "adding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "some code around the critical section like this:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "around",
          "critical",
          "section",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "and presumably is in a critical section. W e could store other infor mation",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "presumably",
          "critical",
          "section",
          "could",
          "store",
          "infor",
          "mation"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand locks: the basic idea",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "locks",
          "basic",
          "idea"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "2 Pthread Locks",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "28.2 Pthread Locks\nThe name that the POSIX library uses for a lock is a mutex, as it is used\nto provide mutual exclusion between threads, i.e., if one thread is in the\ncritical section, it excludes the others from entering until it has completed\nthe section. Thus, when you see the following POSIX threads code, you\nshould understand that it is doing the same thing as above (we aga in use\nour wrappers that check for errors upon lock and unlock):\n1 pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n2\n3 Pthread_mutex_lock(&lock); // wrapper; exits on failure\n4 balance = balance + 1;\n5 Pthread_mutex_unlock(&lock);\nY ou might also notice here that the POSIX version passes a variabl e\nto lock and unlock, as we may be using different locks to protect different\nvariables. Doing so can increase concurrency: instead of one big lock that\nis used any time any critical section is accessed (a coarse-grained locking\nstrategy), one will often protect different data and data struc tures with\ndifferent locks, thus allowing more threads to be in locked code at once\n(a more \ufb01ne-grained approach).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "critical section, it excludes the others from entering until it has completed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "excludes",
          "others",
          "entering",
          "completed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "should understand that it is doing the same thing as above (we aga in use",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "thing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "is used any time any critical section is accessed (a coarse-grained locking",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "used",
          "time",
          "critical",
          "section",
          "accessed",
          "coarse",
          "grained",
          "locking"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": ", one will often protect different data and data struc tures with",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "often",
          "protect",
          "different",
          "data",
          "data",
          "struc",
          "tures"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "(a more \ufb01ne-grained approach).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "grained",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand pthread locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "pthread",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "3 Building A Lock",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "28.3 Building A Lock\nBy now , you should have some understanding of how a lock works,\nfrom the perspective of a programmer . But how should we build a lock?\nWhat hardware support is needed? What OS support? It is this set of\nquestions we address in the rest of this chapter .\nTH E CR U X : H O W TO BU I L D A L O C K\nHow can we build an ef\ufb01cient lock? Ef\ufb01cient locks provide mutual\nexclusion at low cost, and also might attain a few other properties we\ndiscuss below . What hardware support is needed? What OS support ?\nT o build a working lock, we will need some help from our old friend,\nthe hardware, as well as our good pal, the OS. Over the years, a num-\nber of different hardware primitives have been added to the in struction\nsets of various computer architectures; while we won\u2019t study how th ese\ninstructions are implemented (that, after all, is the topic of a computer\narchitecture class), we will study how to use them in order to bu ild a mu-\ntual exclusion primitive like a lock. W e will also study how the O S gets\ninvolved to complete the picture and enable us to build a sophist icated\nlocking library .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "By now , you should have some understanding of how a lock works,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "lock",
          "works"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "instructions are implemented (that, after all, is the topic of a computer",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "instructions",
          "implemented",
          "topic",
          "computer"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand building a lock",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "building",
          "lock"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "28",
    "title": "4 Evaluating Locks",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "28.4 Evaluating Locks\nBefore building any locks, we should \ufb01rst understand what our goal s\nare, and thus we ask how to evaluate the ef\ufb01cacy of a particular l ock\nimplementation. T o evaluate whether a lock works (and works well ), we\nshould establish some basic criteria. The \ufb01rst is whether the l ock does its\nbasic task, which is to provide mutual exclusion . Basically , does the lock\nwork, preventing multiple threads from entering a critical se ction?\nThe second is fairness. Does each thread contending for the lock get\na fair shot at acquiring it once it is free? Another way to look at thi s is\nby examining the more extreme case: does any thread contending f or the\nlock starve while doing so, thus never obtaining it?\nThe \ufb01nal criterion is performance, speci\ufb01cally the time overheads added\nby using the lock. There are a few different cases that are worth con-\nsidering here. One is the case of no contention; when a single thr ead\nis running and grabs and releases the lock, what is the overhead of do-\ning so? Another is the case where multiple threads are contendin g for\nthe lock on a single CPU; in this case, are there performance conce rns? Fi-\nnally , how does the lock perform when there are multiple CPUs invol ved,\nand threads on each contending for the lock? By comparing these dif fer-\nent scenarios, we can better understand the performance impac t of using\nvarious locking techniques, as described below .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Before building any locks, we should \ufb01rst understand what our goal s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "building",
          "locks",
          "understand",
          "goal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "are, and thus we ask how to evaluate the ef\ufb01cacy of a particular l ock",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "thus",
          "evaluate",
          "particular"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "implementation. T o evaluate whether a lock works (and works well ), we",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation",
          "evaluate",
          "whether",
          "lock",
          "works",
          "works",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "work, preventing multiple threads from entering a critical se ction?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "work",
          "preventing",
          "multiple",
          "threads",
          "entering",
          "critical",
          "ction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ent scenarios, we can better understand the performance impac t of using",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "scenarios",
          "better",
          "understand",
          "performance",
          "impac",
          "using"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "various locking techniques, as described below .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "various",
          "locking",
          "techniques",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand evaluating locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "evaluating",
          "locks"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the overhead of do-\ning so",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "overhead"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the lock perform when there are multiple CPUs invol ved,\nand threads on each contending for the lock",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "lock",
          "perform",
          "multiple",
          "cpus",
          "invol",
          "threads",
          "contending",
          "lock"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "5 Controlling Interrupts",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "28.5 Controlling Interrupts\nOne of the earliest solutions used to provide mutual exclusion was\nto disable interrupts for critical sections; this solution was i nvented for\nsingle-processor systems. The code would look like this:\n1 void lock() {\n2 DisableInterrupts();\n3 }\n4 void unlock() {\n5 EnableInterrupts();\n6 }\nAssume we are running on such a single-processor system. By turn -\ning off interrupts (using some kind of special hardware instruc tion) be-\nfore entering a critical section, we ensure that the code inside the critical\nsection will not be interrupted, and thus will execute as if it were atomic.\nWhen we are \ufb01nished, we re-enable interrupts (again, via a ha rdware in-\nstruction) and thus the program proceeds as usual.\nThe main positive of this approach is its simplicity . Y ou certain ly don\u2019t\nhave to scratch your head too hard to \ufb01gure out why this works. With out\ninterruption, a thread can be sure that the code it executes wil l execute\nand that no other thread will interfere with it.\nThe negatives, unfortunately , are many . First, this approach requires\nus to allow any calling thread to perform a privileged operation (turning\ninterrupts on and off), and thus trust that this facility is not abused. As\nyou already know , any time we are required to trust an arbitrary pro-\ngram, we are probably in trouble. Here, the trouble manifests in numer-\nous ways: a greedy program could call lock() at the beginning of its\nexecution and thus monopolize the processor; worse, an errant or mali -\ncious program could call lock() and go into an endless loop. In this\nlatter case, the OS never regains control of the system, and ther e is only\none recourse: restart the system. Using interrupt disabling a s a general-\npurpose synchronization solution requires too much trust in appli cations.\nSecond, the approach does not work on multiprocessors. If multiple\nthreads are running on different CPUs, and each try to enter th e same\ncritical section, it does not matter whether interrupts are dis abled; threads\nwill be able to run on other processors, and thus could enter the cri tical\nsection. As multiprocessors are now commonplace, our general soluti on\nwill have to do better than this.\nThird, turning off interrupts for extended periods of time can le ad to\ninterrupts becoming lost, which can lead to serious systems prob lems.\nImagine, for example, if the CPU missed the fact that a disk dev ice has\n\ufb01nished a read request. How will the OS know to wake the process wa it-\ning for said read?\nFinally , and probably least important, this approach can be ine f\ufb01cient.\nCompared to normal instruction execution, code that masks or unmas ks\ninterrupts tends to be executed slowly by modern CPUs.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to disable interrupts for critical sections; this solution was i nvented for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disable",
          "interrupts",
          "critical",
          "sections",
          "solution",
          "nvented"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "fore entering a critical section, we ensure that the code inside the critical",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fore",
          "entering",
          "critical",
          "section",
          "ensure",
          "code",
          "inside",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The main positive of this approach is its simplicity . Y ou certain ly don\u2019t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "positive",
          "approach",
          "simplicity",
          "certain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "The negatives, unfortunately , are many . First, this approach requires",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "negatives",
          "unfortunately",
          "many",
          "first",
          "approach",
          "requires"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "you already know , any time we are required to trust an arbitrary pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "already",
          "know",
          "time",
          "required",
          "trust",
          "arbitrary"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Second, the approach does not work on multiprocessors. If multiple",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "second",
          "approach",
          "work",
          "multiprocessors",
          "multiple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "critical section, it does not matter whether interrupts are dis abled; threads",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "matter",
          "whether",
          "interrupts",
          "abled",
          "threads"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "will be able to run on other processors, and thus could enter the cri tical",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "processors",
          "thus",
          "could",
          "enter",
          "tical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "\ufb01nished a read request. How will the OS know to wake the process wa it-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "request",
          "know",
          "wake",
          "process"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "Finally , and probably least important, this approach can be ine f\ufb01cient.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "probably",
          "least",
          "important",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand ous ways: a greedy program could call lock() at the beginning of its",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ous ways",
          "greedy",
          "program",
          "could",
          "call",
          "lock",
          "beginning"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand controlling interrupts",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "controlling",
          "interrupts"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "6 A Failed Attempt: Just Using Loads/Stores",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "28.6 A Failed Attempt: Just Using Loads/Stores\nT o move beyond interrupt-based techniques, we will have to rel y on\nCPU hardware and the instructions it provides us to build a prope r lock.\nLet\u2019s \ufb01rst try to build a simple lock by using a single \ufb02ag variab le. In this\nfailed attempt, we\u2019ll see some of the basic ideas needed to build a lock,\nand (hopefully) see why just using a single variable and acces sing it via\nnormal loads and stores is insuf\ufb01cient.\nIn this \ufb01rst attempt (Figure 28.1), the idea is quite simple: use a simple\nvariable ( flag) to indicate whether some thread has possession of a lock.\nThe \ufb01rst thread that enters the critical section will call lock(), which\ntests whether the \ufb02ag is equal to 1 (in this case, it is not), and then sets\nthe \ufb02ag to 1 to indicate that the thread now holds the lock. When \ufb01nished\nwith the critical section, the thread calls unlock() and clears the \ufb02ag,\nthus indicating that the lock is no longer held.\nIf another thread happens to call lock() while that \ufb01rst thread is in\nthe critical section, it will simply spin-wait in the while loop for that\nthread to call unlock() and clear the \ufb02ag. Once that \ufb01rst thread does\nso, the waiting thread will fall out of the while loop, set the \ufb02ag to 1 for\nitself, and proceed into the critical section.\nUnfortunately , the code has two problems: one of correctness, and a n-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o move beyond interrupt-based techniques, we will have to rel y on",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "move",
          "beyond",
          "interrupt",
          "based",
          "techniques"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The \ufb01rst thread that enters the critical section will call lock(), which",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "enters",
          "critical",
          "section",
          "call",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "with the critical section, the thread calls unlock() and clears the \ufb02ag,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "thread",
          "calls",
          "unlock",
          "clears"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "the critical section, it will simply spin-wait in the while loop for that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "simply",
          "spin",
          "wait",
          "loop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "itself, and proceed into the critical section.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proceed",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 6 A Failed Attempt: Just Using Loads/Stores",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 a failed attempt",
          "using",
          "loads",
          "stores"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "7 Building W orking Spin Locks with T est-And-Set",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "28.7 Building W orking Spin Locks with T est-And-Set\nBecause disabling interrupts does not work on multiple processors ,\nand because simple approaches using loads and stores (as shown ab ove)\ndon\u2019t work, system designers started to invent hardware support for lock-\ning. The earliest multiprocessor systems, such as the Burrough s B5000 in\nthe early 1960\u2019s [M82], had such support; today all systems provi de this\ntype of support, even for single CPU systems.\nThe simplest bit of hardware support to understand is known as a\ntest-and-set (or atomic exchange 1 ) instruction. W e de\ufb01ne what the test-\nand-set instruction does via the following C code snippet:\n1 int TestAndSet(int *old_ptr, int new) {\n2 int old = *old_ptr; // fetch old value at old_ptr\n3 *old_ptr = new; // store \u2019new\u2019 into old_ptr\n4 return old; // return the old value\n5 }\n1 Each architecture that supports test-and-set calls it by a different name . On SP ARC it is\ncalled the load/store unsigned byte instruction ( ldstub); on x86 it is the locked version of the\natomic exchange ( xchg).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and because simple approaches using loads and stores (as shown ab ove)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "approaches",
          "using",
          "loads",
          "stores",
          "shown"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "don\u2019t work, system designers started to invent hardware support for lock-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "work",
          "system",
          "designers",
          "started",
          "invent",
          "hardware",
          "support",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The simplest bit of hardware support to understand is known as a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simplest",
          "hardware",
          "support",
          "understand",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand building w orking spin locks with t est-and-set",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "building",
          "orking",
          "spin",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K S 7\nAS I D E : D E K K E R \u2019 S AN D PE T E R S O N \u2019 S AL G O R I T H M S\nIn the 1960\u2019s, Dijkstra posed the concurrency problem to his frie nds, and\none of them, a mathematician named Theodorus Jozef Dekker , came up\nwith a solution [D68]. Unlike the solutions we discuss here, whic h use\nspecial hardware instructions and even OS support, Dekker\u2019s algorithm\nuses just loads and stores (assuming they are atomic with respec t to each\nother , which was true on early hardware).\nDekker \u2019s approach was later re\ufb01ned by Peterson [P81]. Once agai n, just\nloads and stores are used, and the idea is to ensure that two thre ads never\nenter a critical section at the same time. Here is Peterson\u2019s algorithm (for\ntwo threads); see if you can understand the code. What are the flag and\nturn variables used for?\nint flag[2];\nint turn;\nvoid init() {\n// indicate you intend to hold the lock w/ \u2019flag\u2019\nflag[0] = flag[1] = 0;\n// whose turn is it? (thread 0 or 1)\nturn = 0;\n}\nvoid lock() {\n// \u2019self\u2019 is the thread ID of caller\nflag[self] = 1;\n// make it other thread\u2019s turn\nturn = 1 - self;\nwhile ((flag[1-self] == 1) && (turn == 1 - self))\n; // spin-wait while it\u2019s not your turn\n}\nvoid unlock() {\n// simply undo your intent\nflag[self] = 0;\n}\nFor some reason, developing locks that work without special hardwar e\nsupport became all the rage for a while, giving theory-types a lot of prob-\nlems to work on. Of course, this line of work became quite useless wh en\npeople realized it is much easier to assume a little hardware s upport (and\nindeed that support had been around from the earliest days of mult ipro-\ncessing). Further , algorithms like the ones above don\u2019t work on mod-\nern hardware (due to relaxed memory consistency models), thus m aking\nthem even less useful than they were before. Y et more research r elegated\nto the dustbin of history ...\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "special hardware instructions and even OS support, Dekker\u2019s algorithm",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "special",
          "hardware",
          "instructions",
          "even",
          "support",
          "dekker",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Dekker \u2019s approach was later re\ufb01ned by Peterson [P81]. Once agai n, just",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dekker",
          "approach",
          "later",
          "peterson",
          "agai"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "enter a critical section at the same time. Here is Peterson\u2019s algorithm (for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "enter",
          "critical",
          "section",
          "time",
          "peterson",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "two threads); see if you can understand the code. What are the flag and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "threads",
          "understand",
          "code",
          "flag"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "For some reason, developing locks that work without special hardwar e",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "reason",
          "developing",
          "locks",
          "work",
          "without",
          "special",
          "hardwar"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "support became all the rage for a while, giving theory-types a lot of prob-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "became",
          "rage",
          "giving",
          "theory",
          "types",
          "prob"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": ". Further , algorithms like the ones above don\u2019t work on mod-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "like",
          "ones",
          "work"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 LO C K S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 LO C K S\n1 typedef struct __lock_t {\n2 int flag;\n3 } lock_t;\n4\n5 void init(lock_t *lock) {\n6 // 0: lock is available, 1: lock is held\n7 lock->flag = 0;\n8 }\n9\n10 void lock(lock_t *lock) {\n11 while (TestAndSet(&lock->flag, 1) == 1)\n12 ; // spin-wait (do nothing)\n13 }\n14\n15 void unlock(lock_t *lock) {\n16 lock->flag = 0;\n17 }\nFigure 28.3: A Simple Spin Lock Using T est-and-set\nWhat the test-and-set instruction does is as follows. It returns the old\nvalue pointed to by the old\nptr, and simultaneously updates said value\nto new. The key , of course, is that this sequence of operations is performe d\natomically. The reason it is called \u201ctest and set\u201d is that it enables you\nto \u201ctest\u201d the old value (which is what is returned) while simul taneously\n\u201csetting\u201d the memory location to a new value; as it turns out, this slightly\nmore powerful instruction is enough to build a simple spin lock , as we\nnow examine in Figure 28.3. Or better yet: \ufb01gure it out \ufb01rst yours elf!\nLet\u2019s make sure we understand why this lock works. Imagine \ufb01rst t he\ncase where a thread calls lock() and no other thread currently holds the\nlock; thus, flag should be 0. When the thread calls TestAndSet(flag,\n1), the routine will return the old value of flag, which is 0; thus, the call-\ning thread, which is testing the value of \ufb02ag, will not get caught spinning\nin the while loop and will acquire the lock. The thread will also a tomi-\ncally set the value to 1, thus indicating that the lock is now held. When\nthe thread is \ufb01nished with its critical section, it calls unlock() to set the\n\ufb02ag back to zero.\nThe second case we can imagine arises when one thread already ha s\nthe lock held (i.e., flag is 1). In this case, this thread will call lock() and\nthen call TestAndSet(flag, 1) as well. This time, TestAndSet()\nwill return the old value at \ufb02ag, which is 1 (because the lock is h eld),\nwhile simultaneously setting it to 1 again. As long as the lock is held by\nanother thread, TestAndSet() will repeatedly return 1, and thus this\nthread will spin and spin until the lock is \ufb01nally released. Wh en the \ufb02ag is\n\ufb01nally set to 0 by some other thread, this thread will call TestAndSet()\nagain, which will now return 0 while atomically setting the val ue to 1 and\nthus acquire the lock and enter the critical section.\nBy making both the test (of the old lock value) and set (of the new\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s make sure we understand why this lock works. Imagine \ufb01rst t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "sure",
          "understand",
          "lock",
          "works",
          "imagine"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the thread is \ufb01nished with its critical section, it calls unlock() to set the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "critical",
          "section",
          "calls",
          "unlock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "thus acquire the lock and enter the critical section.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "acquire",
          "lock",
          "enter",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 0: lock is available, 1: lock is held",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "0",
          "lock",
          "available",
          "lock",
          "held"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 3: A Simple Spin Lock Using T est-and-set",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "simple",
          "spin",
          "lock",
          "using"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Or better yet: \ufb01gure it out \ufb01rst yours elf!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "or better yet"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "8 Evaluating Spin Locks",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "28.8 Evaluating Spin Locks\nGiven our basic spin lock, we can now evaluate how effective it is\nalong our previously described axes. The most important aspect of a lock\nis correctness: does it provide mutual exclusion? The answer here is yes:\nthe spin lock only allows a single thread to enter the critical se ction at a\ntime. Thus, we have a correct lock.\nThe next axis is fairness. How fair is a spin lock to a waiting thread?\nCan you guarantee that a waiting thread will ever enter the cri tical sec-\ntion? The answer here, unfortunately , is bad news: spin locks don \u2019t pro-\nvide any fairness guarantees. Indeed, a thread spinning may spin forever ,\nunder contention. Simple spin locks (as discussed thus far) are n ot fair\nand may lead to starvation.\nThe \ufb01nal axis is performance. What are the costs of using a spin lock?\nT o analyze this more carefully , we suggest thinking about a few different\ncases. In the \ufb01rst, imagine threads competing for the lock on a sin gle\nprocessor; in the second, consider threads spread out across many C PUs.\nFor spin locks, in the single CPU case, performance overheads can\nbe quite painful; imagine the case where the thread holding th e lock is\npreempted within a critical section. The scheduler might the n run every\nother thread (imagine there are N \u2212 1 others), each of which tries to ac-\nquire the lock. In this case, each of those threads will spin for th e duration\nof a time slice before giving up the CPU, a waste of CPU cycles.\nHowever , on multiple CPUs, spin locks work reasonably well (if the\nnumber of threads roughly equals the number of CPUs). The thinki ng\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Given our basic spin lock, we can now evaluate how effective it is",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "given",
          "basic",
          "spin",
          "lock",
          "evaluate",
          "effective"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "along our previously described axes. The most important aspect of a lock",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "along",
          "previously",
          "described",
          "axes",
          "important",
          "aspect",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the spin lock only allows a single thread to enter the critical se ction at a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "spin",
          "lock",
          "allows",
          "single",
          "thread",
          "enter",
          "critical",
          "ction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o analyze this more carefully , we suggest thinking about a few different",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "analyze",
          "carefully",
          "suggest",
          "thinking",
          "different"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "preempted within a critical section. The scheduler might the n run every",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "preempted",
          "within",
          "critical",
          "section",
          "scheduler",
          "might",
          "every"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand is bad news: spin locks don \u2019t pro-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "is bad news",
          "spin",
          "locks"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand evaluating spin locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "evaluating",
          "spin",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "9 Compare-And-Swap",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "28.9 Compare-And-Swap\nAnother hardware primitive that some systems provide is known as\nthe compare-and-swap instruction (as it is called on SP ARC, for exam-\nple), or compare-and-exchange (as it called on x86). The C pseudocode\nfor this single instruction is found in Figure 28.4.\nThe basic idea is for compare-and-swap to test whether the valu e at the\naddress speci\ufb01ed by ptr is equal to expected; if so, update the memory\nlocation pointed to by ptr with the new value. If not, do nothing. In\neither case, return the original value at that memory location, t hus allow-\ning the code calling compare-and-swap to know whether it succee ded or\nnot.\nWith the compare-and-swap instruction, we can build a lock in a m an-\nner quite similar to that with test-and-set. For example, we c ould just\nreplace the lock() routine above with the following:\n1 void lock(lock_t *lock) {\n2 while (CompareAndSwap(&lock->flag, 0, 1) == 1)\n3 ; // spin\n4 }\nThe rest of the code is the same as the test-and-set example above .\nThis code works quite similarly; it simply checks if the \ufb02ag is 0 and if\nso, atomically swaps in a 1 thus acquiring the lock. Threads that try to\nacquire the lock while it is held will get stuck spinning until the lock is\n\ufb01nally released.\nIf you want to see how to really make a C-callable x86-version of\ncompare-and-swap, the code sequence (from [S05]) might be usefu l2 .\nFinally , as you may have sensed, compare-and-swap is a more power -\nful instruction than test-and-set. W e will make some use of this power in\n2 github.com/remzi-arpacidusseau/ostep-code/tree/master/threads-locks\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Compare-And-Swap",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Another hardware primitive that some systems provide is known as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "hardware",
          "primitive",
          "systems",
          "provide",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the compare-and-swap instruction (as it is called on SP ARC, for exam-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap",
          "instruction",
          "called",
          "exam"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": ", or compare-and-exchange (as it called on x86). The C pseudocode",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "exchange",
          "called",
          "pseudocode"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "The basic idea is for compare-and-swap to test whether the valu e at the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "basic",
          "idea",
          "compare",
          "swap",
          "test",
          "whether",
          "valu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "ing the code calling compare-and-swap to know whether it succee ded or",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "calling",
          "compare",
          "swap",
          "know",
          "whether",
          "succee"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "With the compare-and-swap instruction, we can build a lock in a m an-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap",
          "instruction",
          "build",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "while (CompareAndSwap(&lock->flag, 0, 1) == 1)",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compareandswap",
          "lock",
          "flag"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "compare-and-swap, the code sequence (from [S05]) might be usefu l2 .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap",
          "code",
          "sequence",
          "might",
          "usefu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "Finally , as you may have sensed, compare-and-swap is a more power -",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "finally",
          "sensed",
          "compare",
          "swap",
          "power"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand compare-and-swap",
        "type": "section_concept",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "10 Load-Linked and Store-Conditional",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "28.10 Load-Linked and Store-Conditional\nSome platforms provide a pair of instructions that work in concert to\nhelp build critical sections. On the MIPS architecture [H93] , for example,\nthe load-linked and store-conditional instructions can be used in tandem\nto build locks and other concurrent structures. The C pseudocode f or\nthese instructions is as found in Figure 28.5. Alpha, PowerPC, a nd ARM\nprovide similar instructions [W09].\nThe load-linked operates much like a typical load instruction, a nd sim-\nply fetches a value from memory and places it in a register . The k ey differ-\nence comes with the store-conditional, which only succeeds (and u pdates\nthe value stored at the address just load-linked from) if no inte rvening\nstore to the address has taken place. In the case of success, the store-\nconditional returns 1 and updates the value at ptr to value; if it fails,\nthe value at ptr is not updated and 0 is returned.\nAs a challenge to yourself, try thinking about how to build a lock u sing\nload-linked and store-conditional. Then, when you are \ufb01nished, l ook at\nthe code below which provides one simple solution. Do it! The solution\nis in Figure 28.6.\nThe lock() code is the only interesting piece. First, a thread spins\nwaiting for the \ufb02ag to be set to 0 (and thus indicate the lock is not held).\nOnce so, the thread tries to acquire the lock via the store-condit ional; if it\nsucceeds, the thread has atomically changed the \ufb02ag\u2019s value to 1 and thus\ncan proceed into the critical section.\nNote how failure of the store-conditional might arise. One thread c alls\nlock() and executes the load-linked, returning 0 as the lock is not held .\nBefore it can attempt the store-conditional, it is interrupted a nd another\nthread enters the lock code, also executing the load-linked ins truction,\n1 int LoadLinked(int *ptr) {\n2 return *ptr;\n3 }\n4\n5 int StoreConditional(int *ptr, int value) {\n6 if (no update to *ptr since LoadLinked to this address) {\n7 *ptr = value;\n8 return 1; // success!\n9 } else {\n10 return 0; // failed to update\n11 }\n12 }\nFigure 28.5: Load-linked And Store-conditional\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "help build critical sections. On the MIPS architecture [H93] , for example,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "help",
          "build",
          "critical",
          "sections",
          "mips",
          "architecture",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "can proceed into the critical section.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proceed",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Load-linked And Store-conditional",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "load",
          "linked",
          "store",
          "conditional"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand load-linked and store-conditional",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "load",
          "linked",
          "store",
          "conditional"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "11 Fetch-And-Add",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "28.11 Fetch-And-Add\nOne \ufb01nal hardware primitive is the fetch-and-add instruction, which\natomically increments a value while returning the old value at a partic-\nular address. The C pseudocode for the fetch-and-add instructi on looks\nlike this:\n1 int FetchAndAdd(int *ptr) {\n2 int old = *ptr;\n3 *ptr = old + 1;\n4 return old;\n5 }\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand fetch-and-add",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fetch"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "12 T oo Much Spinning: What Now?",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "28.12 T oo Much Spinning: What Now?\nOur simple hardware-based locks are simple (only a few lines of c ode)\nand they work (you could even prove that if you\u2019d like to, by writing\nsome code), which are two excellent properties of any system or code .\nHowever , in some cases, these solutions can be quite inef\ufb01cient. Imagine\nyou are running two threads on a single processor . Now imagine that\none thread (thread 0) is in a critical section and thus has a lock h eld, and\nunfortunately gets interrupted. The second thread (thread 1) now tries to\nacquire the lock, but \ufb01nds that it is held. Thus, it begins to sp in. And spin.\nThen it spins some more. And \ufb01nally , a timer interrupt goes off, th read\n0 is run again, which releases the lock, and \ufb01nally (the next ti me it runs,\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "one thread (thread 0) is in a critical section and thus has a lock h eld, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "thread",
          "critical",
          "section",
          "thus",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand t oo much spinning: what now?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "much",
          "spinning"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "13 A Simple Approach: Just Yield, Baby",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "28.13 A Simple Approach: Just Yield, Baby\nHardware support got us pretty far: working locks, and even (as wi th\nthe case of the ticket lock) fairness in lock acquisition. However , we still\nhave a problem: what to do when a context switch occurs in a critic al\nsection, and threads start to spin endlessly , waiting for the i nterrupted\n(lock-holding) thread to be run again?\nOur \ufb01rst try is a simple and friendly approach: when you are going to\nspin, instead give up the CPU to another thread. Or , as Al Davis might\nsay , \u201cjust yield, baby!\u201d [D91]. Figure 28.8 (page 15) present s the approach.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A Simple Approach: Just Yield, Baby",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "approach",
          "yield",
          "baby"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Our \ufb01rst try is a simple and friendly approach: when you are going to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "friendly",
          "approach",
          "going"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "say , \u201cjust yield, baby!\u201d [D91]. Figure 28.8 (page 15) present s the approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "yield",
          "baby",
          "figure",
          "page",
          "present",
          "approach"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "14 Using Queues: Sleeping Instead Of Spinning",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "28.14 Using Queues: Sleeping Instead Of Spinning\nThe real problem with our previous approaches is that they leave t oo\nmuch to chance. The scheduler determines which thread runs n ext; if\nthe scheduler makes a bad choice, a thread runs that must eithe r spin\nwaiting for the lock (our \ufb01rst approach), or yield the CPU immediat ely\n(our second approach). Either way , there is potential for waste an d no\nprevention of starvation.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The real problem with our previous approaches is that they leave t oo",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "real",
          "problem",
          "previous",
          "approaches",
          "leave"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "waiting for the lock (our \ufb01rst approach), or yield the CPU immediat ely",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "waiting",
          "lock",
          "approach",
          "yield",
          "immediat"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "(our second approach). Either way , there is potential for waste an d no",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "second",
          "approach",
          "either",
          "potential",
          "waste"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 14 Using Queues: Sleeping Instead Of Spinning",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "14 using queues",
          "sleeping",
          "instead",
          "spinning"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 LO C K S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 LO C K S\n1 typedef struct __lock_t {\n2 int flag;\n3 int guard;\n4 queue_t *q;\n5 } lock_t;\n6\n7 void lock_init(lock_t *m) {\n8 m->flag = 0;\n9 m->guard = 0;\n10 queue_init(m->q);\n11 }\n12\n13 void lock(lock_t *m) {\n14 while (TestAndSet(&m->guard, 1) == 1)\n15 ; //acquire guard lock by spinning\n16 if (m->flag == 0) {\n17 m->flag = 1; // lock is acquired\n18 m->guard = 0;\n19 } else {\n20 queue_add(m->q, gettid());\n21 m->guard = 0;\n22 park();\n23 }\n24 }\n25\n26 void unlock(lock_t *m) {\n27 while (TestAndSet(&m->guard, 1) == 1)\n28 ; //acquire guard lock by spinning\n29 if (queue_empty(m->q))\n30 m->flag = 0; // let go of lock; no one wants it\n31 else\n32 unpark(queue_remove(m->q)); // hold lock\n33 // (for next thread!)\n34 m->guard = 0;\n35 }\nFigure 28.9: Lock With Queues, T est-and-set, Yield, And W akeup\nThus, we must explicitly exert some control over which thread nex t\ngets to acquire the lock after the current holder releases it. T o do this, we\nwill need a little more OS support, as well as a queue to keep trac k of\nwhich threads are waiting to acquire the lock.\nFor simplicity , we will use the support provided by Solaris, in ter ms of\ntwo calls: park() to put a calling thread to sleep, and unpark(threadID)\nto wake a particular thread as designated by threadID. These two rou-\ntines can be used in tandem to build a lock that puts a caller to s leep if it\ntries to acquire a held lock and wakes it when the lock is free. Le t\u2019s look at\nthe code in Figure 28.9 to understand one possible use of such prim itives.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to wake a particular thread as designated by threadID. These two rou-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "wake",
          "particular",
          "thread",
          "designated",
          "threadid"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the code in Figure 28.9 to understand one possible use of such prim itives.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "figure",
          "understand",
          "possible",
          "prim",
          "itives"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 9: Lock With Queues, T est-and-set, Yield, And W akeup",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "9",
          "lock",
          "queues",
          "yield",
          "akeup"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K S 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K S 17\nAS I D E : M O R E RE A S O N TO AV O I D SP I N N I N G : P R I O R I T Y IN V E R S I O N\nOne good reason to avoid spin locks is performance: as described in t he\nmain text, if a thread is interrupted while holding a lock, other threads\nthat use spin locks will spend a large amount of CPU time just wait ing for\nthe lock to become available. However , it turns out there is anothe r inter-\nesting reason to avoid spin locks on some systems: correctness. The prob-\nlem to be wary of is known as priority inversion , which unfortunately is\nan intergalactic scourge, occurring on Earth [M15] and Mars [R9 7]!\nLet\u2019s assume there are two threads in a system. Thread 2 (T2) ha s a high\nscheduling priority , and Thread 1 (T1) has lower priority . In th is example,\nlet\u2019s assume that the CPU scheduler will always run T2 over T1, i f indeed\nboth are runnable; T1 only runs when T2 is not able to do so (e.g., w hen\nT2 is blocked on I/O).\nNow , the problem. Assume T2 is blocked for some reason. So T1 runs,\ngrabs a spin lock, and enters a critical section. T2 now becomes un blocked\n(perhaps because an I/O completed), and the CPU scheduler imm edi-\nately schedules it (thus descheduling T1). T2 now tries to acq uire the lock,\nand because it can\u2019t (T1 holds the lock), it just keeps spinning. Because\nthe lock is a spin lock, T2 spins forever , and the system is hung.\nJust avoiding the use of spin locks, unfortunately , does not avoid th e\nproblem of inversion (alas). Imagine three threads, T1, T2, and T3, with\nT3 at the highest priority , and T1 the lowest. Imagine now that T1 grabs\na lock. T3 then starts, and because it is higher priority than T1 , runs im-\nmediately (preempting T1). T3 tries to acquire the lock that T 1 holds, but\ngets stuck waiting, because T1 still holds it. If T2 starts to r un, it will have\nhigher priority than T1, and thus it will run. T3, which is high er priority\nthan T2, is stuck waiting for T1, which may never run now that T2 i s run-\nning. Isn\u2019t it sad that the mighty T3 can\u2019t run, while lowly T2 cont rols the\nCPU? Having high priority just ain\u2019t what it used to be.\nY ou can address the priority inversion problem in a number of ways. In\nthe speci\ufb01c case where spin locks cause the problem, you can avoid us-\ning spin locks (described more below). More generally , a higher- priority\nthread waiting for a lower-priority thread can temporarily boost t he\nlower thread\u2019s priority , thus enabling it to run and overcoming th e in-\nversion, a technique known as priority inheritance . A last solution is\nsimplest: ensure all threads have the same priority .\nW e do a couple of interesting things in this example. First, we c ombine\nthe old test-and-set idea with an explicit queue of lock waiters to make a\nmore ef\ufb01cient lock. Second, we use a queue to help control who gets th e\nlock next and thus avoid starvation.\nY ou might notice how the guard is used (Figure 28.9, page 16), bas i-\ncally as a spin-lock around the \ufb02ag and queue manipulations the l ock is\nusing. This approach thus doesn\u2019t avoid spin-waiting entirely; a thread\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One good reason to avoid spin locks is performance: as described in t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "good",
          "reason",
          "avoid",
          "spin",
          "locks",
          "performance",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "lem to be wary of is known as priority inversion , which unfortunately is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wary",
          "known",
          "priority",
          "inversion",
          "unfortunately"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "both are runnable; T1 only runs when T2 is not able to do so (e.g., w hen",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "runnable",
          "runs",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "grabs a spin lock, and enters a critical section. T2 now becomes un blocked",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "grabs",
          "spin",
          "lock",
          "enters",
          "critical",
          "section",
          "becomes",
          "blocked"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ing spin locks (described more below). More generally , a higher- priority",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "spin",
          "locks",
          "described",
          "generally",
          "higher",
          "priority"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "version, a technique known as priority inheritance . A last solution is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "version",
          "technique",
          "known",
          "priority",
          "inheritance",
          "last",
          "solution"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "using. This approach thus doesn\u2019t avoid spin-waiting entirely; a thread",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "approach",
          "thus",
          "avoid",
          "spin",
          "waiting",
          "entirely",
          "thread"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "15 Different OS, Different Support",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "28.15 Different OS, Different Support\nW e have thus far seen one type of support that an OS can provide in\norder to build a more ef\ufb01cient lock in a thread library . Other OS\u2019s p rovide\nsimilar support; the details vary .\nFor example, Linux provides a futex which is similar to the Solaris in-\nterface but provides more in-kernel functionality . Speci\ufb01call y , each futex\nhas associated with it a speci\ufb01c physical memory location, as wel l as a\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand different os, different support",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "different",
          "support"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K S 19",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K S 19\n1 void mutex_lock (int *mutex) {\n2 int v;\n3 /* Bit 31 was clear, we got the mutex (the fastpath) */\n4 if (atomic_bit_test_set (mutex, 31) == 0)\n5 return;\n6 atomic_increment (mutex);\n7 while (1) {\n8 if (atomic_bit_test_set (mutex, 31) == 0) {\n9 atomic_decrement (mutex);\n10 return;\n11 }\n12 /* We have to waitFirst make sure the futex value\n13 we are monitoring is truly negative (locked). */\n14 v = *mutex;\n15 if (v >= 0)\n16 continue;\n17 futex_wait (mutex, v);\n18 }\n19 }\n20\n21 void mutex_unlock (int *mutex) {\n22 /* Adding 0x80000000 to counter results in 0 if and\n23 only if there are not other interested threads */\n24 if (atomic_add_zero (mutex, 0x80000000))\n25 return;\n26\n27 /* There are other threads waiting for this mutex,\n28 wake one of them up. */\n29 futex_wake (mutex);\n30 }\nFigure 28.10: Linux-based Futex Locks\nper-futex in-kernel queue. Callers can use futex calls (des cribed below)\nto sleep and wake as need be.\nSpeci\ufb01cally , two calls are available. The call to futex\nwait(address,\nexpected) puts the calling thread to sleep, assuming the value at address\nis equal to expected. If it is not equal, the call returns immediately . The\ncall to the routine futex wake(address) wakes one thread that is wait-\ning on the queue. The usage of these calls in a Linux mutex is shown in\nFigure 28.10 (page 19).\nThis code snippet from lowlevellock.h in the nptl library (part of\nthe gnu libc library) [L09] is interesting for a few reasons. Fi rst, it uses a\nsingle integer to track both whether the lock is held or not (the hi gh bit\nof the integer) and the number of waiters on the lock (all the other b its).\nThus, if the lock is negative, it is held (because the high bit i s set and that\nbit determines the sign of the integer).\nSecond, the code snippet shows how to optimize for the common case,\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 10: Linux-based Futex Locks",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "10",
          "linux",
          "based",
          "futex",
          "locks"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "28",
    "title": "16 T wo-Phase Locks",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "28.16 T wo-Phase Locks\nOne \ufb01nal note: the Linux approach has the \ufb02avor of an old approach\nthat has been used on and off for years, going at least as far back to Dahm\nLocks in the early 1960\u2019s [M82], and is now referred to as a two-phase\nlock. A two-phase lock realizes that spinning can be useful, partic ularly\nif the lock is about to be released. So in the \ufb01rst phase, the lock sp ins for\na while, hoping that it can acquire the lock.\nHowever , if the lock is not acquired during the \ufb01rst spin phase, a sec-\nond phase is entered, where the caller is put to sleep, and only w oken up\nwhen the lock becomes free later . The Linux lock above is a form of suc h\na lock, but it only spins once; a generalization of this could spin in a loop\nfor a \ufb01xed amount of time before using futex support to sleep.\nT wo-phase locks are yet another instance of a hybrid approach, where\ncombining two good ideas may indeed yield a better one. Of course,\nwhether it does depends strongly on many things, including the h ard-\nware environment, number of threads, and other workload details. As\nalways, making a single general-purpose lock, good for all possibl e use\ncases, is quite a challenge.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One \ufb01nal note: the Linux approach has the \ufb02avor of an old approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "note",
          "linux",
          "approach",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T wo-phase locks are yet another instance of a hybrid approach, where",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "phase",
          "locks",
          "another",
          "instance",
          "hybrid",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand t wo-phase locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "phase",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "28",
    "title": "17 Summary",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "28.17 Summary\nThe above approach shows how real locks are built these days: some\nhardware support (in the form of a more powerful instruction) plus s ome\noperating system support (e.g., in the form of park() and unpark()\nprimitives on Solaris, or futex on Linux). Of course, the details differ , and\nthe exact code to perform such locking is usually highly tuned. C heck out\nthe Solaris or Linux code bases if you want to see more details; they a re\na fascinating read [L09, S09]. Also see David et al.\u2019s excellen t work for a\ncomparison of locking strategies on modern multiprocessors [D+13].\n3 Like buy a print copy of OSTEP! Even though the book is available for free online,\nwouldn\u2019t you just love a hard cover for your desk? Or , better yet, te n copies to share with\nfriends and family? And maybe one extra copy to throw at an enemy? (the book is heavy , and\nthus chucking it is surprisingly effective)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The above approach shows how real locks are built these days: some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "shows",
          "real",
          "locks",
          "built",
          "days"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K S 21",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K S 21\nReferences\n[D91] \u201cJust Win, Baby: Al Davis and His Raiders\u201d by Glenn Dickey . Har court, 1991. The book\nabout Al Davis and his famous quote. Or , we suppose, the book is more about Al Davi s and the Raiders,\nand not so much the quote. T o be clear: we are not recommending this book, we ju st needed a citation.\n[D+13] \u201cEverything Y ou Always W anted to Know about Synchronization bu t W ere Afraid to\nAsk\u201d by T udor David, Rachid Guerraoui, V asileios T rigonakis. S OSP \u201913, Nemacolin W ood-\nlands Resort, Pennsylvania, November 2013. An excellent paper comparing many different ways to\nbuild locks using hardware primitives. Great to see how many ideas work on m odern hardware.\n[D68] \u201cCooperating sequential processes\u201d by Edsger W . Dijkstra . 1968. A vailable online here:\nhttp://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. One of the early semi-\nnal papers. Discusses how Dijkstra posed the original concurrency probl em, and Dekker\u2019s solution.\n[H93] \u201cMIPS R4000 Microprocessor User \u2019s Manual\u201d by Joe Heinrich. Prentice-Ha ll, June 1993.\nA vailable: http://cag.csail.mit.edu/raw/documents/R4400\nUman book Ed2.pdf. The old MIPS\nuser\u2019s manual. Download it while it still exists.\n[H91] \u201cW ait-free Synchronization\u201d by Maurice Herlihy . ACM TOPLAS, V olume 13: 1, January\n1991. A landmark paper introducing a different approach to building concurre nt data structures. Be-\ncause of the complexity involved, some of these ideas have been slow to gain acc eptance in deployment.\n[L81] \u201cObservations on the Development of an Operating System\u201d by Hu gh Lauer . SOSP \u201981,\nPaci\ufb01c Grove, California, December 1981. A must-read retrospective about the development of the\nPilot OS, an early PC operating system. Fun and full of insights.\n[L09] \u201cglibc 2.9 (include Linux pthreads implementation)\u201d by Many author s.. A vailable here:\nhttp://ftp.gnu.org/gnu/glibc. In particular , take a look at the nptl subdirectory where you\nwill \ufb01nd most of the pthread support in Linux today.\n[M82] \u201cThe Architecture of the Burroughs B5000: 20 Y ears Later and Still Ahead of the Times?\u201d\nby A. Mayer . 1982. A vailable: www.ajwm.net/amayer/papers/B5000.html. \u201cIt (RDLK)\nis an indivisible operation which reads from and writes into a memory location .\u201d RDLK is thus test-\nand-set! Dave Dahm created spin locks (\u201cBuzz Locks\u201d) and a two-phase lock called \u201cDah m Locks.\u201d\n[M15] \u201cOSSpinLock Is Unsafe\u201d by J. McCall. mjtsai.com/blog/2015/12/16/osspinlock\n-is-unsafe. Calling OSSpinLock on a Mac is unsafe when using threads of different p riorities \u2013 you\nmight spin forever! So be careful, Mac fanatics, even your mighty syste m can be less than perfect...\n[MS91] \u201cAlgorithms for Scalable Synchronization on Shared-Memory Multip rocessors\u201d by\nJohn M. Mellor-Crummey and M. L. Scott. ACM TOCS, V olume 9, Issue 1, Febr uary 1991.\nAn excellent and thorough survey on different locking algorithms. Howev er , no operating systems\nsupport is used, just fancy hardware instructions.\n[P81] \u201cMyths About the Mutual Exclusion Problem\u201d by G.L. Peterson. Inform ation Processing\nLetters, 12(3), pages 115\u2013116, 1981. Peterson\u2019s algorithm introduced here.\n[R97] \u201cWhat Really Happened on Mars?\u201d by Glenn E. Reeves. research.microsoft.com/\nen-us/um/people/mbj/Mars\nPathfinder/Authoritative Account.html. A descrip-\ntion of priority inversion on Mars Path\ufb01nder . Concurrent code correctness m atters, especially in space!\n[S05] \u201cGuide to porting from Solaris to Linux on x86\u201d by Ajay Sood, April 29, 2005. A vailable:\nhttp://www.ibm.com/developerworks/linux/library/l-solar/.\n[S09] \u201cOpenSolaris Thread Library\u201d by Sun.. Code: src.opensolaris.org/source/xref/\nonnv/onnv-gate/usr/src/lib/libc/port/threads/synch.c. Pretty interesting, al-\nthough who knows what will happen now that Oracle owns Sun. Thanks to Mike Swift for the pointer .\n[W09] \u201cLoad-Link, Store-Conditional\u201d by Many authors.. en.wikipedia.org/wiki/Load-\nLink/Store-Conditional. Can you believe we referenced Wikipedia? But, we found the infor-\nmation there and it felt wrong not to. Further , it was useful, listing the ins tructions for the different ar-\nchitectures: ldl l/stl c and ldq l/stq c (Alpha), lwarx/stwcx (PowerPC), ll/sc (MIPS),\nand ldrex/strex (ARM). Actually Wikipedia is pretty amazing, so don\u2019t be so harsh, OK?\n[WG00] \u201cThe SP ARC Architecture Manual: V ersion 9\u201d by D. W eaver , T . Ger mond. SP ARC In-\nternational, 2000. http://www.sparc.org/standards/SPARCV9.pdf. See developers.\nsun.com/solaris/articles/atomic sparc/ for more on atomics.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[D+13] \u201cEverything Y ou Always W anted to Know about Synchronization bu t W ere Afraid to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "everything",
          "always",
          "anted",
          "know",
          "synchronization",
          "afraid"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A landmark paper introducing a different approach to building concurre nt data structures. Be-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "landmark",
          "paper",
          "introducing",
          "different",
          "approach",
          "building",
          "concurre",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[L81] \u201cObservations on the Development of an Operating System\u201d by Hu gh Lauer . SOSP \u201981,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "observations",
          "development",
          "operating",
          "system",
          "lauer",
          "sosp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Paci\ufb01c Grove, California, December 1981. A must-read retrospective about the development of the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "grove",
          "california",
          "december",
          "must",
          "read",
          "retrospective",
          "development"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[L09] \u201cglibc 2.9 (include Linux pthreads implementation)\u201d by Many author s.. A vailable here:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "glibc",
          "include",
          "linux",
          "pthreads",
          "implementation",
          "many",
          "author",
          "vailable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "and-set! Dave Dahm created spin locks (\u201cBuzz Locks\u201d) and a two-phase lock called \u201cDah m Locks.\u201d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dave",
          "dahm",
          "created",
          "spin",
          "locks",
          "buzz",
          "locks",
          "phase"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "[MS91] \u201cAlgorithms for Scalable Synchronization on Shared-Memory Multip rocessors\u201d by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithms",
          "scalable",
          "synchronization",
          "shared",
          "memory",
          "multip",
          "rocessors"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "An excellent and thorough survey on different locking algorithms. Howev er , no operating systems",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "excellent",
          "thorough",
          "survey",
          "different",
          "locking",
          "algorithms",
          "howev",
          "operating"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "Letters, 12(3), pages 115\u2013116, 1981. Peterson\u2019s algorithm introduced here.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "letters",
          "pages",
          "peterson",
          "algorithm",
          "introduced"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "http://www.ibm.com/developerworks/linux/library/l-solar/.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "http",
          "developerworks",
          "linux",
          "library",
          "solar"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Baby: Al Davis and His Raiders\u201d by Glenn Dickey . Har court, 1991. The book",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "baby",
          "davis",
          "raiders",
          "glenn",
          "dickey",
          "court",
          "book"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand T o be clear: we are not recommending this book, we ju st needed a citation.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t o be clear",
          "recommending",
          "book",
          "needed",
          "citation"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable online here: http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. One of the early semi-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online here",
          "http",
          "utexas",
          "users",
          "early",
          "semi"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A vailable: http://cag.csail.mit.edu/raw/documents/R4400",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "csail",
          "documents"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A vailable here: http://ftp.gnu.org/gnu/glibc. In particular , take a look at the nptl subdirectory where you",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable here",
          "http",
          "glibc",
          "particular",
          "take",
          "look",
          "nptl",
          "subdirectory"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand A vailable: www.ajwm.net/amayer/papers/B5000.html. \u201cIt (RDLK)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "ajwm",
          "amayer",
          "papers",
          "html",
          "rdlk"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand A vailable: http://www.ibm.com/developerworks/linux/library/l-solar/.",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "a vailable",
          "http",
          "developerworks",
          "linux",
          "library",
          "solar"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Code: src.opensolaris.org/source/xref/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "opensolaris",
          "source",
          "xref"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand is-unsafe. calling osspinlock on a mac is unsafe when using threads of different p riorities \u2013 you",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "unsafe",
          "calling",
          "osspinlock",
          "unsafe",
          "using",
          "threads",
          "different",
          "riorities"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "4",
    "title": "Set bx to a high value for each thread, and then use the -i \ufb02ag to generate",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "4. Set bx to a high value for each thread, and then use the -i \ufb02ag to generate\ndifferent interrupt frequencies; what values lead to a bad outco mes? Which\nlead to good outcomes?\n5. Now let\u2019s look at the program test-and-set.s. First, try to understand\nthe code, which uses the xchg instruction to build a simple locking primi-\ntive. How is the lock acquire written? How about lock release?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "lead to good outcomes?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lead",
          "good",
          "outcomes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Now let\u2019s look at the program test-and-set.s. First, try to understand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "look",
          "program",
          "test",
          "first",
          "understand"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "6",
    "title": "Now run the code, changing the value of the interrupt interval (-i) again,",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "6. Now run the code, changing the value of the interrupt interval (-i) again,\nand making sure to loop for a number of times. Does the code always wo rk\nas expected? Does it sometimes lead to an inef\ufb01cient use of the CPU? How\ncould you quantify that?\n7. Use the -P \ufb02ag to generate speci\ufb01c tests of the locking code. For example,\nrun a schedule that grabs the lock in the \ufb01rst thread, but then tri es to acquire\nit in the second. Does the right thing happen? What else should you test?\n8. Now let\u2019s look at the code in peterson.s, which implements Peterson\u2019s\nalgorithm (mentioned in a sidebar in the text). Study the code an d see if\nyou can make sense of it.\n9. Now run the code with different values of -i. What kinds of different be-\nhavior do you see? Make sure to set the thread IDs appropriatel y (using -a\nbx=0,bx=1 for example) as the code assumes it.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now let\u2019s look at the code in peterson.s, which implements Peterson\u2019s",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "look",
          "code",
          "peterson",
          "implements",
          "peterson"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "algorithm (mentioned in a sidebar in the text). Study the code an d see if",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "mentioned",
          "sidebar",
          "text",
          "study",
          "code"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "10",
    "title": "Can you control the scheduling (with the -P \ufb02ag) to \u201cprove\u201d that the code",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "10. Can you control the scheduling (with the -P \ufb02ag) to \u201cprove\u201d that the code\nworks? What are the different cases you should show hold? Thin k about\nmutual exclusion and deadlock avoidance.\n11. Now study the code for the ticket lock in ticket.s. Does it match the code\nin the chapter? Then run with the following \ufb02ags: -a bx=1000,bx=1000\n(causing each thread to loop through the critical section 1000 times). W atch\nwhat happens; do the threads spend much time spin-waiting for th e lock?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "(causing each thread to loop through the critical section 1000 times). W atch",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "causing",
          "thread",
          "loop",
          "critical",
          "section",
          "times",
          "atch"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "12",
    "title": "How does the code behave as you add more threads?",
    "document_source": "book.pdf",
    "start_line": 40,
    "type": "chapter",
    "content": "12. How does the code behave as you add more threads?\n13. Now examine yield.s, in which a yield instruction enables one thread\nto yield control of the CPU (realistically , this would be an OS primitive, but\nfor the simplicity , we assume an instruction does the task). Find a scenario\nwhere test-and-set.s wastes cycles spinning, but yield.s does not.\nHow many instructions are saved? In what scenarios do these sav ings arise?\n14. Finally , examine test-and-test-and-set.s. What does this lock do?\nWhat kind of savings does it introduce as compared to test-and-set.s?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "What kind of savings does it introduce as compared to test-and-set.s?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "kind",
          "savings",
          "introduce",
          "compared",
          "test"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the code behave as you add more threads",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "behave",
          "threads"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "29",
    "title": "1 Concurrent Counters",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "29.1 Concurrent Counters\nOne of the simplest data structures is a counter . It is a structu re that\nis commonly used and has a simple interface. W e de\ufb01ne a simple non -\nconcurrent counter in Figure 29.1.\nSimple But Not Scalable\nAs you can see, the non-synchronized counter is a trivial data str ucture,\nrequiring a tiny amount of code to implement. W e now have our next\nchallenge: how can we make this code thread safe ? Figure 29.2 shows\nhow we do so.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "requiring a tiny amount of code to implement. W e now have our next",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "requiring",
          "tiny",
          "amount",
          "code",
          "implement",
          "next"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrent counters",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "counters"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 L O C K -B A S E D CO N C U R R E N T DATA ST R ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 L O C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S\n1 typedef struct __counter_t {\n2 int value;\n3 } counter_t;\n4\n5 void init(counter_t *c) {\n6 c->value = 0;\n7 }\n8\n9 void increment(counter_t *c) {\n10 c->value++;\n11 }\n12\n13 void decrement(counter_t *c) {\n14 c->value--;\n15 }\n16\n17 int get(counter_t *c) {\n18 return c->value;\n19 }\nFigure 29.1: A Counter Without Locks\nThis concurrent counter is simple and works correctly . In fact, i t fol-\nlows a design pattern common to the simplest and most basic concurr ent\ndata structures: it simply adds a single lock, which is acquir ed when call-\ning a routine that manipulates the data structure, and is rele ased when\nreturning from the call. In this manner , it is similar to a data structure\nbuilt with monitors [BH73], where locks are acquired and released auto-\nmatically as you call and return from object methods.\nAt this point, you have a working concurrent data structure. The p rob-\nlem you might have is performance. If your data structure is too sl ow ,\nyou\u2019ll have to do more than just add a single lock; such optimization s, if\nneeded, are thus the topic of the rest of the chapter . Note that if t he data\nstructure is not too slow , you are done! No need to do something fancy if\nsomething simple will work.\nT o understand the performance costs of the simple approach, we ru n a\nbenchmark in which each thread updates a single shared counte r a \ufb01xed\nnumber of times; we then vary the number of threads. Figure 29.5 shows\nthe total time taken, with one to four threads active; each threa d updates\nthe counter one million times. This experiment was run upon an iMa c\nwith four Intel 2.7 GHz i5 CPUs; with more CPUs active, we hope to g et\nmore total work done per unit time.\nFrom the top line in the \ufb01gure (labeled \u2019Precise\u2019), you can see that the\nperformance of the synchronized counter scales poorly . Whereas a s ingle\nthread can complete the million counter updates in a tiny amount of time\n(roughly 0.03 seconds), having two threads each update the coun ter one\nmillion times concurrently leads to a massive slowdown (taking ov er 5\nseconds!). It only gets worse with more threads.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "lows a design pattern common to the simplest and most basic concurr ent",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "lows",
          "design",
          "pattern",
          "common",
          "simplest",
          "basic",
          "concurr"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "matically as you call and return from object methods.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "matically",
          "call",
          "return",
          "object",
          "methods"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T o understand the performance costs of the simple approach, we ru n a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "performance",
          "costs",
          "simple",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: A Counter Without Locks",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "counter",
          "without",
          "locks"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 3\n1 typedef struct __counter_t {\n2 int value;\n3 pthread_mutex_t lock;\n4 } counter_t;\n5\n6 void init(counter_t *c) {\n7 c->value = 0;\n8 Pthread_mutex_init(&c->lock, NULL);\n9 }\n10\n11 void increment(counter_t *c) {\n12 Pthread_mutex_lock(&c->lock);\n13 c->value++;\n14 Pthread_mutex_unlock(&c->lock);\n15 }\n16\n17 void decrement(counter_t *c) {\n18 Pthread_mutex_lock(&c->lock);\n19 c->value--;\n20 Pthread_mutex_unlock(&c->lock);\n21 }\n22\n23 int get(counter_t *c) {\n24 Pthread_mutex_lock(&c->lock);\n25 int rc = c->value;\n26 Pthread_mutex_unlock(&c->lock);\n27 return rc;\n28 }\nFigure 29.2: A Counter With Locks\nIdeally , you\u2019d like to see the threads complete just as quickly on mul-\ntiple processors as the single thread does on one. Achieving this e nd is\ncalled perfect scaling; even though more work is done, it is done in par-\nallel, and hence the time taken to complete the task is not incre ased.\nScalable Counting\nAmazingly , researchers have studied how to build more scalabl e coun-\nters for years [MS04]. Even more amazing is the fact that scalabl e coun-\nters matter , as recent work in operating system performance ana lysis has\nshown [B+10]; without scalable counting, some workloads running on\nLinux suffer from serious scalability problems on multicore mach ines.\nMany techniques have been developed to attack this problem. W e \u2019ll\ndescribe one approach known as an approximate counter [C06].\nThe approximate counter works by representing a single logical c ounter\nvia numerous local physical counters, one per CPU core, as well as a single\nglobal counter . Speci\ufb01cally , on a machine with four CPUs, there are four\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Many techniques have been developed to attack this problem. W e \u2019ll",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "many",
          "techniques",
          "developed",
          "attack",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "describe one approach known as an approximate counter [C06].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describe",
          "approach",
          "known",
          "approximate",
          "counter"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 L O C K -B A S E D CO N C U R R E N T DATA ST R ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 L O C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S\nTime L1 L2 L3 L4 G\n0 0 0 0 0 0\n1 0 0 1 1 0\n2 1 0 2 1 0\n3 2 0 3 1 0\n4 3 0 3 2 0\n5 4 1 3 3 0\n6 5 \u2192 0 1 3 4 5 (from L1)\n7 0 2 4 5 \u2192 0 10 (from L4)\nFigure 29.3: T racing the Approximate Counters\nlocal counters and one global one. In addition to these counters, the re are\nalso locks: one for each local counter 1 , and one for the global counter .\nThe basic idea of approximate counting is as follows. When a thread\nrunning on a given core wishes to increment the counter , it incre ments its\nlocal counter; access to this local counter is synchronized via th e corre-\nsponding local lock. Because each CPU has its own local counter , thr eads\nacross CPUs can update local counters without contention, and thus up-\ndates to the counter are scalable.\nHowever , to keep the global counter up to date (in case a thread wi shes\nto read its value), the local values are periodically transfer red to the global\ncounter , by acquiring the global lock and incrementing it by the local\ncounter \u2019s value; the local counter is then reset to zero.\nHow often this local-to-global transfer occurs is determined by a t hresh-\nold S. The smaller S is, the more the counter behaves like the non-scalable\ncounter above; the bigger S is, the more scalable the counter , but the fur-\nther off the global value might be from the actual count. One could s im-\nply acquire all the local locks and the global lock (in a speci\ufb01ed or der , to\navoid deadlock) to get an exact value, but that is not scalable.\nT o make this clear , let\u2019s look at an example (Figure 29.3). In thi s ex-\nample, the threshold S is set to 5, and there are threads on each of four\nCPUs updating their local counters L1 ... L4. The global counter value\n(G) is also shown in the trace, with time increasing downward. At e ach\ntime step, a local counter may be incremented; if the local value reaches\nthe threshold S, the local value is transferred to the global counter and\nthe local counter is reset.\nThe lower line in Figure 29.5 (labeled \u2019Approximate\u2019, on page 6) sh ows\nthe performance of approximate counters with a threshold S of 1024. Per-\nformance is excellent; the time taken to update the counter four million\ntimes on four processors is hardly higher than the time taken to up date it\none million times on one processor .\n1 W e need the local locks because we assume there may be more than one threa d on each\ncore. If, instead, only one thread ran on each core, no local lock would be ne eded.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 3: T racing the Approximate Counters",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "racing",
          "approximate",
          "counters"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 5\n1 typedef struct __counter_t {\n2 int global; // global count\n3 pthread_mutex_t glock; // global lock\n4 int local[NUMCPUS]; // per-CPU count\n5 pthread_mutex_t llock[NUMCPUS]; // ... and locks\n6 int threshold; // update frequency\n7 } counter_t;\n8\n9 // init: record threshold, init locks, init values\n10 // of all local counts and global count\n11 void init(counter_t *c, int threshold) {\n12 c->threshold = threshold;\n13 c->global = 0;\n14 pthread_mutex_init(&c->glock, NULL);\n15 int i;\n16 for (i = 0; i < NUMCPUS; i++) {\n17 c->local[i] = 0;\n18 pthread_mutex_init(&c->llock[i], NULL);\n19 }\n20 }\n21\n22 // update: usually, just grab local lock and update\n23 // local amount; once local count has risen \u2019threshold\u2019,\n24 // grab global lock and transfer local values to it\n25 void update(counter_t *c, int threadID, int amt) {\n26 int cpu = threadID % NUMCPUS;\n27 pthread_mutex_lock(&c->llock[cpu]);\n28 c->local[cpu] += amt;\n29 if (c->local[cpu] >= c->threshold) {\n30 // transfer to global (assumes amt>0)\n31 pthread_mutex_lock(&c->glock);\n32 c->global += c->local[cpu];\n33 pthread_mutex_unlock(&c->glock);\n34 c->local[cpu] = 0;\n35 }\n36 pthread_mutex_unlock(&c->llock[cpu]);\n37 }\n38\n39 // get: just return global amount (approximate)\n40 int get(counter_t *c) {\n41 pthread_mutex_lock(&c->glock);\n42 int val = c->global;\n43 pthread_mutex_unlock(&c->glock);\n44 return val; // only approximate!\n45 }\nFigure 29.4: Approximate Counter Implementation\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Figure 29.4: Approximate Counter Implementation",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "figure",
          "approximate",
          "counter",
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand init: record threshold, init locks, init values",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "init",
          "record",
          "threshold",
          "init",
          "locks",
          "init",
          "values"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand update: usually, just grab local lock and update",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "update",
          "usually",
          "grab",
          "local",
          "lock",
          "update"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand get: just return global amount (approximate)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "get",
          "return",
          "global",
          "amount",
          "approximate"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 4: Approximate Counter Implementation",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "4",
          "approximate",
          "counter",
          "implementation"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 L O C K -B A S E D CO N C U R R E N T DATA ST R ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 L O C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S\n1 2 3 4\n0\n5\n10\n15\nThreads\nTime (seconds)\nPrecise\nApproximate\nFigure 29.5: Performance of T raditional vs. Approximate Counters\n1 2 4 8 16 32 64 128 256 1024 512\n0\n5\n10\n15\nApproximation Factor (S)\nTime (seconds)\nFigure 29.6: Scaling Approximate Counters\nFigure 29.6 shows the importance of the threshold value S, with four\nthreads each incrementing the counter 1 million times on four CPU s. If S\nis low , performance is poor (but the global count is always quite acc urate);\nif S is high, performance is excellent, but the global count lags (by at most\nthe number of CPUs multiplied by S). This accuracy/performance trade-\noff is what approximate counters enable.\nA rough version of an approximate counter is found in Figure 29.4\n(page 5). Read it, or better yet, run it yourself in some experime nts to\nbetter understand how it works.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "better understand how it works.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "better",
          "understand",
          "works"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Performance of T raditional vs. Approximate Counters",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "performance",
          "raditional",
          "approximate",
          "counters"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 6: Scaling Approximate Counters",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "scaling",
          "approximate",
          "counters"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "29",
    "title": "2 Concurrent Linked Lists",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "29.2 Concurrent Linked Lists\nW e next examine a more complicated structure, the linked list. Let\u2019s\nstart with a basic approach once again. For simplicity , we\u2019ll omit some of\nthe obvious routines that such a list would have and just focus on conc ur-\nrent insert; we\u2019ll leave it to the reader to think about lookup, de lete, and\nso forth. Figure 29.7 shows the code for this rudimentary data str ucture.\nAs you can see in the code, the code simply acquires a lock in the ins ert\nroutine upon entry , and releases it upon exit. One small tricky i ssue arises\nif malloc() happens to fail (a rare case); in this case, the code must also\nrelease the lock before failing the insert.\nThis kind of exceptional control \ufb02ow has been shown to be quite error\nprone; a recent study of Linux kernel patches found that a huge fr action of\nbugs (nearly 40%) are found on such rarely-taken code paths (ind eed, this\nobservation sparked some of our own research, in which we removed all\nmemory-failing paths from a Linux \ufb01le system, resulting in a mor e robust\nsystem [S+11]).\nThus, a challenge: can we rewrite the insert and lookup routines to re-\nmain correct under concurrent insert but avoid the case where th e failure\npath also requires us to add the call to unlock?\nThe answer , in this case, is yes. Speci\ufb01cally , we can rearrang e the code\na bit so that the lock and release only surround the actual critic al section\nin the insert code, and that a common exit path is used in the lookup c ode.\nThe former works because part of the lookup actually need not be locke d;\nassuming that malloc() itself is thread-safe, each thread can call into it\nwithout worry of race conditions or other concurrency bugs. Only when\nupdating the shared list does a lock need to be held. See Figure 29 .8 for\nthe details of these modi\ufb01cations.\nAs for the lookup routine, it is a simple code transformation to jump\nout of the main search loop to a single return path. Doing so again re -\nduces the number of lock acquire/release points in the code, and t hus\ndecreases the chances of accidentally introducing bugs (such as forget-\nting to unlock before returning) into the code.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "start with a basic approach once again. For simplicity , we\u2019ll omit some of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "basic",
          "approach",
          "simplicity",
          "omit"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand a challenge: can we rewrite the insert and lookup routines to re-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a challenge",
          "rewrite",
          "insert",
          "lookup",
          "routines"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrent linked lists",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "linked",
          "lists"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 L O C K -B A S E D CO N C U R R E N T DATA ST R ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 L O C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S\n1 // basic node structure\n2 typedef struct __node_t {\n3 int key;\n4 struct __node_t *next;\n5 } node_t;\n6\n7 // basic list structure (one used per list)\n8 typedef struct __list_t {\n9 node_t *head;\n10 pthread_mutex_t lock;\n11 } list_t;\n12\n13 void List_Init(list_t *L) {\n14 L->head = NULL;\n15 pthread_mutex_init(&L->lock, NULL);\n16 }\n17\n18 int List_Insert(list_t *L, int key) {\n19 pthread_mutex_lock(&L->lock);\n20 node_t *new = malloc(sizeof(node_t));\n21 if (new == NULL) {\n22 perror(\"malloc\");\n23 pthread_mutex_unlock(&L->lock);\n24 return -1; // fail\n25 }\n26 new->key = key;\n27 new->next = L->head;\n28 L->head = new;\n29 pthread_mutex_unlock(&L->lock);\n30 return 0; // success\n31 }\n32\n33 int List_Lookup(list_t *L, int key) {\n34 pthread_mutex_lock(&L->lock);\n35 node_t *curr = L->head;\n36 while (curr) {\n37 if (curr->key == key) {\n38 pthread_mutex_unlock(&L->lock);\n39 return 0; // success\n40 }\n41 curr = curr->next;\n42 }\n43 pthread_mutex_unlock(&L->lock);\n44 return -1; // failure\n45 }\nFigure 29.7: Concurrent Linked List\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 7: Concurrent Linked List",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "concurrent",
          "linked",
          "list"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 9\n1 void List_Init(list_t *L) {\n2 L->head = NULL;\n3 pthread_mutex_init(&L->lock, NULL);\n4 }\n5\n6 void List_Insert(list_t *L, int key) {\n7 // synchronization not needed\n8 node_t *new = malloc(sizeof(node_t));\n9 if (new == NULL) {\n10 perror(\"malloc\");\n11 return;\n12 }\n13 new->key = key;\n14\n15 // just lock critical section\n16 pthread_mutex_lock(&L->lock);\n17 new->next = L->head;\n18 L->head = new;\n19 pthread_mutex_unlock(&L->lock);\n20 }\n21\n22 int List_Lookup(list_t *L, int key) {\n23 int rv = -1;\n24 pthread_mutex_lock(&L->lock);\n25 node_t *curr = L->head;\n26 while (curr) {\n27 if (curr->key == key) {\n28 rv = 0;\n29 break;\n30 }\n31 curr = curr->next;\n32 }\n33 pthread_mutex_unlock(&L->lock);\n34 return rv; // now both success and failure\n35 }\nFigure 29.8: Concurrent Linked List: Rewritten\nScaling Linked Lists\nThough we again have a basic concurrent linked list, once again w e are\nin a situation where it does not scale particularly well. One tec hnique\nthat researchers have explored to enable more concurrency with in a list is\nsomething called hand-over-hand locking (a.k.a. lock coupling) [MS04].\nThe idea is pretty simple. Instead of having a single lock for the entire\nlist, you instead add a lock per node of the list. When traversing t he\nlist, the code \ufb01rst grabs the next node\u2019s lock and then releases th e current\nnode\u2019s lock (which inspires the name hand-over-hand).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "// just lock critical section",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lock",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 8: Concurrent Linked List: Rewritten",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8",
          "concurrent",
          "linked",
          "list",
          "rewritten"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "29",
    "title": "3 Concurrent Queues",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "29.3 Concurrent Queues\nAs you know by now , there is always a standard method to make a\nconcurrent data structure: add a big lock. For a queue, we\u2019ll skip that\napproach, assuming you can \ufb01gure it out.\nInstead, we\u2019ll take a look at a slightly more concurrent queue desi gned\nby Michael and Scott [MS98]. The data structures and code used for t his\nqueue are found in Figure 29.9 on the following page.\nIf you study this code carefully , you\u2019ll notice that there are two l ocks,\none for the head of the queue, and one for the tail. The goal of these two\nlocks is to enable concurrency of enqueue and dequeue operations. In\nthe common case, the enqueue routine will only access the tail lock , and\ndequeue only the head lock.\nOne trick used by Michael and Scott is to add a dummy node (allo-\ncated in the queue initialization code); this dummy enables th e separa-\ntion of head and tail operations. Study the code, or better yet, type i t in,\nrun it, and measure it, to understand how it works deeply .\nQueues are commonly used in multi-threaded applications. Howev er ,\nthe type of queue used here (with just locks) often does not complete ly\nmeet the needs of such programs. A more fully developed bounded\nqueue, that enables a thread to wait if the queue is either emp ty or overly\nfull, is the subject of our intense study in the next chapter on con dition\nvariables. W atch for it!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "As you know by now , there is always a standard method to make a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "always",
          "standard",
          "method",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "approach, assuming you can \ufb01gure it out.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "assuming"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "one for the head of the queue, and one for the tail. The goal of these two",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "head",
          "queue",
          "tail",
          "goal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "run it, and measure it, to understand how it works deeply .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "measure",
          "understand",
          "works",
          "deeply"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "meet the needs of such programs. A more fully developed bounded",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "meet",
          "needs",
          "programs",
          "fully",
          "developed",
          "bounded"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrent queues",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "queues"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 11\n1 typedef struct __node_t {\n2 int value;\n3 struct __node_t *next;\n4 } node_t;\n5\n6 typedef struct __queue_t {\n7 node_t *head;\n8 node_t *tail;\n9 pthread_mutex_t head_lock, tail_lock;\n10 }\n11\n12 void Queue_Init(queue_t *q) {\n13 node_t *tmp = malloc(sizeof(node_t));\n14 tmp->next = NULL;\n15 q->head = q->tail = tmp;\n16 pthread_mutex_init(&q->head_lock, NULL);\n17 pthread_mutex_init(&q->tail_lock, NULL);\n18 }\n19\n20 void Queue_Enqueue(queue_t *q, int value) {\n21 node_t *tmp = malloc(sizeof(node_t));\n22 assert(tmp != NULL);\n23 tmp->value = value;\n24 tmp->next = NULL;\n25\n26 pthread_mutex_lock(&q->tail_lock);\n27 q->tail->next = tmp;\n28 q->tail = tmp;\n29 pthread_mutex_unlock(&q->tail_lock);\n30 }\n31\n32 int Queue_Dequeue(queue_t *q, int *value) {\n33 pthread_mutex_lock(&q->head_lock);\n34 node_t *tmp = q->head;\n35 node_t *new_head = tmp->next;\n36 if (new_head == NULL) {\n37 pthread_mutex_unlock(&q->head_lock);\n38 return -1; // queue was empty\n39 }\n40 *value = new_head->value;\n41 q->head = new_head;\n42 pthread_mutex_unlock(&q->head_lock);\n43 free(tmp);\n44 return 0;\n45 }\nFigure 29.9: Michael and Scott Concurrent Queue\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 9: Michael and Scott Concurrent Queue",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "9",
          "michael",
          "scott",
          "concurrent",
          "queue"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "29",
    "title": "4 Concurrent Hash T able",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "29.4 Concurrent Hash T able\nW e end our discussion with a simple and widely applicable concur rent\ndata structure, the hash table. W e\u2019ll focus on a simple hash tabl e that does\nnot resize; a little more work is required to handle resizing, wh ich we\nleave as an exercise for the reader (sorry!).\nThis concurrent hash table (Figure 29.10) is straightforward , is built us-\ning the concurrent lists we developed earlier , and works incred ibly well.\nThe reason for its good performance is that instead of having a singl e\nlock for the entire structure, it uses a lock per hash bucket (eac h of which\nis represented by a list). Doing so enables many concurrent oper ations to\ntake place.\nFigure 29.11 shows the performance of the hash table under concur -\nrent updates (from 10,000 to 50,000 concurrent updates from eac h of four\nthreads, on the same iMac with four CPUs). Also shown, for the sake\nof comparison, is the performance of a linked list (with a single loc k).\nAs you can see from the graph, this simple concurrent hash table s cales\nmagni\ufb01cently; the linked list, in contrast, does not.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ing the concurrent lists we developed earlier , and works incred ibly well.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "concurrent",
          "lists",
          "developed",
          "earlier",
          "works",
          "incred",
          "ibly",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "magni\ufb01cently; the linked list, in contrast, does not.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "linked",
          "list",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand concurrent hash t able",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "concurrent",
          "hash",
          "able"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "29",
    "title": "5 Summary",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "29.5 Summary\nW e have introduced a sampling of concurrent data structures, fr om\ncounters, to lists and queues, and \ufb01nally to the ubiquitous and heavily-\nused hash table. W e have learned a few important lessons along th e way:\nto be careful with acquisition and release of locks around control \ufb02 ow\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "used hash table. W e have learned a few important lessons along th e way:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "used",
          "hash",
          "table",
          "learned",
          "important",
          "lessons",
          "along"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 13\n0 10 20 30 40\n0\n5\n10\n15\nInserts (Thousands)\nTime (seconds)\nSimple Concurrent List\nConcurrent Hash Table\nFigure 29.11: Scaling Hash T ables\nchanges; that enabling more concurrency does not necessarily in crease\nperformance; that performance problems should only be remedied on ce\nthey exist. This last point, of avoiding premature optimization , is cen-\ntral to any performance-minded developer; there is no value in making\nsomething faster if doing so will not improve the overall performan ce of\nthe application.\nOf course, we have just scratched the surface of high performanc e\nstructures. See Moir and Shavit\u2019s excellent survey for more informa tion,\nas well as links to other sources [MS04]. In particular , you might be inter-\nested in other structures (such as B-trees); for this knowledge , a database\nclass is your best bet. Y ou also might be interested in techniqu es that don\u2019t\nuse traditional locks at all; such non-blocking data structures are some-\nthing we\u2019ll get a taste of in the chapter on common concurrency bugs,\nbut frankly this topic is an entire area of knowledge requiring m ore study\nthan is possible in this humble book. Find out more on your own if you\nare interested (as always!).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tral to any performance-minded developer; there is no value in making",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tral",
          "performance",
          "minded",
          "developer",
          "value",
          "making"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ested in other structures (such as B-trees); for this knowledge , a database",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ested",
          "structures",
          "trees",
          "knowledge",
          "database"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "but frankly this topic is an entire area of knowledge requiring m ore study",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "frankly",
          "topic",
          "entire",
          "area",
          "knowledge",
          "requiring",
          "study"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 L O C K -B A S E D CO N C U R R E N T DATA ST R...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 L O C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S\nTI P : A V O I D PR E M AT U R E OP T I M I Z AT I O N (K N U T H \u2019 S LAW)\nWhen building a concurrent data structure, start with the most basic ap-\nproach, which is to add a single big lock to provide synchronized a ccess.\nBy doing so, you are likely to build a correct lock; if you then \ufb01nd that it\nsuffers from performance problems, you can re\ufb01ne it, thus only mak ing\nit fast if need be. As Knuth famously stated, \u201cPremature optimization is\nthe root of all evil.\u201d\nMany operating systems utilized a single lock when \ufb01rst transi tioning\nto multiprocessors, including Sun OS and Linux. In the latter , t his lock\neven had a name, the big kernel lock (BKL). For many years, this sim-\nple approach was a good one, but when multi-CPU systems became the\nnorm, only allowing a single active thread in the kernel at a time became\na performance bottleneck. Thus, it was \ufb01nally time to add the opt imiza-\ntion of improved concurrency to these systems. Within Linux, the more\nstraightforward approach was taken: replace one lock with many . Within\nSun, a more radical decision was made: build a brand new operating sys-\ntem, known as Solaris, that incorporates concurrency more fundamen -\ntally from day one. Read the Linux and Solaris kernel books for more\ninformation about these fascinating systems [BC05, MM00].\n.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ple approach was a good one, but when multi-CPU systems became the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "good",
          "multi",
          "systems",
          "became"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "straightforward approach was taken: replace one lock with many . Within",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "straightforward",
          "approach",
          "taken",
          "replace",
          "lock",
          "many",
          "within"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "tem, known as Solaris, that incorporates concurrency more fundamen -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "solaris",
          "incorporates",
          "concurrency",
          "fundamen"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C K -B A S E D CO N C U R R E N T DATA ST R U C T U R E S 15\nReferences\n[B+10] \u201cAn Analysis of Linux Scalability to Many Cores\u201d by Silas Boy d-Wickizer , Austin T .\nClements, Y andong Mao, Aleksey Pesterev , M. Frans Kaashoek, Robert Mo rris, Nickolai Zel-\ndovich . OSDI \u201910, V ancouver , Canada, October 2010. A great study of how Linux performs on\nmulticore machines, as well as some simple solutions. Includes a neat sloppy counter to solve one form\nof the scalable counting problem.\n[BH73] \u201cOperating System Principles\u201d by Per Brinch Hansen. Prentice-Hall, 1 973. A vailable:\nhttp://portal.acm.org/citation.cfm?id=540365. One of the \ufb01rst books on operating\nsystems; certainly ahead of its time. Introduced monitors as a concurrency pri mitive.\n[BC05] \u201cUnderstanding the Linux Kernel (Third Edition)\u201d by Daniel P . Bovet and Marco Cesati.\nO\u2019Reilly Media, November 2005. The classic book on the Linux kernel. Y ou should read it.\n[C06] \u201cThe Search For Fast, Scalable Counters\u201d by Jonathan Corbet. Feb ruary 1, 2006. A vail-\nable: https://lwn.net/Articles/170003. L WN has many wonderful articles about the latest\nin Linux This article is a short description of scalable approximate countin g; read it, and others, to learn\nmore about the latest in Linux.\n[L+13] \u201cA Study of Linux File System Evolution\u201d by Lanyue Lu, Andre a C. Arpaci-Dusseau,\nRemzi H. Arpaci-Dusseau, Shan Lu. F AST \u201913, San Jose, CA, Februar y 2013. Our paper that\nstudies every patch to Linux \ufb01le systems over nearly a decade. Lots of fun \ufb01 ndings in there; read it to\nsee! The work was painful to do though; the poor graduate student, Lanyue Lu, had to look through\nevery single patch by hand in order to understand what they did.\n[MS98] \u201cNonblocking Algorithms and Preemption-safe Locking on by Multipro grammed Shared-\nmemory Multiprocessors. \u201d M. Michael, M. Scott. Journal of Parallel and Di stributed Com-\nputing, V ol. 51, No. 1, 1998 Professor Scott and his students have been at the forefront of concurrent\nalgorithms and data structures for many years; check out his web page, numer ous papers, or books to\n\ufb01nd out more.\n[MS04] \u201cConcurrent Data Structures\u201d by Mark Moir and Nir Shavit. In Handb ook of Data\nStructures and Applications (Editors D. Metha and S.Sahni). Chapman and Ha ll/CRC Press,\n2004. A vailable: www.cs.tau.ac.il/\u02dcshanir/concurrent-data-structures.pdf.\nA short but relatively comprehensive reference on concurrent data str uctures. Though it is missing\nsome of the latest works in the area (due to its age), it remains an incredibly use ful reference.\n[MM00] \u201cSolaris Internals: Core Kernel Architecture\u201d by Jim Mauro and Richa rd McDougall.\nPrentice Hall, October 2000. The Solaris book. Y ou should also read this, if you want to learn about\nsomething other than Linux.\n[S+11] \u201cMaking the Common Case the Only Case with Anticipatory Memory Al location\u201d by\nSwaminathan Sundararaman, Y upu Zhang, Sriram Subramanian, Andrea C. Arpaci-Dusseau,\nRemzi H. Arpaci-Dusseau . F AST \u201911, San Jose, CA, February 2011. Our work on removing\npossibly-failing allocation calls from kernel code paths. By allocating all potenti ally needed memory\nbefore doing any work, we avoid failure deep down in the storage stack.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "multicore machines, as well as some simple solutions. Includes a neat sloppy counter to solve one form",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "multicore",
          "machines",
          "well",
          "simple",
          "solutions",
          "includes",
          "neat",
          "sloppy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[BH73] \u201cOperating System Principles\u201d by Per Brinch Hansen. Prentice-Hall, 1 973. A vailable:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "system",
          "principles",
          "brinch",
          "hansen",
          "prentice",
          "hall",
          "vailable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[BC05] \u201cUnderstanding the Linux Kernel (Third Edition)\u201d by Daniel P . Bovet and Marco Cesati.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "linux",
          "kernel",
          "third",
          "edition",
          "daniel",
          "bovet",
          "marco"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "in Linux This article is a short description of scalable approximate countin g; read it, and others, to learn",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "linux",
          "article",
          "short",
          "description",
          "scalable",
          "approximate",
          "countin",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "every single patch by hand in order to understand what they did.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "every",
          "single",
          "patch",
          "hand",
          "order",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "[MS98] \u201cNonblocking Algorithms and Preemption-safe Locking on by Multipro grammed Shared-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "nonblocking",
          "algorithms",
          "preemption",
          "safe",
          "locking",
          "multipro",
          "grammed",
          "shared"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "algorithms and data structures for many years; check out his web page, numer ous papers, or books to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "algorithms",
          "data",
          "structures",
          "many",
          "years",
          "check",
          "page",
          "numer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "Prentice Hall, October 2000. The Solaris book. Y ou should also read this, if you want to learn about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "prentice",
          "hall",
          "october",
          "solaris",
          "book",
          "also",
          "read",
          "want"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand A vailable: http://portal.acm.org/citation.cfm?id=540365. One of the \ufb01rst books on operating",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "portal",
          "citation",
          "books",
          "operating"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand able: https://lwn.net/Articles/170003. L WN has many wonderful articles about the latest",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "https",
          "articles",
          "many",
          "wonderful",
          "articles",
          "latest"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable: www.cs.tau.ac.il/\u02dcshanir/concurrent-data-structures.pdf.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "shanir",
          "concurrent",
          "data",
          "structures"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Solaris Internals: Core Kernel Architecture\u201d by Jim Mauro and Richa rd McDougall.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "solaris internals",
          "core",
          "kernel",
          "architecture",
          "mauro",
          "richa",
          "mcdougall"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "Now , build a simple concurrent counter and measure how long it",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "2. Now , build a simple concurrent counter and measure how long it\ntakes to increment the counter many times as the number of threa ds\nincreases. How many CPUs are available on the system you are\nusing? Does this number impact your measurements at all?\n3. Next, build a version of the sloppy counter . Once again, measur e its\nperformance as the number of threads varies, as well as the thre sh-\nold. Do the numbers match what you see in the chapter?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Build a version of a linked list that uses hand-over-hand locki ng",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "4. Build a version of a linked list that uses hand-over-hand locki ng\n[MS04], as cited in the chapter . Y ou should read the paper \ufb01rst\nto understand how it works, and then implement it. Measure its\nperformance. When does a hand-over-hand list work better than a\nstandard list as shown in the chapter?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to understand how it works, and then implement it. Measure its",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "understand",
          "works",
          "implement",
          "measure"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Pick your favorite interesting data structure, such as a B-t ree or",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "5. Pick your favorite interesting data structure, such as a B-t ree or\nother slightly more interested structure. Implement it, and s tart\nwith a simple locking strategy such as a single lock. Measure it s\nperformance as the number of concurrent threads increases.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "other slightly more interested structure. Implement it, and s tart",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "slightly",
          "interested",
          "structure",
          "implement",
          "tart"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "with a simple locking strategy such as a single lock. Measure it s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "locking",
          "strategy",
          "single",
          "lock",
          "measure"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Finally , think of a more interesting locking strategy for this favorite",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "6. Finally , think of a more interesting locking strategy for this favorite\ndata structure of yours. Implement it, and measure its performa nce.\nHow does it compare to the straightforward locking approach?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Finally , think of a more interesting locking strategy for this favorite",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "think",
          "interesting",
          "locking",
          "strategy",
          "favorite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "data structure of yours. Implement it, and measure its performa nce.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "data",
          "structure",
          "implement",
          "measure",
          "performa"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "How does it compare to the straightforward locking approach?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "straightforward",
          "locking",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand it compare to the straightforward locking approach",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "straightforward",
          "locking",
          "approach"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "30\nCondition V ariables\nThus far we have developed the notion of a lock and seen how one can be\nproperly built with the right combination of hardware and OS supp ort.\nUnfortunately , locks are not the only primitives that are needed to build\nconcurrent programs.\nIn particular , there are many cases where a thread wishes to c heck\nwhether a condition is true before continuing its execution. For example,\na parent thread might wish to check whether a child thread has completed\nbefore continuing (this is often called a join()); how should such a wait\nbe implemented? Let\u2019s look at Figure 30.1.\n1 void *child(void *arg) {\n2 printf(\"child\\n\");\n3 // XXX how to indicate we are done?\n4 return NULL;\n5 }\n6\n7 int main(int argc, char *argv[]) {\n8 printf(\"parent: begin\\n\");\n9 pthread_t c;\n10 Pthread_create(&c, NULL, child, NULL); // create child\n11 // XXX how to wait for child?\n12 printf(\"parent: end\\n\");\n13 return 0;\n14 }\nFigure 30.1: A Parent W aiting For Its Child\nWhat we would like to see here is the following output:\nparent: begin\nchild\nparent: end\nW e could try using a shared variable, as you see in Figure 30.2. T his\nsolution will generally work, but it is hugely inef\ufb01cient as the parent spins\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus far we have developed the notion of a lock and seen how one can be",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "thus",
          "developed",
          "notion",
          "lock",
          "seen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "be implemented? Let\u2019s look at Figure 30.1.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implemented",
          "look",
          "figure"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Pthread_create(&c, NULL, child, NULL); // create child",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "child",
          "null",
          "create",
          "child"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 1: A Parent W aiting For Its Child",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "parent",
          "aiting",
          "child"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "30",
    "title": "1 De\ufb01nition and Routines",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "30.1 De\ufb01nition and Routines\nT o wait for a condition to become true, a thread can make use of what\nis known as a condition variable . A condition variable is an explicit\nqueue that threads can put themselves on when some state of execu tion\n(i.e., some condition) is not as desired (by waiting on the condition);\nsome other thread, when it changes said state, can then wake one ( or\nmore) of those waiting threads and thus allow them to continue (by sig-\nnaling on the condition). The idea goes back to Dijkstra\u2019s use of \u201cprivate\nsemaphores\u201d [D68]; a similar idea was later named a \u201ccondition v ariable\u201d\nby Hoare in his work on monitors [H74].\nT o declare such a condition variable, one simply writes somethin g\nlike this: pthread cond t c;, which declares c as a condition variable\n(note: proper initialization is also required). A condition vari able has two\noperations associated with it: wait() and signal(). The wait() call\nis executed when a thread wishes to put itself to sleep; the signal() call\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "is known as a condition variable . A condition variable is an explicit",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "condition",
          "variable",
          "condition",
          "variable",
          "explicit"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand note: proper initialization is also required). A condition vari able has two",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "note",
          "proper",
          "initialization",
          "also",
          "required",
          "condition",
          "vari",
          "able"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand operations associated with it: wait() and signal(). The wait() call",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "operations associated with it",
          "wait",
          "signal",
          "wait",
          "call"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand de\ufb01nition and routines",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "routines"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 3\n1 int done = 0;\n2 pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\n3 pthread_cond_t c = PTHREAD_COND_INITIALIZER;\n4\n5 void thr_exit() {\n6 Pthread_mutex_lock(&m);\n7 done = 1;\n8 Pthread_cond_signal(&c);\n9 Pthread_mutex_unlock(&m);\n10 }\n11\n12 void *child(void *arg) {\n13 printf(\"child\\n\");\n14 thr_exit();\n15 return NULL;\n16 }\n17\n18 void thr_join() {\n19 Pthread_mutex_lock(&m);\n20 while (done == 0)\n21 Pthread_cond_wait(&c, &m);\n22 Pthread_mutex_unlock(&m);\n23 }\n24\n25 int main(int argc, char *argv[]) {\n26 printf(\"parent: begin\\n\");\n27 pthread_t p;\n28 Pthread_create(&p, NULL, child, NULL);\n29 thr_join();\n30 printf(\"parent: end\\n\");\n31 return 0;\n32 }\nFigure 30.3: Parent W aiting For Child: Use A Condition V ariable\nis executed when a thread has changed something in the program a nd\nthus wants to wake a sleeping thread waiting on this condition. Sp eci\ufb01-\ncally , the POSIX calls look like this:\npthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);\npthread_cond_signal(pthread_cond_t *c);\nW e will often refer to these as wait() and signal() for simplicity .\nOne thing you might notice about the wait() call is that it also takes a\nmutex as a parameter; it assumes that this mutex is locked when wait()\nis called. The responsibility of wait() is to release the lock and put the\ncalling thread to sleep (atomically); when the thread wakes u p (after some\nother thread has signaled it), it must re-acquire the lock befor e returning\nto the caller . This complexity stems from the desire to prevent certain\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pthread_create(&p, NULL, child, NULL);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "child",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 3: Parent W aiting For Child: Use A Condition V ariable",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "parent",
          "aiting",
          "child",
          "condition",
          "ariable"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 CO N D I T I O N VA R I A B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 CO N D I T I O N VA R I A B L E S\nrace conditions from occurring when a thread is trying to put itse lf to\nsleep. Let\u2019s take a look at the solution to the join problem (Figure 30 .3) to\nunderstand this better .\nThere are two cases to consider . In the \ufb01rst, the parent create s the child\nthread but continues running itself (assume we have only a sing le pro-\ncessor) and thus immediately calls into thr join() to wait for the child\nthread to complete. In this case, it will acquire the lock, chec k if the child\nis done (it is not), and put itself to sleep by calling wait() (hence releas-\ning the lock). The child will eventually run, print the messag e \u201cchild\u201d,\nand call thr exit() to wake the parent thread; this code just grabs the\nlock, sets the state variable done, and signals the parent thus waking it.\nFinally , the parent will run (returning from wait() with the lock held),\nunlock the lock, and print the \ufb01nal message \u201cparent: end\u201d.\nIn the second case, the child runs immediately upon creation, se ts\ndone to 1, calls signal to wake a sleeping thread (but there is none, so\nit just returns), and is done. The parent then runs, calls thr join(), sees\nthat done is 1, and thus does not wait and returns.\nOne last note: you might observe the parent uses a while loop instead\nof just an if statement when deciding whether to wait on the condition.\nWhile this does not seem strictly necessary per the logic of the pr ogram,\nit is always a good idea, as we will see below .\nT o make sure you understand the importance of each piece of the\nthr exit() and thr join() code, let\u2019s try a few alternate implemen-\ntations. First, you might be wondering if we need the state varia ble done.\nWhat if the code looked like the example below? (Figure 30.4)\nUnfortunately this approach is broken. Imagine the case where t he\nchild runs immediately and calls thr exit() immediately; in this case,\nthe child will signal, but there is no thread asleep on the condi tion. When\nthe parent runs, it will simply call wait and be stuck; no thre ad will ever\nwake it. From this example, you should appreciate the importance of\nthe state variable done; it records the value the threads are interested in\nknowing. The sleeping, waking, and locking all are built around it.\n1 void thr_exit() {\n2 Pthread_mutex_lock(&m);\n3 Pthread_cond_signal(&c);\n4 Pthread_mutex_unlock(&m);\n5 }\n6\n7 void thr_join() {\n8 Pthread_mutex_lock(&m);\n9 Pthread_cond_wait(&c, &m);\n10 Pthread_mutex_unlock(&m);\n11 }\nFigure 30.4: Parent W aiting: No State V ariable\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "understand this better .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "better"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "There are two cases to consider . In the \ufb01rst, the parent create s the child",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cases",
          "consider",
          "parent",
          "create",
          "child"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T o make sure you understand the importance of each piece of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "sure",
          "understand",
          "importance",
          "piece"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Unfortunately this approach is broken. Imagine the case where t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unfortunately",
          "approach",
          "broken",
          "imagine",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "knowing. The sleeping, waking, and locking all are built around it.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowing",
          "sleeping",
          "waking",
          "locking",
          "built",
          "around"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand One last note: you might observe the parent uses a while loop instead",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last note",
          "might",
          "observe",
          "parent",
          "uses",
          "loop",
          "instead"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 4: Parent W aiting: No State V ariable",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "parent",
          "aiting",
          "state",
          "ariable"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 5\n1 void thr_exit() {\n2 done = 1;\n3 Pthread_cond_signal(&c);\n4 }\n5\n6 void thr_join() {\n7 if (done == 0)\n8 Pthread_cond_wait(&c);\n9 }\nFigure 30.5: Parent W aiting: No Lock\nHere (Figure 30.5) is another poor implementation. In this examp le,\nwe imagine that one does not need to hold a lock in order to signal and\nwait. What problem could occur here? Think about it 1 !\nThe issue here is a subtle race condition. Speci\ufb01cally , if the pa rent calls\nthr\njoin() and then checks the value of done, it will see that it is 0 and\nthus try to go to sleep. But just before it calls wait to go to sle ep, the parent\nis interrupted, and the child runs. The child changes the sta te variable\ndone to 1 and signals, but no thread is waiting and thus no thread is\nwoken. When the parent runs again, it sleeps forever , which is s ad.\nHopefully , from this simple join example, you can see some of the ba-\nsic requirements of using condition variables properly . T o make sure you\nunderstand, we now go through a more complicated example: the pro-\nducer/consumer or bounded-buffer problem.\nTI P : A LWAY S HO L D TH E LO C K WH I L E SI G N A L I N G\nAlthough it is strictly not necessary in all cases, it is likely simplest and\nbest to hold the lock while signaling when using condition variab les. The\nexample above shows a case where you must hold the lock for correct-\nness; however , there are some other cases where it is likely OK not to, but\nprobably is something you should avoid. Thus, for simplicity , hold the\nlock when calling signal .\nThe converse of this tip, i.e., hold the lock when calling wait, is not just\na tip, but rather mandated by the semantics of wait, because wa it always\n(a) assumes the lock is held when you call it, (b) releases said l ock when\nputting the caller to sleep, and (c) re-acquires the lock just before return-\ning. Thus, the generalization of this tip is correct: hold the lock when\ncalling signal or wait , and you will always be in good shape.\n1 Note that this example is not \u201creal\u201d code, because the call to pthread cond wait()\nalways requires a mutex as well as a condition variable; here, we just pretend that the interface\ndoes not do so for the sake of the negative example.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Here (Figure 30.5) is another poor implementation. In this examp le,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "figure",
          "another",
          "poor",
          "implementation",
          "examp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand, we now go through a more complicated example: the pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "complicated",
          "example"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "calling signal or wait , and you will always be in good shape.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "calling",
          "signal",
          "wait",
          "always",
          "good",
          "shape"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Parent W aiting: No Lock",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "parent",
          "aiting",
          "lock"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand TI P: A LWAY S HO L D TH E LO C K WH I L E SI G N A L I N G",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ti p",
          "lway"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "30",
    "title": "2 The Producer/Consumer (Bounded Buffer) Problem",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "30.2 The Producer/Consumer (Bounded Buffer) Problem\nThe next synchronization problem we will confront in this chapter is\nknown as the producer/consumer problem, or sometimes as the bounded\nbuffer problem, which was \ufb01rst posed by Dijkstra [D72]. Indeed, it was\nthis very producer/consumer problem that led Dijkstra and his c o-workers\nto invent the generalized semaphore (which can be used as eith er a lock\nor a condition variable) [D01]; we will learn more about semaphores later .\nImagine one or more producer threads and one or more consumer\nthreads. Producers generate data items and place them in a buf fer; con-\nsumers grab said items from the buffer and consume them in some wa y .\nThis arrangement occurs in many real systems. For example, in a\nmulti-threaded web server , a producer puts HTTP requests int o a work\nqueue (i.e., the bounded buffer); consumer threads take reque sts out of\nthis queue and process them.\nA bounded buffer is also used when you pipe the output of one pro-\ngram into another , e.g., grep foo file.txt | wc -l. This example\nruns two processes concurrently; grep writes lines from file.txt with\nthe string foo in them to what it thinks is standard output; the U N I X\nshell redirects the output to what is called a U N I X pipe (created by the\npipe system call). The other end of this pipe is connected to the stan-\ndard input of the process wc, which simply counts the number of lines in\nthe input stream and prints out the result. Thus, the grep process is the\nproducer; the wc process is the consumer; between them is an in-kernel\nbounded buffer; you, in this example, are just the happy user .\nBecause the bounded buffer is a shared resource, we must of course\nrequire synchronized access to it, lest 2 a race condition arise. T o begin to\nunderstand this problem better , let us examine some actual code .\nThe \ufb01rst thing we need is a shared buffer , into which a producer puts\ndata, and out of which a consumer takes data. Let\u2019s just use a singl e\n2 This is where we drop some serious Old English on you, and the subjunctiv e form.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known as the producer/consumer problem, or sometimes as the bounded",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "producer",
          "consumer",
          "problem",
          "sometimes",
          "bounded"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "or a condition variable) [D01]; we will learn more about semaphores later .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "condition",
          "variable",
          "learn",
          "semaphores",
          "later"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "shell redirects the output to what is called a U N I X pipe (created by the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "shell",
          "redirects",
          "output",
          "called",
          "pipe",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "understand this problem better , let us examine some actual code .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "problem",
          "better",
          "examine",
          "actual",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the producer/consumer (bounded buffer) problem",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "producer",
          "consumer",
          "bounded",
          "buffer",
          "problem"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 7\n1 void *producer(void *arg) {\n2 int i;\n3 int loops = (int) arg;\n4 for (i = 0; i < loops; i++) {\n5 put(i);\n6 }\n7 }\n8\n9 void *consumer(void *arg) {\n10 int i;\n11 while (1) {\n12 int tmp = get();\n13 printf(\"%d\\n\", tmp);\n14 }\n15 }\nFigure 30.7: Producer/Consumer Threads (V ersion 1)\ninteger for simplicity (you can certainly imagine placing a poi nter to a\ndata structure into this slot instead), and the two inner routi nes to put\na value into the shared buffer , and to get a value out of the buffe r . See\nFigure 30.6 (page 6) for details.\nPretty simple, no? The put() routine assumes the buffer is empty\n(and checks this with an assertion), and then simply puts a val ue into the\nshared buffer and marks it full by setting count to 1. The get() routine\ndoes the opposite, setting the buffer to empty (i.e., setting count to 0)\nand returning the value. Don\u2019t worry that this shared buffer has just a\nsingle entry; later , we\u2019ll generalize it to a queue that can hol d multiple\nentries, which will be even more fun than it sounds.\nNow we need to write some routines that know when it is OK to access\nthe buffer to either put data into it or get data out of it. The condi tions for\nthis should be obvious: only put data into the buffer when count is zero\n(i.e., when the buffer is empty), and only get data from the buff er when\ncount is one (i.e., when the buffer is full). If we write the synchroni zation\ncode such that a producer puts data into a full buffer , or a consume r gets\ndata from an empty one, we have done something wrong (and in this\ncode, an assertion will \ufb01re).\nThis work is going to be done by two types of threads, one set of which\nwe\u2019ll call the producer threads, and the other set which we\u2019ll call con-\nsumer threads. Figure 30.7 shows the code for a producer that puts an\ninteger into the shared buffer loops number of times, and a consumer\nthat gets the data out of that shared buffer (forever), each time printing\nout the data item it pulled from the shared buffer .\nA Broken Solution\nNow imagine that we have just a single producer and a single consu mer .\nObviously the put() and get() routines have critical sections within\nthem, as put() updates the buffer , and get() reads from it. However ,\nputting a lock around the code doesn\u2019t work; we need something more.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now we need to write some routines that know when it is OK to access",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "write",
          "routines",
          "know",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Obviously the put() and get() routines have critical sections within",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "obviously",
          "routines",
          "critical",
          "sections",
          "within"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 7: Producer/Consumer Threads (V ersion 1)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "producer",
          "consumer",
          "threads",
          "ersion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 CO N D I T I O N VA R I A B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 CO N D I T I O N VA R I A B L E S\n1 int loops; // must initialize somewhere...\n2 cond_t cond;\n3 mutex_t mutex;\n4\n5 void *producer(void *arg) {\n6 int i;\n7 for (i = 0; i < loops; i++) {\n8 Pthread_mutex_lock(&mutex); // p1\n9 if (count == 1) // p2\n10 Pthread_cond_wait(&cond, &mutex); // p3\n11 put(i); // p4\n12 Pthread_cond_signal(&cond); // p5\n13 Pthread_mutex_unlock(&mutex); // p6\n14 }\n15 }\n16\n17 void *consumer(void *arg) {\n18 int i;\n19 for (i = 0; i < loops; i++) {\n20 Pthread_mutex_lock(&mutex); // c1\n21 if (count == 0) // c2\n22 Pthread_cond_wait(&cond, &mutex); // c3\n23 int tmp = get(); // c4\n24 Pthread_cond_signal(&cond); // c5\n25 Pthread_mutex_unlock(&mutex); // c6\n26 printf(\"%d\\n\", tmp);\n27 }\n28 }\nFigure 30.8: Producer/Consumer: Single CV And If Statement\nNot surprisingly , that something more is some condition variables . In this\n(broken) \ufb01rst try (Figure 30.8), we have a single condition vari able cond\nand associated lock mutex.\nLet\u2019s examine the signaling logic between producers and consume rs.\nWhen a producer wants to \ufb01ll the buffer , it waits for it to be empt y (p1\u2013\np3). The consumer has the exact same logic, but waits for a differ ent\ncondition: fullness (c1\u2013c3).\nWith just a single producer and a single consumer , the code in Fig ure\n30.8 works. However , if we have more than one of these threads (e.g. ,\ntwo consumers), the solution has two critical problems. What are they?\n... (pause here to think) ...\nLet\u2019s understand the \ufb01rst problem, which has to do with the if state-\nment before the wait. Assume there are two consumers ( Tc1 and Tc2) and\none producer ( Tp). First, a consumer ( Tc1) runs; it acquires the lock (c1),\nchecks if any buffers are ready for consumption (c2), and \ufb01nding that\nnone are, waits (c3) (which releases the lock).\nThen the producer ( Tp) runs. It acquires the lock (p1), checks if all\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "two consumers), the solution has two critical problems. What are they?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consumers",
          "solution",
          "critical",
          "problems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Let\u2019s understand the \ufb01rst problem, which has to do with the if state-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "problem",
          "state"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 8: Producer/Consumer: Single CV And If Statement",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8",
          "producer",
          "consumer",
          "single",
          "statement"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand works. however , if we have more than one of these threads (e.g. ,",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "works",
          "however",
          "threads"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 9\nTc1 State T c2 State Tp State\nCount\nComment\nc1 Run Ready Ready 0\nc2 Run Ready Ready 0\nc3 Sleep Ready Ready 0 Nothing to get\nSleep Ready p1 Run 0\nSleep Ready p2 Run 0\nSleep Ready p4 Run 1 Buffer now full\nReady Ready p5 Run 1 T c1 awoken\nReady Ready p6 Run 1\nReady Ready p1 Run 1\nReady Ready p2 Run 1\nReady Ready p3 Sleep 1 Buffer full; sleep\nReady c1 Run Sleep 1 T c2 sneaks in ...\nReady c2 Run Sleep 1\nReady c4 Run Sleep 0 ... and grabs data\nReady c5 Run Ready 0 T p awoken\nReady c6 Run Ready 0\nc4 Run Ready Ready 0 Oh oh! No data\nFigure 30.9: Thread T race: Broken Solution (V ersion 1)\nbuffers are full (p2), and \ufb01nding that not to be the case, goes ah ead and\n\ufb01lls the buffer (p4). The producer then signals that a buffer h as been\n\ufb01lled (p5). Critically , this moves the \ufb01rst consumer ( Tc1) from sleeping\non a condition variable to the ready queue; Tc1 is now able to run (but\nnot yet running). The producer then continues until realizing t he buffer\nis full, at which point it sleeps (p6, p1\u2013p3).\nHere is where the problem occurs: another consumer ( Tc2) sneaks in\nand consumes the one existing value in the buffer (c1, c2, c4, c5 , c6, skip-\nping the wait at c3 because the buffer is full). Now assume Tc1 runs; just\nbefore returning from the wait, it re-acquires the lock and then returns. It\nthen calls get() (c4), but there are no buffers to consume! An assertion\ntriggers, and the code has not functioned as desired. Clearly , w e should\nhave somehow prevented Tc1 from trying to consume because Tc2 snuck\nin and consumed the one value in the buffer that had been produced . Fig-\nure 30.9 shows the action each thread takes, as well as its sched uler state\n(Ready , Running, or Sleeping) over time.\nThe problem arises for a simple reason: after the producer woke Tc1,\nbut before Tc1 ever ran, the state of the bounded buffer changed (thanks to\nTc2). Signaling a thread only wakes them up; it is thus a hint that the state\nof the world has changed (in this case, that a value has been plac ed in the\nbuffer), but there is no guarantee that when the woken thread r uns, the\nstate will still be as desired. This interpretation of what a signal means\nis often referred to as Mesa semantics , after the \ufb01rst research that built\na condition variable in such a manner [LR80]; the contrast, refe rred to as\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01lled (p5). Critically , this moves the \ufb01rst consumer ( Tc1) from sleeping",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critically",
          "moves",
          "consumer",
          "sleeping"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "on a condition variable to the ready queue; Tc1 is now able to run (but",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "condition",
          "variable",
          "ready",
          "queue",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "a condition variable in such a manner [LR80]; the contrast, refe rred to as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "condition",
          "variable",
          "manner",
          "contrast",
          "refe",
          "rred"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 9: Thread T race: Broken Solution (V ersion 1)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "9",
          "thread",
          "race",
          "broken",
          "solution",
          "ersion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 CO N D I T I O N VA R I A B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 CO N D I T I O N VA R I A B L E S\n1 int loops;\n2 cond_t cond;\n3 mutex_t mutex;\n4\n5 void *producer(void *arg) {\n6 int i;\n7 for (i = 0; i < loops; i++) {\n8 Pthread_mutex_lock(&mutex); // p1\n9 while (count == 1) // p2\n10 Pthread_cond_wait(&cond, &mutex); // p3\n11 put(i); // p4\n12 Pthread_cond_signal(&cond); // p5\n13 Pthread_mutex_unlock(&mutex); // p6\n14 }\n15 }\n16\n17 void *consumer(void *arg) {\n18 int i;\n19 for (i = 0; i < loops; i++) {\n20 Pthread_mutex_lock(&mutex); // c1\n21 while (count == 0) // c2\n22 Pthread_cond_wait(&cond, &mutex); // c3\n23 int tmp = get(); // c4\n24 Pthread_cond_signal(&cond); // c5\n25 Pthread_mutex_unlock(&mutex); // c6\n26 printf(\"%d\\n\", tmp);\n27 }\n28 }\nFigure 30.10: Producer/Consumer: Single CV And While\nHoare semantics , is harder to build but provides a stronger guarantee\nthat the woken thread will run immediately upon being woken [H74 ].\nVirtually every system ever built employs Mesa semantics.\nBetter, But Still Broken: While, Not If\nFortunately , this \ufb01x is easy (Figure 30.10): change the if to a while.\nThink about why this works; now consumer Tc1 wakes up and (with the\nlock held) immediately re-checks the state of the shared varia ble (c2). If\nthe buffer is empty at that point, the consumer simply goes back t o sleep\n(c3). The corollary if is also changed to a while in the producer (p2).\nThanks to Mesa semantics, a simple rule to remember with condi tion\nvariables is to always use while loops . Sometimes you don\u2019t have to re-\ncheck the condition, but it is always safe to do so; just do it and b e happy .\nHowever , this code still has a bug, the second of two problems men-\ntioned above. Can you see it? It has something to do with the fact th at\nthere is only one condition variable. T ry to \ufb01gure out what the probl em\nis, before reading ahead. DO IT! (pause for you to think, or close your eyes...)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 10: Producer/Consumer: Single CV And While",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "10",
          "producer",
          "consumer",
          "single"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 11\nTc1 State T c2 State Tp State\nCount\nComment\nc1 Run Ready Ready 0\nc2 Run Ready Ready 0\nc3 Sleep Ready Ready 0 Nothing to get\nSleep c1 Run Ready 0\nSleep c2 Run Ready 0\nSleep c3 Sleep Ready 0 Nothing to get\nSleep Sleep p1 Run 0\nSleep Sleep p2 Run 0\nSleep Sleep p4 Run 1 Buffer now full\nReady Sleep p5 Run 1 T c1 awoken\nReady Sleep p6 Run 1\nReady Sleep p1 Run 1\nReady Sleep p2 Run 1\nReady Sleep p3 Sleep 1 Must sleep (full)\nc2 Run Sleep Sleep 1 Recheck condition\nc4 Run Sleep Sleep 0 T c1 grabs data\nc5 Run Ready Sleep 0 Oops! W oke T c2\nc6 Run Ready Sleep 0\nc1 Run Ready Sleep 0\nc2 Run Ready Sleep 0\nc3 Sleep Ready Sleep 0 Nothing to get\nSleep c2 Run Sleep 0\nSleep c3 Sleep Sleep 0 Everyone asleep...\nFigure 30.11: Thread T race: Broken Solution (V ersion 2)\nLet\u2019s con\ufb01rm you \ufb01gured it out correctly , or perhaps let\u2019s con\ufb01rm that\nyou are now awake and reading this part of the book. The problem oc-\ncurs when two consumers run \ufb01rst ( Tc1 and Tc2) and both go to sleep (c3).\nThen, the producer runs, puts a value in the buffer , and wakes on e of the\nconsumers (say Tc1). The producer then loops back (releasing and reac-\nquiring the lock along the way) and tries to put more data in the bu ffer;\nbecause the buffer is full, the producer instead waits on the con dition\n(thus sleeping). Now , one consumer is ready to run ( Tc1), and two threads\nare sleeping on a condition ( Tc2 and Tp). W e are about to cause a problem:\nthings are getting exciting!\nThe consumer Tc1 then wakes by returning from wait() (c3), re-checks\nthe condition (c2), and \ufb01nding the buffer full, consumes the val ue (c4).\nThis consumer then, critically , signals on the condition (c5), w aking only\none thread that is sleeping. However , which thread should it wake?\nBecause the consumer has emptied the buffer , it clearly should wake\nthe producer . However , if it wakes the consumer Tc2 (which is de\ufb01nitely\npossible, depending on how the wait queue is managed), we have a p rob-\nlem. Speci\ufb01cally , the consumer Tc2 will wake up and \ufb01nd the buffer\nempty (c2), and go back to sleep (c3). The producer Tp, which has a value\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "This consumer then, critically , signals on the condition (c5), w aking only",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consumer",
          "critically",
          "signals",
          "condition",
          "aking"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 11: Thread T race: Broken Solution (V ersion 2)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "11",
          "thread",
          "race",
          "broken",
          "solution",
          "ersion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 CO N D I T I O N VA R I A B L E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 CO N D I T I O N VA R I A B L E S\n1 cond_t empty, fill;\n2 mutex_t mutex;\n3\n4 void *producer(void *arg) {\n5 int i;\n6 for (i = 0; i < loops; i++) {\n7 Pthread_mutex_lock(&mutex);\n8 while (count == 1)\n9 Pthread_cond_wait(&empty, &mutex);\n10 put(i);\n11 Pthread_cond_signal(&fill);\n12 Pthread_mutex_unlock(&mutex);\n13 }\n14 }\n15\n16 void *consumer(void *arg) {\n17 int i;\n18 for (i = 0; i < loops; i++) {\n19 Pthread_mutex_lock(&mutex);\n20 while (count == 0)\n21 Pthread_cond_wait(&fill, &mutex);\n22 int tmp = get();\n23 Pthread_cond_signal(&empty);\n24 Pthread_mutex_unlock(&mutex);\n25 printf(\"%d\\n\", tmp);\n26 }\n27 }\nFigure 30.12: Producer/Consumer: T wo CVs And While\nto put into the buffer , is left sleeping. The other consumer thr ead, Tc1,\nalso goes back to sleep. All three threads are left sleeping, a clear bug; see\nFigure 30.11 for the brutal step-by-step of this terrible cala mity .\nSignaling is clearly needed, but must be more directed. A consum er\nshould not wake other consumers, only producers, and vice-versa.\nThe Single Buffer Producer/Consumer Solution\nThe solution here is once again a small one: use two condition variables,\ninstead of one, in order to properly signal which type of thread shou ld\nwake up when the state of the system changes. Figure 30.12 shows the\nresulting code.\nIn the code, producer threads wait on the condition empty, and sig-\nnals \ufb01ll . Conversely , consumer threads wait on \ufb01ll and signal empty. By\ndoing so, the second problem above is avoided by design: a consumer\ncan never accidentally wake a consumer , and a producer can neve r acci-\ndentally wake a producer .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "doing so, the second problem above is avoided by design: a consumer",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "second",
          "problem",
          "avoided",
          "design",
          "consumer"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 12: Producer/Consumer: T wo CVs And While",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "12",
          "producer",
          "consumer"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 13\n1 int buffer[MAX];\n2 int fill_ptr = 0;\n3 int use_ptr = 0;\n4 int count = 0;\n5\n6 void put(int value) {\n7 buffer[fill_ptr] = value;\n8 fill_ptr = (fill_ptr + 1) % MAX;\n9 count++;\n10 }\n11\n12 int get() {\n13 int tmp = buffer[use_ptr];\n14 use_ptr = (use_ptr + 1) % MAX;\n15 count--;\n16 return tmp;\n17 }\nFigure 30.13: The Correct Put And Get Routines\n1 cond_t empty, fill;\n2 mutex_t mutex;\n3\n4 void *producer(void *arg) {\n5 int i;\n6 for (i = 0; i < loops; i++) {\n7 Pthread_mutex_lock(&mutex); // p1\n8 while (count == MAX) // p2\n9 Pthread_cond_wait(&empty, &mutex); // p3\n10 put(i); // p4\n11 Pthread_cond_signal(&fill); // p5\n12 Pthread_mutex_unlock(&mutex); // p6\n13 }\n14 }\n15\n16 void *consumer(void *arg) {\n17 int i;\n18 for (i = 0; i < loops; i++) {\n19 Pthread_mutex_lock(&mutex); // c1\n20 while (count == 0) // c2\n21 Pthread_cond_wait(&fill, &mutex); // c3\n22 int tmp = get(); // c4\n23 Pthread_cond_signal(&empty); // c5\n24 Pthread_mutex_unlock(&mutex); // c6\n25 printf(\"%d\\n\", tmp);\n26 }\n27 }\nFigure 30.14: The Correct Producer/Consumer Synchronization\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 13: The Correct Put And Get Routines",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "13",
          "correct",
          "routines"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 14: The Correct Producer/Consumer Synchronization",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "14",
          "correct",
          "producer",
          "consumer",
          "synchronization"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "30",
    "title": "3 Covering Conditions",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "30.3 Covering Conditions\nW e\u2019ll now look at one more example of how condition variables can\nbe used. This code study is drawn from Lampson and Redell\u2019s paper on\nPilot [LR80], the same group who \ufb01rst implemented the Mesa semantics\ndescribed above (the language they used was Mesa, hence the na me).\nThe problem they ran into is best shown via simple example, in th is\ncase in a simple multi-threaded memory allocation library . Fig ure 30.15\nshows a code snippet which demonstrates the issue.\nAs you might see in the code, when a thread calls into the memory\nallocation code, it might have to wait in order for more memory to be-\ncome free. Conversely , when a thread frees memory , it signals th at more\nmemory is free. However , our code above has a problem: which waiting\nthread (there can be more than one) should be woken up?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pilot [LR80], the same group who \ufb01rst implemented the Mesa semantics",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "pilot",
          "group",
          "implemented",
          "mesa",
          "semantics"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "described above (the language they used was Mesa, hence the na me).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "language",
          "used",
          "mesa",
          "hence"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "shows a code snippet which demonstrates the issue.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "shows",
          "code",
          "snippet",
          "demonstrates",
          "issue"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand covering conditions",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "covering",
          "conditions"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 15\n1 // how many bytes of the heap are free?\n2 int bytesLeft = MAX_HEAP_SIZE;\n3\n4 // need lock and condition too\n5 cond_t c;\n6 mutex_t m;\n7\n8 void *\n9 allocate(int size) {\n10 Pthread_mutex_lock(&m);\n11 while (bytesLeft < size)\n12 Pthread_cond_wait(&c, &m);\n13 void *ptr = ...; // get mem from heap\n14 bytesLeft -= size;\n15 Pthread_mutex_unlock(&m);\n16 return ptr;\n17 }\n18\n19 void free(void *ptr, int size) {\n20 Pthread_mutex_lock(&m);\n21 bytesLeft += size;\n22 Pthread_cond_signal(&c); // whom to signal??\n23 Pthread_mutex_unlock(&m);\n24 }\nFigure 30.15: Covering Conditions: An Example\nConsider the following scenario. Assume there are zero bytes fre e;\nthread Ta calls allocate(100), followed by thread Tb which asks for\nless memory by calling allocate(10). Both Ta and Tb thus wait on the\ncondition and go to sleep; there aren\u2019t enough free bytes to satis fy either\nof these requests.\nAt that point, assume a third thread, Tc, calls free(50). Unfortu-\nnately , when it calls signal to wake a waiting thread, it migh t not wake\nthe correct waiting thread, Tb, which is waiting for only 10 bytes to be\nfreed; Ta should remain waiting, as not enough memory is yet free. Thus,\nthe code in the \ufb01gure does not work, as the thread waking other threa ds\ndoes not know which thread (or threads) to wake up.\nThe solution suggested by Lampson and Redell is straightforward : re-\nplace the pthread\ncond signal() call in the code above with a call to\npthread cond broadcast(), which wakes up all waiting threads. By\ndoing so, we guarantee that any threads that should be woken are. T he\ndownside, of course, can be a negative performance impact, as we m ight\nneedlessly wake up many other waiting threads that shouldn\u2019t (y et) be\nawake. Those threads will simply wake up, re-check the conditi on, and\nthen go immediately back to sleep.\nLampson and Redell call such a condition a covering condition , as it\ncovers all the cases where a thread needs to wake up (conservati vely);\nthe cost, as we\u2019ve discussed, is that too many threads might be wok en.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "does not know which thread (or threads) to wake up.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "thread",
          "threads",
          "wake"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 15: Covering Conditions: An Example",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "15",
          "covering",
          "conditions",
          "example"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "30",
    "title": "4 Summary",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "30.4 Summary\nW e have seen the introduction of another important synchronization\nprimitive beyond locks: condition variables. By allowing thread s to sleep\nwhen some program state is not as desired, CVs enable us to neatly solve\na number of important synchronization problems, including the fa mous\n(and still important) producer/consumer problem, as well as cove ring\nconditions. A more dramatic concluding sentence would go here, su ch as\n\u201cHe loved Big Brother \u201d [O49].\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e have seen the introduction of another important synchronization",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "seen",
          "introduction",
          "another",
          "important",
          "synchronization"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "when some program state is not as desired, CVs enable us to neatly solve",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "state",
          "desired",
          "enable",
          "neatly",
          "solve"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "a number of important synchronization problems, including the fa mous",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "number",
          "important",
          "synchronization",
          "problems",
          "including",
          "mous"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "(and still important) producer/consumer problem, as well as cove ring",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "still",
          "important",
          "producer",
          "consumer",
          "problem",
          "well",
          "cove",
          "ring"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 17\nReferences\n[D68] \u201cCooperating sequential processes\u201d by Edsger W . Dijkstra . 1968. A vailable online here:\nhttp://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. Another classic from Di-\njkstra; reading his early works on concurrency will teach you much of what you n eed to know.\n[D72] \u201cInformation Streams Sharing a Finite Buffer \u201d by E.W . Dijkstr a. Information Processing\nLetters 1: 179180, 1972. A vailable: http://www .cs.utexas.e du/users/EWD/ewd03xx/EWD329.PDF\nThe famous paper that introduced the producer/consumer problem.\n[D01] \u201cMy recollections of operating system design\u201d by E.W . Dijkstr a. April, 2001. A vail-\nable: http://www.cs.utexas.edu/users/EWD/ewd13xx/EWD1303.PDF. A fascinating\nread for those of you interested in how the pioneers of our \ufb01eld came up with some v ery basic and\nfundamental concepts, including ideas like \u201cinterrupts\u201d and even \u201ca stac k\u201d!\n[H74] \u201cMonitors: An Operating System Structuring Concept\u201d by C.A.R. H oare. Communica-\ntions of the ACM, 17:10, pages 549\u2013557, October 1974. Hoare did a fair amount of theoretical work\nin concurrency. However , he is still probably most known for his work on Qu icksort, the coolest sorting\nalgorithm in the world, at least according to these authors.\n[L11] \u201cPthread\ncond signal Man Page\u201d by Mysterious author . March, 2011. A vailable online:\nhttp://linux.die.net/man/3/pthread cond signal. The Linux man page shows a nice\nsimple example of why a thread might get a spurious wakeup, due to race con ditions within the sig-\nnal/wakeup code.\n[LR80] \u201cExperience with Processes and Monitors in Mesa\u201d by B.W . Lampso n, D.R. Redell.\nCommunications of the ACM. 23:2, pages 105-117, February 1980. A terri\ufb01c paper about how\nto actually implement signaling and condition variables in a real system, l eading to the term \u201cMesa\u201d\nsemantics for what it mzshortns to be woken up; the older semantics, developed by T ony Hoare [H74],\nthen became known as \u201cHoare\u201d semantics, which is hard to say out loud in class wi th a straight face.\n[O49] \u201c1984\u201d by George Orwell. Secker and W arburg, 1949. A little heavy-handed, but of course\na must read. That said, we kind of gave away the ending by quoting the last sente nce. Sorry! And if\nthe government is reading this, let us just say that we think that the govern ment is \u201cdouble plus good\u201d.\nHear that, our pals at the NSA?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "jkstra; reading his early works on concurrency will teach you much of what you n eed to know.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "jkstra",
          "reading",
          "early",
          "works",
          "concurrency",
          "teach",
          "much",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[D01] \u201cMy recollections of operating system design\u201d by E.W . Dijkstr a. April, 2001. A vail-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "recollections",
          "operating",
          "system",
          "design",
          "dijkstr",
          "april",
          "vail"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "fundamental concepts, including ideas like \u201cinterrupts\u201d and even \u201ca stac k\u201d!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "concepts",
          "including",
          "ideas",
          "like",
          "interrupts",
          "even",
          "stac"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[H74] \u201cMonitors: An Operating System Structuring Concept\u201d by C.A.R. H oare. Communica-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "monitors",
          "operating",
          "system",
          "structuring",
          "concept",
          "oare",
          "communica"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "in concurrency. However , he is still probably most known for his work on Qu icksort, the coolest sorting",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concurrency",
          "however",
          "still",
          "probably",
          "known",
          "work",
          "icksort",
          "coolest"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "algorithm in the world, at least according to these authors.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "algorithm",
          "world",
          "least",
          "according",
          "authors"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "to actually implement signaling and condition variables in a real system, l eading to the term \u201cMesa\u201d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "actually",
          "implement",
          "signaling",
          "condition",
          "variables",
          "real",
          "system",
          "eading"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "semantics for what it mzshortns to be woken up; the older semantics, developed by T ony Hoare [H74],",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "semantics",
          "mzshortns",
          "woken",
          "older",
          "semantics",
          "developed",
          "hoare"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "then became known as \u201cHoare\u201d semantics, which is hard to say out loud in class wi th a straight face.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "became",
          "known",
          "hoare",
          "semantics",
          "hard",
          "loud",
          "class",
          "straight"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand A vailable online here: http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. Another classic from Di-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online here",
          "http",
          "utexas",
          "users",
          "another",
          "classic"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Information Processing\nLetters 1: 179180, 1972. A vailable: http://www .cs.utexas.e du/users/EWD/ewd03xx/EWD329.PDF",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "information processing\nletters 1",
          "vailable",
          "http",
          "utexas",
          "users"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand able: http://www.cs.utexas.edu/users/EWD/ewd13xx/EWD1303.PDF. A fascinating",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "http",
          "utexas",
          "users",
          "fascinating"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 17: 10, pages 549\u2013557, October 1974. Hoare did a fair amount of theoretical work",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "17",
          "pages",
          "october",
          "hoare",
          "fair",
          "amount",
          "theoretical",
          "work"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A vailable online: http://linux.die.net/man/3/pthread cond signal. The Linux man page shows a nice",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online",
          "http",
          "linux",
          "pthread",
          "cond",
          "signal",
          "linux",
          "page",
          "shows"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 23: 2, pages 105-117, February 1980. A terri\ufb01c paper about how",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "23",
          "pages",
          "february",
          "paper"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "Run with one producer and one consumer , and have the producer",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "2. Run with one producer and one consumer , and have the producer\nproduce a few values. Start with a buffer (size 1), and then incr ease\nit. How does the behavior of the code change with larger buffers?\n(or does it?) What would you predict num\nfull to be with different\nbuffer sizes (e.g., -m 10) and different numbers of produced items\n(e.g., -l 100), when you change the consumer sleep string from\ndefault (no sleep) to -C 0,0,0,0,0,0,1?\n3. If possible, run the code on different systems (e.g., a Mac and Linux).\nDo you see different behavior across these systems?\n4. Let\u2019s look at some timings. How long do you think the follow-\ning execution, with one producer , three consumers, a single-ent ry\nshared buffer , and each consumer pausing at point c3 for a sec-\nond, will take? ./main-two-cvs-while -p 1 -c 3 -m 1 -C\n0,0,0,1,0,0,0:0,0,0,1,0,0,0:0,0,0,1,0,0,0 -l 10 -v\n-t\n5. Now change the size of the shared buffer to 3 ( -m 3). Will this make\nany difference in the total time?",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 0: 0,0,0,1,0,0,0:0,0,0,1,0,0,0 -l 10 -v",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "0"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand the behavior of the code change with larger buffers",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "behavior",
          "code",
          "change",
          "larger",
          "buffers"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "6",
    "title": "Now change the location of the sleep to c6 (this models a con-",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "6. Now change the location of the sleep to c6 (this models a con-\nsumer taking something off the queue and then doing something\nwith it), again using a single-entry buffer . What time do you p re-\ndict in this case? ./main-two-cvs-while -p 1 -c 3 -m 1\n-C 0,0,0,0,0,0,1:0,0,0,0,0,0,1:0,0,0,0,0,0,1 -l 10\n-v -t\n7. Finally , change the buffer size to 3 again ( -m 3). What time do you\npredict now?\n8. Now let\u2019s look at main-one-cv-while.c. Can you con\ufb01gure\na sleep string, assuming a single producer , one consumer , and a\nbuffer of size 1, to cause a problem with this code?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: 0,0,0,0,0,0,1:0,0,0,0,0,0,1 -l 10",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand c 0,0,0,0,0,0,1:0,0,0,0,0,0,1:0,0,0,0,0,0,1 -l 10",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO N D I T I O N VA R I A B L E S 19",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO N D I T I O N VA R I A B L E S 19\n9. Now change the number of consumers to two. Can you construct\nsleep strings for the producer and the consumers so as to cause a\nproblem in the code?\n10. Now examine main-two-cvs-if.c. Can you cause a problem to\nhappen in this code? Again consider the case where there is only\none consumer , and then the case where there is more than one.\n11. Finally , examine main-two-cvs-while-extra-unlock.c. What\nproblem arises when you release the lock before doing a put or a\nget? Can you reliably cause such a problem to happen, given the\nsleep strings? What bad thing can happen?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "1 Semaphores: A De\ufb01nition",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "31.1 Semaphores: A De\ufb01nition\nA semaphore is an object with an integer value that we can manipu late\nwith two routines; in the POSIX standard, these routines are sem wait()\nand sem post()1 . Because the initial value of the semaphore deter-\nmines its behavior , before calling any other routine to interact with the\nsemaphore, we must \ufb01rst initialize it to some value, as the code i n Figure\n31.1 does.\n1 Historically ,sem wait() was called P() by Dijkstra and sem post() called V(). These\nshortened forms come from Dutch words; interestingly , which Dutch words they supposedly\nderive from has changed over time. Originally , P() came from \u201cpassering\u201d (to pass) and\nV() from \u201cvrijgave\u201d (release); later , Dijkstra wrote P() was from \u201cprolaag\u201d, a contraction\nof \u201cprobeer \u201d (Dutch for \u201ctry\u201d) and \u201cverlaag\u201d (\u201cdecrease\u201d), and V() from \u201cverhoog\u201d which\nmeans \u201cincrease\u201d. Sometimes, people call them down and up. Use the Du tch versions to\nimpress your friends, or confuse them, or both. See https://news.ycombinator.com/\nitem?id=876) for details.\n1",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand which: \u201cincrease\u201d. Sometimes, people call them down and up. Use the Du tch versions to",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which",
          "increase",
          "sometimes",
          "people",
          "call",
          "versions"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand See https: //news.ycombinator.com/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "see https",
          "news",
          "ycombinator"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand semaphores: a de\ufb01nition",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "semaphores"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand does.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 SE M A P H O R E S\n1 #include <semaphore.h>\n2 sem_t s;\n3 sem_init(&s, 0, 1);\nFigure 31.1: Initializing A Semaphore\nIn the \ufb01gure, we declare a semaphore s and initialize it to the v alue 1\nby passing 1 in as the third argument. The second argument to sem init()\nwill be set to 0 in all of the examples we\u2019ll see; this indicates t hat the\nsemaphore is shared between threads in the same process. See the man\npage for details on other usages of semaphores (namely , how they can\nbe used to synchronize access across different processes), which require a\ndifferent value for that second argument.\nAfter a semaphore is initialized, we can call one of two functions to\ninteract with it, sem\nwait() or sem post(). The behavior of these two\nfunctions is seen in Figure 31.2.\nFor now , we are not concerned with the implementation of these rou-\ntines, which clearly requires some care; with multiple threa ds calling into\nsem wait() and sem post(), there is the obvious need for managing\nthese critical sections. W e will now focus on how to use these primitives;\nlater we may discuss how they are built.\nW e should discuss a few salient aspects of the interfaces here. First, we\ncan see that sem wait() will either return right away (because the value\nof the semaphore was one or higher when we called sem wait()), or it\nwill cause the caller to suspend execution waiting for a subseq uent post.\nOf course, multiple calling threads may call into sem wait(), and thus\nall be queued waiting to be woken.\nSecond, we can see that sem post() does not wait for some particular\ncondition to hold like sem wait() does. Rather , it simply increments the\nvalue of the semaphore and then, if there is a thread waiting to b e woken,\nwakes one of them up.\nThird, the value of the semaphore, when negative, is equal to th e num-\nber of waiting threads [D68b]. Though the value generally isn\u2019t seen by\nusers of the semaphores, this invariant is worth knowing and perh aps\ncan help you remember how a semaphore functions.\n1 int sem_wait(sem_t *s) {\n2 decrement the value of semaphore s by one\n3 wait if value of semaphore s is negative\n4 }\n5\n6 int sem_post(sem_t *s) {\n7 increment the value of semaphore s by one\n8 if there are one or more threads waiting, wake one\n9 }\nFigure 31.2: Semaphore: De\ufb01nitions Of W ait And Post\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "For now , we are not concerned with the implementation of these rou-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "concerned",
          "implementation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "these critical sections. W e will now focus on how to use these primitives;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "sections",
          "focus",
          "primitives"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "users of the semaphores, this invariant is worth knowing and perh aps",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "users",
          "semaphores",
          "invariant",
          "worth",
          "knowing",
          "perh"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: Initializing A Semaphore",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "initializing",
          "semaphore"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 2: Semaphore: De\ufb01nitions Of W ait And Post",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "semaphore",
          "post"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "2 Binary Semaphores (Locks)",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "31.2 Binary Semaphores (Locks)\nW e are now ready to use a semaphore. Our \ufb01rst use will be one with\nwhich we are already familiar: using a semaphore as a lock. See Fi gure",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand binary semaphores (locks)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "binary",
          "semaphores",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "31",
    "title": "3 for a code snippet; therein, you\u2019ll see that we simply surroun d the",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "31.3 for a code snippet; therein, you\u2019ll see that we simply surroun d the\ncritical section of interest with a sem\nwait()/sem post() pair . Criti-\ncal to making this work, though, is the initial value of the semap hore m\n(initialized to X in the \ufb01gure). What should X be?\n... (T ry thinking about it before going on) ...\nLooking back at de\ufb01nition of the sem\nwait() and sem post() rou-\ntines above, we can see that the initial value should be 1.\nT o make this clear , let\u2019s imagine a scenario with two threads. The \ufb01rst\nthread (Thread 0) calls sem wait(); it will \ufb01rst decrement the value of\nthe semaphore, changing it to 0. Then, it will wait only if the va lue is\nnot greater than or equal to 0. Because the value is 0, sem wait() will\nsimply return and the calling thread will continue; Thread 0 i s now free to\nenter the critical section. If no other thread tries to acquire the lock while\nThread 0 is inside the critical section, when it calls sem post(), it will\nsimply restore the value of the semaphore to 1 (and not wake a waiti ng\nthread, because there are none). Figure 31.4 shows a trace of thi s scenario.\nA more interesting case arises when Thread 0 \u201cholds the lock\u201d (i. e.,\nit has called sem wait() but not yet called sem post()), and another\nthread (Thread 1) tries to enter the critical section by calli ng sem wait().\nIn this case, Thread 1 will decrement the value of the semaphore to -1, and\nV alue of Semaphore Thread 0 Thread 1\n1\n1 call sem\nwait()\n0 sem wait() returns\n0 (crit sect)\n0 call sem post()\n1 sem post() returns\nFigure 31.4: Thread T race: Single Thread Using A Semaphore\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "critical section of interest with a sem",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "section",
          "interest"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "enter the critical section. If no other thread tries to acquire the lock while",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "enter",
          "critical",
          "section",
          "thread",
          "tries",
          "acquire",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Thread 0 is inside the critical section, when it calls sem post(), it will",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "inside",
          "critical",
          "section",
          "calls",
          "post"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "thread (Thread 1) tries to enter the critical section by calli ng sem wait().",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "thread",
          "tries",
          "enter",
          "critical",
          "section",
          "calli",
          "wait"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 4: Thread T race: Single Thread Using A Semaphore",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "thread",
          "race",
          "single",
          "thread",
          "using",
          "semaphore"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand for a code snippet; therein, you\u2019ll see that we simply surroun d the",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "snippet",
          "therein",
          "simply",
          "surroun"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "3 Semaphores For Ordering",
    "document_source": "book.pdf",
    "start_line": 43,
    "type": "chapter",
    "content": "31.3 Semaphores For Ordering\nSemaphores are also useful to order events in a concurrent program .\nFor example, a thread may wish to wait for a list to become non-empt y ,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand semaphores for ordering",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "semaphores",
          "ordering"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE M A P H O R E S 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE M A P H O R E S 5\n1 sem_t s;\n2\n3 void *child(void *arg) {\n4 printf(\"child\\n\");\n5 sem_post(&s); // signal here: child is done\n6 return NULL;\n7 }\n8\n9 int main(int argc, char *argv[]) {\n10 sem_init(&s, 0, X); // what should X be?\n11 printf(\"parent: begin\\n\");\n12 pthread_t c;\n13 Pthread_create(&c, NULL, child, NULL);\n14 sem_wait(&s); // wait here for child\n15 printf(\"parent: end\\n\");\n16 return 0;\n17 }\nFigure 31.6: A Parent W aiting For Its Child\nso it can delete an element from it. In this pattern of usage, we of ten \ufb01nd\none thread waiting for something to happen, and another thread making\nthat something happen and then signaling that it has happened, thus wak-\ning the waiting thread. W e are thus using the semaphore as an ordering\nprimitive (similar to our use of condition variables earlier).\nA simple example is as follows. Imagine a thread creates another\nthread and then wants to wait for it to complete its execution (Fi gure\n31.6). When this program runs, we would like to see the following:\nparent: begin\nchild\nparent: end\nThe question, then, is how to use a semaphore to achieve this effe ct; as\nit turns out, the answer is relatively easy to understand. As y ou can see in\nthe code, the parent simply calls sem\nwait() and the child sem post()\nto wait for the condition of the child \ufb01nishing its execution to bec ome\ntrue. However , this raises the question: what should the initia l value of\nthis semaphore be?\n(Again, think about it here, instead of reading ahead)\nThe answer , of course, is that the value of the semaphore should be s et\nto is 0. There are two cases to consider . First, let us assume th at the parent\ncreates the child but the child has not run yet (i.e., it is sitt ing in a ready\nqueue but not running). In this case (Figure 31.7, page 6), the parent will\ncall sem\nwait() before the child has called sem post(); we\u2019d like the\nparent to wait for the child to run. The only way this will happen is if the\nvalue of the semaphore is not greater than 0; hence, 0 is the initi al value.\nThe parent runs, decrements the semaphore (to -1), then waits (sleeping).\nWhen the child \ufb01nally runs, it will call sem post(), increment the value\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Pthread_create(&c, NULL, child, NULL);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "null",
          "child",
          "null"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A simple example is as follows. Imagine a thread creates another",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "example",
          "follows",
          "imagine",
          "thread",
          "creates",
          "another"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "it turns out, the answer is relatively easy to understand. As y ou can see in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "turns",
          "answer",
          "relatively",
          "easy",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "creates the child but the child has not run yet (i.e., it is sitt ing in a ready",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creates",
          "child",
          "child",
          "sitt",
          "ready"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 6: A Parent W aiting For Its Child",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "parent",
          "aiting",
          "child"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand this raises the question: what should the initia l value of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this raises the question",
          "initia",
          "value"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand ). when this program runs, we would like to see the following:",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "runs",
          "would",
          "like",
          "following"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "4 The Producer/Consumer (Bounded Buffer) Problem",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "31.4 The Producer/Consumer (Bounded Buffer) Problem\nThe next problem we will confront in this chapter is known as the pro-\nducer/consumer problem, or sometimes as the bounded buffer problem\n[D72]. This problem is described in detail in the previous chap ter on con-\ndition variables; see there for details.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The next problem we will confront in this chapter is known as the pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "next",
          "problem",
          "confront",
          "chapter",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[D72]. This problem is described in detail in the previous chap ter on con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "described",
          "detail",
          "previous",
          "chap"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the producer/consumer (bounded buffer) problem",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "producer",
          "consumer",
          "bounded",
          "buffer",
          "problem"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE M A P H O R E S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE M A P H O R E S 7\nAS I D E : S E T T I N G TH E VA L U E OF A S E M A P H O R E\nW e\u2019ve now seen two examples of initializing a semaphore. In the \ufb01r st\ncase, we set the value to 1 to use the semaphore as a lock; in the se cond,\nto 0, to use the semaphore for ordering. So what\u2019s the general rule f or\nsemaphore initialization?\nOne simple way to think about it, thanks to Perry Kivolowitz, is t o con-\nsider the number of resources you are willing to give away immedi ately\nafter initialization. With the lock, it was 1, because you are wi lling to\nhave the lock locked (given away) immediately after initializ ation. With\nthe ordering case, it was 0, because there is nothing to give awa y at the\nstart; only when the child thread is done is the resource created , at which\npoint, the value is incremented to 1. T ry this line of thinking on future\nsemaphore problems, and see if it helps.\nFirst Attempt\nOur \ufb01rst attempt at solving the problem introduces two semaphore s, empty\nand full, which the threads will use to indicate when a buffer entry ha s\nbeen emptied or \ufb01lled, respectively . The code for the put and get routines\nis in Figure 31.9, and our attempt at solving the producer and cons umer\nproblem is in Figure 31.10 (page 8).\nIn this example, the producer \ufb01rst waits for a buffer to become em pty\nin order to put data into it, and the consumer similarly waits for a buffer\nto become \ufb01lled before using it. Let us \ufb01rst imagine that MAX=1 (there is\nonly one buffer in the array), and see if this works.\nImagine again there are two threads, a producer and a consumer . Let\nus examine a speci\ufb01c scenario on a single CPU. Assume the consum er\ngets to run \ufb01rst. Thus, the consumer will hit Line C1 in Figure 3 1.10,\ncalling sem\nwait(&full). Because full was initialized to the value 0,\n1 int buffer[MAX];\n2 int fill = 0;\n3 int use = 0;\n4\n5 void put(int value) {\n6 buffer[fill] = value; // Line F1\n7 fill = (fill + 1) % MAX; // Line F2\n8 }\n9\n10 int get() {\n11 int tmp = buffer[use]; // Line G1\n12 use = (use + 1) % MAX; // Line G2\n13 return tmp;\n14 }\nFigure 31.9: The Put And Get Routines\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "start; only when the child thread is done is the resource created , at which",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "child",
          "thread",
          "done",
          "resource",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 9: The Put And Get Routines",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "9",
          "routines"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 SE M A P H O R E S\n1 sem_t empty;\n2 sem_t full;\n3\n4 void *producer(void *arg) {\n5 int i;\n6 for (i = 0; i < loops; i++) {\n7 sem_wait(&empty); // Line P1\n8 put(i); // Line P2\n9 sem_post(&full); // Line P3\n10 }\n11 }\n12\n13 void *consumer(void *arg) {\n14 int i, tmp = 0;\n15 while (tmp != -1) {\n16 sem_wait(&full); // Line C1\n17 tmp = get(); // Line C2\n18 sem_post(&empty); // Line C3\n19 printf(\"%d\\n\", tmp);\n20 }\n21 }\n22\n23 int main(int argc, char *argv[]) {\n24 // ...\n25 sem_init(&empty, 0, MAX); // MAX are empty\n26 sem_init(&full, 0, 0); // 0 are full\n27 // ...\n28 }\nFigure 31.10: Adding The Full And Empty Conditions\nthe call will decrement full (to -1), block the consumer , and wait for\nanother thread to call sem\npost() on full, as desired.\nAssume the producer then runs. It will hit Line P1, thus callin g the\nsem wait(&empty) routine. Unlike the consumer , the producer will\ncontinue through this line, because empty was initialized to the value\nMAX (in this case, 1). Thus, empty will be decremented to 0 and the pro-\nducer will put a data value into the \ufb01rst entry of buffer (Line P 2). The pro-\nducer will then continue on to P3 and call sem post(&full), changing\nthe value of the full semaphore from -1 to 0 and waking the consumer\n(e.g., move it from blocked to ready).\nIn this case, one of two things could happen. If the producer contin ues\nto run, it will loop around and hit Line P1 again. This time, howeve r , it\nwould block, as the empty semaphore\u2019s value is 0. If the producer instead\nwas interrupted and the consumer began to run, it would return f rom\nsem wait(&full) (Line C1), \ufb01nd that the buffer was full, and consume\nit. In either case, we achieve the desired behavior .\nY ou can try this same example with more threads (e.g., multiple pro-\nducers, and multiple consumers). It should still work.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 10: Adding The Full And Empty Conditions",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "10",
          "adding",
          "full",
          "empty",
          "conditions"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE M A P H O R E S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE M A P H O R E S 9\n1 void *producer(void *arg) {\n2 int i;\n3 for (i = 0; i < loops; i++) {\n4 sem_wait(&mutex); // Line P0 (NEW LINE)\n5 sem_wait(&empty); // Line P1\n6 put(i); // Line P2\n7 sem_post(&full); // Line P3\n8 sem_post(&mutex); // Line P4 (NEW LINE)\n9 }\n10 }\n11\n12 void *consumer(void *arg) {\n13 int i;\n14 for (i = 0; i < loops; i++) {\n15 sem_wait(&mutex); // Line C0 (NEW LINE)\n16 sem_wait(&full); // Line C1\n17 int tmp = get(); // Line C2\n18 sem_post(&empty); // Line C3\n19 sem_post(&mutex); // Line C4 (NEW LINE)\n20 printf(\"%d\\n\", tmp);\n21 }\n22 }\nFigure 31.11: Adding Mutual Exclusion (Incorrectly)\nLet us now imagine that MAX is greater than 1 (say MAX=10). For this\nexample, let us assume that there are multiple producers and m ultiple\nconsumers. W e now have a problem: a race condition. Do you see where\nit occurs? (take some time and look for it) If you can\u2019t see it, here\u2019s a h int:\nlook more closely at the put() and get() code.\nOK, let\u2019s understand the issue. Imagine two producers (Pa and P b)\nboth calling into put() at roughly the same time. Assume producer Pa\ngets to run \ufb01rst, and just starts to \ufb01ll the \ufb01rst buffer entry ( fill=0 at\nLine F1). Before Pa gets a chance to increment the fill counter to 1, it\nis interrupted. Producer Pb starts to run, and at Line F1 it als o puts its\ndata into the 0th element of buffer , which means that the old dat a there\nis overwritten! This action is a no-no; we don\u2019t want any data from the\nproducer to be lost.\nA Solution: Adding Mutual Exclusion\nAs you can see, what we\u2019ve forgotten here is mutual exclusion . The \ufb01ll-\ning of a buffer and incrementing of the index into the buffer is a critical\nsection, and thus must be guarded carefully . So let\u2019s use our frie nd the\nbinary semaphore and add some locks. Figure 31.11 shows our attemp t.\nNow we\u2019ve added some locks around the entire put()/get() parts of\nthe code, as indicated by the NEW LINE comments. That seems like the\nright idea, but it also doesn\u2019t work. Why? Deadlock. Why does deadl ock\noccur? T ake a moment to consider it; try to \ufb01nd a case where deadloc k\narises. What sequence of steps must happen for the program to dea dlock?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "OK, let\u2019s understand the issue. Imagine two producers (Pa and P b)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "issue",
          "imagine",
          "producers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ing of a buffer and incrementing of the index into the buffer is a critical",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "buffer",
          "incrementing",
          "index",
          "buffer",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand which: that the old dat a there",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 11: Adding Mutual Exclusion (Incorrectly)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "11",
          "adding",
          "mutual",
          "exclusion",
          "incorrectly"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand s a h int: look more closely at the put() and get() code.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s a h int",
          "look",
          "closely",
          "code"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand A Solution: Adding Mutual Exclusion",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a solution",
          "adding",
          "mutual",
          "exclusion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 SE M A P H O R E S\n1 void *producer(void *arg) {\n2 int i;\n3 for (i = 0; i < loops; i++) {\n4 sem_wait(&empty); // Line P1\n5 sem_wait(&mutex); // Line P1.5 (MUTEX HERE)\n6 put(i); // Line P2\n7 sem_post(&mutex); // Line P2.5 (AND HERE)\n8 sem_post(&full); // Line P3\n9 }\n10 }\n11\n12 void *consumer(void *arg) {\n13 int i;\n14 for (i = 0; i < loops; i++) {\n15 sem_wait(&full); // Line C1\n16 sem_wait(&mutex); // Line C1.5 (MUTEX HERE)\n17 int tmp = get(); // Line C2\n18 sem_post(&mutex); // Line C2.5 (AND HERE)\n19 sem_post(&empty); // Line C3\n20 printf(\"%d\\n\", tmp);\n21 }\n22 }\nFigure 31.12: Adding Mutual Exclusion (Correctly)\nA voiding Deadlock\nOK, now that you \ufb01gured it out, here is the answer . Imagine two thr eads,\none producer and one consumer . The consumer gets to run \ufb01rst. It\nacquires the mutex (Line C0), and then calls sem\nwait() on the full\nsemaphore (Line C1); because there is no data yet, this call ca uses the\nconsumer to block and thus yield the CPU; importantly , though, th e con-\nsumer still holds the lock.\nA producer then runs. It has data to produce and if it were able to run,\nit would be able to wake the consumer thread and all would be good. Un -\nfortunately , the \ufb01rst thing it does is call sem wait() on the binary mutex\nsemaphore (Line P0). The lock is already held. Hence, the produc er is\nnow stuck waiting too.\nThere is a simple cycle here. The consumer holds the mutex and is\nwaiting for the someone to signal full. The producer could signal full but\nis waiting for the mutex. Thus, the producer and consumer are each stuck\nwaiting for each other: a classic deadlock.\nAt Last, A W orking Solution\nT o solve this problem, we simply must reduce the scope of the lock. F ig-\nure 31.12 (page 10) shows the correct solution. As you can see, we si mply\nmove the mutex acquire and release to be just around the critica l section;\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "consumer to block and thus yield the CPU; importantly , though, th e con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consumer",
          "block",
          "thus",
          "yield",
          "importantly",
          "though"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A producer then runs. It has data to produce and if it were able to run,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "producer",
          "runs",
          "data",
          "produce",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "it would be able to wake the consumer thread and all would be good. Un -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "would",
          "able",
          "wake",
          "consumer",
          "thread",
          "would",
          "good"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o solve this problem, we simply must reduce the scope of the lock. F ig-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "problem",
          "simply",
          "must",
          "reduce",
          "scope",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 12: Adding Mutual Exclusion (Correctly)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "12",
          "adding",
          "mutual",
          "exclusion",
          "correctly"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "5 Reader-W riter Locks",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "31.5 Reader-W riter Locks\nAnother classic problem stems from the desire for a more \ufb02exible loc k-\ning primitive that admits that different data structure acc esses might re-\nquire different kinds of locking. For example, imagine a number of con-\ncurrent list operations, including inserts and simple lookups. While in-\nserts change the state of the list (and thus a traditional criti cal section\nmakes sense), lookups simply read the data structure; as long as we can\nguarantee that no insert is on-going, we can allow many lookups to p ro-\nceed concurrently . The special type of lock we will now develop to s up-\nport this type of operation is known as a reader-writer lock [CHP71]. The\ncode for such a lock is available in Figure 31.13 (page 12).\nThe code is pretty simple. If some thread wants to update the dat a\nstructure in question, it should call the new pair of synchroniza tion op-\nerations: rwlock acquire writelock(), to acquire a write lock, and\nrwlock release writelock(), to release it. Internally , these simply\nuse the writelock semaphore to ensure that only a single writer can ac-\nquire the lock and thus enter the critical section to update the data struc-\nture in question.\nMore interesting is the pair of routines to acquire and release r ead\nlocks. When acquiring a read lock, the reader \ufb01rst acquires lock and\nthen increments the readers variable to track how many readers are\ncurrently inside the data structure. The important step then taken within\nrwlock acquire readlock() occurs when the \ufb01rst reader acquires\nthe lock; in that case, the reader also acquires the write lock b y calling\nsem wait() on the writelock semaphore, and then releasing the lock\nby calling sem post().\nThus, once a reader has acquired a read lock, more readers will be\nallowed to acquire the read lock too; however , any thread that wish es to\nacquire the write lock will have to wait until all readers are \ufb01nished; the\nlast one to exit the critical section calls sem post() on \u201cwritelock\u201d and\nthus enables a waiting writer to acquire the lock.\nThis approach works (as desired), but does have some negatives, e spe-\ncially when it comes to fairness. In particular , it would be rel atively easy\nfor readers to starve writers. More sophisticated solutions to th is prob-\nlem exist; perhaps you can think of a better implementation? Hin t: think\nabout what you would need to do to prevent more readers from enterin g\nthe lock once a writer is waiting.\n2 Indeed, it may have been more natural to place the mutex acquire/release inside the\nput() and get() functions for the purposes of modularity .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ceed concurrently . The special type of lock we will now develop to s up-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ceed",
          "concurrently",
          "special",
          "type",
          "lock",
          "develop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "port this type of operation is known as a reader-writer lock [CHP71]. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "port",
          "type",
          "operation",
          "known",
          "reader",
          "writer",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "quire the lock and thus enter the critical section to update the data struc-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quire",
          "lock",
          "thus",
          "enter",
          "critical",
          "section",
          "update",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "then increments the readers variable to track how many readers are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "increments",
          "readers",
          "variable",
          "track",
          "many",
          "readers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "currently inside the data structure. The important step then taken within",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "currently",
          "inside",
          "data",
          "structure",
          "important",
          "step",
          "taken",
          "within"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "last one to exit the critical section calls sem post() on \u201cwritelock\u201d and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "exit",
          "critical",
          "section",
          "calls",
          "post",
          "writelock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "This approach works (as desired), but does have some negatives, e spe-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "works",
          "desired",
          "negatives"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "lem exist; perhaps you can think of a better implementation? Hin t: think",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "exist",
          "perhaps",
          "think",
          "better",
          "implementation",
          "think"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand erations: rwlock acquire writelock(), to acquire a write lock, and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "erations",
          "rwlock",
          "acquire",
          "writelock",
          "acquire",
          "write",
          "lock"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand reader-w riter locks",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reader",
          "riter",
          "locks"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 SE M A P H O R E S\n1 typedef struct _rwlock_t {\n2 sem_t lock; // binary semaphore (basic lock)\n3 sem_t writelock; // allow ONE writer/MANY readers\n4 int readers; // #readers in critical section\n5 } rwlock_t;\n6\n7 void rwlock_init(rwlock_t *rw) {\n8 rw->readers = 0;\n9 sem_init(&rw->lock, 0, 1);\n10 sem_init(&rw->writelock, 0, 1);\n11 }\n12\n13 void rwlock_acquire_readlock(rwlock_t *rw) {\n14 sem_wait(&rw->lock);\n15 rw->readers++;\n16 if (rw->readers == 1) // first reader gets writelock\n17 sem_wait(&rw->writelock);\n18 sem_post(&rw->lock);\n19 }\n20\n21 void rwlock_release_readlock(rwlock_t *rw) {\n22 sem_wait(&rw->lock);\n23 rw->readers--;\n24 if (rw->readers == 0) // last reader lets it go\n25 sem_post(&rw->writelock);\n26 sem_post(&rw->lock);\n27 }\n28\n29 void rwlock_acquire_writelock(rwlock_t *rw) {\n30 sem_wait(&rw->writelock);\n31 }\n32\n33 void rwlock_release_writelock(rwlock_t *rw) {\n34 sem_post(&rw->writelock);\n35 }\nFigure 31.13: A Simple Reader-W riter Lock\nFinally , it should be noted that reader-writer locks should be us ed\nwith some caution. They often add more overhead (especially with m ore\nsophisticated implementations), and thus do not end up speedin g up\nperformance as compared to just using simple and fast locking pr imi-\ntives [CB08]. Either way , they showcase once again how we can use\nsemaphores in an interesting and useful way .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "int readers; // #readers in critical section",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "readers",
          "readers",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "sophisticated implementations), and thus do not end up speedin g up",
        "type": "explicit_objective",
        "difficulty": "advanced",
        "keywords": [
          "sophisticated",
          "implementations",
          "thus",
          "speedin"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "performance as compared to just using simple and fast locking pr imi-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "performance",
          "compared",
          "using",
          "simple",
          "fast",
          "locking"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 13: A Simple Reader-W riter Lock",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "13",
          "simple",
          "reader",
          "riter",
          "lock"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "6 The Dining Philosophers",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "31.6 The Dining Philosophers\nOne of the most famous concurrency problems posed, and solved, by\nDijkstra, is known as the dining philosopher\u2019s problem [D71]. The prob-\nlem is famous because it is fun and somewhat intellectually int eresting;\nhowever , its practical utility is low . However , its fame forces i ts inclu-\nsion here; indeed, you might be asked about it on some interview , an d\nyou\u2019d really hate your OS professor if you miss that question and don\u2019t\nget the job. Conversely , if you get the job, please feel free to sen d your OS\nprofessor a nice note, or some stock options.\nThe basic setup for the problem is this (as shown in Figure 31.14) : as-\nsume there are \ufb01ve \u201cphilosophers\u201d sitting around a table. Betwe en each\npair of philosophers is a single fork (and thus, \ufb01ve total). The phi loso-\nphers each have times where they think, and don\u2019t need any forks, and\ntimes where they eat. In order to eat, a philosopher needs two fork s, both\nthe one on their left and the one on their right. The contention for the se\nforks, and the synchronization problems that ensue, are what mak es this\na problem we study in concurrent programming.\nHere is the basic loop of each philosopher , assuming each has a uniq ue\nthread identi\ufb01er p from 0 to 4 (inclusive):\nwhile (1) {\nthink();\nget_forks(p);\neat();\nput_forks(p);\n}\nThe key challenge, then, is to write the routines get\nforks() and\nput forks() such that there is no deadlock, no philosopher starves and\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One of the most famous concurrency problems posed, and solved, by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "famous",
          "concurrency",
          "problems",
          "posed",
          "solved"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Dijkstra, is known as the dining philosopher\u2019s problem [D71]. The prob-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "dijkstra",
          "known",
          "dining",
          "philosopher",
          "problem",
          "prob"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the dining philosophers",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "dining",
          "philosophers"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 SE M A P H O R E S\nP0\nP1\nP2\nP3\nP4\nf0\nf1\nf2\nf3\nf4\nFigure 31.14: The Dining Philosophers\nnever gets to eat, and concurrency is high (i.e., as many philos ophers can\neat at the same time as possible).\nFollowing Downey\u2019s solutions [D08], we\u2019ll use a few helper functions\nto get us towards a solution. They are:\nint left(int p) { return p; }\nint right(int p) { return (p + 1) % 5; }\nWhen philosopher p wishes to refer to the fork on their left, they sim-\nply call left(p). Similarly , the fork on the right of a philosopher p is\nreferred to by calling right(p); the modulo operator therein handles\nthe one case where the last philosopher ( p=4) tries to grab the fork on\ntheir right, which is fork 0.\nW e\u2019ll also need some semaphores to solve this problem. Let us assum e\nwe have \ufb01ve, one for each fork: sem\nt forks[5].\nBroken Solution\nW e attempt our \ufb01rst solution to the problem. Assume we initialize\neach semaphore (in the forks array) to a value of 1. Assume also that\neach philosopher knows its own number ( p). W e can thus write the\nget forks() and put forks() routine (Figure 31.15, page 15).\nThe intuition behind this (broken) solution is as follows. T o acqui re\nthe forks, we simply grab a \u201clock\u201d on each one: \ufb01rst the one on the left ,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e\u2019ll also need some semaphores to solve this problem. Let us assum e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "need",
          "semaphores",
          "solve",
          "problem",
          "assum"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "each philosopher knows its own number ( p). W e can thus write the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "philosopher",
          "knows",
          "number",
          "thus",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 14: The Dining Philosophers",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "14",
          "dining",
          "philosophers"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand They are: int left(int p) { return p; }",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "they are",
          "left",
          "return"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand on each one: \ufb01rst the one on the left ,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "on each one",
          "left"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SE M A P H O R E S 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SE M A P H O R E S 15\n1 void get_forks(int p) {\n2 sem_wait(&forks[left(p)]);\n3 sem_wait(&forks[right(p)]);\n4 }\n5\n6 void put_forks(int p) {\n7 sem_post(&forks[left(p)]);\n8 sem_post(&forks[right(p)]);\n9 }\nFigure 31.15: The get\nforks() And put forks() Routines\n1 void get_forks(int p) {\n2 if (p == 4) {\n3 sem_wait(&forks[right(p)]);\n4 sem_wait(&forks[left(p)]);\n5 } else {\n6 sem_wait(&forks[left(p)]);\n7 sem_wait(&forks[right(p)]);\n8 }\n9 }\nFigure 31.16: Breaking The Dependency In get forks()\nand then the one on the right. When we are done eating, we release t hem.\nSimple, no? Unfortunately , in this case, simple means broken. Ca n you\nsee the problem that arises? Think about it.\nThe problem is deadlock. If each philosopher happens to grab the fork\non their left before any philosopher can grab the fork on their right , each\nwill be stuck holding one fork and waiting for another , forever . Spec i\ufb01-\ncally , philosopher 0 grabs fork 0, philosopher 1 grabs fork 1, philos opher\n2 grabs fork 2, philosopher 3 grabs fork 3, and philosopher 4 grabs for k 4;\nall the forks are acquired, and all the philosophers are stuck wa iting for\na fork that another philosopher possesses. W e\u2019ll study deadlock in m ore\ndetail soon; for now , it is safe to say that this is not a working soluti on.\nA Solution: Breaking The Dependency\nThe simplest way to attack this problem is to change how forks are ac-\nquired by at least one of the philosophers; indeed, this is how Dijk stra\nhimself solved the problem. Speci\ufb01cally , let\u2019s assume that phil osopher\n4 (the highest numbered one) gets the forks in a different order than the\nothers (Figure 31.16); the put\nforks() code remains the same.\nBecause the last philosopher tries to grab right before left, th ere is no\nsituation where each philosopher grabs one fork and is stuck waiti ng for\nanother; the cycle of waiting is broken. Think through the rami\ufb01c ations\nof this solution, and convince yourself that it works.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "himself solved the problem. Speci\ufb01cally , let\u2019s assume that phil osopher",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solved",
          "problem",
          "assume",
          "phil",
          "osopher"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 16: Breaking The Dependency In get forks()",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "16",
          "breaking",
          "dependency",
          "forks"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A Solution: Breaking The Dependency",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a solution",
          "breaking",
          "dependency"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "7 Thread Throttling",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "31.7 Thread Throttling\nOne other simple use case for semaphores arises on occasion, and thu s\nwe present it here. The speci\ufb01c problem is this: how can a program mer\nprevent \u201ctoo many\u201d threads from doing something at once and bogging\nthe system down? Answer: decide upon a threshold for \u201ctoo many\u201d,\nand then use a semaphore to limit the number of threads concurren tly\nexecuting the piece of code in question. W e call this approach throttling\n[T99], and consider it a form of admission control .\nLet\u2019s consider a more speci\ufb01c example. Imagine that you create hu n-\ndreds of threads to work on some problem in parallel. However , in a\ncertain part of the code, each thread acquires a large amount of me m-\nory to perform part of the computation; let\u2019s call this part of the code the\nmemory-intensive region . If all of the threads enter the memory-intensive\nregion at the same time, the sum of all the memory allocation reques ts\nwill exceed the amount of physical memory on the machine. As a resu lt,\nthe machine will start thrashing (i.e., swapping pages to an d from the\ndisk), and the entire computation will slow to a crawl.\nA simple semaphore can solve this problem. By initializing the v alue\nof the semaphore to the maximum number of threads you wish to enter\nthe memory-intensive region at once, and then putting a sem\nwait()\nand sem post() around the region, a semaphore can naturally throttle\nthe number of threads that are ever concurrently in the dangerou s region\nof the code.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "executing the piece of code in question. W e call this approach throttling",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "executing",
          "piece",
          "code",
          "question",
          "call",
          "approach",
          "throttling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Let\u2019s consider a more speci\ufb01c example. Imagine that you create hu n-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consider",
          "example",
          "imagine",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "A simple semaphore can solve this problem. By initializing the v alue",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "semaphore",
          "solve",
          "problem",
          "initializing",
          "alue"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Answer: decide upon a threshold for \u201ctoo many\u201d,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "answer",
          "decide",
          "upon",
          "threshold",
          "many"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand thread throttling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "thread",
          "throttling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "31",
    "title": "8 How T o Implement Semaphores",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "31.8 How T o Implement Semaphores\nFinally , let\u2019s use our low-level synchronization primitives, loc ks and\ncondition variables, to build our own version of semaphores called . ..\n(drum roll here) ... Zemaphores. This task is fairly straightforward, as\nyou can see in Figure 31.17 (page 17).\nIn the code above, we use just one lock and one condition variable,\nplus a state variable to track the value of the semaphore. Study t he code\nfor yourself until you really understand it. Do it!\nOne subtle difference between our Zemaphore and pure semaphore s\nas de\ufb01ned by Dijkstra is that we don\u2019t maintain the invariant th at the\nvalue of the semaphore, when negative, re\ufb02ects the number of wai ting\nthreads; indeed, the value will never be lower than zero. This b ehavior is\neasier to implement and matches the current Linux implement ation.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "How T o Implement Semaphores",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "semaphores"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "plus a state variable to track the value of the semaphore. Study t he code",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "plus",
          "state",
          "variable",
          "track",
          "value",
          "semaphore",
          "study",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "for yourself until you really understand it. Do it!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "really",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "easier to implement and matches the current Linux implement ation.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "easier",
          "implement",
          "matches",
          "current",
          "linux",
          "implement",
          "ation"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "31",
    "title": "9 Summary",
    "document_source": "book.pdf",
    "start_line": 35,
    "type": "chapter",
    "content": "31.9 Summary\nSemaphores are a powerful and \ufb02exible primitive for writing concu r-\nrent programs. Some programmers use them exclusively , shunning locks\nand condition variables, due to their simplicity and utility .\nIn this chapter , we have presented just a few classic problems and solu-\ntions. If you are interested in \ufb01nding out more, there are many othe r ma-\nterials you can reference. One great (and free reference) is A llen Downey\u2019s\nbook on concurrency and programming with semaphores [D08]. This\nbook has lots of puzzles you can work on to improve your understand-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "book has lots of puzzles you can work on to improve your understand-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "book",
          "lots",
          "puzzles",
          "work",
          "improve",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "18 SE M A P H O R E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "18 SE M A P H O R E S\nTI P : B E CA R E F U L WI T H GE N E R A L I Z AT I O N\nThe abstract technique of generalization can thus be quite use ful in sys-\ntems design, where one good idea can be made slightly broader and t hus\nsolve a larger class of problems. However , be careful when genera lizing;\nas Lampson warns us \u201cDon\u2019t generalize; generalizations are gene rally\nwrong\u201d [L83].\nOne could view semaphores as a generalization of locks and condition\nvariables; however , is such a generalization needed? And, giv en the dif-\n\ufb01culty of realizing a condition variable on top of a semaphore, perha ps\nthis generalization is not as general as you might think.\ning of both semaphores in speci\ufb01c and concurrency in general. Bec oming\na real concurrency expert takes years of effort; going beyond what you\nlearn in this class is undoubtedly the key to mastering such a t opic.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The abstract technique of generalization can thus be quite use ful in sys-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "abstract",
          "technique",
          "generalization",
          "thus",
          "quite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tems design, where one good idea can be made slightly broader and t hus",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tems",
          "design",
          "good",
          "idea",
          "made",
          "slightly",
          "broader"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "solve a larger class of problems. However , be careful when genera lizing;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "larger",
          "class",
          "problems",
          "however",
          "careful",
          "genera",
          "lizing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "learn in this class is undoubtedly the key to mastering such a t opic.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "class",
          "undoubtedly",
          "mastering",
          "opic"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2004",
    "title": "An interesting read on how dif\ufb01cult implementing CVs on top of semaphores r eally is, and the",
    "document_source": "book.pdf",
    "start_line": 3,
    "type": "chapter",
    "content": "2004. An interesting read on how dif\ufb01cult implementing CVs on top of semaphores r eally is, and the\nmistakes the author and co-workers made along the way. Particularly relevant because the group had\ndone a ton of concurrent programming; Birrell, for example, is known for (amon g other things) writing\nvarious thread-programming guides.\n[CB08] \u201cReal-world Concurrency\u201d by Bryan Cantrill, Jeff Bonwick. ACM Qu eue. V olume 6,\nNo. 5. September 2008. A nice article by some kernel hackers from a company formerly known as Sun\non the real problems faced in concurrent code.\n[CHP71] \u201cConcurrent Control with Readers and W riters\u201d by P .J. Courto is, F . Heymans, D.L.\nParnas. Communications of the ACM, 14:10, October 1971. The introduction of the reader-writer\nproblem, and a simple solution. Later work introduced more complex solutions , skipped here because,\nwell, they are pretty complex.\n[D59] \u201cA Note on T wo Problems in Connexion with Graphs\u201d by E. W . Dijk stra. Numerische\nMathematik 1, 269271, 1959. A vailable: http://www-m3.ma.tum.de/twiki/pub/MN0506/\nWebHome/dijkstra.pdf. Can you believe people worked on algorithms in 1959? We can\u2019t. Even\nbefore computers were any fun to use, these people had a sense that they woul d transform the world...\n[D68a] \u201cGo-to Statement Considered Harmful\u201d by E.W . Dijkstra. CA CM, volume 11(3), March\n1968. http://www.cs.utexas.edu/users/EWD/ewd02xx/EWD215.PDF. Sometimes thought\nof as the beginning of the \ufb01eld of software engineering.\n[D68b] \u201cThe Structure of the THE Multiprogramming System\u201d by E.W . Dij kstra. CACM, vol-\nume 11(5), 1968. One of the earliest papers to point out that systems work in computer science is an\nengaging intellectual endeavor . Also argues strongly for modularity in the form of layered systems.\n[D72] \u201cInformation Streams Sharing a Finite Buffer \u201d by E.W . Dijkstr a. Information Processing\nLetters 1, 1972. http://www.cs.utexas.edu/users/EWD/ewd03xx/EWD329.PDF. Did\nDijkstra invent everything? No, but maybe close. He certainly was the \ufb01r st to clearly write down\nwhat the problems were in concurrent code. However , practitioners in OS design knew of many of the\nproblems described by Dijkstra, so perhaps giving him too much credi t would be a misrepresentation.\n[D08] \u201cThe Little Book of Semaphores\u201d by A.B. Downey . A vailable at the following site:\nhttp://greenteapress.com/semaphores/. A nice (and free!) book about semaphores. Lots\nof fun problems to solve, if you like that sort of thing.\n[D71] \u201cHierarchical ordering of sequential processes\u201d by E.W . Dijk stra. A vailable online here:\nhttp://www.cs.utexas.edu/users/EWD/ewd03xx/EWD310.PDF. Presents numerous con-\ncurrency problems, including Dining Philosophers. The wikiped ia page about this problem is also useful.\n[GR92] \u201cT ransaction Processing: Concepts and T echniques\u201d by Jim Gray , Andr eas Reuter .\nMorgan Kaufmann, September 1992. The exact quote that we \ufb01nd particularly humorous is found\non page 485, at the top of Section 8.8: \u201cThe \ufb01rst multiprocessors, circa 196 0, had test and set instruc-\ntions ... presumably the OS implementors worked out the appropriate algorithms , although Dijkstra is\ngenerally credited with inventing semaphores many years later .\u201d Oh, sn ap!\n[H87] \u201cAspects of Cache Memory and Instruction Buffer Performance\u201d by Mark D . Hill. Ph.D.\nDissertation, U.C. Berkeley , 1987. Hill\u2019s dissertation work, for those obsessed with caching in early\nsystems. A great example of a quantitative dissertation.\n[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems\nReview , 15:5, October 1983. Lampson, a famous systems researcher , loved using hints in the design\nof computer systems. A hint is something that is often correct but can be wron g; in this use, a signal()\nis telling a waiting thread that it changed the condition that the waiter was waiting on, but not to trust\nthat the condition will be in the desired state when the waiting thread wakes up. In this paper about\nhints for designing systems, one of Lampson\u2019s general hints is that you shou ld use hints. It is not as\nconfusing as it sounds.\n[T99] \u201cRe: NT kernel guy playing with Linux\u201d by Linus T orvalds. June 27 , 1999. A vailable:\nhttps://yarchive.net/comp/linux/semaphores.html. A response from Linus himself\nabout the utility of semaphores, including the throttling case we mention in the text. As always, Linus\nis slightly insulting but quite informative.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "An interesting read on how dif\ufb01cult implementing CVs on top of semaphores r eally is, and the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "interesting",
          "read",
          "implementing",
          "semaphores",
          "eally"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "done a ton of concurrent programming; Birrell, for example, is known for (amon g other things) writing",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "done",
          "concurrent",
          "programming",
          "birrell",
          "example",
          "known",
          "amon",
          "things"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "No. 5. September 2008. A nice article by some kernel hackers from a company formerly known as Sun",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "september",
          "nice",
          "article",
          "kernel",
          "hackers",
          "company",
          "formerly",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "WebHome/dijkstra.pdf. Can you believe people worked on algorithms in 1959? We can\u2019t. Even",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "webhome",
          "dijkstra",
          "believe",
          "people",
          "worked",
          "algorithms",
          "even"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "what the problems were in concurrent code. However , practitioners in OS design knew of many of the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "problems",
          "concurrent",
          "code",
          "however",
          "practitioners",
          "design",
          "knew",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "problems described by Dijkstra, so perhaps giving him too much credi t would be a misrepresentation.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problems",
          "described",
          "dijkstra",
          "perhaps",
          "giving",
          "much",
          "credi",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "of fun problems to solve, if you like that sort of thing.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problems",
          "solve",
          "like",
          "sort",
          "thing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "[GR92] \u201cT ransaction Processing: Concepts and T echniques\u201d by Jim Gray , Andr eas Reuter .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ransaction",
          "processing",
          "concepts",
          "echniques",
          "gray",
          "andr",
          "reuter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "tions ... presumably the OS implementors worked out the appropriate algorithms , although Dijkstra is",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tions",
          "presumably",
          "implementors",
          "worked",
          "appropriate",
          "algorithms",
          "although",
          "dijkstra"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "[L83] \u201cHints for Computer Systems Design\u201d by Butler Lampson. ACM Op erating Systems",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hints",
          "computer",
          "systems",
          "design",
          "butler",
          "lampson",
          "erating",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 14: 10, October 1971. The introduction of the reader-writer",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "14",
          "october",
          "introduction",
          "reader",
          "writer"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand A vailable: http://www-m3.ma.tum.de/twiki/pub/MN0506/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "twiki"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand http: //www.cs.utexas.edu/users/EWD/ewd02xx/EWD215.PDF. Sometimes thought",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "utexas",
          "users",
          "sometimes",
          "thought"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand http: //www.cs.utexas.edu/users/EWD/ewd03xx/EWD329.PDF. Did",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "utexas",
          "users"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A vailable online here: http://www.cs.utexas.edu/users/EWD/ewd03xx/EWD310.PDF. Presents numerous con-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online here",
          "http",
          "utexas",
          "users",
          "presents",
          "numerous"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand 8: \u201cThe \ufb01rst multiprocessors, circa 196 0, had test and set instruc-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8",
          "multiprocessors",
          "circa",
          "test",
          "instruc"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand 15: 5, October 1983. Lampson, a famous systems researcher , loved using hints in the design",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "15",
          "october",
          "lampson",
          "famous",
          "systems",
          "researcher",
          "loved",
          "using",
          "hints"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "The \ufb01rst problem is just to implement and test a solution to the fork/join",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "1. The \ufb01rst problem is just to implement and test a solution to the fork/join\nproblem, as described in the text. Even though this solution is describe d in\nthe text, the act of typing it in on your own is worthwhile; even B ach would\nrewrite Vivaldi, allowing one soon-to-be master to learn fro m an existing\none. See fork-join.c for details. Add the call sleep(1) to the child to\nensure it is working.\n2. Let\u2019s now generalize this a bit by investigating the rendezvous problem .\nThe problem is as follows: you have two threads, each of which are about\nto enter the rendezvous point in the code. Neither should exit th is part of\nthe code before the other enters it. Consider using two semapho res for this\ntask, and see rendezvous.c for details.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The \ufb01rst problem is just to implement and test a solution to the fork/join",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "problem",
          "implement",
          "test",
          "solution",
          "fork",
          "join"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "problem, as described in the text. Even though this solution is describe d in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "described",
          "text",
          "even",
          "though",
          "solution",
          "describe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "rewrite Vivaldi, allowing one soon-to-be master to learn fro m an existing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rewrite",
          "vivaldi",
          "allowing",
          "soon",
          "master",
          "learn",
          "existing"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Now go one step further by implementing a general solution to barrier syn-",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "3. Now go one step further by implementing a general solution to barrier syn-\nchronization. Assume there are two points in a sequential piece of code,\ncalled P1 and P2. Putting a barrier between P1 and P2 guarantees that all\nthreads will execute P1 before any one thread executes P2. Y our task: write\nthe code to implement a barrier() function that can be used in this man-\nner . It is safe to assume you know N (the total number of threads in the\nrunning program) and that all N threads will try to enter the barrier . Again,\nyou should likely use two semaphores to achieve the solution, and some\nother integers to count things. See barrier.c for details.\n4. Now let\u2019s solve the reader-writer problem , also as described in the text. In\nthis \ufb01rst take, don\u2019t worry about starvation. See the code in reader-writer.c\nfor details. Add sleep() calls to your code to demonstrate it works as you\nexpect. Can you show the existence of the starvation problem?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now go one step further by implementing a general solution to barrier syn-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "step",
          "implementing",
          "general",
          "solution",
          "barrier"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the code to implement a barrier() function that can be used in this man-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "implement",
          "barrier",
          "function",
          "used"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ner . It is safe to assume you know N (the total number of threads in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "safe",
          "assume",
          "know",
          "total",
          "number",
          "threads"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Now let\u2019s solve the reader-writer problem , also as described in the text. In",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "reader",
          "writer",
          "problem",
          "also",
          "described",
          "text"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "for details. Add sleep() calls to your code to demonstrate it works as you",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "details",
          "sleep",
          "calls",
          "code",
          "demonstrate",
          "works"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Let\u2019s look at the reader-writer problem again, but this time , worry about",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "5. Let\u2019s look at the reader-writer problem again, but this time , worry about\nstarvation. How can you ensure that all readers and writers ev entually\nmake progress? See reader-writer-nostarve.c for details.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Use semaphores to build a no-starve mutex , in which any thread that tries to",
    "document_source": "book.pdf",
    "start_line": 40,
    "type": "chapter",
    "content": "6. Use semaphores to build a no-starve mutex , in which any thread that tries to\nacquire the mutex will eventually obtain it. See the code in mutex-nostarve.c\nfor more information.\n7. Liked these problems? See Downey\u2019s free text for more just like them. And\ndon\u2019t forget, have fun! But, you always do when you write code, n o?\n3 A vailable: http://greenteapress.com/semaphores/downey08semaphores.pdf.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 3 A vailable: http://greenteapress.com/semaphores/downey08semaphores.pdf.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 a vailable",
          "http",
          "greenteapress",
          "semaphores"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "32",
    "title": "1 What T ypes Of Bugs Exist?",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "32.1 What T ypes Of Bugs Exist?\nThe \ufb01rst, and most obvious, question is this: what types of concur-\nrency bugs manifest in complex, concurrent programs? This ques tion is\ndif\ufb01cult to answer in general, but fortunately , some others hav e done the\nwork for us. Speci\ufb01cally , we rely upon a study by Lu et al. [L+08], w hich\nanalyzes a number of popular concurrent applications in great de tail to\nunderstand what types of bugs arise in practice.\nThe study focuses on four major and important open-source applica-\ntions: MySQL (a popular database management system), Apache (a well-\nknown web server), Mozilla (the famous web browser), and OpenOf\ufb01 ce\n(a free version of the MS Of\ufb01ce suite, which some people actually u se).\nIn the study , the authors examine concurrency bugs that have be en found\nand \ufb01xed in each of these code bases, turning the developers\u2019 work into a\nquantitative bug analysis; understanding these results ca n help you un-\nderstand what types of problems actually occur in mature code bas es.\nFigure 32.1 shows a summary of the bugs Lu and colleagues studied .\nFrom the \ufb01gure, you can see that there were 105 total bugs, most of wh ich\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "analyzes a number of popular concurrent applications in great de tail to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "analyzes",
          "number",
          "popular",
          "concurrent",
          "applications",
          "great",
          "tail"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand what types of bugs arise in practice.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "types",
          "bugs",
          "arise",
          "practice"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The study focuses on four major and important open-source applica-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "study",
          "focuses",
          "four",
          "major",
          "important",
          "open",
          "source",
          "applica"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "known web server), Mozilla (the famous web browser), and OpenOf\ufb01 ce",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "server",
          "mozilla",
          "famous",
          "browser"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "and \ufb01xed in each of these code bases, turning the developers\u2019 work into a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "bases",
          "turning",
          "developers",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "quantitative bug analysis; understanding these results ca n help you un-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quantitative",
          "analysis",
          "understanding",
          "results",
          "help"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand question is this: what types of concur-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "question is this",
          "types",
          "concur"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand tions: MySQL (a popular database management system), Apache (a well-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "tions",
          "mysql",
          "popular",
          "database",
          "management",
          "system",
          "apache",
          "well"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand what t ypes of bugs exist?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ypes",
          "bugs",
          "exist"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "32",
    "title": "2 Non-Deadlock Bugs",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "32.2 Non-Deadlock Bugs\nNon-deadlock bugs make up a majority of concurrency bugs, accord-\ning to Lu\u2019s study . But what types of bugs are these? How do they ari se?\nHow can we \ufb01x them? W e now discuss the two major types of non-\ndeadlock bugs found by Lu et al.: atomicity violation bugs and order\nviolation bugs.\nAtomicity-Violation Bugs\nThe \ufb01rst type of problem encountered is referred to as an atomicity vi-\nolation. Here is a simple example, found in MySQL. Before reading the\nexplanation, try \ufb01guring out what the bug is. Do it!\n1 Thread 1::\n2 if (thd->proc_info) {\n3 fputs(thd->proc_info, ...);\n4 }\n5\n6 Thread 2::\n7 thd->proc_info = NULL;\nFigure 32.2: Atomicity Violation (atomicity.c)\nIn the example, two different threads access the \ufb01eld proc\ninfo in\nthe structure thd. The \ufb01rst thread checks if the value is non-NULL and\nthen prints its value; the second thread sets it to NULL. Clear ly , if the\n\ufb01rst thread performs the check but then is interrupted before t he call to\nfputs, the second thread could run in-between, thus setting the point er\nto NULL; when the \ufb01rst thread resumes, it will crash, as a NULL pointer\nwill be dereferenced by fputs.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand 2: Atomicity Violation (atomicity.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "atomicity",
          "violation",
          "atomicity"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand non-deadlock bugs",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "deadlock",
          "bugs"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M M O N CO N C U R R E N C Y PR O B L E M S 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M M O N CO N C U R R E N C Y PR O B L E M S 3\nThe more formal de\ufb01nition of an atomicity violation, according to Lu\net al, is this: \u201cThe desired serializability among multiple m emory accesses\nis violated (i.e. a code region is intended to be atomic, but the at omicity\nis not enforced during execution).\u201d In our example above, the code h as\nan atomicity assumption (in Lu\u2019s words) about the check for non-NULL of\nproc info and the usage of proc info in the fputs() call; when the\nassumption is incorrect, the code will not work as desired.\nFinding a \ufb01x for this type of problem is often (but not always) strai ght-\nforward. Can you think of how to \ufb01x the code above?\nIn this solution (Figure 32.3), we simply add locks around the sha red-\nvariable references, ensuring that when either thread acce sses the proc info\n\ufb01eld, it has a lock held ( proc info lock). Of course, any other code that\naccesses the structure should also acquire this lock before doin g so.\n1 pthread_mutex_t proc_info_lock = PTHREAD_MUTEX_INITIALIZER;\n2\n3 Thread 1::\n4 pthread_mutex_lock(&proc_info_lock);\n5 if (thd->proc_info) {\n6 fputs(thd->proc_info, ...);\n7 }\n8 pthread_mutex_unlock(&proc_info_lock);\n9\n10 Thread 2::\n11 pthread_mutex_lock(&proc_info_lock);\n12 thd->proc_info = NULL;\n13 pthread_mutex_unlock(&proc_info_lock);\nFigure 32.3: Atomicity Violation Fixed (atomicity\nfixed.c)\nOrder-Violation Bugs\nAnother common type of non-deadlock bug found by Lu et al. is known\nas an order violation. Here is another simple example; once again, see if\nyou can \ufb01gure out why the code below has a bug in it.\n1 Thread 1::\n2 void init() {\n3 mThread = PR_CreateThread(mMain, ...);\n4 }\n5\n6 Thread 2::\n7 void mMain(...) {\n8 mState = mThread->State;\n9 }\nFigure 32.4: Ordering Bug (ordering.c)\nAs you probably \ufb01gured out, the code in Thread 2 seems to assume\nthat the variable mThread has already been initialized (and is not NULL);\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Another common type of non-deadlock bug found by Lu et al. is known",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "common",
          "type",
          "deadlock",
          "found",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "mThread = PR_CreateThread(mMain, ...);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mthread",
          "mmain"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand is this: \u201cThe desired serializability among multiple m emory accesses",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "is this",
          "desired",
          "serializability",
          "among",
          "multiple",
          "emory",
          "accesses"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 3: Atomicity Violation Fixed (atomicity",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "atomicity",
          "violation",
          "fixed",
          "atomicity"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand 4: Ordering Bug (ordering.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "ordering",
          "ordering"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 C O M M O N CO N C U R R E N C Y PR O B L E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 C O M M O N CO N C U R R E N C Y PR O B L E M S\n1 pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;\n2 pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;\n3 int mtInit = 0;\n4\n5 Thread 1::\n6 void init() {\n7 ...\n8 mThread = PR_CreateThread(mMain, ...);\n9\n10 // signal that the thread has been created...\n11 pthread_mutex_lock(&mtLock);\n12 mtInit = 1;\n13 pthread_cond_signal(&mtCond);\n14 pthread_mutex_unlock(&mtLock);\n15 ...\n16 }\n17\n18 Thread 2::\n19 void mMain(...) {\n20 ...\n21 // wait for the thread to be initialized...\n22 pthread_mutex_lock(&mtLock);\n23 while (mtInit == 0)\n24 pthread_cond_wait(&mtCond, &mtLock);\n25 pthread_mutex_unlock(&mtLock);\n26\n27 mState = mThread->State;\n28 ...\n29 }\nFigure 32.5: Fixing The Ordering Violation (ordering\nfixed.c)\nhowever , if Thread 2 runs immediately once created, the value of mThread\nwill not be set when it is accessed within mMain() in Thread 2, and will\nlikely crash with a NULL-pointer dereference. Note that we ass ume the\nvalue of mThread is initially NULL; if not, even stranger things could\nhappen as arbitrary memory locations are accessed through the de refer-\nence in Thread 2.\nThe more formal de\ufb01nition of an order violation is the following: \u201cThe\ndesired order between two (groups of) memory accesses is \ufb02ipped ( i.e., A\nshould always be executed before B, but the order is not enforced during\nexecution)\u201d [L+08].\nThe \ufb01x to this type of bug is generally to enforce ordering. As dis -\ncussed previously , using condition variables is an easy and robust way\nto add this style of synchronization into modern code bases. In the exam-\nple above, we could thus rewrite the code as seen in Figure 32.5.\nIn this \ufb01xed-up code sequence, we have added a condition variabl e\n(mtCond) and corresponding lock ( mtLock), as well as a state variable\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "mThread = PR_CreateThread(mMain, ...);",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mthread",
          "mmain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "// signal that the thread has been created...",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "signal",
          "thread",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "however , if Thread 2 runs immediately once created, the value of mThread",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "thread",
          "runs",
          "immediately",
          "created",
          "value",
          "mthread"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 5: Fixing The Ordering Violation (ordering",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "fixing",
          "ordering",
          "violation",
          "ordering"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "32",
    "title": "3 Deadlock Bugs",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "32.3 Deadlock Bugs\nBeyond the concurrency bugs mentioned above, a classic problem th at\narises in many concurrent systems with complex locking protocols i s known\nas deadlock. Deadlock occurs, for example, when a thread (say Thread\n1) is holding a lock ( L1) and waiting for another one ( L2); unfortunately ,\nthe thread (Thread 2) that holds lock L2 is waiting for L1 to be released.\nHere is a code snippet that demonstrates such a potential deadloc k:\nThread 1: Thread 2:\npthread_mutex_lock(L1); pthread_mutex_lock(L2);\npthread_mutex_lock(L2); pthread_mutex_lock(L1);\nFigure 32.6: Simple Deadlock (deadlock.c)\nNote that if this code runs, deadlock does not necessarily occur; ra ther ,\nit may occur , if, for example, Thread 1 grabs lock L1 and then a context\nswitch occurs to Thread 2. At that point, Thread 2 grabs L2, and tries to\nacquire L1. Thus we have a deadlock, as each thread is waiting for the\nother and neither can run. See Figure 32.7 for a graphical depict ion; the\npresence of a cycle in the graph is indicative of the deadlock.\nThe \ufb01gure should make the problem clear . How should programmers\nwrite code so as to handle deadlock in some way?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "arises in many concurrent systems with complex locking protocols i s known",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "arises",
          "many",
          "concurrent",
          "systems",
          "complex",
          "locking",
          "protocols",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Here is a code snippet that demonstrates such a potential deadloc k:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "snippet",
          "demonstrates",
          "potential",
          "deadloc"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 6: Simple Deadlock (deadlock.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "simple",
          "deadlock",
          "deadlock"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand deadlock bugs",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "deadlock",
          "bugs"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 C O M M O N CO N C U R R E N C Y PR O B L E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 C O M M O N CO N C U R R E N C Y PR O B L E M S\nThread 1\nThread 2\nLock L1\nLock L2\nHolds\nHolds\nWanted by\nWanted by\nFigure 32.7: The Deadlock Dependency Graph\nCR U X : H O W TO DE A L WI T H DE A D L O C K\nHow should we build systems to prevent, avoid, or at least detect a nd\nrecover from deadlock? Is this a real problem in systems today?\nWhy Do Deadlocks Occur?\nAs you may be thinking, simple deadlocks such as the one above seem\nreadily avoidable. For example, if Thread 1 and 2 both made sure t o grab\nlocks in the same order , the deadlock would never arise. So why do de ad-\nlocks happen?\nOne reason is that in large code bases, complex dependencies ari se\nbetween components. T ake the operating system, for example. The vir-\ntual memory system might need to access the \ufb01le system in order t o page\nin a block from disk; the \ufb01le system might subsequently require a page\nof memory to read the block into and thus contact the virtual memory\nsystem. Thus, the design of locking strategies in large system s must be\ncarefully done to avoid deadlock in the case of circular dependen cies that\nmay occur naturally in the code.\nAnother reason is due to the nature of encapsulation. As software de-\nvelopers, we are taught to hide details of implementations and t hus make\nsoftware easier to build in a modular way . Unfortunately , such m odular-\nity does not mesh well with locking. As Jula et al. point out [J+08], some\nseemingly innocuous interfaces almost invite you to deadlock. For exam-\nple, take the Java V ector class and the method AddAll(). This routine\nwould be called as follows:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "system. Thus, the design of locking strategies in large system s must be",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "thus",
          "design",
          "locking",
          "strategies",
          "large",
          "system",
          "must"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "velopers, we are taught to hide details of implementations and t hus make",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "velopers",
          "taught",
          "hide",
          "details",
          "implementations",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ple, take the Java V ector class and the method AddAll(). This routine",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "take",
          "java",
          "ector",
          "class",
          "method",
          "addall",
          "routine"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 7: The Deadlock Dependency Graph",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "deadlock",
          "dependency",
          "graph"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand CR U X: H O W TO DE A L WI T H DE A D L O C K",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cr u x"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M M O N CO N C U R R E N C Y PR O B L E M S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M M O N CO N C U R R E N C Y PR O B L E M S 7\nVector v1, v2;\nv1.AddAll(v2);\nInternally , because the method needs to be multi-thread safe , locks for\nboth the vector being added to (v1) and the parameter (v2) need t o be\nacquired. The routine acquires said locks in some arbitrary orde r (say v1\nthen v2) in order to add the contents of v2 to v1. If some other thread\ncalls v2.AddAll(v1) at nearly the same time, we have the potential for\ndeadlock, all in a way that is quite hidden from the calling appl ication.\nConditions for Deadlock\nFour conditions need to hold for a deadlock to occur [C+71]:\n\u2022 Mutual exclusion: Threads claim exclusive control of resources that\nthey require (e.g., a thread grabs a lock).\n\u2022 Hold-and-wait: Threads hold resources allocated to them (e.g., locks\nthat they have already acquired) while waiting for additional re-\nsources (e.g., locks that they wish to acquire).\n\u2022 No preemption: Resources (e.g., locks) cannot be forcibly removed\nfrom threads that are holding them.\n\u2022 Circular wait: There exists a circular chain of threads such that each\nthread holds one or more resources (e.g., locks) that are being re-\nquested by the next thread in the chain.\nIf any of these four conditions are not met, deadlock cannot occur .\nThus, we \ufb01rst explore techniques to prevent deadlock; each of these strate-\ngies seeks to prevent one of the above conditions from arising and th us is\none approach to handling the deadlock problem.\nPrevention\nCircular W ait\nProbably the most practical prevention technique (and certain ly one that\nis frequently employed) is to write your locking code such that you never\ninduce a circular wait. The most straightforward way to do that is to pro-\nvide a total ordering on lock acquisition. For example, if there are only\ntwo locks in the system ( L1 and L2), you can prevent deadlock by always\nacquiring L1 before L2. Such strict ordering ensures that no cyclical wait\narises; hence, no deadlock.\nOf course, in more complex systems, more than two locks will exist,\nand thus total lock ordering may be dif\ufb01cult to achieve (and perh aps\nis unnecessary anyhow). Thus, a partial ordering can be a useful way\nto structure lock acquisition so as to avoid deadlock. An excelle nt real\nexample of partial lock ordering can be seen in the memory mapping\ncode in Linux [T+94] (v5.2); the comment at the top of the source code\nreveals ten different groups of lock acquisition orders, includi ng simple\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Internally , because the method needs to be multi-thread safe , locks for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "internally",
          "method",
          "needs",
          "multi",
          "thread",
          "safe",
          "locks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Thus, we \ufb01rst explore techniques to prevent deadlock; each of these strate-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "explore",
          "techniques",
          "prevent",
          "deadlock",
          "strate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "one approach to handling the deadlock problem.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "handling",
          "deadlock",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Probably the most practical prevention technique (and certain ly one that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "probably",
          "practical",
          "prevention",
          "technique",
          "certain"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Mutual exclusion: Threads claim exclusive control of resources that",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "mutual exclusion",
          "threads",
          "claim",
          "exclusive",
          "control",
          "resources"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand wait: Threads hold resources allocated to them (e.g., locks",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "threads",
          "hold",
          "resources",
          "allocated",
          "locks"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand No preemption: Resources (e.g., locks) cannot be forcibly removed",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "no preemption",
          "resources",
          "locks",
          "cannot",
          "forcibly",
          "removed"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Circular wait: There exists a circular chain of threads such that each",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "circular wait",
          "exists",
          "circular",
          "chain",
          "threads"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 C O M M O N CO N C U R R E N C Y PR O B L E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 C O M M O N CO N C U R R E N C Y PR O B L E M S\nTI P : E N F O R C E LO C K OR D E R I N G BY LO C K AD D R E S S\nIn some cases, a function must grab two (or more) locks; thus, we know\nwe must be careful or deadlock could arise. Imagine a function tha t is\ncalled as follows: do\nsomething(mutex t *m1, mutex t *m2). If\nthe code always grabs m1 before m2 (or always m2 before m1), it could\ndeadlock, because one thread could call do something(L1, L2) while\nanother thread could call do something(L2, L1).\nT o avoid this particular issue, the clever programmer can use t he address\nof each lock as a way of ordering lock acquisition. By acquiring locks in\neither high-to-low or low-to-high address order , do something() can\nguarantee that it always acquires locks in the same order , rega rdless of\nwhich order they are passed in. The code would look something like th is:\nif (m1 > m2) { // grab in high-to-low address order\npthread_mutex_lock(m1);\npthread_mutex_lock(m2);\n} else {\npthread_mutex_lock(m2);\npthread_mutex_lock(m1);\n}\n// Code assumes that m1 != m2 (not the same lock)\nBy using this simple technique, a programmer can ensure a simp le and\nef\ufb01cient deadlock-free implementation of multi-lock acquisit ion.\nones such as \u201c i\nmutex before i mmap rwsem\u201d and more complex orders\nsuch as \u201c i mmap rwsem before private lock before swap lock before\ni pages lock\u201d.\nAs you can imagine, both total and partial ordering require caref ul\ndesign of locking strategies and must be constructed with great care. Fur-\nther , ordering is just a convention, and a sloppy programmer can ea sily\nignore the locking protocol and potentially cause deadlock. Finall y , lock\nordering requires a deep understanding of the code base, and how v ari-\nous routines are called; just one mistake could result in the \u201cD\u201d w ord1 .\nHold-and-wait\nThe hold-and-wait requirement for deadlock can be avoided by acq uiring\nall locks at once, atomically . In practice, this could be achieve d as follows:\n1 pthread_mutex_lock(prevention); // begin acquisition\n2 pthread_mutex_lock(L1);\n3 pthread_mutex_lock(L2);\n4 ...\n5 pthread_mutex_unlock(prevention); // end\n1 Hint: \u201cD\u201d stands for \u201cDeadlock\u201d.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In some cases, a function must grab two (or more) locks; thus, we know",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cases",
          "function",
          "must",
          "grab",
          "locks",
          "thus",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "By using this simple technique, a programmer can ensure a simp le and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "simple",
          "technique",
          "programmer",
          "ensure",
          "simp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ef\ufb01cient deadlock-free implementation of multi-lock acquisit ion.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "deadlock",
          "free",
          "implementation",
          "multi",
          "lock",
          "acquisit"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "design of locking strategies and must be constructed with great care. Fur-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "locking",
          "strategies",
          "must",
          "constructed",
          "great",
          "care"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ordering requires a deep understanding of the code base, and how v ari-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ordering",
          "requires",
          "deep",
          "understanding",
          "code",
          "base"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand end\n1 Hint: \u201cD\u201d stands for \u201cDeadlock\u201d.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "end\n1 hint",
          "stands",
          "deadlock"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M M O N CO N C U R R E N C Y PR O B L E M S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M M O N CO N C U R R E N C Y PR O B L E M S 9\nBy \ufb01rst grabbing the lock prevention, this code guarantees that no\nuntimely thread switch can occur in the midst of lock acquisition and thus\ndeadlock can once again be avoided. Of course, it requires that an y time\nany thread grabs a lock, it \ufb01rst acquires the global prevention l ock. For\nexample, if another thread was trying to grab locks L1 and L2 in a dif-\nferent order , it would be OK, because it would be holding the preve ntion\nlock while doing so.\nNote that the solution is problematic for a number of reasons. As\nbefore, encapsulation works against us: when calling a routine, this ap-\nproach requires us to know exactly which locks must be held and to ac-\nquire them ahead of time. This technique also is likely to decr ease con-\ncurrency as all locks must be acquired early on (at once) instead of when\nthey are truly needed.\nNo Preemption\nBecause we generally view locks as held until unlock is called, multiple\nlock acquisition often gets us into trouble because when waiting for one\nlock we are holding another . Many thread libraries provide a more \ufb02 ex-\nible set of interfaces to help avoid this situation. Speci\ufb01cally , the routine\npthread\nmutex trylock() either grabs the lock (if it is available) and\nreturns success or returns an error code indicating the lock is he ld; in the\nlatter case, you can try again later if you want to grab that lock.\nSuch an interface could be used as follows to build a deadlock-free ,\nordering-robust lock acquisition protocol:\n1 top:\n2 pthread_mutex_lock(L1);\n3 if (pthread_mutex_trylock(L2) != 0) {\n4 pthread_mutex_unlock(L1);\n5 goto top;\n6 }\nNote that another thread could follow the same protocol but grab the\nlocks in the other order ( L2 then L1) and the program would still be dead-\nlock free. One new problem does arise, however: livelock. It is possible\n(though perhaps unlikely) that two threads could both be repeat edly at-\ntempting this sequence and repeatedly failing to acquire bot h locks. In\nthis case, both systems are running through this code sequence ov er and\nover again (and thus it is not a deadlock), but progress is not being made,\nhence the name livelock. There are solutions to the livelock probl em, too:\nfor example, one could add a random delay before looping back and try-\ning the entire thing over again, thus decreasing the odds of repe ated in-\nterference among competing threads.\nOne point about this solution: it skirts around the hard parts of usi ng\na trylock approach. The \ufb01rst problem that would likely exist agai n arises\ndue to encapsulation: if one of these locks is buried in some routine that\nis getting called, the jump back to the beginning becomes more c omplex\nto implement. If the code had acquired some resources (other than L1)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "proach requires us to know exactly which locks must be held and to ac-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "proach",
          "requires",
          "know",
          "exactly",
          "locks",
          "must",
          "held"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "quire them ahead of time. This technique also is likely to decr ease con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quire",
          "ahead",
          "time",
          "technique",
          "also",
          "likely",
          "decr",
          "ease"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "a trylock approach. The \ufb01rst problem that would likely exist agai n arises",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trylock",
          "approach",
          "problem",
          "would",
          "likely",
          "exist",
          "agai",
          "arises"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "to implement. If the code had acquired some resources (other than L1)",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "code",
          "acquired",
          "resources"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand encapsulation works against us: when calling a routine, this ap-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "encapsulation works against us",
          "calling",
          "routine"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand however: livelock. It is possible",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "livelock",
          "possible"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand too: for example, one could add a random delay before looping back and try-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "too",
          "example",
          "could",
          "random",
          "delay",
          "looping",
          "back"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 C O M M O N CO N C U R R E N C Y PR O B L E M S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 C O M M O N CO N C U R R E N C Y PR O B L E M S\nalong the way , it must make sure to carefully release them as we ll; for\nexample, if after acquiring L1, the code had allocated some memory , it\nwould have to release that memory upon failure to acquire L2, before\njumping back to the top to try the entire sequence again. Howeve r , in\nlimited circumstances (e.g., the Java vector method mentioned earlier),\nthis type of approach could work well.\nY ou might also notice that this approach doesn\u2019t really add preemption\n(the forcible action of taking a lock away from a thread that owns it) ,\nbut rather uses the trylock approach to allow a developer to back ou t of\nlock ownership (i.e., preempt their own ownership) in a graceful way .\nHowever , it is a practical approach, and thus we include it here , despite\nits imperfection in this regard.\nMutual Exclusion\nThe \ufb01nal prevention technique would be to avoid the need for mutua l\nexclusion at all. In general, we know this is dif\ufb01cult, because the code we\nwish to run does indeed have critical sections. So what can we do?\nHerlihy had the idea that one could design various data structur es\nwithout locks at all [H91, H93]. The idea behind these lock-free (and\nrelated wait-free) approaches here is simple: using powerful hardware\ninstructions, you can build data structures in a manner that doe s not re-\nquire explicit locking.\nAs a simple example, let us assume we have a compare-and-swap i n-\nstruction, which as you may recall is an atomic instruction provid ed by\nthe hardware that does the following:\n1 int CompareAndSwap(int *address, int expected, int new) {\n2 if (*address == expected) {\n3 *address = new;\n4 return 1; // success\n5 }\n6 return 0; // failure\n7 }\nImagine we now wanted to atomically increment a value by a certa in\namount, using compare-and-swap. W e could do so with the following\nsimple function:\n1 void AtomicIncrement(int *value, int amount) {\n2 do {\n3 int old = *value;\n4 } while (CompareAndSwap(value, old, old + amount) == 0);\n5 }\nInstead of acquiring a lock, doing the update, and then releasin g it, we\nhave instead built an approach that repeatedly tries to updat e the value to\nthe new amount and uses the compare-and-swap to do so. In this man ner ,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "limited circumstances (e.g., the Java vector method mentioned earlier),",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "limited",
          "circumstances",
          "java",
          "vector",
          "method",
          "mentioned",
          "earlier"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "this type of approach could work well.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "type",
          "approach",
          "could",
          "work",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Y ou might also notice that this approach doesn\u2019t really add preemption",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "might",
          "also",
          "notice",
          "approach",
          "really",
          "preemption"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "but rather uses the trylock approach to allow a developer to back ou t of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "rather",
          "uses",
          "trylock",
          "approach",
          "allow",
          "developer",
          "back"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "However , it is a practical approach, and thus we include it here , despite",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "practical",
          "approach",
          "thus",
          "include",
          "despite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "The \ufb01nal prevention technique would be to avoid the need for mutua l",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "prevention",
          "technique",
          "would",
          "avoid",
          "need",
          "mutua"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "exclusion at all. In general, we know this is dif\ufb01cult, because the code we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "exclusion",
          "general",
          "know",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "wish to run does indeed have critical sections. So what can we do?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wish",
          "indeed",
          "critical",
          "sections"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "Herlihy had the idea that one could design various data structur es",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "herlihy",
          "idea",
          "could",
          "design",
          "various",
          "data",
          "structur"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "related wait-free) approaches here is simple: using powerful hardware",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "related",
          "wait",
          "free",
          "approaches",
          "simple",
          "using",
          "powerful",
          "hardware"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand approaches here is simple: using powerful hardware",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "approaches here is simple",
          "using",
          "powerful",
          "hardware"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M M O N CO N C U R R E N C Y PR O B L E M S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M M O N CO N C U R R E N C Y PR O B L E M S 11\nno lock is acquired, and no deadlock can arise (though livelock is still\na possibility , and thus a robust solution will be more complex than t he\nsimple code snippet above).\nLet us consider a slightly more complex example: list insertion. Here\nis code that inserts at the head of a list:\n1 void insert(int value) {\n2 node_t *n = malloc(sizeof(node_t));\n3 assert(n != NULL);\n4 n->value = value;\n5 n->next = head;\n6 head = n;\n7 }\nThis code performs a simple insertion, but if called by multiple threads\nat the \u201csame time\u201d, has a race condition. Can you \ufb01gure out why? (dr aw\na picture of what could happen to a list if two concurrent inserti ons take\nplace, assuming, as always, a malicious scheduling interlea ving). Of\ncourse, we could solve this by surrounding this code with a lock acqu ire\nand release:\n1 void insert(int value) {\n2 node_t *n = malloc(sizeof(node_t));\n3 assert(n != NULL);\n4 n->value = value;\n5 pthread_mutex_lock(listlock); // begin critical section\n6 n->next = head;\n7 head = n;\n8 pthread_mutex_unlock(listlock); // end critical section\n9 }\nIn this solution, we are using locks in the traditional manner 2 . Instead,\nlet us try to perform this insertion in a lock-free manner simply using the\ncompare-and-swap instruction. Here is one possible approach:\n1 void insert(int value) {\n2 node_t *n = malloc(sizeof(node_t));\n3 assert(n != NULL);\n4 n->value = value;\n5 do {\n6 n->next = head;\n7 } while (CompareAndSwap(&head, n->next, n) == 0);\n8 }\n2 The astute reader might be asking why we grabbed the lock so late, inste ad of right\nwhen entering insert(); can you, astute reader , \ufb01gure out why that is likely correct? What\nassumptions does the code make, for example, about the call to malloc()?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "course, we could solve this by surrounding this code with a lock acqu ire",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "course",
          "could",
          "solve",
          "surrounding",
          "code",
          "lock",
          "acqu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "pthread_mutex_lock(listlock); // begin critical section",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "listlock",
          "begin",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "pthread_mutex_unlock(listlock); // end critical section",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "listlock",
          "critical",
          "section"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "compare-and-swap instruction. Here is one possible approach:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "swap",
          "instruction",
          "possible",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "} while (CompareAndSwap(&head, n->next, n) == 0);",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compareandswap",
          "head",
          "next"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 C O M M O N CO N C U R R E N C Y PR O B L E M S...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 C O M M O N CO N C U R R E N C Y PR O B L E M S\nThe code here updates the next pointer to point to the current hea d,\nand then tries to swap the newly-created node into position as th e new\nhead of the list. However , this will fail if some other thread succ essfully\nswapped in a new head in the meanwhile, causing this thread to retry\nagain with the new head.\nOf course, building a useful list requires more than just a list insert,\nand not surprisingly building a list that you can insert into, de lete from,\nand perform lookups on in a lock-free manner is non-trivial. Read th e\nrich literature on lock-free and wait-free synchronization to l earn more\n[H01, H91, H93].\nDeadlock A voidance via Scheduling\nInstead of deadlock prevention, in some scenarios deadlock avoidance\nis preferable. A voidance requires some global knowledge of which locks\nvarious threads might grab during their execution, and subseq uently sched-\nules said threads in a way as to guarantee no deadlock can occur .\nFor example, assume we have two processors and four threads which\nmust be scheduled upon them. Assume further we know that Thread\n1 (T1) grabs locks L1 and L2 (in some order , at some point during its\nexecution), T2 grabs L1 and L2 as well, T3 grabs just L2, and T4 grabs no\nlocks at all. W e can show these lock acquisition demands of the thre ads\nin tabular form:\nT1 T2 T3 T4\nL1 yes yes no no\nL2 yes yes yes no\nA smart scheduler could thus compute that as long as T1 and T2 are\nnot run at the same time, no deadlock could ever arise. Here is one s uch\nschedule:\nCPU 1\nCPU 2\nT1 T2\nT3 T4\nNote that it is OK for (T3 and T1) or (T3 and T2) to overlap. Even\nthough T3 grabs lock L2, it can never cause a deadlock by running con-\ncurrently with other threads because it only grabs one lock.\nLet\u2019s look at one more example. In this one, there is more contention\nfor the same resources (again, locks L1 and L2), as indicated by the fol-\nlowing contention table:\nT1 T2 T3 T4\nL1 yes yes yes no\nL2 yes yes yes no\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and then tries to swap the newly-created node into position as th e new",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tries",
          "swap",
          "newly",
          "created",
          "node",
          "position"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "is preferable. A voidance requires some global knowledge of which locks",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "preferable",
          "voidance",
          "requires",
          "global",
          "knowledge",
          "locks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "must be scheduled upon them. Assume further we know that Thread",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "must",
          "scheduled",
          "upon",
          "assume",
          "know",
          "thread"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CO M M O N CO N C U R R E N C Y PR O B L E M S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CO M M O N CO N C U R R E N C Y PR O B L E M S 13\nTI P : D O N\u2019 T ALWAY S DO IT PE R F E C T LY (T O M WE S T \u2019 S LAW)\nT om W est, famous as the subject of the classic computer-industry book\nSoul of a New Machine [K81], says famously: \u201cNot everything worth doing\nis worth doing well\u201d, which is a terri\ufb01c engineering maxim. If a bad\nthing happens rarely , certainly one should not spend a great dea l of effort\nto prevent it, particularly if the cost of the bad thing occurrin g is small.\nIf, on the other hand, you are building a space shuttle, and the cos t of\nsomething going wrong is the space shuttle blowing up, well, perh aps\nyou should ignore this piece of advice.\nSome readers object: \u201cThis sounds like you are suggesting mediocri ty\nas a solution!\u201d Perhaps they are right, that we should be careful w ith\nadvice such as this. However , our experience tells us that in th e world of\nengineering, with pressing deadlines and other real-world con cerns, one\nwill always have to decide which aspects of a system to build we ll and\nwhich to put aside for another day . The hard part is knowing which to\ndo when, a bit of insight only gained through experience and dedi cation\nto the task at hand.\nIn particular , threads T1, T2, and T3 all need to grab both locks L1 and\nL2 at some point during their execution. Here is a possible schedule that\nguarantees that no deadlock could ever occur:\nCPU 1\nCPU 2\nT1 T2 T3\nT4\nAs you can see, static scheduling leads to a conservative approa ch\nwhere T1, T2, and T3 are all run on the same processor , and thus the\ntotal time to complete the jobs is lengthened considerably . Thoug h it may\nhave been possible to run these tasks concurrently , the fear of d eadlock\nprevents us from doing so, and the cost is performance.\nOne famous example of an approach like this is Dijkstra\u2019s Banker \u2019s Al-\ngorithm [D64], and many similar approaches have been describe d in the\nliterature. Unfortunately , they are only useful in very limit ed environ-\nments, for example, in an embedded system where one has full know l-\nedge of the entire set of tasks that must be run and the locks that t hey\nneed. Further , such approaches can limit concurrency , as we sa w in the\nsecond example above. Thus, avoidance of deadlock via scheduling is\nnot a widely-used general-purpose solution.\nDetect and Recover\nOne \ufb01nal general strategy is to allow deadlocks to occasionally oc cur , and\nthen take some action once such a deadlock has been detected. For ex am-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "which to put aside for another day . The hard part is knowing which to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "aside",
          "another",
          "hard",
          "part",
          "knowing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One famous example of an approach like this is Dijkstra\u2019s Banker \u2019s Al-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "famous",
          "example",
          "approach",
          "like",
          "dijkstra",
          "banker"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "gorithm [D64], and many similar approaches have been describe d in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "gorithm",
          "many",
          "similar",
          "approaches",
          "describe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ments, for example, in an embedded system where one has full know l-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ments",
          "example",
          "embedded",
          "system",
          "full",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "need. Further , such approaches can limit concurrency , as we sa w in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "approaches",
          "limit",
          "concurrency"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "One \ufb01nal general strategy is to allow deadlocks to occasionally oc cur , and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "general",
          "strategy",
          "allow",
          "deadlocks",
          "occasionally"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand says famously: \u201cNot everything worth doing",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "says famously",
          "everything",
          "worth"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Some readers object: \u201cThis sounds like you are suggesting mediocri ty",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "some readers object",
          "sounds",
          "like",
          "suggesting",
          "mediocri"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "32",
    "title": "4 Summary",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "32.4 Summary\nIn this chapter , we have studied the types of bugs that occur in c on-\ncurrent programs. The \ufb01rst type, non-deadlock bugs, are surpri singly\ncommon, but often are easier to \ufb01x. They include atomicity violati ons,\nin which a sequence of instructions that should have been execut ed to-\ngether was not, and order violations, in which the needed order bet ween\ntwo threads was not enforced.\nW e have also brie\ufb02y discussed deadlock: why it occurs, and what can\nbe done about it. The problem is as old as concurrency itself, and ma ny\nhundreds of papers have been written about the topic. The best sol u-\ntion in practice is to be careful, develop a lock acquisition order , and\nthus prevent deadlock from occurring in the \ufb01rst place. W ait-fr ee ap-\nproaches also have promise, as some wait-free data structures a re now\n\ufb01nding their way into commonly-used libraries and critical sy stems, in-\ncluding Linux. However , their lack of generality and the comple xity to\ndevelop a new wait-free data structure will likely limit the ov erall util-\nity of this approach. Perhaps the best solution is to develop new con cur-\nrent programming models: in systems such as MapReduce (from Googl e)\n[GD02], programmers can describe certain types of parallel com putations\nwithout any locks whatsoever . Locks are problematic by their very na-\nture; perhaps we should seek to avoid using them unless we truly must.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tion in practice is to be careful, develop a lock acquisition order , and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tion",
          "practice",
          "careful",
          "develop",
          "lock",
          "acquisition",
          "order"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "\ufb01nding their way into commonly-used libraries and critical sy stems, in-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "commonly",
          "used",
          "libraries",
          "critical",
          "stems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "develop a new wait-free data structure will likely limit the ov erall util-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "develop",
          "wait",
          "free",
          "data",
          "structure",
          "likely",
          "limit",
          "erall"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ity of this approach. Perhaps the best solution is to develop new con cur-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "approach",
          "perhaps",
          "best",
          "solution",
          "develop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[GD02], programmers can describe certain types of parallel com putations",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "programmers",
          "describe",
          "certain",
          "types",
          "parallel",
          "putations"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand rent programming models: in systems such as MapReduce (from Googl e)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "rent programming models",
          "systems",
          "mapreduce",
          "googl"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2008",
    "title": "An excellent recent paper on deadlocks and how to avoid getting caught in the s ame ones over",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "2008. An excellent recent paper on deadlocks and how to avoid getting caught in the s ame ones over\nand over again in a particular system.\n[K81] \u201cSoul of a New Machine\u201d by T racy Kidder . Backbay Books, 2000 (rep rint of 1980 ver-\nsion). A must-read for any systems builder or engineer , detailing the early days of how a team inside\nData General (DG), led by T om West, worked to produce a \u201cnew machine.\u201d Kidde r\u2019s other books are\nalso excellent, including \u201cMountains beyond Mountains.\u201d Or maybe you don \u2019t agree with us, comma?\n[K87] \u201cDeadlock Detection in Distributed Databases\u201d by Edgar K napp. ACM Computing Sur-\nveys, 19:4, December 1987. An excellent overview of deadlock detection in distributed database sys-\ntems. Also points to a number of other related works, and thus is a good place to start your reading.\n[L+08] \u201cLearning from Mistakes \u2014 A Comprehensive Study on Real W orld Concurrency Bug\nCharacteristics\u201d by Shan Lu, Soyeon Park, Eunsoo Seo, Y uanyuan Zhou. ASPLOS \u201908, March\n2008, Seattle, W ashington. The \ufb01rst in-depth study of concurrency bugs in real software, and the basis\nfor this chapter . Look at Y .Y . Zhou\u2019s or Shan Lu\u2019s web pages for many more intere sting papers on bugs.\n[T+94] \u201cLinux File Memory Map Code\u201d by Linus T orvalds and many others. A vailable online\nat: http://lxr.free-electrons.com/source/mm/filemap.c. Thanks to Michael Wal-\n\ufb01sh (NYU) for pointing out this precious example. The real world, as you can s ee in this \ufb01le, can be a\nbit more complex than the simple clarity found in textbooks...\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[L+08] \u201cLearning from Mistakes \u2014 A Comprehensive Study on Real W orld Concurrency Bug",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learning",
          "mistakes",
          "comprehensive",
          "study",
          "real",
          "orld",
          "concurrency"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 19: 4, December 1987. An excellent overview of deadlock detection in distributed database sys-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "19",
          "december",
          "excellent",
          "overview",
          "deadlock",
          "detection",
          "distributed",
          "database"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand A vailable online\nat: http://lxr.free-electrons.com/source/mm/filemap.c. Thanks to Michael Wal-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online\nat",
          "http",
          "free",
          "electrons",
          "source",
          "filemap",
          "thanks",
          "michael"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "First let\u2019s make sure you understand how the programs generall y work, and",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "1. First let\u2019s make sure you understand how the programs generall y work, and\nsome of the key options. Study the code in vector-deadlock.c, as well\nas in main-common.c and related \ufb01les.\nNow , run ./vector-deadlock -n 2 -l 1 -v, which instantiates two\nthreads ( -n 2), each of which does one vector add ( -l 1), and does so in\nverbose mode ( -v). Make sure you understand the output. How does the\noutput change from run to run?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "First let\u2019s make sure you understand how the programs generall y work, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "first",
          "make",
          "sure",
          "understand",
          "programs",
          "generall",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "verbose mode ( -v). Make sure you understand the output. How does the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "verbose",
          "mode",
          "make",
          "sure",
          "understand",
          "output"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the\noutput change from run to run",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "output",
          "change"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now add the -d \ufb02ag, and change the number of loops ( -l) from 1 to higher",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "2. Now add the -d \ufb02ag, and change the number of loops ( -l) from 1 to higher\nnumbers. What happens? Does the code (always) deadlock?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "How does changing the number of threads ( -n) change the outcome of the",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "3. How does changing the number of threads ( -n) change the outcome of the\nprogram? Are there any values of -n that ensure no deadlock occurs?\n4. Now examine the code in vector-global-order.c. First, make sure you\nunderstand what the code is trying to do; do you understand why t he code\navoids deadlock? Also, why is there a special case in this vector\nadd()\nroutine when the source and destination vectors are the same?\n5. Now run the code with the following \ufb02ags: -t -n 2 -l 100000 -d.\nHow long does the code take to complete? How does the total time c hange\nwhen you increase the number of loops, or the number of threads?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "How does changing the number of threads ( -n) change the outcome of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "changing",
          "number",
          "threads",
          "change",
          "outcome"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "understand what the code is trying to do; do you understand why t he code",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "code",
          "trying",
          "understand",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand changing the number of threads ( -n) change the outcome of the\nprogram",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "changing",
          "number",
          "threads",
          "change",
          "outcome",
          "program"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the total time c hange\nwhen you increase the number of loops, or the number of threads",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "total",
          "time",
          "hange",
          "increase",
          "number",
          "loops",
          "number",
          "threads"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_3",
        "text": "understand there a special case in this vector\nadd()\nroutine when the source and destination vectors are the same",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "special",
          "case",
          "vector",
          "routine",
          "source",
          "destination",
          "vectors"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "What happens if you turn on the parallelism \ufb02ag ( -p)? How much would",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "6. What happens if you turn on the parallelism \ufb02ag ( -p)? How much would\nyou expect performance to change when each thread is working on adding\ndifferent vectors (which is what -p enables) versus working on the same\nones?\n7. Now let\u2019s study vector-try-wait.c. First make sure you understand\nthe code. Is the \ufb01rst call to pthread mutex trylock() really needed?\nNow run the code. How fast does it run compared to the global order ap-\nproach? How does the number of retries, as counted by the code, ch ange as\nthe number of threads increases?\n8. Now let\u2019s look at vector-avoid-hold-and-wait.c. What is the main\nproblem with this approach? How does its performance compare t o the\nother versions, when running both with -p and without it?\n9. Finally , let\u2019s look at vector-nolock.c. This version doesn\u2019t use locks at\nall; does it provide the exact same semantics as the other versio ns? Why or\nwhy not?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now let\u2019s study vector-try-wait.c. First make sure you understand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "study",
          "vector",
          "wait",
          "first",
          "make",
          "sure",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Now run the code. How fast does it run compared to the global order ap-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "fast",
          "compared",
          "global",
          "order"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "problem with this approach? How does its performance compare t o the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "problem",
          "approach",
          "performance",
          "compare"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the main\nproblem with this approach",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "main",
          "problem",
          "approach"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the number of retries, as counted by the code, ch ange as\nthe number of threads increases",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "number",
          "retries",
          "counted",
          "code",
          "ange",
          "number",
          "threads",
          "increases"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_3",
        "text": "understand its performance compare t o the\nother versions, when running both with -p and without it",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "performance",
          "compare",
          "versions",
          "running",
          "without"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "10",
    "title": "Now compare its performance to the other versions, both whe n threads are",
    "document_source": "book.pdf",
    "start_line": 42,
    "type": "chapter",
    "content": "10. Now compare its performance to the other versions, both whe n threads are\nworking on the same two vectors (no -p) and when each thread is working\non separate vectors ( -p). How does this no-lock version perform?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now compare its performance to the other versions, both whe n threads are",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "performance",
          "versions",
          "threads"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand this no-lock version perform",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "lock",
          "version",
          "perform"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "1 The Basic Idea: An Event Loop",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "33.1 The Basic Idea: An Event Loop\nThe basic approach we\u2019ll use, as stated above, is called event-based\nconcurrency. The approach is quite simple: you simply wait for some-\nthing (i.e., an \u201cevent\u201d) to occur; when it does, you check what ty pe of\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The basic approach we\u2019ll use, as stated above, is called event-based",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "approach",
          "stated",
          "called",
          "event",
          "based"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "concurrency. The approach is quite simple: you simply wait for some-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "concurrency",
          "approach",
          "quite",
          "simple",
          "simply",
          "wait"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the basic idea: an event loop",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "idea",
          "event",
          "loop"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "2 An Important API: select() (or poll())",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "33.2 An Important API: select() (or poll())\nWith that basic event loop in mind, we next must address the ques tion\nof how to receive events. In most systems, a basic API is availabl e, via\neither the select() or poll() system calls.\nWhat these interfaces enable a program to do is simple: check w hether\nthere is any incoming I/O that should be attended to. For example, imag-\nine that a network application (such as a web server) wishes to c heck\nwhether any network packets have arrived, in order to service t hem.\nThese system calls let you do exactly that.\nT ake select() for example. The manual page (on a Mac) describes\nthe API in this manner:\nint select(int nfds,\nfd_set *restrict readfds,\nfd_set *restrict writefds,\nfd_set *restrict errorfds,\nstruct timeval *restrict timeout);\nThe actual description from the man page: select() examines the I/O de-\nscriptor sets whose addresses are passed in readfds, writefds, an d errorfds to see\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "An Important API: select() (or poll())",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "select",
          "poll"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T ake select() for example. The manual page (on a Mac) describes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "select",
          "example",
          "manual",
          "page",
          "describes"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "3 Using select()",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "33.3 Using select()\nT o make this more concrete, let\u2019s examine how to use select() to see\nwhich network descriptors have incoming messages upon them. Fig ure\n33.1 shows a simple example.\nThis code is actually fairly simple to understand. After some i nitial-\nization, the server enters an in\ufb01nite loop. Inside the loop, it use s the\nFD ZERO() macro to \ufb01rst clear the set of \ufb01le descriptors, and then uses\nFD SET() to include all of the \ufb01le descriptors from minFD to maxFD in\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "This code is actually fairly simple to understand. After some i nitial-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "actually",
          "fairly",
          "simple",
          "understand",
          "nitial"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand using select()",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "select"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand shows a simple example.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "simple",
          "example"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 E V E N T-B A S E D CO N C U R R E N C Y (A D VA...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 E V E N T-B A S E D CO N C U R R E N C Y (A D VA N C E D)\n1 #include <stdio.h>\n2 #include <stdlib.h>\n3 #include <sys/time.h>\n4 #include <sys/types.h>\n5 #include <unistd.h>\n6\n7 int main(void) {\n8 // open and set up a bunch of sockets (not shown)\n9 // main loop\n10 while (1) {\n11 // initialize the fd_set to all zero\n12 fd_set readFDs;\n13 FD_ZERO(&readFDs);\n14\n15 // now set the bits for the descriptors\n16 // this server is interested in\n17 // (for simplicity, all of them from min to max)\n18 int fd;\n19 for (fd = minFD; fd < maxFD; fd++)\n20 FD_SET(fd, &readFDs);\n21\n22 // do the select\n23 int rc = select(maxFD+1, &readFDs, NULL, NULL, NULL);\n24\n25 // check which actually have data using FD_ISSET()\n26 int fd;\n27 for (fd = minFD; fd < maxFD; fd++)\n28 if (FD_ISSET(fd, &readFDs))\n29 processFD(fd);\n30 }\n31 }\nFigure 33.1: Simple Code Using select()\nthe set. This set of descriptors might represent, for example, a ll of the net-\nwork sockets to which the server is paying attention. Finally , t he server\ncalls select() to see which of the connections have data available upon\nthem. By then using FD\nISSET() in a loop, the event server can see\nwhich of the descriptors have data ready and process the incoming data.\nOf course, a real server would be more complicated than this, and\nrequire logic to use when sending messages, issuing disk I/O, and many\nother details. For further information, see Stevens and Rago [SR05 ] for\nAPI information, or Pai et. al or W elsh et al. for a good overview of the\ngeneral \ufb02ow of event-based servers [PDZ99, WCB01].\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: Simple Code Using select()",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "simple",
          "code",
          "using",
          "select"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "4 Why Simpler? No Locks Needed",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "33.4 Why Simpler? No Locks Needed\nWith a single CPU and an event-based application, the problems found\nin concurrent programs are no longer present. Speci\ufb01cally , beca use only\none event is being handled at a time, there is no need to acquire or release\nlocks; the event-based server cannot be interrupted by another thread be-\ncause it is decidedly single threaded. Thus, concurrency bug s common in\nthreaded programs do not manifest in the basic event-based app roach.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand why simpler? no locks needed",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "simpler",
          "locks",
          "needed"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "33",
    "title": "5 A Problem: Blocking System Calls",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "33.5 A Problem: Blocking System Calls\nThus far , event-based programming sounds great, right? Y ou prog ram\na simple loop, and handle events as they arise. Y ou don\u2019t even need t o\nthink about locking! But there is an issue: what if an event requ ires that\nyou issue a system call that might block?\nFor example, imagine a request comes from a client into a server t o\nread a \ufb01le from disk and return its contents to the requesting cl ient (much\nlike a simple HTTP request). T o service such a request, some ev ent han-\ndler will eventually have to issue an open() system call to open the \ufb01le,\nfollowed by a series of read() calls to read the \ufb01le. When the \ufb01le is read\ninto memory , the server will likely start sending the results to the client.\nBoth the open() and read() calls may issue I/O requests to the stor-\nage system (when the needed metadata or data is not in memory alre ady),\nand thus may take a long time to service. With a thread-based se rver , this\nis no issue: while the thread issuing the I/O request suspend s (waiting\nfor the I/O to complete), other threads can run, thus enabling th e server\nto make progress. Indeed, this natural overlap of I/O and other computa-\ntion is what makes thread-based programming quite natural and straight-\nforward.\nWith an event-based approach, however , there are no other threa ds to\nrun: just the main event loop. And this implies that if an event h andler\nissues a call that blocks, the entire server will do just that: block until the\ncall completes. When the event loop blocks, the system sits idle, and thus\nis a huge potential waste of resources. W e thus have a rule that mu st be\nobeyed in event-based systems: no blocking calls are allowed.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "With an event-based approach, however , there are no other threa ds to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "event",
          "based",
          "approach",
          "however",
          "threa"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5 A Problem: Blocking System Calls",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5 a problem",
          "blocking",
          "system",
          "calls"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand this\nis no issue: while the thread issuing the I/O request suspend s (waiting",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this\nis no issue",
          "thread",
          "issuing",
          "request",
          "suspend",
          "waiting"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand based systems: no blocking calls are allowed.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "based systems",
          "blocking",
          "calls",
          "allowed"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "6 A Solution: Asynchronous I/O",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "33.6 A Solution: Asynchronous I/O\nT o overcome this limit, many modern operating systems have intro-\nduced new ways to issue I/O requests to the disk system, refer red to\ngenerically as asynchronous I/O. These interfaces enable an application\nto issue an I/O request and return control immediately to the ca ller , be-\nfore the I/O has completed; additional interfaces enable an app lication to\ndetermine whether various I/Os have completed.\nFor example, let us examine the interface provided on a Mac (other\nsystems have similar APIs). The APIs revolve around a basic str ucture,\nthe struct aiocb or AIO control block in common terminology . A\nsimpli\ufb01ed version of the structure looks like this (see the manua l pages\nfor more information):\nstruct aiocb {\nint aio_fildes; // File descriptor\noff_t aio_offset; // File offset\nvolatile void *aio_buf; // Location of buffer\nsize_t aio_nbytes; // Length of transfer\n};\nT o issue an asynchronous read to a \ufb01le, an application should \ufb01rst\n\ufb01ll in this structure with the relevant information: the \ufb01le de scriptor of\nthe \ufb01le to be read ( aio\nfildes), the offset within the \ufb01le ( aio offset)\nas well as the length of the request ( aio nbytes), and \ufb01nally the tar-\nget memory location into which the results of the read should be copi ed\n(aio buf).\nAfter this structure is \ufb01lled in, the application must issue t he asyn-\nchronous call to read the \ufb01le; on a Mac, this API is simply the asyn-\nchronous read API:\nint aio_read(struct aiocb *aiocbp);\nThis call tries to issue the I/O; if successful, it simply ret urns right\naway and the application (i.e., the event-based server) can c ontinue with\nits work.\nThere is one last piece of the puzzle we must solve, however . How can\nwe tell when an I/O is complete, and thus that the buffer (pointe d to by\naio buf) now has the requested data within it?\nOne last API is needed. On a Mac, it is referred to (somewhat conf us-\ningly) as aio error(). The API looks like this:\nint aio_error(const struct aiocb *aiocbp);\nThis system call checks whether the request referred to by aiocbp has\ncompleted. If it has, the routine returns success (indicated b y a zero);\nif not, EINPROGRESS is returned. Thus, for every outstanding asy n-\nchronous I/O, an application can periodically poll the system via a call\nto aio error() to determine whether said I/O has yet completed.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "There is one last piece of the puzzle we must solve, however . How can",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "piece",
          "puzzle",
          "must",
          "solve",
          "however"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand chronous read API: int aio_read(struct aiocb *aiocbp);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "chronous read api",
          "struct",
          "aiocb",
          "aiocbp"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a solution: asynchronous i/o",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "asynchronous"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "7 Another Problem: State Management",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "33.7 Another Problem: State Management\nAnother issue with the event-based approach is that such code is gen-\nerally more complicated to write than traditional thread-base d code. The\nreason is as follows: when an event handler issues an asynchronous I/O,\nit must package up some program state for the next event handler t o use\nwhen the I/O \ufb01nally completes; this additional work is not needed in\nthread-based programs, as the state the program needs is on the s tack of\nthe thread. Adya et al. call this work manual stack management, and it\nis fundamental to event-based programming [A+02].\nT o make this point more concrete, let\u2019s look at a simple example in\nwhich a thread-based server needs to read from a \ufb01le descriptor (fd) and,\nonce complete, write the data that it read from the \ufb01le to a network socket\ndescriptor ( sd). The code (ignoring error checking) looks like this:\nint rc = read(fd, buffer, size);\nrc = write(sd, buffer, size);\nAs you can see, in a multi-threaded program, doing this kind of work\nis trivial; when the read() \ufb01nally returns, the code immediately knows\nwhich socket to write to because that information is on the stack of the\nthread (in the variable sd).\nIn an event-based system, life is not so easy . T o perform the sam e task,\nwe\u2019d \ufb01rst issue the read asynchronously , using the AIO calls des cribed\nabove. Let\u2019s say we then periodically check for completion of the rea d\nusing the aio\nerror() call; when that call informs us that the read is\ncomplete, how does the event-based server know what to do?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Another issue with the event-based approach is that such code is gen-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "issue",
          "event",
          "based",
          "approach",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "is fundamental to event-based programming [A+02].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "event",
          "based",
          "programming"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "is trivial; when the read() \ufb01nally returns, the code immediately knows",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "trivial",
          "read",
          "returns",
          "code",
          "immediately",
          "knows"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "complete, how does the event-based server know what to do?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "complete",
          "event",
          "based",
          "server",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand looks like this: int rc = read(fd, buffer, size);",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "looks like this",
          "read",
          "buffer",
          "size"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand another problem: state management",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "problem",
          "state",
          "management"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the event-based server know what to do",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "event",
          "based",
          "server",
          "know"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 E V E N T-B A S E D CO N C U R R E N C Y (A D VA...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 E V E N T-B A S E D CO N C U R R E N C Y (A D VA N C E D)\nAS I D E : U N I X SI G N A L S\nA huge and fascinating infrastructure known as signals is present in all\nmodern U N I X variants. At its simplest, signals provide a way to commu-\nnicate with a process. Speci\ufb01cally , a signal can be delivered t o an appli-\ncation; doing so stops the application from whatever it is doing to r un a\nsignal handler , i.e., some code in the application to handle that signal.\nWhen \ufb01nished, the process just resumes its previous behavior .\nEach signal has a name, such as HUP (hang up), INT (interrupt), SEGV\n(segmentation violation), etc.; see the man page for details. In terestingly ,\nsometimes it is the kernel itself that does the signaling. For ex ample,\nwhen your program encounters a segmentation violation, the OS send s it\na SIGSEGV (prepending SIG to signal names is common); if your pro-\ngram is con\ufb01gured to catch that signal, you can actually run some code\nin response to this erroneous program behavior (which is helpful f or de-\nbugging). When a signal is sent to a process not con\ufb01gured to hand le a\nsignal, the default behavior is enacted; for SEGV , the process is killed.\nHere is a simple program that goes into an in\ufb01nite loop, but has \ufb01rs t set\nup a signal handler to catch SIGHUP:\nvoid handle(int arg) {\nprintf(\"stop wakin\u2019 me up...\\n\");\n}\nint main(int argc, char *argv[]) {\nsignal(SIGHUP, handle);\nwhile (1)\n; // doin\u2019 nothin\u2019 except catchin\u2019 some sigs\nreturn 0;\n}\nY ou can send signals to it with the kill command line tool (yes, this is an\nodd and aggressive name). Doing so will interrupt the main whil e loop\nin the program and run the handler code handle():\nprompt> ./main &\n[3] 36705\nprompt> kill -HUP 36705\nstop wakin\u2019 me up...\nprompt> kill -HUP 36705\nstop wakin\u2019 me up...\nThere is a lot more to learn about signals, so much that a single ch apter ,\nmuch less a single page, does not nearly suf\ufb01ce. As always, ther e is one\ngreat source: Stevens and Rago [SR05]. Read more if interested.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A huge and fascinating infrastructure known as signals is present in all",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "huge",
          "fascinating",
          "infrastructure",
          "known",
          "signals",
          "present"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "There is a lot more to learn about signals, so much that a single ch apter ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "signals",
          "much",
          "single",
          "apter"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "8 What Is Still Dif\ufb01cult With Events",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "33.8 What Is Still Dif\ufb01cult With Events\nThere are a few other dif\ufb01culties with the event-based approac h that\nwe should mention. For example, when systems moved from a single\nCPU to multiple CPUs, some of the simplicity of the event-based a p-\nproach disappeared. Speci\ufb01cally , in order to utilize more than on e CPU,\nthe event server has to run multiple event handlers in parall el; when do-\ning so, the usual synchronization problems (e.g., critical sect ions) arise,\nand the usual solutions (e.g., locks) must be employed. Thus, on mod -\nern multicore systems, simple event handling without locks is n o longer\npossible.\nAnother problem with the event-based approach is that it does not\nintegrate well with certain kinds of systems activity , such a s paging. For\nexample, if an event-handler page faults, it will block, and t hus the server\nwill not make progress until the page fault completes. Even thoug h the\nserver has been structured to avoid explicit blocking, this type of implicit\nblocking due to page faults is hard to avoid and thus can lead to l arge\nperformance problems when prevalent.\nA third issue is that event-based code can be hard to manage over time,\nas the exact semantics of various routines changes [A+02]. For ex ample,\nif a routine changes from non-blocking to blocking, the event hand ler\nthat calls that routine must also change to accommodate its new n ature,\nby ripping itself into two pieces. Because blocking is so disa strous for\nevent-based servers, a programmer must always be on the lookout for\nsuch changes in the semantics of the APIs each event uses.\nFinally , though asynchronous disk I/O is now possible on most plat-\nforms, it has taken a long time to get there [PDZ99], and it never quite\nintegrates with asynchronous network I/O in as simple and unifor m a\nmanner as you might think. For example, while one would simply lik e\nto use the select() interface to manage all outstanding I/Os, usually\nsome combination of select() for networking and the AIO calls for\ndisk I/O are required.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ing so, the usual synchronization problems (e.g., critical sect ions) arise,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "usual",
          "synchronization",
          "problems",
          "critical",
          "sect",
          "ions",
          "arise"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Another problem with the event-based approach is that it does not",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "problem",
          "event",
          "based",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand what is still dif\ufb01cult with events",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "still",
          "events"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "33",
    "title": "9 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "33.9 Summary\nW e\u2019ve presented a bare bones introduction to a different style of c on-\ncurrency based on events. Event-based servers give control of sc hedul-\ning to the application itself, but do so at some cost in complexity and\ndif\ufb01culty of integration with other aspects of modern systems (e. g., pag-\ning). Because of these challenges, no single approach has emer ged as\nbest; thus, both threads and events are likely to persist as tw o different\napproaches to the same concurrency problem for many years to come.\nRead some research papers (e.g., [A+02, PDZ99, vB+03, WCB01] ) or bet-\nter yet, write some event-based code, to learn more.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": ". Because of these challenges, no single approach has emer ged as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "challenges",
          "single",
          "approach",
          "emer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "approaches to the same concurrency problem for many years to come.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches",
          "concurrency",
          "problem",
          "many",
          "years",
          "come"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ter yet, write some event-based code, to learn more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "write",
          "event",
          "based",
          "code",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "EV E N T-B A S E D CO N C U R R E N C Y (A D VA N ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "EV E N T-B A S E D CO N C U R R E N C Y (A D VA N C E D) 11\nReferences\n[A+02] \u201cCooperative T ask Management Without Manual Stack Management\u201d b y Atul Adya,\nJon Howell, Marvin Theimer , William J. Bolosky , John R. Douceur . USEN IX A TC \u201902, Monterey ,\nCA, June 2002. This gem of a paper is the \ufb01rst to clearly articulate some of the dif\ufb01culties of event-based\nconcurrency, and suggests some simple solutions, as well explores the e ven crazier idea of combining\nthe two types of concurrency management into a single application!\n[FHK84] \u201cProgramming With Continuations\u201d by Daniel P . Friedman, Chri stopher T . Haynes,\nEugene E. Kohlbecker . In Program T ransformation and Programming Envir onments, Springer\nV erlag, 1984. The classic reference to this old idea from the world of programming langu ages. Now\nincreasingly popular in some modern languages.\n[N13] \u201cNode.js Documentation\u201d by the folks who built node.js. A vaila ble: nodejs.org/api.\nOne of the many cool new frameworks that help you readily build web services and applications. Every\nmodern systems hacker should be pro\ufb01cient in frameworks such as this one (and likely, more than one).\nSpend the time and do some development in one of these worlds and become an ex pert.\n[O96] \u201cWhy Threads Are A Bad Idea (for most purposes)\u201d by John Ousterhout. I nvited T alk\nat USENIX \u201996, San Diego, CA, January 1996. A great talk about how threads aren\u2019t a great match\nfor GUI-based applications (but the ideas are more general). Ousterhout formed m any of these opinions\nwhile he was developing T cl/Tk, a cool scripting language and toolkit that made it 100x easier to develop\nGUI-based applications than the state of the art at the time. While the Tk GUI toolkit live s on (in Python\nfor example), T cl seems to be slowly dying (unfortunately).\n[PDZ99] \u201cFlash: An Ef\ufb01cient and Portable W eb Server \u201d by Vivek S. Pai, Pe ter Druschel, Willy\nZwaenepoel. USENIX \u201999, Monterey , CA, June 1999. A pioneering paper on how to structure\nweb servers in the then-burgeoning Internet era. Read it to understand the basics as well as to see the\nauthors\u2019 ideas on how to build hybrids when support for asynchronous I/O is l acking.\n[SR05] \u201cAdvanced Programming in the U N I X Environment\u201d by W . Richard Stevens and Stephen\nA. Rago. Addison-W esley , 2005. Once again, we refer to the classic must-have-on-your-bookshelf\nbook of UN I X systems programming. If there is some detail you need to know, it is in here.\n[vB+03] \u201cCapriccio: Scalable Threads for Internet Services\u201d by Rob von Behren, Jeremy Condit,\nFeng Zhou, George C. Necula, Eric Brewer . SOSP \u201903, Lake George, N ew Y ork, October 2003.\nA paper about how to make threads work at extreme scale; a counter to all the event-base d work ongoing\nat the time.\n[WCB01] \u201cSEDA: An Architecture for W ell-Conditioned, Scalable Interne t Services\u201d by Matt\nW elsh, David Culler , and Eric Brewer . SOSP \u201901, Banff, Canada, Octobe r 2001. A nice twist\non event-based serving that combines threads, queues, and event-based hand ling into one streamlined\nwhole. Some of these ideas have found their way into the infrastructures of comp anies such as Google,\nAmazon, and elsewhere.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Spend the time and do some development in one of these worlds and become an ex pert.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "spend",
          "time",
          "development",
          "worlds",
          "become",
          "pert"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "while he was developing T cl/Tk, a cool scripting language and toolkit that made it 100x easier to develop",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developing",
          "cool",
          "scripting",
          "language",
          "toolkit",
          "made",
          "easier",
          "develop"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "web servers in the then-burgeoning Internet era. Read it to understand the basics as well as to see the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "servers",
          "burgeoning",
          "internet",
          "read",
          "understand",
          "basics",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "book of UN I X systems programming. If there is some detail you need to know, it is in here.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "book",
          "systems",
          "programming",
          "detail",
          "need",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Flash: An Ef\ufb01cient and Portable W eb Server \u201d by Vivek S. Pai, Pe ter Druschel, Willy",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "flash",
          "portable",
          "server",
          "vivek",
          "druschel",
          "willy"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Capriccio: Scalable Threads for Internet Services\u201d by Rob von Behren, Jeremy Condit,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "capriccio",
          "scalable",
          "threads",
          "internet",
          "services",
          "behren",
          "jeremy",
          "condit"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand SEDA: An Architecture for W ell-Conditioned, Scalable Interne t Services\u201d by Matt",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "seda",
          "architecture",
          "conditioned",
          "scalable",
          "interne",
          "services",
          "matt"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "First, write a simple server that can accept and serve TCP c onnec-",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "1. First, write a simple server that can accept and serve TCP c onnec-\ntions. Y ou\u2019ll have to poke around the Internet a bit if you don\u2019t\nalready know how to do this. Build this to serve exactly one re-\nquest at a time; have each request be very simple, e.g., to get the\ncurrent time of day .\n2. Now , add the select() interface. Build a main program that can\naccept multiple connections, and an event loop that checks which\n\ufb01le descriptors have data on them, and then read and process those\nrequests. Make sure to carefully test that you are using select()\ncorrectly .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "already know how to do this. Build this to serve exactly one re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "already",
          "know",
          "build",
          "serve",
          "exactly"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Next, let\u2019s make the requests a little more interesting, to m imic a",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "3. Next, let\u2019s make the requests a little more interesting, to m imic a\nsimple web or \ufb01le server . Each request should be to read the con-\ntents of a \ufb01le (named in the request), and the server should resp ond\nby reading the \ufb01le into a buffer , and then returning the conten ts\nto the client. Use the standard open(), read(), close() system\ncalls to implement this feature. Be a little careful here: if you leave\nthis running for a long time, someone may \ufb01gure out how to use it\nto read all the \ufb01les on your computer!",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "calls to implement this feature. Be a little careful here: if you leave",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "calls",
          "implement",
          "feature",
          "little",
          "careful",
          "leave"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Now , instead of using standard I/O system calls, use the asyn -",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "4. Now , instead of using standard I/O system calls, use the asyn -\nchronous I/O interfaces as described in the chapter . How hard wa s\nit to incorporate asynchronous interfaces into your program?\n5. For fun, add some signal handling to your code. One common use\nof signals is to poke a server to reload some kind of con\ufb01guration\n\ufb01le, or take some other kind of administrative action. Perhaps one\nnatural way to play around with this is to add a user-level \ufb01le c ache\nto your server , which stores recently accessed \ufb01les. Implemen t a\nsignal handler that clears the cache when the signal is sent t o the\nserver process.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "chronous I/O interfaces as described in the chapter . How hard wa s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "chronous",
          "interfaces",
          "described",
          "chapter",
          "hard"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Finally , we have the hard part: how can you tell if the effort to build",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "6. Finally , we have the hard part: how can you tell if the effort to build\nan asynchronous, event-based approach are worth it? Can you cre-\nate an experiment to show the bene\ufb01ts? How much implementa-\ntion complexity did your approach add?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "an asynchronous, event-based approach are worth it? Can you cre-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "asynchronous",
          "event",
          "based",
          "approach",
          "worth"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ate an experiment to show the bene\ufb01ts? How much implementa-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "experiment",
          "show",
          "much",
          "implementa"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "tion complexity did your approach add?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tion",
          "complexity",
          "approach"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "34\nSummary Dialogue on Concurrency\nProfessor: So, does your head hurt now?\nStudent: (taking two Motrin tablets) Well, some. It\u2019s hard to think about all t he\nways threads can interleave.\nProfessor: Indeed it is. I am always amazed that when concurrent execution is\ninvolved, just a few lines of code can become nearly impossible to unders tand.\nStudent: Me too! It\u2019s kind of embarrassing, as a Computer Scientist, not to be\nable to make sense of \ufb01ve lines of code.\nProfessor: Oh, don\u2019t feel too badly. If you look through the \ufb01rst papers on con -\ncurrent algorithms, they are sometimes wrong! And the authors o ften professors!\nStudent: (gasps) Professors can be ... umm... wrong?\nProfessor: Y es, it is true. Though don\u2019t tell anybody \u2014 it\u2019s one of our trade\nsecrets.\nStudent: I am sworn to secrecy. But if concurrent code is so hard to think ab out,\nand so hard to get right, how are we supposed to write correct con current code?\nProfessor: Well that is the real question, isn\u2019t it? I think it starts with a few\nsimple things. First, keep it simple! Avoid complex interactions betwee n threads,\nand use well-known and tried-and-true ways to manage thread inte ractions.\nStudent: Like simple locking, and maybe a producer-consumer queue?\nProfessor: Exactly! Those are common paradigms, and you should be able to\nproduce the working solutions given what you\u2019ve learned. Second, o nly use con-\ncurrency when absolutely needed; avoid it if at all possible. There is n othing\nworse than premature optimization of a program.\nStudent: I see \u2014 why add threads if you don\u2019t need them?\nProfessor: Exactly. Third, if you really need parallelism, seek it in other sim-\npli\ufb01ed forms. For example, the Map-Reduce method for writing parallel d ata\nanalysis code is an excellent example of achieving parallelism without hav ing to\nhandle any of the horri\ufb01c complexities of locks, condition variables, an d the other\nnasty things we\u2019ve talked about.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "able to make sense of \ufb01ve lines of code.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "make",
          "sense",
          "lines",
          "code"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "current algorithms, they are sometimes wrong! And the authors o ften professors!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "current",
          "algorithms",
          "sometimes",
          "wrong",
          "authors",
          "ften",
          "professors"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "and use well-known and tried-and-true ways to manage thread inte ractions.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "well",
          "known",
          "tried",
          "true",
          "ways",
          "manage",
          "thread",
          "inte"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Professor: Exactly! Those are common paradigms, and you should be able to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "exactly",
          "common",
          "paradigms",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "produce the working solutions given what you\u2019ve learned. Second, o nly use con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "produce",
          "working",
          "solutions",
          "given",
          "learned",
          "second"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "pli\ufb01ed forms. For example, the Map-Reduce method for writing parallel d ata",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "forms",
          "example",
          "reduce",
          "method",
          "writing",
          "parallel"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: (taking two Motrin tablets) Well, some. It\u2019s hard to think about all t he",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "taking",
          "motrin",
          "tablets",
          "well",
          "hard",
          "think"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: Indeed it is. I am always amazed that when concurrent execution is",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "indeed",
          "always",
          "amazed",
          "concurrent",
          "execution"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Student: Me too! It\u2019s kind of embarrassing, as a Computer Scientist, not to be",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "kind",
          "embarrassing",
          "computer",
          "scientist"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Oh, don\u2019t feel too badly. If you look through the \ufb01rst papers on con -",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "feel",
          "badly",
          "look",
          "papers"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Student: (gasps) Professors can be ... umm... wrong?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "gasps",
          "professors",
          "wrong"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Professor: Y es, it is true. Though don\u2019t tell anybody \u2014 it\u2019s one of our trade",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "true",
          "though",
          "tell",
          "anybody",
          "trade"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Student: I am sworn to secrecy. But if concurrent code is so hard to think ab out,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sworn",
          "secrecy",
          "concurrent",
          "code",
          "hard",
          "think"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Professor: Well that is the real question, isn\u2019t it? I think it starts with a few",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "real",
          "question",
          "think",
          "starts"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S U M M A RY DI A L O G U E O N CO N C U R R E N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S U M M A RY DI A L O G U E O N CO N C U R R E N C Y\nStudent: Map-Reduce, huh? Sounds interesting \u2014 I\u2019ll have to read more abou t\nit on my own.\nProfessor: Good! Y ou should. In the end, you\u2019ll have to do a lot of that, as\nwhat we learn together can only serve as the barest introduction t o the wealth\nof knowledge that is out there. Read, read, and read some more! A nd then try\nthings out, write some code, and then write some more too. And pra ctice more,\ntoo; beyond what\u2019s in this book, there are plenty of other resour ces out there 1 .\nAs Gladwell talks about in his book \u201cOutliers\u201d, you need to put roughly 10,000\nhours into something in order to become a real expert. Y ou can\u2019t d o that all inside\nof class time!\nStudent: Wow, I\u2019m not sure if that is depressing, or uplifting. But I\u2019ll assume\nthe latter , and get to work! Time to write some more concurrent co de...\n1 Here is a link to one, in gami\ufb01ed form: https://deadlockempire.github.io/\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "what we learn together can only serve as the barest introduction t o the wealth",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "together",
          "serve",
          "barest",
          "introduction",
          "wealth"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of knowledge that is out there. Read, read, and read some more! A nd then try",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowledge",
          "read",
          "read",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Professor: Good! Y ou should. In the end, you\u2019ll have to do a lot of that, as",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Wow, I\u2019m not sure if that is depressing, or uplifting. But I\u2019ll assume",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sure",
          "depressing",
          "uplifting",
          "assume"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand in gami\ufb01ed form: https://deadlockempire.github.io/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "in gami\ufb01ed form",
          "https",
          "deadlockempire",
          "github"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "Part III\nPersistence\n1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "35\nA Dialogue on Persistence\nProfessor: And thus we reach the third of our four ... err ... three pillars of\noperating systems: persistence.\nStudent: Did you say there were three pillars, or four? What is the fourth?\nProfessor: No. Just three, young student, just three. T rying to keep it simple\nhere.\nStudent: OK, \ufb01ne. But what is persistence, oh \ufb01ne and noble professor?\nProfessor: Actually, you probably know what it means in the traditional sense,\nright? As the dictionary would say: \u201ca \ufb01rm or obstinate continuance in a course\nof action in spite of dif\ufb01culty or opposition.\u201d\nStudent: It\u2019s kind of like taking your class: some obstinance required.\nProfessor: Ha! Y es. But persistence here means something else. Let me explain .\nImagine you are outside, in a \ufb01eld, and you pick a \u2014\nStudent: (interrupting) I know! A peach! From a peach tree!\nProfessor: I was going to say apple, from an apple tree. Oh well; we\u2019ll do it your\nway, I guess.\nStudent: (stares blankly)\nProfessor: Anyhow, you pick a peach; in fact, you pick many many peaches,\nbut you want to make them last for a long time. Winter is hard and cruel in\nWisconsin, after all. What do you do?\nStudent: Well, I think there are some different things you can do. Y ou can pickle\nit! Or bake a pie. Or make a jam of some kind. Lots of fun!\nProfessor: Fun? Well, maybe. Certainly, you have to do a lot more work to make\nthe peach persist. And so it is with information as well; making information\npersist, despite computer crashes, disk failures, or power outage s is a tough and\ninteresting challenge.\nStudent: Nice segue; you\u2019re getting quite good at that.\nProfessor: Thanks! A professor can always use a few kind words, you know.\n3",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Professor: Actually, you probably know what it means in the traditional sense,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "actually",
          "probably",
          "know",
          "means",
          "traditional",
          "sense"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Professor: Ha! Y es. But persistence here means something else. Let me explain .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "persistence",
          "means",
          "something",
          "else",
          "explain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Student: (interrupting) I know! A peach! From a peach tree!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "interrupting",
          "know",
          "peach",
          "peach",
          "tree"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Professor: Thanks! A professor can always use a few kind words, you know.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "thanks",
          "professor",
          "always",
          "kind",
          "words",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand But persistence here: something else. Let me explain .",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "but persistence here",
          "something",
          "else",
          "explain"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Did you say there were three pillars, or four? What is the fourth?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "three",
          "pillars",
          "four",
          "fourth"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: No. Just three, young student, just three. T rying to keep it simple",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "three",
          "young",
          "student",
          "three",
          "rying",
          "keep",
          "simple"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: OK, \ufb01ne. But what is persistence, oh \ufb01ne and noble professor?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "persistence",
          "noble",
          "professor"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Student: It\u2019s kind of like taking your class: some obstinance required.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "kind",
          "like",
          "taking",
          "class",
          "obstinance",
          "required"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_2",
        "text": "understand persistence, oh \ufb01ne and noble professor",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "persistence",
          "noble",
          "professor"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 A D I A L O G U E O NPE R S I S T E N C E",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 A D I A L O G U E O NPE R S I S T E N C E\nStudent: I\u2019ll try to remember that. I guess it\u2019s time to stop talking peaches, and\nstart talking computers?\nProfessor: Y es, it is that time...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand Professor: Y es, it is that time...",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "time"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "1 System Architecture",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "36.1 System Architecture\nT o begin our discussion, let\u2019s look at a \u201cclassical\u201d diagram of a typ ical\nsystem (Figure 36.1, page 2). The picture shows a single CPU at tached\nto the main memory of the system via some kind of memory bus or in-\nterconnect. Some devices are connected to the system via a genera l I/O\nbus, which in many modern systems would be PCI (or one of its many\nderivatives); graphics and some other higher-performance I/O devices\nmight be found here. Finally , even lower down are one or more of what\nwe call a peripheral bus , such as SCSI, SA T A, or USB. These connect\nslow devices to the system, including disks, mice, and keyboards.\nOne question you might ask is: why do we need a hierarchical stru c-\nture like this? Put simply: physics, and cost. The faster a bus is, the\nshorter it must be; thus, a high-performance memory bus does not ha ve\nmuch room to plug devices and such into it. In addition, engineer ing\na bus for high performance is quite costly . Thus, system designe rs have\nadopted this hierarchical approach, where components that dema nd high\nperformance (such as the graphics card) are nearer the CPU. Low er per-\nformance components are further away . The bene\ufb01ts of placing dis ks and\nother slow devices on a peripheral bus are manifold; in particula r , you\ncan place a large number of devices on it.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "a bus for high performance is quite costly . Thus, system designe rs have",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "high",
          "performance",
          "quite",
          "costly",
          "thus",
          "system",
          "designe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "adopted this hierarchical approach, where components that dema nd high",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "adopted",
          "hierarchical",
          "approach",
          "components",
          "dema",
          "high"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Put simply: physics, and cost. The faster a bus is, the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "put simply",
          "physics",
          "cost",
          "faster"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand system architecture",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "architecture"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 I/O D E V I C E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 I/O D E V I C E S\nGraphics\nMemoryCPU\nMemory Bus\n(proprietary)\nGeneral I/O Bus\n(e.g., PCI)\nPeripheral I/O Bus\n(e.g., SCSI, SATA, USB)\nFigure 36.1: Prototypical System Architecture\nOf course, modern systems increasingly use specialized chips ets and\nfaster point-to-point interconnects to improve performance. Fig ure 36.2\n(page 3) shows an approximate diagram of Intel\u2019s Z270 Chipset [H1 7].\nAlong the top, the CPU connects most closely to the memory system,\nbut also has a high-performance connection to the graphics card (and\nthus, the display) to enable gaming (oh, the horror!) and other gra phics-\nintensive applications.\nThe CPU connects to an I/O chip via Intel\u2019s proprietary DMI (Direct\nMedia Interface ), and the rest of the devices connect to this chip via a\nnumber of different interconnects. On the right, one or more hard d rives\nconnect to the system via the eSA T Ainterface; A T A(the A T Attachment,\nin reference to providing connection to the IBM PC A T), then SA T A(for\nSerial A T A), and now eSA T A (for external SA T A) represent an evolu-\ntion of storage interfaces over the past decades, with each step f orward\nincreasing performance to keep pace with modern storage device s.\nBelow the I/O chip are a number of USB (Universal Serial Bus ) con-\nnections, which in this depiction enable a keyboard and mouse to b e at-\ntached to the computer . On many modern systems, USB is used for low\nperformance devices such as these.\nFinally , on the left, other higher performance devices can be con nected\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: Prototypical System Architecture",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "prototypical",
          "system",
          "architecture"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "2 A Canonical Device",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "36.2 A Canonical Device\nLet us now look at a canonical device (not a real one), and use this\ndevice to drive our understanding of some of the machinery requir ed to\nmake device interaction ef\ufb01cient. From Figure 36.3 (page 4), w e can see\nthat a device has two important components. The \ufb01rst is the hardw are\ninterface it presents to the rest of the system. Just like a piece of softwar e,\nhardware must also present some kind of interface that allows th e system\nsoftware to control its operation. Thus, all devices have some spec i\ufb01ed\ninterface and protocol for typical interaction.\nThe second part of any device is its internal structure . This part of\nthe device is implementation speci\ufb01c and is responsible for imp lement-\ning the abstraction the device presents to the system. V ery si mple devices\nwill have one or a few hardware chips to implement their function ality;\nmore complex devices will include a simple CPU, some general pur pose\nmemory , and other device-speci\ufb01c chips to get their job done. For e xam-\nple, modern RAID controllers might consist of hundreds of thousands of\nlines of \ufb01rmware (i.e., software within a hardware device) to implement\nits functionality .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "device to drive our understanding of some of the machinery requir ed to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "device",
          "drive",
          "understanding",
          "machinery",
          "requir"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "that a device has two important components. The \ufb01rst is the hardw are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "device",
          "important",
          "components",
          "hardw"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the device is implementation speci\ufb01c and is responsible for imp lement-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "device",
          "implementation",
          "responsible",
          "lement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "will have one or a few hardware chips to implement their function ality;",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hardware",
          "chips",
          "implement",
          "function",
          "ality"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "lines of \ufb01rmware (i.e., software within a hardware device) to implement",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "lines",
          "software",
          "within",
          "hardware",
          "device",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a canonical device",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "canonical",
          "device"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "3 The Canonical Protocol",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "36.3 The Canonical Protocol\nIn the picture above, the (simpli\ufb01ed) device interface is comp rised of\nthree registers: a status register , which can be read to see the current sta-\ntus of the device; a command register , to tell the device to perform a cer-\ntain task; and a data register to pass data to the device, or get data from\nthe device. By reading and writing these registers, the opera ting system\ncan control device behavior .\nLet us now describe a typical interaction that the OS might have with\nthe device in order to get the device to do something on its behalf . The\nprotocol is as follows:\nWhile (STATUS == BUSY)\n; // wait until device is not busy\nWrite data to DATA register\nWrite command to COMMAND register\n(starts the device and executes the command)\nWhile (STATUS == BUSY)\n; // wait until device is done with your request\nThe protocol has four steps. In the \ufb01rst, the OS waits until the dev ice is\nready to receive a command by repeatedly reading the status re gister; we\ncall this polling the device (basically , just asking it what is going on). Sec-\nond, the OS sends some data down to the data register; one can imagi ne\nthat if this were a disk, for example, that multiple writes woul d need to\ntake place to transfer a disk block (say 4KB) to the device. Whe n the main\nCPU is involved with the data movement (as in this example protocol ),\nwe refer to it as programmed I/O (PIO) . Third, the OS writes a command\nto the command register; doing so implicitly lets the device kn ow that\nboth the data is present and that it should begin working on the com-\nmand. Finally , the OS waits for the device to \ufb01nish by again poll ing it\nin a loop, waiting to see if it is \ufb01nished (it may then get an error c ode to\nindicate success or failure).\nThis basic protocol has the positive aspect of being simple and work -\ning. However , there are some inef\ufb01ciencies and inconveniences involved.\nThe \ufb01rst problem you might notice in the protocol is that polling seem s\ninef\ufb01cient; speci\ufb01cally , it wastes a great deal of CPU time ju st waiting for\nthe (potentially slow) device to complete its activity , instea d of switching\nto another ready process and thus better utilizing the CPU.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let us now describe a typical interaction that the OS might have with",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describe",
          "typical",
          "interaction",
          "might"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the canonical protocol",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "canonical",
          "protocol"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "4 Lowering CPU Overhead With Interrupts",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "36.4 Lowering CPU Overhead With Interrupts\nThe invention that many engineers came upon years ago to improve\nthis interaction is something we\u2019ve seen already: the interrupt. Instead of\npolling the device repeatedly , the OS can issue a request, put the calling\nprocess to sleep, and context switch to another task. When the de vice\nis \ufb01nally \ufb01nished with the operation, it will raise a hardware i nterrupt,\ncausing the CPU to jump into the OS at a predetermined interrupt service\nroutine (ISR) or more simply an interrupt handler . The handler is just a\npiece of operating system code that will \ufb01nish the request (for ex ample,\nby reading data and perhaps an error code from the device) and wak e the\nprocess waiting for the I/O, which can then proceed as desired.\nInterrupts thus allow for overlap of computation and I/O, which is\nkey for improved utilization. This timeline shows the problem:\nCPU\nDisk 1 1 1 1 1\n1 1 1 1 1 p p p p p 1 1 1 1 1\nIn the diagram, Process 1 runs on the CPU for some time (indicated b y\na repeated 1 on the CPU line), and then issues an I/O request to the disk\nto read some data. Without interrupts, the system simply spins , polling\nthe status of the device repeatedly until the I/O is complete (i ndicated by\na p). The disk services the request and \ufb01nally Process 1 can run ag ain.\nIf instead we utilize interrupts and allow for overlap, the OS ca n do\nsomething else while waiting for the disk:\nCPU\nDisk 1 1 1 1 1\n1 1 1 1 1 2 2 2 2 2 1 1 1 1 1\nIn this example, the OS runs Process 2 on the CPU while the disk se r-\nvices Process 1\u2019s request. When the disk request is \ufb01nished, an interrupt\noccurs, and the OS wakes up Process 1 and runs it again. Thus, both the\nCPU and the disk are properly utilized during the middle stret ch of time.\nNote that using interrupts is not always the best solution. For example,\nimagine a device that performs its tasks very quickly: the \ufb01rs t poll usually\n\ufb01nds the device to be done with task. Using an interrupt in this case will\nactually slow down the system: switching to another process, handling the\ninterrupt, and switching back to the issuing process is expen sive. Thus, if\na device is fast, it may be best to poll; if it is slow , interrupts , which allow\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand ve seen already: the interrupt. Instead of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ve seen already",
          "interrupt",
          "instead"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand lowering cpu overhead with interrupts",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "lowering",
          "overhead",
          "interrupts"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "5 More Ef\ufb01cient Data Movement With DMA",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "36.5 More Ef\ufb01cient Data Movement With DMA\nUnfortunately , there is one other aspect of our canonical protocol tha t\nrequires our attention. In particular , when using programmed I /O (PIO)\nto transfer a large chunk of data to a device, the CPU is once agai n over-\nburdened with a rather trivial task, and thus wastes a lot of tim e and\neffort that could better be spent running other processes. This t imeline\nillustrates the problem:\nCPU\nDisk 1 1 1 1 1\n1 1 1 1 1 c c c 2 2 2 2 2 1 1\nIn the timeline, Process 1 is running and then wishes to write s ome data to\nthe disk. It then initiates the I/O, which must copy the data fr om memory\nto the device explicitly , one word at a time (marked c in the diagram).\nWhen the copy is complete, the I/O begins on the disk and the CPU ca n\n\ufb01nally be used for something else.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand more ef\ufb01cient data movement with dma",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "data",
          "movement"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "6 Methods Of Device Interaction",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "36.6 Methods Of Device Interaction\nNow that we have some sense of the ef\ufb01ciency issues involved with\nperforming I/O, there are a few other problems we need to handle t o\nincorporate devices into modern systems. One problem you may have\nnoticed thus far: we have not really said anything about how the OS ac-\ntually communicates with the device! Thus, the problem:\nTH E CR U X : H O W TO CO M M U N I C AT E WI T H DE V I C E S\nHow should the hardware communicate with a device? Should there\nbe explicit instructions? Or are there other ways to do it?\nOver time, two primary methods of device communication have de-\nveloped. The \ufb01rst, oldest method (used by IBM mainframes for many\nyears) is to have explicit I/O instructions . These instructions specify a\nway for the OS to send data to speci\ufb01c device registers and thus allow the\nconstruction of the protocols described above.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Methods Of Device Interaction",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "methods",
          "device",
          "interaction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Over time, two primary methods of device communication have de-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "time",
          "primary",
          "methods",
          "device",
          "communication"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "veloped. The \ufb01rst, oldest method (used by IBM mainframes for many",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "veloped",
          "oldest",
          "method",
          "used",
          "mainframes",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "construction of the protocols described above.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "construction",
          "protocols",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand the problem: TH E CR U X : H O W TO CO M M U N I C AT E WI T H DE V I C E S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the problem"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand methods of device interaction",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "methods",
          "device",
          "interaction"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "7 Fitting Into The OS: The Device Driver",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "36.7 Fitting Into The OS: The Device Driver\nOne \ufb01nal problem we will discuss: how to \ufb01t devices, each of which\nhave very speci\ufb01c interfaces, into the OS, which we would like t o keep\nas general as possible. For example, consider a \ufb01le system. W e\u2019d l ike\nto build a \ufb01le system that worked on top of SCSI disks, IDE disks, USB\nkeychain drives, and so forth, and we\u2019d like the \ufb01le system to be relatively\noblivious to all of the details of how to issue a read or write request to\nthese different types of drives. Thus, our problem:\nTH E CR U X : H O W TO BU I L D A D E V I C E -N E U T R A L OS\nHow can we keep most of the OS device-neutral, thus hiding the de-\ntails of device interactions from major OS subsystems?\nThe problem is solved through the age-old technique of abstraction.\nAt the lowest level, a piece of software in the OS must know in detai l\nhow a device works. W e call this piece of software a device driver , and\nany speci\ufb01cs of device interaction are encapsulated within.\nLet us see how this abstraction might help OS design and impleme n-\ntation by examining the Linux \ufb01le system software stack. Figur e 36.4 is\na rough and approximate depiction of the Linux software organizati on.\nAs you can see from the diagram, a \ufb01le system (and certainly , an a ppli-\ncation above) is completely oblivious to the speci\ufb01cs of which disk class\nit is using; it simply issues block read and write requests to t he generic\nblock layer , which routes them to the appropriate device driver , which\nhandles the details of issuing the speci\ufb01c request. Although s impli\ufb01ed,\nthe diagram shows how such detail can be hidden from most of the OS.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The problem is solved through the age-old technique of abstraction.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "solved",
          "technique",
          "abstraction"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "At the lowest level, a piece of software in the OS must know in detai l",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lowest",
          "level",
          "piece",
          "software",
          "must",
          "know",
          "detai"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Let us see how this abstraction might help OS design and impleme n-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "abstraction",
          "might",
          "help",
          "design",
          "impleme"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand our problem: TH E CR U X : H O W TO BU I L D A D E V I C E -N E U T R A L OS",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "our problem"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand fitting into the os: the device driver",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fitting",
          "device",
          "driver"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "8 Case Study: A Simple IDE Disk Driver",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "36.8 Case Study: A Simple IDE Disk Driver\nT o dig a little deeper here, let\u2019s take a quick look at an actual de vice: an\nIDE disk drive [L94]. W e summarize the protocol as described in t his ref-\nerence [W10]; we\u2019ll also peek at the xv6 source code for a simple ex ample\nof a working IDE driver [CK+08].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "IDE disk drive [L94]. W e summarize the protocol as described in t his ref-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "drive",
          "summarize",
          "protocol",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 8 Case Study: A Simple IDE Disk Driver",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8 case study",
          "simple",
          "disk",
          "driver"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 I/O D E V I C E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 I/O D E V I C E S\nControl Register:\nAddress 0x3F6 = 0x08 (0000 1RE0): R=reset,\nE=0 means \"enable interrupt\"\nCommand Block Registers:\nAddress 0x1F0 = Data Port\nAddress 0x1F1 = Error\nAddress 0x1F2 = Sector Count\nAddress 0x1F3 = LBA low byte\nAddress 0x1F4 = LBA mid byte\nAddress 0x1F5 = LBA hi byte\nAddress 0x1F6 = 1B1D TOP4LBA: B=LBA, D=drive\nAddress 0x1F7 = Command/status\nStatus Register (Address 0x1F7):\n7 6 5 4 3 2 1 0\nBUSY READY FAULT SEEK DRQ CORR IDDEX ERROR\nError Register (Address 0x1F1): (check when ERROR==1)\n7 6 5 4 3 2 1 0\nBBK UNC MC IDNF MCR ABRT T0NF AMNF\nBBK = Bad Block\nUNC = Uncorrectable data error\nMC = Media Changed\nIDNF = ID mark Not Found\nMCR = Media Change Requested\nABRT = Command aborted\nT0NF = Track 0 Not Found\nAMNF = Address Mark Not Found\nFigure 36.5: The IDE Interface\nAn IDE disk presents a simple interface to the system, consist ing of\nfour types of register: control, command block, status, and error . T hese\nregisters are available by reading or writing to speci\ufb01c \u201cI/O addresses\u201d\n(such as 0x3F6 below) using (on x86) the in and out I/O instructions.\nThe basic protocol to interact with the device is as follows, assum ing\nit has already been initialized.\n\u2022 W ait for drive to be ready . Read Status Register (0x1F7) until drive\nis READY and not BUSY .\n\u2022 W rite parameters to command registers. W rite the sector count,\nlogical block address (LBA) of the sectors to be accessed, and dri ve\nnumber (master=0x00 or slave=0x10, as IDE permits just two dr ives)\nto command registers (0x1F2-0x1F6).\n\u2022 Start the I/O. by issuing read/write to command register . W rite\nREAD\u2014WRITE command to command register (0x1F7).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand Command Block Registers: Address 0x1F0 = Data Port",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "command block registers",
          "address",
          "data",
          "port"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand w ait for drive to be ready . read status register (0x1f7) until drive",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "drive",
          "ready",
          "read",
          "status",
          "register",
          "drive"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand w rite parameters to command registers. w rite the sector count,",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "parameters",
          "command",
          "registers",
          "rite",
          "sector",
          "count"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand start the i/o. by issuing read/write to command register . w rite",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "issuing",
          "read",
          "write",
          "command",
          "register",
          "rite"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "9 Historical Notes",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "36.9 Historical Notes\nBefore ending, we include a brief historical note on the origin of som e\nof these fundamental ideas. If you are interested in learning m ore, read\nSmotherman\u2019s excellent summary [S08].\nInterrupts are an ancient idea, existing on the earliest of mac hines. For\nexample, the UNIV AC in the early 1950\u2019s had some form of interrupt vec-\ntoring, although it is unclear in exactly which year this featu re was avail-\nable [S08]. Sadly , even in its infancy , we are beginning to lose t he origins\nof computing history .\nThere is also some debate as to which machine \ufb01rst introduced th e idea\nof DMA. For example, Knuth and others point to the DYSEAC (a \u201cmo-\nbile\u201d machine, which at the time meant it could be hauled in a tr ailer),\nwhereas others think the IBM SAGE may have been the \ufb01rst [S08]. Ei -\nther way , by the mid 50\u2019s, systems with I/O devices that communi cated\ndirectly with memory and interrupted the CPU when \ufb01nished exi sted.\nThe history here is dif\ufb01cult to trace because the inventions ar e tied to\nreal, and sometimes obscure, machines. For example, some think t hat the\nLincoln Labs TX-2 machine was \ufb01rst with vectored interrupts [S0 8], but\nthis is hardly clear .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "of these fundamental ideas. If you are interested in learning m ore, read",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "ideas",
          "interested",
          "learning",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand historical notes",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "historical",
          "notes"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 I/O D E V I C E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 I/O D E V I C E S\nstatic int ide_wait_ready() {\nwhile (((int r = inb(0x1f7)) & IDE_BSY) || !(r & IDE_DRDY))\n; // loop until drive isn\u2019t busy\n}\nstatic void ide_start_request(struct buf *b) {\nide_wait_ready();\noutb(0x3f6, 0); // generate interrupt\noutb(0x1f2, 1); // how many sectors?\noutb(0x1f3, b->sector & 0xff); // LBA goes here ...\noutb(0x1f4, (b->sector >> 8) & 0xff); // ... and here\noutb(0x1f5, (b->sector >> 16) & 0xff); // ... and here!\noutb(0x1f6, 0xe0 | ((b->dev&1)<<4) | ((b->sector>>24)&0x0f));\nif(b->flags & B_DIRTY){\noutb(0x1f7, IDE_CMD_WRITE); // this is a WRITE\noutsl(0x1f0, b->data, 512/4); // transfer data too!\n} else {\noutb(0x1f7, IDE_CMD_READ); // this is a READ (no data)\n}\n}\nvoid ide_rw(struct buf *b) {\nacquire(&ide_lock);\nfor (struct buf **pp = &ide_queue; *pp; pp=&(*pp)->qnext)\n; // walk queue\n*pp = b; // add request to end\nif (ide_queue == b) // if q is empty\nide_start_request(b); // send req to disk\nwhile ((b->flags & (B_VALID|B_DIRTY)) != B_VALID)\nsleep(b, &ide_lock); // wait for completion\nrelease(&ide_lock);\n}\nvoid ide_intr() {\nstruct buf *b;\nacquire(&ide_lock);\nif (!(b->flags & B_DIRTY) && ide_wait_ready() >= 0)\ninsl(0x1f0, b->data, 512/4); // if READ: get data\nb->flags |= B_VALID;\nb->flags &= \u02dcB_DIRTY;\nwakeup(b); // wake waiting process\nif ((ide_queue = b->qnext) != 0) // start next request\nide_start_request(ide_queue); // (if one exists)\nrelease(&ide_lock);\n}\nFigure 36.6: The xv6 IDE Disk Driver (Simpli\ufb01ed)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand 6: The xv6 IDE Disk Driver (Simpli\ufb01ed)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "disk",
          "driver"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand pp = b; // add request to end",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "request"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "36",
    "title": "10 Summary",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "36.10 Summary\nY ou should now have a very basic understanding of how an OS inter-\nacts with a device. T wo techniques, the interrupt and DMA, ha ve been\nintroduced to help with device ef\ufb01ciency , and two approaches t o access-\ning device registers, explicit I/O instructions and memory-m apped I/O,\nhave been described. Finally , the notion of a device driver has b een pre-\nsented, showing how the OS itself can encapsulate low-level det ails and\nthus make it easier to build the rest of the OS in a device-neutr al fashion.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Y ou should now have a very basic understanding of how an OS inter-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "understanding",
          "inter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "acts with a device. T wo techniques, the interrupt and DMA, ha ve been",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "acts",
          "device",
          "techniques",
          "interrupt"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "introduced to help with device ef\ufb01ciency , and two approaches t o access-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "introduced",
          "help",
          "device",
          "approaches",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "have been described. Finally , the notion of a device driver has b een pre-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "described",
          "finally",
          "notion",
          "device",
          "driver"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2008",
    "title": "Our own work on building a tool to \ufb01nd code in Linux \ufb01le systems that does not han dle error",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "2008. Our own work on building a tool to \ufb01nd code in Linux \ufb01le systems that does not han dle error\nreturn properly. We found hundreds and hundreds of bugs, many of whic h have now been \ufb01xed.\n[H17] \u201cIntel Core i7-7700K review: Kaby Lake Debuts for Desktop\u201d by Joel Hruska. January 3,\n2017. www.extremetech.com/extreme/241950-intels-core-i7-7700k-reviewed-kaby\n-lake-debuts-desktop. An in-depth review of a recent Intel chipset, including CPUs and the\nI/O subsystem.\n[H18] \u201cHacker News\u201d by Many contributors. A vailable: https://news. ycombinator .com. One\nof the better aggregrators for tech-related stuff. Once back in 2014, this book be came a highly-ranked\nentry, leading to 1 million chapter downloads in just one day! Sadly, we have yet to re-experience such\na high.\n[L94] \u201cA T Attachment Interface for Disk Drives\u201d by Lawrence J. Lamers. Re ference number:\nANSI X3.221, 1994. A vailable: ftp://ftp.t10.org/t13/project/d0791r4c-ATA-1.pdf.\nA rather dry document about device interfaces. Read it at your own peril.\n[MR96] \u201cEliminating Receive Livelock in an Interrupt-driven Kernel\u201d by Jeffrey Mogul, K. K.\nRamakrishnan. USENIX \u201996, San Diego, CA, January 1996. Mogul and colleagues did a great deal\nof pioneering work on web server network performance. This paper is but one example.\n[S08] \u201cInterrupts\u201d by Mark Smotherman. July \u201908. A vailable: http://people.cs.clemson.edu/\n\u02dcmark/interrupts.html. A treasure trove of information on the history of interrupts, DMA, and\nrelated early ideas in computing.\n[S03] \u201cImproving the Reliability of Commodity Operating Systems \u201d by Michael M. Swift, Brian\nN. Bershad, Henry M. Levy . SOSP \u201903. Swift\u2019s work revived interest in a more microkernel-like\napproach to operating systems; minimally, it \ufb01nally gave some good reasons why address-space based\nprotection could be useful in a modern OS.\n[W10] \u201cHard Disk Driver \u201d by W ashington State Course Homepage. A vailable online at this\nsite: http://eecs.wsu.edu/\u02dccs460/cs560/HDdriver.html. A nice summary of a simple\nIDE disk drive\u2019s interface and how to build a device driver for it.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "approach to operating systems; minimally, it \ufb01nally gave some good reasons why address-space based",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "operating",
          "systems",
          "minimally",
          "gave",
          "good",
          "reasons",
          "address"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 7700K review: Kaby Lake Debuts for Desktop\u201d by Joel Hruska. January 3,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7700k review",
          "kaby",
          "lake",
          "debuts",
          "desktop",
          "joel",
          "hruska",
          "january"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand A vailable: https://news. ycombinator .com. One",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "https",
          "news",
          "ycombinator"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Re ference number: ANSI X3.221, 1994. A vailable: ftp://ftp.t10.org/t13/project/d0791r4c-ATA-1.pdf.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "re ference number",
          "ansi",
          "vailable",
          "project"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A vailable: http://people.cs.clemson.edu/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "people",
          "clemson"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand lake-debuts-desktop. an in-depth review of a recent intel chipset, including cpus and the",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "lake",
          "debuts",
          "desktop",
          "depth",
          "review",
          "recent",
          "intel",
          "chipset"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "1 The Interface",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "37.1 The Interface\nLet\u2019s start by understanding the interface to a modern disk dri ve. The\nbasic interface for all modern drives is straightforward. The d rive consists\nof a large number of sectors (512-byte blocks), each of which can be read\nor written. The sectors are numbered from 0 to n \u2212 1 on a disk with n\nsectors. Thus, we can view the disk as an array of sectors; 0 to n \u2212 1 is\nthus the address space of the drive.\nMulti-sector operations are possible; indeed, many \ufb01le systems will\nread or write 4KB at a time (or more). However , when updating the di sk,\nthe only guarantee drive manufacturers make is that a single 5 12-byte\nwrite is atomic (i.e., it will either complete in its entirety or it won\u2019t com-\nplete at all); thus, if an untimely power loss occurs, only a portion of a\nlarger write may complete (sometimes called a torn write ).\nThere are some assumptions most clients of disk drives make, but\nthat are not speci\ufb01ed directly in the interface; Schlosser and G anger have\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s start by understanding the interface to a modern disk dri ve. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "understanding",
          "interface",
          "modern",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the interface",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "interface"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "2 Basic Geometry",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "37.2 Basic Geometry\nLet\u2019s start to understand some of the components of a modern disk.\nW e start with a platter, a circular hard surface on which data is stored\npersistently by inducing magnetic changes to it. A disk may h ave one\nor more platters; each platter has 2 sides, each of which is calle d a sur-\nface. These platters are usually made of some hard material (such as\naluminum), and then coated with a thin magnetic layer that ena bles the\ndrive to persistently store bits even when the drive is powered off.\nThe platters are all bound together around the spindle, which is con-\nnected to a motor that spins the platters around (while the drive is pow-\nered on) at a constant (\ufb01xed) rate. The rate of rotation is often meas ured in\nrotations per minute (RPM) , and typical modern values are in the 7,200\nRPM to 15,000 RPM range. Note that we will often be interested in the\ntime of a single rotation, e.g., a drive that rotates at 10,000 RPM means\nthat a single rotation takes about 6 milliseconds (6 ms).\nData is encoded on each surface in concentric circles of sectors; w e call\none such concentric circle a track. A single surface contains many thou-\nsands and thousands of tracks, tightly packed together , with hu ndreds of\ntracks \ufb01tting into the width of a human hair .\nT o read and write from the surface, we need a mechanism that all ows\nus to either sense (i.e., read) the magnetic patterns on the di sk or to in-\nduce a change in (i.e., write) them. This process of reading and writing is\naccomplished by the disk head ; there is one such head per surface of the\ndrive. The disk head is attached to a single disk arm , which moves across\nthe surface to position the head over the desired track.\n1 W e, and others, often use the terms block and sector interchangeably , assuming the\nreader will know exactly what is meant per context. Sorry about this!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s start to understand some of the components of a modern disk.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "start",
          "understand",
          "components",
          "modern",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "reader will know exactly what is meant per context. Sorry about this!",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reader",
          "know",
          "exactly",
          "meant",
          "context",
          "sorry"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 000 RPM: that a single rotation takes about 6 milliseconds (6 ms).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "000 rpm",
          "single",
          "rotation",
          "takes",
          "milliseconds"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand basic geometry",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "geometry"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "3 A Simple Disk Drive",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "37.3 A Simple Disk Drive\nLet\u2019s understand how disks work by building up a model one track at\na time. Assume we have a simple disk with a single track (Figur e 37.1).\nThis track has just 12 sectors, each of which is 512 bytes in size (our typical\nsector size, recall) and addressed therefore by the numbers 0 t hrough 11.\nThe single platter we have here rotates around the spindle, to w hich a\nmotor is attached.\nOf course, the track by itself isn\u2019t too interesting; we want to b e able\nto read or write those sectors, and thus we need a disk head, attac hed\nto a disk arm, as we now see (Figure 37.2). In the \ufb01gure, the disk head,\nattached to the end of the arm, is positioned over sector 6, and the s urface\nis rotating counter-clockwise.\nSingle-track Latency: The Rotational Delay\nT o understand how a request would be processed on our simple, one-\ntrack disk, imagine we now receive a request to read block 0. How s hould\nthe disk service this request?\nIn our simple disk, the disk doesn\u2019t have to do much. In particula r , it\nmust just wait for the desired sector to rotate under the disk hea d. This\nwait happens often enough in modern drives, and is an important en ough\ncomponent of I/O service time, that it has a special name: rotational de-\nlay (sometimes rotation delay , though that sounds weird). In the exam-\nple, if the full rotational delay is R, the disk has to incur a rotational delay\nof about R\n2 to wait for 0 to come under the read/write head (if we start at\n6). A worst-case request on this single track would be to sector 5, causing\nnearly a full rotational delay in order to service such a request .\nMultiple T racks: Seek Time\nSo far our disk just has a single track, which is not too realistic; modern\ndisks of course have many millions. Let\u2019s thus look at ever-so-sligh tly\nmore realistic disk surface, this one with three tracks (Figur e 37.3, left).\nIn the \ufb01gure, the head is currently positioned over the innermost track\n(which contains sectors 24 through 35); the next track over contai ns the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s understand how disks work by building up a model one track at",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "disks",
          "work",
          "building",
          "model",
          "track"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "T o understand how a request would be processed on our simple, one-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "request",
          "would",
          "processed",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "wait happens often enough in modern drives, and is an important en ough",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "happens",
          "often",
          "enough",
          "modern",
          "drives",
          "important",
          "ough"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a simple disk drive",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "disk",
          "drive"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "11",
    "title": "T o service this read, the drive has to \ufb01rst move the disk arm to the cor-",
    "document_source": "book.pdf",
    "start_line": 67,
    "type": "chapter",
    "content": "11. T o service this read, the drive has to \ufb01rst move the disk arm to the cor-\nrect track (in this case, the outermost one), in a process known as a seek.\nSeeks, along with rotations, are one of the most costly disk operations.\nThe seek, it should be noted, has many phases: \ufb01rst an acceleration\nphase as the disk arm gets moving; then coasting as the arm is moving\nat full speed, then deceleration as the arm slows down; \ufb01nally settling as\nthe head is carefully positioned over the correct track. The settling time\nis often quite signi\ufb01cant, e.g., 0.5 to 2 ms, as the drive must b e certain to\n\ufb01nd the right track (imagine if it just got close instead!).\nAfter the seek, the disk arm has positioned the head over the righ t\ntrack. A depiction of the seek is found in Figure 37.3 (right).\nAs we can see, during the seek, the arm has been moved to the desi red\ntrack, and the platter of course has rotated, in this case about 3 s ectors.\nThus, sector 9 is just about to pass under the disk head, and we mu st\nonly endure a short rotational delay to complete the transfer .\nWhen sector 11 passes under the disk head, the \ufb01nal phase of I/O\nwill take place, known as the transfer, where data is either read from or\nwritten to the surface. And thus, we have a complete picture of I /O time:\n\ufb01rst a seek, then waiting for the rotational delay , and \ufb01nally th e transfer .\nSome Other Details\nThough we won\u2019t spend too much time on it, there are some other inter-\nesting details about how hard drives operate. Many drives employ some\nkind of track skew to make sure that sequential reads can be properly\nserviced even when crossing track boundaries. In our simple exa mple\ndisk, this might appear as seen in Figure 37.4 (page 5).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "rect track (in this case, the outermost one), in a process known as a seek.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rect",
          "track",
          "case",
          "outermost",
          "process",
          "known",
          "seek"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "will take place, known as the transfer, where data is either read from or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "take",
          "place",
          "known",
          "transfer",
          "data",
          "either",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand O time: \ufb01rst a seek, then waiting for the rotational delay , and \ufb01nally th e transfer .",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "o time",
          "seek",
          "waiting",
          "rotational",
          "delay",
          "transfer"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 5\nTrack skew: 2 blocks\n0\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n22\n21\n201918\n17\n16\n15\n14 13 12\n23\n32\n31\n302928\n27\n26\n25\n24 35 34\n33\nSpindle\nRotates this way\nFigure 37.4: Three T racks: T rack Skew Of 2\nSectors are often skewed like this because when switching from one\ntrack to another , the disk needs time to reposition the head (eve n to neigh-\nboring tracks). Without such skew , the head would be moved to the n ext\ntrack but the desired next block would have already rotated unde r the\nhead, and thus the drive would have to wait almost the entire rota tional\ndelay to access the next block.\nAnother reality is that outer tracks tend to have more sectors tha n\ninner tracks, which is a result of geometry; there is simply more room\nout there. These tracks are often referred to as multi-zoned disk drives,\nwhere the disk is organized into multiple zones, and where a zone is con-\nsecutive set of tracks on a surface. Each zone has the same number of\nsectors per track, and outer zones have more sectors than inner zone s.\nFinally , an important part of any modern disk drive is its cache, for\nhistorical reasons sometimes called a track buffer . This cache is just some\nsmall amount of memory (usually around 8 or 16 MB) which the drive\ncan use to hold data read from or written to the disk. For example, w hen\nreading a sector from the disk, the drive might decide to read in all of the\nsectors on that track and cache them in its memory; doing so allows t he\ndrive to quickly respond to any subsequent requests to the sam e track.\nOn writes, the drive has a choice: should it acknowledge the writ e has\ncompleted when it has put the data in its memory , or after the writ e has\nactually been written to disk? The former is called write back caching\n(or sometimes immediate reporting ), and the latter write through . W rite\nback caching sometimes makes the drive appear \u201cfaster \u201d, but c an be dan-\ngerous; if the \ufb01le system or applications require that data be wr itten to\ndisk in a certain order for correctness, write-back caching can lead to\nproblems (read the chapter on \ufb01le-system journaling for details ).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Finally , an important part of any modern disk drive is its cache, for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "important",
          "part",
          "modern",
          "disk",
          "drive",
          "cache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "On writes, the drive has a choice: should it acknowledge the writ e has",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "writes",
          "drive",
          "choice",
          "acknowledge",
          "writ"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 4: Three T racks: T rack Skew Of 2",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "three",
          "racks",
          "rack",
          "skew"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "4 I/O Time: Doing The Math",
    "document_source": "book.pdf",
    "start_line": 46,
    "type": "chapter",
    "content": "37.4 I/O Time: Doing The Math\nNow that we have an abstract model of the disk, we can use a little\nanalysis to better understand disk performance. In particul ar , we can\nnow represent I/O time as the sum of three major components:\nTI/O = Tseek + Trotation + Ttransfer (37.1)\nNote that the rate of I/O ( RI/O ), which is often more easily used for\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "analysis to better understand disk performance. In particul ar , we can",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "analysis",
          "better",
          "understand",
          "disk",
          "performance",
          "particul"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand i/o time: doing the math",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "time",
          "math"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 7\nCheetah 15K.5 Barracuda\nCapacity 300 GB 1 TB\nRPM 15,000 7,200\nA verage Seek 4 ms 9 ms\nMax T ransfer 125 MB/s 105 MB/s\nPlatters 4 4\nCache 16 MB 16/32 MB\nConnects via SCSI SA T A\nFigure 37.5: Disk Drive Specs: SCSI V ersus SA T A\ncomparison between drives (as we will do below), is easily comput ed\nfrom the time. Simply divide the size of the transfer by the time i t took:\nRI/O = SizeT ransfer\nTI/O\n(37.2)\nT o get a better feel for I/O time, let us perform the following calc u-\nlation. Assume there are two workloads we are interested in. The \ufb01rst,\nknown as the random workload, issues small (e.g., 4KB) reads to random\nlocations on the disk. Random workloads are common in many impor-\ntant applications, including database management systems. The second,\nknown as the sequential workload, simply reads a large number of sec-\ntors consecutively from the disk, without jumping around. Sequent ial\naccess patterns are quite common and thus important as well.\nT o understand the difference in performance between random an d se-\nquential workloads, we need to make a few assumptions about the di sk\ndrive \ufb01rst. Let\u2019s look at a couple of modern disks from Seagate. The \ufb01rs t,\nknown as the Cheetah 15K.5 [S09b], is a high-performance SCSI driv e.\nThe second, the Barracuda [S09a], is a drive built for capacity . Details on\nboth are found in Figure 37.5.\nAs you can see, the drives have quite different characteristi cs, and\nin many ways nicely summarize two important components of the dis k\ndrive market. The \ufb01rst is the \u201chigh performance\u201d drive market , where\ndrives are engineered to spin as fast as possible, deliver low s eek times,\nand transfer data quickly . The second is the \u201ccapacity\u201d marke t, where\ncost per byte is the most important aspect; thus, the drives are s lower but\npack as many bits as possible into the space available.\nFrom these numbers, we can start to calculate how well the drive s\nwould do under our two workloads outlined above. Let\u2019s start by looking\nat the random workload. Assuming each 4 KB read occurs at a random\nlocation on disk, we can calculate how long each such read would take .\nOn the Cheetah:\nTseek = 4ms, Trotation = 2ms, Ttransfer = 30microsecs (37.3)\nThe average seek time (4 milliseconds) is just taken as the ave rage time\nreported by the manufacturer; note that a full seek (from one end of the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known as the random workload, issues small (e.g., 4KB) reads to random",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "random",
          "workload",
          "issues",
          "small",
          "reads",
          "random"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "known as the sequential workload, simply reads a large number of sec-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "sequential",
          "workload",
          "simply",
          "reads",
          "large",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "access patterns are quite common and thus important as well.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "access",
          "patterns",
          "quite",
          "common",
          "thus",
          "important",
          "well"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o understand the difference in performance between random an d se-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "difference",
          "performance",
          "random"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "known as the Cheetah 15K.5 [S09b], is a high-performance SCSI driv e.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "cheetah",
          "high",
          "performance",
          "scsi",
          "driv"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "in many ways nicely summarize two important components of the dis k",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "ways",
          "nicely",
          "summarize",
          "important",
          "components"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "cost per byte is the most important aspect; thus, the drives are s lower but",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cost",
          "byte",
          "important",
          "aspect",
          "thus",
          "drives",
          "lower"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Disk Drive Specs: SCSI V ersus SA T A",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "disk",
          "drive",
          "specs",
          "scsi",
          "ersus"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand On the Cheetah: Tseek = 4ms, Trotation = 2ms, Ttransfer = 30microsecs (37.3)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "on the cheetah",
          "tseek",
          "trotation",
          "ttransfer"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 HA R D DI S K DR I V E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 HA R D DI S K DR I V E S\nTI P : U S E DI S K S SE Q U E N T I A L LY\nWhen at all possible, transfer data to and from disks in a sequen tial man-\nner . If sequential is not possible, at least think about transfe rring data\nin large chunks: the bigger , the better . If I/O is done in littl e random\npieces, I/O performance will suffer dramatically . Also, user s will suffer .\nAlso, you will suffer , knowing what suffering you have wrought wit h\nyour careless random I/Os.\nsurface to the other) would likely take two or three times longer . The\naverage rotational delay is calculated from the RPM directly . 1 5000 RPM\nis equal to 250 RPS (rotations per second); thus, each rotation tak es 4 ms.\nOn average, the disk will encounter a half rotation and thus 2 ms i s the\naverage time. Finally , the transfer time is just the size of th e transfer over\nthe peak transfer rate; here it is vanishingly small (30 microseconds; note\nthat we need 1000 microseconds just to get 1 millisecond!).\nThus, from our equation above, TI/O for the Cheetah roughly equals\n6 ms. T o compute the rate of I/O, we just divide the size of the tran sfer\nby the average time, and thus arrive at RI/O for the Cheetah under the\nrandom workload of about 0.66 MB/s. The same calculation for the Bar-\nracuda yields a TI/O of about 13.2 ms, more than twice as slow , and thus\na rate of about 0.31 MB/s.\nNow let\u2019s look at the sequential workload. Here we can assume there\nis a single seek and rotation before a very long transfer . For simpl icity ,\nassume the size of the transfer is 100 MB. Thus, TI/O for the Cheetah and\nBarracuda is about 800 ms and 950 ms, respectively . The rates of I/O\nare thus very nearly the peak transfer rates of 125 MB/s and 105 MB/s,\nrespectively . Figure 37.6 summarizes these numbers.\nCheetah Barracuda\nRI/O Random 0.66 MB/s 0.31 MB/s\nRI/O Sequential 125 MB/s 105 MB/s\nFigure 37.6: Disk Drive Performance: SCSI V ersus SA T A\nThe \ufb01gure shows us a number of important things. First, and most\nimportantly , there is a huge gap in drive performance between r andom\nand sequential workloads, almost a factor of 200 or so for the Cheetah\nand more than a factor 300 difference for the Barracuda. And thus we\narrive at the most obvious design tip in the history of computing.\nA second, more subtle point: there is a large difference in perfor mance\nbetween high-end \u201cperformance\u201d drives and low-end \u201ccapacity \u201d drives.\nFor this reason (and others), people are often willing to pay top doll ar for\nthe former while trying to get the latter as cheaply as possible .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Also, you will suffer , knowing what suffering you have wrought wit h",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "suffer",
          "knowing",
          "suffering",
          "wrought"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The \ufb01gure shows us a number of important things. First, and most",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "number",
          "important",
          "things",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "importantly , there is a huge gap in drive performance between r andom",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "importantly",
          "huge",
          "drive",
          "performance",
          "andom"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "arrive at the most obvious design tip in the history of computing.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "arrive",
          "obvious",
          "design",
          "history",
          "computing"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 6: Disk Drive Performance: SCSI V ersus SA T A",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "disk",
          "drive",
          "performance",
          "scsi",
          "ersus"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand more subtle point: there is a large difference in perfor mance",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "more subtle point",
          "large",
          "difference",
          "perfor",
          "mance"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 9\nAS I D E : C O M P U T I N G TH E \u201cA V E R A G E \u201d S E E K\nIn many books and papers, you will see average disk-seek time cit ed\nas being roughly one-third of the full seek time. Where does this c ome\nfrom?\nT urns out it arises from a simple calculation based on average see k\ndistance, not time. Imagine the disk as a set of tracks, from 0 to N. The\nseek distance between any two tracks x and y is thus computed as the\nabsolute value of the difference between them: |x \u2212 y|.\nT o compute the average seek distance, all you need to do is to \ufb01rs t add\nup all possible seek distances:\nN\u2211\nx=0\nN\u2211\ny=0\n|x \u2212 y|. (37.4)\nThen, divide this by the number of different possible seeks: N2. T o\ncompute the sum, we\u2019ll just use the integral form:\n\u222b N\nx=0\n\u222b N\ny=0\n|x \u2212 y| dy dx. (37.5)\nT o compute the inner integral, let\u2019s break out the absolute value :\n\u222b x\ny=0\n(x \u2212 y) dy +\n\u222b N\ny=x\n(y \u2212 x) dy. (37.6)\nSolving this leads to (xy \u2212 1\n2 y2)\n\u23d0\n\u23d0x\n0 + (1\n2 y2 \u2212 xy)\n\u23d0\n\u23d0N\nx which can be sim-\npli\ufb01ed to (x2 \u2212 Nx + 1\n2 N2).Now we have to compute the outer integral:\n\u222b N\nx=0\n(x2 \u2212 Nx + 1\n2 N2) dx, (37.7)\nwhich results in:\n( 1\n3 x3 \u2212 N\n2 x2 + N2\n2 x)\n\u23d0\n\u23d0\n\u23d0\n\u23d0\nN\n0\n= N3\n3 . (37.8)\nRemember that we still have to divide by the total number of seek s\n(N2) to compute the average seek distance: ( N3\n3 )/(N2) = 1\n3 N. Thus the\naverage seek distance on a disk, over all possible seeks, is one-t hird the\nfull distance. And now when you hear that an average seek is one-t hird\nof a full seek, you\u2019ll know where it came from.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In many books and papers, you will see average disk-seek time cit ed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "books",
          "papers",
          "average",
          "disk",
          "seek",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of a full seek, you\u2019ll know where it came from.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "full",
          "seek",
          "know",
          "came"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "5 Disk Scheduling",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "37.5 Disk Scheduling\nBecause of the high cost of I/O, the OS has historically played a rol e in\ndeciding the order of I/Os issued to the disk. More speci\ufb01cally , given a\nset of I/O requests, the disk scheduler examines the requests and decides\nwhich one to schedule next [SCO90, JW91].\nUnlike job scheduling, where the length of each job is usually un -\nknown, with disk scheduling, we can make a good guess at how long\na \u201cjob\u201d (i.e., disk request) will take. By estimating the seek and possi-\nble rotational delay of a request, the disk scheduler can know how l ong\neach request will take, and thus (greedily) pick the one that w ill take the\nleast time to service \ufb01rst. Thus, the disk scheduler will try to follow the\nprinciple of SJF (shortest job \ufb01rst) in its operation.\nSSTF: Shortest Seek Time First\nOne early disk scheduling approach is known as shortest-seek-time-\ufb01rst\n(SSTF) (also called shortest-seek-\ufb01rst or SSF). SSTF orders the queue of\nI/O requests by track, picking requests on the nearest track t o complete\n\ufb01rst. For example, assuming the current position of the head is ove r the\ninner track, and we have requests for sectors 21 (middle track) and 2\n(outer track), we would then issue the request to 21 \ufb01rst, wait f or it to\ncomplete, and then issue the request to 2 (Figure 37.7).\nSSTF works well in this example, seeking to the middle track \ufb01rst and\nthen the outer track. However , SSTF is not a panacea, for the following\nreasons. First, the drive geometry is not available to the host OS; rather ,\nit sees an array of blocks. Fortunately , this problem is rather ea sily \ufb01xed.\nInstead of SSTF , an OS can simply implement nearest-block-\ufb01rst (NBF),\nwhich schedules the request with the nearest block address ne xt.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known, with disk scheduling, we can make a good guess at how long",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "disk",
          "scheduling",
          "make",
          "good",
          "guess",
          "long"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ble rotational delay of a request, the disk scheduler can know how l ong",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rotational",
          "delay",
          "request",
          "disk",
          "scheduler",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "principle of SJF (shortest job \ufb01rst) in its operation.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "principle",
          "shortest",
          "operation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "One early disk scheduling approach is known as shortest-seek-time-\ufb01rst",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "early",
          "disk",
          "scheduling",
          "approach",
          "known",
          "shortest",
          "seek",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "reasons. First, the drive geometry is not available to the host OS; rather ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reasons",
          "first",
          "drive",
          "geometry",
          "available",
          "host",
          "rather"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Instead of SSTF , an OS can simply implement nearest-block-\ufb01rst (NBF),",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "instead",
          "sstf",
          "simply",
          "implement",
          "nearest",
          "block"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand SSTF: Shortest Seek Time First",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sstf",
          "shortest",
          "seek",
          "time",
          "first"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand disk scheduling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "scheduling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 11\nThe second problem is more fundamental: starvation. Imagine in\nour example above if there were a steady stream of requests to the in-\nner track, where the head currently is positioned. Requests to any other\ntracks would then be ignored completely by a pure SSTF approach. And\nthus the crux of the problem:\nCR U X : H O W TO HA N D L E DI S K STA RVAT I O N\nHow can we implement SSTF-like scheduling but avoid starvation?\nElevator (a.k.a. SCAN or C-SCAN)\nThe answer to this query was developed some time ago (see [CKR72 ]\nfor example), and is relatively straightforward. The algorith m, originally\ncalled SCAN, simply moves back and forth across the disk servicing re-\nquests in order across the tracks. Let\u2019s call a single pass across the disk\n(from outer to inner tracks, or inner to outer) a sweep. Thus, if a request\ncomes for a block on a track that has already been serviced on this sw eep\nof the disk, it is not handled immediately , but rather queued un til the next\nsweep (in the other direction).\nSCAN has a number of variants, all of which do about the same thing.\nFor example, Coffman et al. introduced F-SCAN, which freezes the queue\nto be serviced when it is doing a sweep [CKR72]; this action plac es re-\nquests that come in during the sweep into a queue to be serviced later .\nDoing so avoids starvation of far-away requests, by delaying the servic-\ning of late-arriving (but nearer by) requests.\nC-SCAN is another common variant, short for Circular SCAN . In-\nstead of sweeping in both directions across the disk, the algorith m only\nsweeps from outer-to-inner , and then resets at the outer track to begin\nagain. Doing so is a bit more fair to inner and outer tracks, as pur e back-\nand-forth SCAN favors the middle tracks, i.e., after servicing the outer\ntrack, SCAN passes through the middle twice before coming back to the\nouter track again.\nFor reasons that should now be clear , the SCAN algorithm (and its\ncousins) is sometimes referred to as the elevator algorithm, because it\nbehaves like an elevator which is either going up or down and not jus t\nservicing requests to \ufb02oors based on which \ufb02oor is closer . Imagine h ow\nannoying it would be if you were going down from \ufb02oor 10 to 1, and\nsomebody got on at 3 and pressed 4, and the elevator went up to 4 be-\ncause it was \u201ccloser \u201d than 1! As you can see, the elevator algorith m, when\nused in real life, prevents \ufb01ghts from taking place on elevators . In disks,\nit just prevents starvation.\nUnfortunately , SCAN and its cousins do not represent the best sch edul-\ning technology . In particular , SCAN (or SSTF even) does not actually a d-\nhere as closely to the principle of SJF as they could. In particula r , they\nignore rotation. And thus, another crux:\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The second problem is more fundamental: starvation. Imagine in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "second",
          "problem",
          "fundamental",
          "starvation",
          "imagine"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tracks would then be ignored completely by a pure SSTF approach. And",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tracks",
          "would",
          "ignored",
          "completely",
          "pure",
          "sstf",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "How can we implement SSTF-like scheduling but avoid starvation?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "sstf",
          "like",
          "scheduling",
          "avoid",
          "starvation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "The answer to this query was developed some time ago (see [CKR72 ]",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "answer",
          "query",
          "developed",
          "time"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "For reasons that should now be clear , the SCAN algorithm (and its",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reasons",
          "clear",
          "scan",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "is sometimes referred to as the elevator algorithm, because it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sometimes",
          "referred",
          "elevator",
          "algorithm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "here as closely to the principle of SJF as they could. In particula r , they",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "closely",
          "principle",
          "could",
          "particula"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand another crux: c\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "another crux"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 HA R D DI S K DR I V E S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 HA R D DI S K DR I V E S\nCR U X : H O W TO AC C O U N T FO R DI S K RO TAT I O N CO S T S\nHow can we implement an algorithm that more closely approximates SJ F\nby taking both seek and rotation into account?\nSPTF: Shortest Positioning Time First\nBefore discussing shortest positioning time \ufb01rst or SPTF scheduling (some-\ntimes also called shortest access time \ufb01rst or SA TF), which is the solution\nto our problem, let us make sure we understand the problem in more d e-\ntail. Figure 37.8 presents an example.\nIn the example, the head is currently positioned over sector 30 on t he\ninner track. The scheduler thus has to decide: should it sched ule sector 16\n(on the middle track) or sector 8 (on the outer track) for its next req uest.\nSo which should it service next?\nThe answer , of course, is \u201cit depends\u201d. In engineering, it turn s out\n\u201cit depends\u201d is almost always the answer , re\ufb02ecting that trad e-offs are\npart of the life of the engineer; such maxims are also good in a pinc h,\ne.g., when you don\u2019t know an answer to your boss\u2019s question, you might\nwant to try this gem. However , it is almost always better to know why it\ndepends, which is what we discuss here.\nWhat it depends on here is the relative time of seeking as compare d\nto rotation. If, in our example, seek time is much higher than rota tional\ndelay , then SSTF (and variants) are just \ufb01ne. However , imagine i f seek is\nquite a bit faster than rotation. Then, in our example, it would ma ke more\nsense to seek further to service request 8 on the outer track than it would\nto perform the shorter seek to the middle track to service 16, wh ich has to\nrotate all the way around before passing under the disk head.\n0\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n12\n23\n222120\n19\n18\n17\n16 15 14\n13\n24\n35\n343332\n31\n30\n29\n28 27 26\n25\nSpindle\nRotates this way\nFigure 37.8: SSTF: Sometimes Not Good Enough\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "How can we implement an algorithm that more closely approximates SJ F",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "algorithm",
          "closely",
          "approximates"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to our problem, let us make sure we understand the problem in more d e-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "make",
          "sure",
          "understand",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "e.g., when you don\u2019t know an answer to your boss\u2019s question, you might",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "answer",
          "boss",
          "question",
          "might"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "want to try this gem. However , it is almost always better to know why it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "want",
          "however",
          "almost",
          "always",
          "better",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "What it depends on here is the relative time of seeking as compare d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "depends",
          "relative",
          "time",
          "seeking",
          "compare"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand SPTF: Shortest Positioning Time First",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sptf",
          "shortest",
          "positioning",
          "time",
          "first"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 8: SSTF: Sometimes Not Good Enough",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "8",
          "sstf",
          "sometimes",
          "good",
          "enough"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 13\nTI P : I T ALWAY S DE P E N D S (L I V N Y \u2019 S LAW)\nAlmost any question can be answered with \u201cit depends\u201d, as our coll eague\nMiron Livny always says. However , use with caution, as if you answ er\ntoo many questions this way , people will stop asking you questions a lto-\ngether . For example, somebody asks: \u201cwant to go to lunch?\u201d Y ou rep ly:\n\u201cit depends, are you coming along?\u201d\nOn modern drives, as we saw above, both seek and rotation are roughly\nequivalent (depending, of course, on the exact requests), and t hus SPTF\nis useful and improves performance. However , it is even more dif\ufb01 cult\nto implement in an OS, which generally does not have a good idea wher e\ntrack boundaries are or where the disk head currently is (in a rot ational\nsense). Thus, SPTF is usually performed inside a drive, descri bed below .\nOther Scheduling Issues\nThere are many other issues we do not discuss in this brief descr iption\nof basic disk operation, scheduling, and related topics. One suc h is-\nsue is this: where is disk scheduling performed on modern systems? In\nolder systems, the operating system did all the scheduling; af ter looking\nthrough the set of pending requests, the OS would pick the best one , and\nissue it to the disk. When that request completed, the next one w ould be\nchosen, and so forth. Disks were simpler then, and so was life.\nIn modern systems, disks can accommodate multiple outstanding r e-\nquests, and have sophisticated internal schedulers themsel ves (which can\nimplement SPTF accurately; inside the disk controller , all rel evant details\nare available, including exact head position). Thus, the OS sc heduler usu-\nally picks what it thinks the best few requests are (say 16) an d issues them\nall to disk; the disk then uses its internal knowledge of head pos ition and\ndetailed track layout information to service said requests in t he best pos-\nsible (SPTF) order .\nAnother important related task performed by disk schedulers is I/O\nmerging. For example, imagine a series of requests to read blocks 33,\nthen 8, then 34, as in Figure 37.8. In this case, the scheduler should merge\nthe requests for blocks 33 and 34 into a single two-block request; any re-\nordering that the scheduler does is performed upon the merged req uests.\nMerging is particularly important at the OS level, as it reduc es the num-\nber of requests sent to the disk and thus lowers overheads.\nOne \ufb01nal problem that modern schedulers address is this: how long\nshould the system wait before issuing an I/O to disk? One might n aively\nthink that the disk, once it has even a single I/O, should immedi ately\nissue the request to the drive; this approach is called work-conserving, as\nthe disk will never be idle if there are requests to serve. Howe ver , research\non anticipatory disk scheduling has shown that sometimes it is better to\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to implement in an OS, which generally does not have a good idea wher e",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "generally",
          "good",
          "idea",
          "wher"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "implement SPTF accurately; inside the disk controller , all rel evant details",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "sptf",
          "accurately",
          "inside",
          "disk",
          "controller",
          "evant",
          "details"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "all to disk; the disk then uses its internal knowledge of head pos ition and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "disk",
          "uses",
          "internal",
          "knowledge",
          "head",
          "ition"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Another important related task performed by disk schedulers is I/O",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "important",
          "related",
          "task",
          "performed",
          "disk",
          "schedulers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Merging is particularly important at the OS level, as it reduc es the num-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "merging",
          "particularly",
          "important",
          "level",
          "reduc"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "issue the request to the drive; this approach is called work-conserving, as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "issue",
          "request",
          "drive",
          "approach",
          "called",
          "work",
          "conserving"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand somebody asks: \u201cwant to go to lunch?\u201d Y ou rep ly:",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "somebody asks",
          "want",
          "lunch"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand sue is this: where is disk scheduling performed on modern systems? In",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sue is this",
          "disk",
          "scheduling",
          "performed",
          "modern",
          "systems"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand disk scheduling performed on modern systems",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "scheduling",
          "performed",
          "modern",
          "systems"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "37",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "37.6 Summary\nW e have presented a summary of how disks work. The summary is\nactually a detailed functional model; it does not describe the am azing\nphysics, electronics, and material science that goes into act ual drive de-\nsign. For those interested in even more details of that nature, we suggest\na different major (or perhaps minor); for those that are happy with this\nmodel, good! W e can now proceed to using the model to build more in-\nteresting systems on top of these incredible devices.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "actually a detailed functional model; it does not describe the am azing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "actually",
          "detailed",
          "functional",
          "model",
          "describe",
          "azing"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "HA R D DI S K DR I V E S 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "HA R D DI S K DR I V E S 15\nReferences\n[ADR03] \u201cMore Than an Interface: SCSI vs. A T A \u201d by Dave Anderson, Jim Dyke s, Erik Riedel.\nF AST \u201903, 2003. One of the best recent-ish references on how modern disk drives really work; a must\nread for anyone interested in knowing more.\n[CKR72] \u201cAnalysis of Scanning Policies for Reducing Disk Seek Times\u201d E.G . Coffman, L.A.\nKlimko, B. Ryan SIAM Journal of Computing, September 1972, V ol 1 . No 3. Some of the early\nwork in the \ufb01eld of disk scheduling.\n[HK+17] \u201cThe Unwritten Contract of Solid State Drives\u201d by Jun He, Sud arsun Kannan, Andrea\nC. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau. EuroSys \u201917, Belgr ade, Serbia, April 2017. We\ntake the idea of the unwritten contract, and extend it to SSDs. Using SSDs well s eems as complicated\nthan hard drives, and sometimes more so.\n[ID01] \u201cAnticipatory Scheduling: A Disk-scheduling Framework T o Overco me Deceptive Idle-\nness In Synchronous I/O\u201d by Sitaram Iyer , Peter Druschel. SOSP \u201901, Octobe r 2001. A cool paper\nshowing how waiting can improve disk scheduling: better requests may be on their way!\n[JW91] \u201cDisk Scheduling Algorithms Based On Rotational Position\u201d by D. Jacobson, J. Wilkes.\nT echnical Report HPL-CSP-91-7rev1, Hewlett-Packard, February 1991. A more modern take on\ndisk scheduling. It remains a technical report (and not a published pap er) because the authors were\nscooped by Seltzer et al. [S90].\n[RW92] \u201cAn Introduction to Disk Drive Modeling\u201d by C. Ruemmler , J. W ilkes. IEEE Computer ,\n27:3, March 1994. A terri\ufb01c introduction to the basics of disk operation. Some pieces are out of date,\nbut most of the basics remain.\n[SCO90] \u201cDisk Scheduling Revisited\u201d by Margo Seltzer , Peter Chen, John Ou sterhout. USENIX\n1990. A paper that talks about how rotation matters too in the world of disk scheduling.\n[SG04] \u201cMEMS-based storage devices and standard disk interfaces: A squ are peg in a round\nhole?\u201d Steven W . Schlosser , Gregory R. Ganger F AST \u201904, pp. 87-100, 2004 While the MEMS\naspect of this paper hasn\u2019t yet made an impact, the discussion of the contract be tween \ufb01le systems and\ndisks is wonderful and a lasting contribution. We later build on this work to stu dy the \u201cUnwritten\nContract of Solid State Drives\u201d [HK+17]\n[S09a] \u201cBarracuda ES.2 data sheet\u201d by Seagate, Inc.. A vailable at this website, at least, it was:\nhttp://www.seagate.com/docs/pdf/datasheet/disc/ds_barracuda_es.pdf. A\ndata sheet; read at your own risk. Risk of what? Boredom.\n[S09b] \u201cCheetah 15K.5\u201d by Seagate, Inc.. A vailable at this websit e, we\u2019re pretty sure it is:\nhttp://www.seagate.com/docs/pdf/datasheet/disc/ds-cheetah-15k-5-us.pdf.\nSee above commentary on data sheets.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "read for anyone interested in knowing more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "anyone",
          "interested",
          "knowing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[JW91] \u201cDisk Scheduling Algorithms Based On Rotational Position\u201d by D. Jacobson, J. Wilkes.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "scheduling",
          "algorithms",
          "based",
          "rotational",
          "position",
          "jacobson",
          "wilkes"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand More Than an Interface: SCSI vs. A T A \u201d by Dave Anderson, Jim Dyke s, Erik Riedel.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "more than an interface",
          "scsi",
          "dave",
          "anderson",
          "dyke",
          "erik",
          "riedel"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Anticipatory Scheduling: A Disk-scheduling Framework T o Overco me Deceptive Idle-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "anticipatory scheduling",
          "disk",
          "scheduling",
          "framework",
          "overco",
          "deceptive",
          "idle"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 27: 3, March 1994. A terri\ufb01c introduction to the basics of disk operation. Some pieces are out of date,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "27",
          "march",
          "introduction",
          "basics",
          "disk",
          "operation",
          "pieces",
          "date"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand it was: http://www.seagate.com/docs/pdf/datasheet/disc/ds_barracuda_es.pdf. A",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it was",
          "http",
          "seagate",
          "docs",
          "datasheet",
          "disc"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Compute the seek, rotation, and transfer times for the follow ing sets of re-",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. Compute the seek, rotation, and transfer times for the follow ing sets of re-\nquests: -a 0, -a 6, -a 30, -a 7,30,8, and \ufb01nally -a 10,11,12,13.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand quests: -a 0, -a 6, -a 30, -a 7,30,8, and \ufb01nally -a 10,11,12,13.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "quests"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Do the same requests above, but change the seek rate to differe nt values: -S",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "2. Do the same requests above, but change the seek rate to differe nt values: -S\n2, -S 4, -S 8, -S 10, -S 40, -S 0.1. How do the times change?\n3. Do the same requests above, but change the rotation rate: -R 0.1, -R 0.5,\n-R 0.01. How do the times change?\n4. FIFO is not always best, e.g., with the request stream -a 7,30,8, what or-\nder should the requests be processed in? Run the shortest seek-t ime \ufb01rst\n(SSTF) scheduler ( -p SSTF) on this workload; how long should it take\n(seek, rotation, transfer) for each request to be served?\n5. Now use the shortest access-time \ufb01rst (SA TF) scheduler ( -p SATF). Does it\nmake any difference for -a 7,30,8 workload? Find a set of requests where\nSA TF outperforms SSTF; more generally , when is SA TF better than SSTF?\n6. Here is a request stream to try: -a 10,11,12,13. What goes poorly when\nit runs? T ry adding track skew to address this problem ( -o skew). Given\nthe default seek rate, what should the skew be to maximize performan ce?\nWhat about for different seek rates (e.g., -S 2, -S 4)? In general, could\nyou write a formula to \ufb01gure out the skew?\n7. Specify a disk with different density per zone, e.g., -z 10,20,30, which\nspeci\ufb01es the angular difference between blocks on the outer , mi ddle, and\ninner tracks. Run some random requests (e.g., -a -1 -A 5,-1,0, which\nspeci\ufb01es that random requests should be used via the -a -1 \ufb02ag and that\n\ufb01ve requests ranging from 0 to the max be generated), and compute t he\nseek, rotation, and transfer times. Use different random seed s. What is the\nbandwidth (in sectors per unit time) on the outer , middle, and inn er tracks?",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand r 0.01. how do the times change?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "times",
          "change"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the\nbandwidth (in sectors per unit time) on the outer , middle, and inn er tracks",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "bandwidth",
          "sectors",
          "unit",
          "time",
          "outer",
          "middle",
          "tracks"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "8",
    "title": "A scheduling window determines how many requests the disk can e xamine",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "8. A scheduling window determines how many requests the disk can e xamine\nat once. Generate random workloads (e.g., -A 1000,-1,0, with different\nseeds) and see how long the SA TF scheduler takes when the sched uling win-\ndow is changed from 1 up to the number of requests. How big of a windo w\nis needed to maximize performance? Hint: use the -c \ufb02ag and don\u2019t turn\non graphics ( -G) to run these quickly . When the scheduling window is set\nto 1, does it matter which policy you are using?",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Hint: use the -c \ufb02ag and don\u2019t turn",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "hint",
          "turn"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "9",
    "title": "Create a series of requests to starve a particular request, as suming an SA TF",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "9. Create a series of requests to starve a particular request, as suming an SA TF\npolicy . Given that sequence, how does it perform if you use a bounded\nSA TF (BSA TF) scheduling approach? In this approach, you specify the\nscheduling window (e.g., -w 4); the scheduler only moves onto the next\nwindow of requests when all requests in the current window have been ser-\nviced. Does this solve starvation? How does it perform, as comp ared to\nSA TF? In general, how should a disk make this trade-off between perfor-\nmance and starvation avoidance?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Create a series of requests to starve a particular request, as suming an SA TF",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "series",
          "requests",
          "starve",
          "particular",
          "request",
          "suming"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "SA TF (BSA TF) scheduling approach? In this approach, you specify the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "scheduling",
          "approach",
          "approach",
          "specify"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "viced. Does this solve starvation? How does it perform, as comp ared to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "viced",
          "solve",
          "starvation",
          "perform",
          "comp",
          "ared"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand it perform if you use a bounded\nSA TF (BSA TF) scheduling approach",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "perform",
          "bounded",
          "scheduling",
          "approach"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand it perform, as comp ared to\nSA TF",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "perform",
          "comp",
          "ared"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "10",
    "title": "All the scheduling policies we have looked at thus far are greedy; they pick",
    "document_source": "book.pdf",
    "start_line": 46,
    "type": "chapter",
    "content": "10. All the scheduling policies we have looked at thus far are greedy; they pick\nthe next best option instead of looking for an optimal schedule. Can you\n\ufb01nd a set of requests in which greedy is not optimal?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "38\nRedundant Arrays of Inexpensive Disks\n(RAIDs)\nWhen we use a disk, we sometimes wish it to be faster; I/O operati ons\nare slow and thus can be the bottleneck for the entire system. Whe n we\nuse a disk, we sometimes wish it to be larger; more and more data is being\nput online and thus our disks are getting fuller and fuller . Whe n we use\na disk, we sometimes wish for it to be more reliable; when a disk fa ils, if\nour data isn\u2019t backed up, all that valuable data is gone.\nCR U X : H O W TO MA K E A L A R G E , F A S T, R E L I A B L E DI S K\nHow can we make a large, fast, and reliable storage system? What are\nthe key techniques? What are trade-offs between different ap proaches?\nIn this chapter , we introduce the Redundant Array of Inexpensive\nDisks better known as RAID [P+88], a technique to use multiple disks in\nconcert to build a faster , bigger , and more reliable disk syste m. The term\nwas introduced in the late 1980s by a group of researchers at U.C. Berke-\nley (led by Professors David Patterson and Randy Katz and then st udent\nGarth Gibson); it was around this time that many different rese archers si-\nmultaneously arrived upon the basic idea of using multiple disk s to build\na better storage system [BG88, K86,K88,PB86,SG86].\nExternally , a RAID looks like a disk: a group of blocks one can read\nor write. Internally , the RAID is a complex beast, consisting of m ultiple\ndisks, memory (both volatile and non-), and one or more processors to\nmanage the system. A hardware RAID is very much like a computer\nsystem, specialized for the task of managing a group of disks.\nRAIDs offer a number of advantages over a single disk. One advan-\ntage is performance. Using multiple disks in parallel can greatly speed\nup I/O times. Another bene\ufb01t is capacity. Large data sets demand large\ndisks. Finally , RAIDs can improve reliability; spreading data across mul-\ntiple disks (without RAID techniques) makes the data vulnera ble to the\nloss of a single disk; with some form of redundancy, RAIDs can tolerate\nthe loss of a disk and keep operating as if nothing were wrong.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the key techniques? What are trade-offs between different ap proaches?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "techniques",
          "trade",
          "offs",
          "different",
          "proaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Disks better known as RAID [P+88], a technique to use multiple disks in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disks",
          "better",
          "known",
          "raid",
          "technique",
          "multiple",
          "disks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "tiple disks (without RAID techniques) makes the data vulnera ble to the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tiple",
          "disks",
          "without",
          "raid",
          "techniques",
          "makes",
          "data",
          "vulnera"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand CR U X: H O W TO MA K E A L A R G E , F A S T, R E L I A B L E DI S K",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cr u x"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "1 Interface And RAID Internals",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "38.1 Interface And RAID Internals\nT o a \ufb01le system above, a RAID looks like a big, (hopefully) fast, an d\n(hopefully) reliable disk. Just as with a single disk, it pres ents itself as\na linear array of blocks, each of which can be read or written by the \ufb01le\nsystem (or other client).\nWhen a \ufb01le system issues a logical I/O request to the RAID, the RAID\ninternally must calculate which disk (or disks) to access in or der to com-\nplete the request, and then issue one or more physical I/Os to do so. The\nexact nature of these physical I/Os depends on the RAID level, a s we will\ndiscuss in detail below . However , as a simple example, consider a RAID\nthat keeps two copies of each block (each one on a separate disk); wh en\nwriting to such a mirrored RAID system, the RAID will have to perform\ntwo physical I/Os for every one logical I/O it is issued.\nA RAID system is often built as a separate hardware box, with a st an-\ndard connection (e.g., SCSI, or SA T A) to a host. Internally , however ,\nRAIDs are fairly complex, consisting of a microcontroller that run s \ufb01rmware\nto direct the operation of the RAID, volatile memory such as DRAM\nto buffer data blocks as they are read and written, and in some ca ses,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand interface and raid internals",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "interface",
          "raid",
          "internals"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "2 Fault Model",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "38.2 Fault Model\nT o understand RAID and compare different approaches, we must h ave\na fault model in mind. RAIDs are designed to detect and recover f rom\ncertain kinds of disk faults; thus, knowing exactly which faul ts to expect\nis critical in arriving upon a working design.\nThe \ufb01rst fault model we will assume is quite simple, and has bee n\ncalled the fail-stop fault model [S84]. In this model, a disk can be in\nexactly one of two states: working or failed. With a working disk, a ll\nblocks can be read or written. In contrast, when a disk has failed , we\nassume it is permanently lost.\nOne critical aspect of the fail-stop model is what it assumes abou t fault\ndetection. Speci\ufb01cally , when a disk has failed, we assume that this is\neasily detected. For example, in a RAID array , we would assume t hat the\nRAID controller hardware (or software) can immediately observe w hen a\ndisk has failed.\nThus, for now , we do not have to worry about more complex \u201csilent\u201d\nfailures such as disk corruption. W e also do not have to worry about a sin-\ngle block becoming inaccessible upon an otherwise working disk (s ome-\ntimes called a latent sector error). W e will consider these more c omplex\n(and unfortunately , more realistic) disk faults later .",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand RAID and compare different approaches, we must h ave",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "understand",
          "raid",
          "compare",
          "different",
          "approaches",
          "must"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a fault model in mind. RAIDs are designed to detect and recover f rom",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "fault",
          "model",
          "mind",
          "raids",
          "designed",
          "detect",
          "recover"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "certain kinds of disk faults; thus, knowing exactly which faul ts to expect",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "certain",
          "kinds",
          "disk",
          "faults",
          "thus",
          "knowing",
          "exactly",
          "faul"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "is critical in arriving upon a working design.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "critical",
          "arriving",
          "upon",
          "working",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "blocks can be read or written. In contrast, when a disk has failed , we",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "blocks",
          "read",
          "written",
          "contrast",
          "disk",
          "failed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "One critical aspect of the fail-stop model is what it assumes abou t fault",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "critical",
          "aspect",
          "fail",
          "stop",
          "model",
          "assumes",
          "abou",
          "fault"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand fault model",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fault",
          "model"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "38",
    "title": "3 How T o Evaluate A RAID",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "38.3 How T o Evaluate A RAID\nAs we will soon see, there are a number of different approaches to\nbuilding a RAID. Each of these approaches has different charac teristics\nwhich are worth evaluating, in order to understand their stren gths and\nweaknesses.\nSpeci\ufb01cally , we will evaluate each RAID design along three axe s. The\n\ufb01rst axis is capacity; given a set of N disks each with B blocks, how much\nuseful capacity is available to clients of the RAID? Without re dundancy ,\nthe answer is N \u00b7 B; in contrast, if we have a system that keeps two copies\nof each block (called mirroring), we obtain a useful capacity of (N \u00b7 B)/2.\nDifferent schemes (e.g., parity-based ones) tend to fall in b etween.\nThe second axis of evaluation is reliability. How many disk faults can\nthe given design tolerate? In alignment with our fault model, we assume\nonly that an entire disk can fail; in later chapters (i.e., on da ta integrity),\nwe\u2019ll think about how to handle more complex failure modes.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "How T o Evaluate A RAID",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "evaluate",
          "raid"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "As we will soon see, there are a number of different approaches to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "soon",
          "number",
          "different",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "building a RAID. Each of these approaches has different charac teristics",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "building",
          "raid",
          "approaches",
          "different",
          "charac",
          "teristics"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "which are worth evaluating, in order to understand their stren gths and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "worth",
          "evaluating",
          "order",
          "understand",
          "stren",
          "gths"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Speci\ufb01cally , we will evaluate each RAID design along three axe s. The",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "evaluate",
          "raid",
          "design",
          "along",
          "three"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "useful capacity is available to clients of the RAID? Without re dundancy ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "useful",
          "capacity",
          "available",
          "clients",
          "raid",
          "without",
          "dundancy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "the answer is N \u00b7 B; in contrast, if we have a system that keeps two copies",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "answer",
          "contrast",
          "system",
          "keeps",
          "copies"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "the given design tolerate? In alignment with our fault model, we assume",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "given",
          "design",
          "tolerate",
          "alignment",
          "fault",
          "model",
          "assume"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "4 RAID Level 0: Striping",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "38.4 RAID Level 0: Striping\nThe \ufb01rst RAID level is actually not a RAID level at all, in that t here is\nno redundancy . However , RAID level 0, or striping as it is better known,\nserves as an excellent upper-bound on performance and capacity and\nthus is worth understanding.\nThe simplest form of striping will stripe blocks across the disks of the\nsystem as follows (assume here a 4-disk array):\nDisk 0 Disk 1 Disk 2 Disk 3\n0 1 2 3\n4 5 6 7\n8 9 10 11\n12 13 14 15\nFigure 38.1: RAID-0: Simple Striping\nFrom Figure 38.1, you get the basic idea: spread the blocks of the a rray\nacross the disks in a round-robin fashion. This approach is design ed to\nextract the most parallelism from the array when requests are m ade for\ncontiguous chunks of the array (as in a large, sequential read, f or exam-\nple). W e call the blocks in the same row a stripe; thus, blocks 0, 1, 2, and\n3 are in the same stripe above.\nIn the example, we have made the simplifying assumption that on ly 1\nblock (each of say size 4KB) is placed on each disk before moving on to\nthe next. However , this arrangement need not be the case. For exa mple,\nwe could arrange the blocks across disks as in Figure 38.2:\nDisk 0 Disk 1 Disk 2 Disk 3\n0 2 4 6 chunk size:\n1 3 5 7 2 blocks\n8 10 12 14\n9 11 13 15\nFigure 38.2: Striping With A Bigger Chunk Size\nIn this example, we place two 4KB blocks on each disk before moving\non to the next disk. Thus, the chunk size of this RAID array is 8KB, and\na stripe thus consists of 4 chunks or 32KB of data.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "no redundancy . However , RAID level 0, or striping as it is better known,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "redundancy",
          "however",
          "raid",
          "level",
          "striping",
          "better",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "thus is worth understanding.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "worth",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "across the disks in a round-robin fashion. This approach is design ed to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "across",
          "disks",
          "round",
          "robin",
          "fashion",
          "approach",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1: RAID-0: Simple Striping",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "raid",
          "simple",
          "striping"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 2: Disk 0 Disk 1 Disk 2 Disk 3",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "disk",
          "disk",
          "disk",
          "disk"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand 2: Striping With A Bigger Chunk Size",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "striping",
          "bigger",
          "chunk",
          "size"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand raid level 0: striping",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "level",
          "striping"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "RE D U N D A N T AR R AY S O F IN E X P E N S I V ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "RE D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S) 5\nAS I D E : T H E RAID M A P P I N G PR O B L E M\nBefore studying the capacity , reliability , and performance c haracteristics\nof the RAID, we \ufb01rst present an aside on what we call the mapping prob-\nlem. This problem arises in all RAID arrays; simply put, given a log ical\nblock to read or write, how does the RAID know exactly which physica l\ndisk and offset to access?\nFor these simple RAID levels, we do not need much sophistication i n\norder to correctly map logical blocks onto their physical locations . T ake\nthe \ufb01rst striping example above (chunk size = 1 block = 4KB). In t his case,\ngiven a logical block address A, the RAID can easily compute the d esired\ndisk and offset with two simple equations:\nDisk = A % number_of_disks\nOffset = A / number_of_disks\nNote that these are all integer operations (e.g., 4 / 3 = 1 not 1.333 33...).\nLet\u2019s see how these equations work for a simple example. Imagine in the\n\ufb01rst RAID above that a request arrives for block 14. Given that th ere are\n4 disks, this would mean that the disk we are interested in is (1 4 % 4 = 2):\ndisk 2. The exact block is calculated as (14 / 4 = 3): block 3. Thus , block\n14 should be found on the fourth block (block 3, starting at 0) of the th ird\ndisk (disk 2, starting at 0), which is exactly where it is.\nY ou can think about how these equations would be modi\ufb01ed to support\ndifferent chunk sizes. T ry it! It\u2019s not too hard.\nChunk Sizes\nChunk size mostly affects performance of the array . For example, a small\nchunk size implies that many \ufb01les will get striped across many disks, thus\nincreasing the parallelism of reads and writes to a single \ufb01le ; however , the\npositioning time to access blocks across multiple disks increas es, because\nthe positioning time for the entire request is determined by the maximum\nof the positioning times of the requests across all drives.\nA big chunk size, on the other hand, reduces such intra-\ufb01le para l-\nlelism, and thus relies on multiple concurrent requests to ach ieve high\nthroughput. However , large chunk sizes reduce positioning time ; if, for\nexample, a single \ufb01le \ufb01ts within a chunk and thus is placed on a s ingle\ndisk, the positioning time incurred while accessing it will ju st be the po-\nsitioning time of a single disk.\nThus, determining the \u201cbest\u201d chunk size is hard to do, as it req uires a\ngreat deal of knowledge about the workload presented to the disk sy stem\n[CL95]. For the rest of this discussion, we will assume that the a rray uses\na chunk size of a single block (4KB). Most arrays use larger chunk sizes\n(e.g., 64 KB), but for the issues we discuss below , the exact chu nk size\ndoes not matter; thus we use a single block for the sake of simplicit y .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "block to read or write, how does the RAID know exactly which physica l",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "block",
          "read",
          "write",
          "raid",
          "know",
          "exactly",
          "physica"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "great deal of knowledge about the workload presented to the disk sy stem",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "great",
          "deal",
          "knowledge",
          "workload",
          "presented",
          "disk",
          "stem"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand the RAID know exactly which physica l\ndisk and offset to access",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "know",
          "exactly",
          "physica",
          "disk",
          "offset",
          "access"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 R E D U N D A N T AR R AY S O F IN E X P E N S I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 R E D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S)\nBack T o RAID-0 Analysis\nLet us now evaluate the capacity , reliability , and performanc e of striping.\nFrom the perspective of capacity , it is perfect: given N disks each of size\nB blocks, striping delivers N \u00b7B blocks of useful capacity . From the stand-\npoint of reliability , striping is also perfect, but in the bad w ay: any disk\nfailure will lead to data loss. Finally , performance is excell ent: all disks\nare utilized, often in parallel, to service user I/O requests .\nEvaluating RAID Performance\nIn analyzing RAID performance, one can consider two different p erfor-\nmance metrics. The \ufb01rst is single-request latency . Understanding the la-\ntency of a single I/O request to a RAID is useful as it reveals how much\nparallelism can exist during a single logical I/O operation. Th e second\nis steady-state throughput of the RAID, i.e., the total bandwidth of many\nconcurrent requests. Because RAIDs are often used in high-per formance\nenvironments, the steady-state bandwidth is critical, and t hus will be the\nmain focus of our analyses.\nT o understand throughput in more detail, we need to put forth some\nworkloads of interest. W e will assume, for this discussion, that t here\nare two types of workloads: sequential and random. With a sequential\nworkload, we assume that requests to the array come in large conti gu-\nous chunks; for example, a request (or series of requests) that ac cesses\n1 MB of data, starting at block x and ending at block (x+1 MB ), would be\ndeemed sequential. Sequential workloads are common in many envir on-\nments (think of searching through a large \ufb01le for a keyword), and t hus\nare considered important.\nFor random workloads, we assume that each request is rather small ,\nand that each request is to a different random location on disk. For exam-\nple, a random stream of requests may \ufb01rst access 4KB at logical ad dress\n10, then at logical address 550,000, then at 20,100, and so fort h. Some im-\nportant workloads, such as transactional workloads on a database ma n-\nagement system (DBMS), exhibit this type of access pattern, an d thus it is\nconsidered an important workload.\nOf course, real workloads are not so simple, and often have a mix\nof sequential and random-seeming components as well as behaviors in-\nbetween the two. For simplicity , we just consider these two possi bilities.\nAs you can tell, sequential and random workloads will result in wi dely\ndifferent performance characteristics from a disk. With sequ ential access,\na disk operates in its most ef\ufb01cient mode, spending little time s eeking and\nwaiting for rotation and most of its time transferring data. With r andom\naccess, just the opposite is true: most time is spent seeking and waiting\nfor rotation and relatively little time is spent transferring d ata. T o capture\nthis difference in our analysis, we will assume that a disk can transfer\ndata at S MB/s under a sequential workload, and R MB/s when under a\nrandom workload. In general, S is much greater than R (i.e., S \u226b R).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let us now evaluate the capacity , reliability , and performanc e of striping.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "evaluate",
          "capacity",
          "reliability",
          "performanc",
          "striping"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "mance metrics. The \ufb01rst is single-request latency . Understanding the la-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mance",
          "metrics",
          "single",
          "request",
          "latency",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "environments, the steady-state bandwidth is critical, and t hus will be the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "environments",
          "steady",
          "state",
          "bandwidth",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "T o understand throughput in more detail, we need to put forth some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "throughput",
          "detail",
          "need",
          "forth"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "are considered important.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "considered",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "considered an important workload.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "considered",
          "important",
          "workload"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand it is perfect: given N disks each of size",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it is perfect",
          "given",
          "disks",
          "size"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "5 RAID Level 1: Mirroring",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "38.5 RAID Level 1: Mirroring\nOur \ufb01rst RAID level beyond striping is known as RAID level 1, or\nmirroring. With a mirrored system, we simply make more than one cop y\nof each block in the system; each copy should be placed on a separate\ndisk, of course. By doing so, we can tolerate disk failures.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Our \ufb01rst RAID level beyond striping is known as RAID level 1, or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "level",
          "beyond",
          "striping",
          "known",
          "raid",
          "level"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand raid level 1: mirroring",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "level",
          "mirroring"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 R E D U N D A N T AR R AY S O F IN E X P E N S I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 R E D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S)\nIn a typical mirrored system, we will assume that for each logica l\nblock, the RAID keeps two physical copies of it. Here is an exampl e:\nDisk 0 Disk 1 Disk 2 Disk 3\n0 0 1 1\n2 2 3 3\n4 4 5 5\n6 6 7 7\nFigure 38.3: Simple RAID-1: Mirroring\nIn the example, disk 0 and disk 1 have identical contents, and d isk 2\nand disk 3 do as well; the data is striped across these mirror pai rs. In fact,\nyou may have noticed that there are a number of different ways to p lace\nblock copies across the disks. The arrangement above is a common one\nand is sometimes called RAID-10 or ( RAID 1+0) because it uses mirrored\npairs (RAID-1) and then stripes (RAID-0) on top of them; another c om-\nmon arrangement is RAID-01 (or RAID 0+1), which contains two large\nstriping (RAID-0) arrays, and then mirrors (RAID-1) on top of the m. For\nnow , we will just talk about mirroring assuming the above layout.\nWhen reading a block from a mirrored array , the RAID has a choice: i t\ncan read either copy . For example, if a read to logical block 5 is is sued to\nthe RAID, it is free to read it from either disk 2 or disk 3. When wr iting\na block, though, no such choice exists: the RAID must update both copies\nof the data, in order to preserve reliability . Do note, though, th at these\nwrites can take place in parallel; for example, a write to logic al block 5\ncould proceed to disks 2 and 3 at the same time.\nRAID-1 Analysis\nLet us assess RAID-1. From a capacity standpoint, RAID-1 is exp ensive;\nwith the mirroring level = 2, we only obtain half of our peak useful c a-\npacity . With N disks of B blocks, RAID-1 useful capacity is (N \u00b7 B)/2.\nFrom a reliability standpoint, RAID-1 does well. It can tolerate the fail-\nure of any one disk. Y ou may also notice RAID-1 can actually do bett er\nthan this, with a little luck. Imagine, in the \ufb01gure above, tha t disk 0 and\ndisk 2 both failed. In such a situation, there is no data loss! More gen-\nerally , a mirrored system (with mirroring level of 2) can tolerat e 1 disk\nfailure for certain, and up to N/2 failures depending on which d isks fail.\nIn practice, we generally don\u2019t like to leave things like this t o chance; thus\nmost people consider mirroring to be good for handling a single failu re.\nFinally , we analyze performance. From the perspective of the la tency\nof a single read request, we can see it is the same as the latency on a single\ndisk; all the RAID-1 does is direct the read to one of its copies. A w rite\nis a little different: it requires two physical writes to comp lete before it\nis done. These two writes happen in parallel, and thus the time will be\nroughly equivalent to the time of a single write; however , becau se the\nlogical write must wait for both physical writes to complete, it s uffers the\nworst-case seek and rotational delay of the two requests, and thu s (on\naverage) will be slightly higher than a write to a single disk .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Finally , we analyze performance. From the perspective of the la tency",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "finally",
          "analyze",
          "performance",
          "perspective",
          "tency"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 3: Simple RAID-1: Mirroring",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "simple",
          "raid",
          "mirroring"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand no such choice exists: the RAID must update both copies",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "no such choice exists",
          "raid",
          "must",
          "update",
          "copies"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "RE D U N D A N T AR R AY S O F IN E X P E N S I V ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "RE D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S) 9\nAS I D E : T H E RAID C O N S I S T E N T-U P D AT E PR O B L E M\nBefore analyzing RAID-1, let us \ufb01rst discuss a problem that ari ses in\nany multi-disk RAID system, known as the consistent-update problem\n[DAA05]. The problem occurs on a write to any RAID that has to up-\ndate multiple disks during a single logical operation. In this c ase, let us\nassume we are considering a mirrored disk array .\nImagine the write is issued to the RAID, and then the RAID deci des that\nit must be written to two disks, disk 0 and disk 1. The RAID then issues\nthe write to disk 0, but just before the RAID can issue the reque st to disk\n1, a power loss (or system crash) occurs. In this unfortunate case, let us\nassume that the request to disk 0 completed (but clearly the re quest to\ndisk 1 did not, as it was never issued).\nThe result of this untimely power loss is that the two copies of the b lock\nare now inconsistent; the copy on disk 0 is the new version, and the copy\non disk 1 is the old. What we would like to happen is for the state of bot h\ndisks to change atomically, i.e., either both should end up as the new\nversion or neither .\nThe general way to solve this problem is to use a write-ahead log of some\nkind to \ufb01rst record what the RAID is about to do (i.e., update two disks\nwith a certain piece of data) before doing it. By taking this appr oach, we\ncan ensure that in the presence of a crash, the right thing will happen; by\nrunning a recovery procedure that replays all pending transactions to the\nRAID, we can ensure that no two mirrored copies (in the RAID-1 ca se)\nare out of sync.\nOne last note: because logging to disk on every write is prohibiti vely\nexpensive, most RAID hardware includes a small amount of non-vola tile\nRAM (e.g., battery-backed) where it performs this type of loggi ng. Thus,\nconsistent update is provided without the high cost of logging to di sk.\nT o analyze steady-state throughput, let us start with the seq uential\nworkload. When writing out to disk sequentially , each logical wr ite must\nresult in two physical writes; for example, when we write logic al block\n0 (in the \ufb01gure above), the RAID internally would write it to both disk\n0 and disk 1. Thus, we can conclude that the maximum bandwidth ob -\ntained during sequential writing to a mirrored array is ( N\n2 \u00b7 S), or half the\npeak bandwidth.\nUnfortunately , we obtain the exact same performance during a se -\nquential read. One might think that a sequential read could do better ,\nbecause it only needs to read one copy of the data, not both. However ,\nlet\u2019s use an example to illustrate why this doesn\u2019t help much. Im agine we\nneed to read blocks 0, 1, 2, 3, 4, 5, 6, and 7. Let\u2019s say we issue the read of\n0 to disk 0, the read of 1 to disk 2, the read of 2 to disk 1, and the re ad of\n3 to disk 3. W e continue by issuing reads to 4, 5, 6, and 7 to disks 0, 2, 1,\nand 3, respectively . One might naively think that because we are utilizing\nall disks, we are achieving the full bandwidth of the array .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "any multi-disk RAID system, known as the consistent-update problem",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "multi",
          "disk",
          "raid",
          "system",
          "known",
          "consistent",
          "update",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The general way to solve this problem is to use a write-ahead log of some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "general",
          "solve",
          "problem",
          "write",
          "ahead"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T o analyze steady-state throughput, let us start with the seq uential",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "analyze",
          "steady",
          "state",
          "throughput",
          "start",
          "uential"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand One last note: because logging to disk on every write is prohibiti vely",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one last note",
          "logging",
          "disk",
          "every",
          "write",
          "prohibiti",
          "vely"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "6 RAID Level 4: Saving Space With Parity",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "38.6 RAID Level 4: Saving Space With Parity\nW e now present a different method of adding redundancy to a disk a r-\nray known as parity. Parity-based approaches attempt to use less capac-\nity and thus overcome the huge space penalty paid by mirrored sys tems.\nThey do so at a cost, however: performance.\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4\n0 1 2 3 P0\n4 5 6 7 P1\n8 9 10 11 P2\n12 13 14 15 P3\nFigure 38.4: RAID-4 With Parity\nHere is an example \ufb01ve-disk RAID-4 system (Figure 38.4). For e ach\nstripe of data, we have added a single parity block that stores the redun-\ndant information for that stripe of blocks. For example, parity bloc k P1\nhas redundant information that it calculated from blocks 4, 5, 6, and 7.\nT o compute parity , we need to use a mathematical function that e n-\nables us to withstand the loss of any one block from our stripe. It tur ns\nout the simple function XOR does the trick quite nicely . For a given set of\nbits, the XOR of all of those bits returns a 0 if there are an even nu mber of\n1\u2019s in the bits, and a 1 if there are an odd number of 1\u2019s. For example:\nC0 C1 C2 C3 P\n0 0 1 1 XOR(0,0,1,1) = 0\n0 1 0 0 XOR(0,1,0,0) = 1\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e now present a different method of adding redundancy to a disk a r-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "present",
          "different",
          "method",
          "adding",
          "redundancy",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ray known as parity. Parity-based approaches attempt to use less capac-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "parity",
          "parity",
          "based",
          "approaches",
          "attempt",
          "less",
          "capac"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 6 RAID Level 4: Saving Space With Parity",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 raid level 4",
          "saving",
          "space",
          "parity"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "RE D U N D A N T AR R AY S O F IN E X P E N S I V ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "RE D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S) 11\nIn the \ufb01rst row (0,0,1,1), there are two 1\u2019s (C2, C3), and thus XO R of\nall of those values will be 0 (P); similarly , in the second row ther e is only\none 1 (C1), and thus the XOR must be 1 (P). Y ou can remember this in a\nsimple way: that the number of 1s in any row , including the parit y bit,\nmust be an even (not odd) number; that is the invariant that the RAID\nmust maintain in order for parity to be correct.\nFrom the example above, you might also be able to guess how parity\ninformation can be used to recover from a failure. Imagine the colu mn la-\nbeled C2 is lost. T o \ufb01gure out what values must have been in the col umn,\nwe simply have to read in all the other values in that row (includ ing the\nXOR\u2019d parity bit) and reconstruct the right answer . Speci\ufb01cally , assume\nthe \ufb01rst row\u2019s value in column C2 is lost (it is a 1); by reading the ot her\nvalues in that row (0 from C0, 0 from C1, 1 from C3, and 0 from the parit y\ncolumn P), we get the values 0, 0, 1, and 0. Because we know that XO R\nkeeps an even number of 1\u2019s in each row , we know what the missing dat a\nmust be: a 1. And that is how reconstruction works in a XOR-based pa r-\nity scheme! Note also how we compute the reconstructed value: we j ust\nXOR the data bits and the parity bits together , in the same way t hat we\ncalculated the parity in the \ufb01rst place.\nNow you might be wondering: we are talking about XORing all of\nthese bits, and yet from above we know that the RAID places 4KB (or\nlarger) blocks on each disk; how do we apply XOR to a bunch of blocks\nto compute the parity? It turns out this is easy as well. Simply pe rform a\nbitwise XOR across each bit of the data blocks; put the result of ea ch bit-\nwise XOR into the corresponding bit slot in the parity block. For ex ample,\nif we had blocks of size 4 bits (yes, this is still quite a bit smal ler than a\n4KB block, but you get the picture), they might look something like this:\nBlock0 Block1 Block2 Block3 Parity\n00 10 11 10 11\n10 01 00 01 10\nAs you can see from the \ufb01gure, the parity is computed for each bit of\neach block and the result placed in the parity block.\nRAID-4 Analysis\nLet us now analyze RAID-4. From a capacity standpoint, RAID-4 us es 1\ndisk for parity information for every group of disks it is protecting . Thus,\nour useful capacity for a RAID group is (N \u2212 1) \u00b7 B.\nReliability is also quite easy to understand: RAID-4 tolerat es 1 disk\nfailure and no more. If more than one disk is lost, there is simply n o way\nto reconstruct the lost data.\nFinally , there is performance. This time, let us start by anal yzing steady-\nstate throughput. Sequential read performance can utilize all of the disks\nexcept for the parity disk, and thus deliver a peak effective b andwidth of\n(N \u2212 1) \u00b7 S MB/s (an easy case).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "From the example above, you might also be able to guess how parity",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "might",
          "also",
          "able",
          "guess",
          "parity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "column P), we get the values 0, 0, 1, and 0. Because we know that XO R",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "column",
          "values",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "keeps an even number of 1\u2019s in each row , we know what the missing dat a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "keeps",
          "even",
          "number",
          "know",
          "missing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "these bits, and yet from above we know that the RAID places 4KB (or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bits",
          "know",
          "raid",
          "places"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "blocks on each disk; how do we apply XOR to a bunch of blocks",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "blocks",
          "disk",
          "apply",
          "bunch",
          "blocks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Let us now analyze RAID-4. From a capacity standpoint, RAID-4 us es 1",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "analyze",
          "raid",
          "capacity",
          "standpoint",
          "raid"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "Reliability is also quite easy to understand: RAID-4 tolerat es 1 disk",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reliability",
          "also",
          "quite",
          "easy",
          "understand",
          "raid",
          "tolerat",
          "disk"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 R E D U N D A N T AR R AY S O F IN E X P E N S ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 R E D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S)\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4\n0 1 2 3 P0\n4 5 6 7 P1\n8 9 10 11 P2\n12 13 14 15 P3\nFigure 38.5: Full-stripe W rites In RAID-4\nT o understand the performance of sequential writes, we must \ufb01r st un-\nderstand how they are done. When writing a big chunk of data to dis k,\nRAID-4 can perform a simple optimization known as a full-stripe write.\nFor example, imagine the case where the blocks 0, 1, 2, and 3 have been\nsent to the RAID as part of a write request (Figure 38.5).\nIn this case, the RAID can simply calculate the new value of P0 ( by\nperforming an XOR across the blocks 0, 1, 2, and 3) and then write a ll of\nthe blocks (including the parity block) to the \ufb01ve disks above in parallel\n(highlighted in gray in the \ufb01gure). Thus, full-stripe write s are the most\nef\ufb01cient way for RAID-4 to write to disk.\nOnce we understand the full-stripe write, calculating the p erformance\nof sequential writes on RAID-4 is easy; the effective bandwidt h is also\n(N \u2212 1) \u00b7 S MB/s. Even though the parity disk is constantly in use during\nthe operation, the client does not gain performance advantage from it.\nNow let us analyze the performance of random reads. As you can also\nsee from the \ufb01gure above, a set of 1-block random reads will be sprea d\nacross the data disks of the system but not the parity disk. Thus, the\neffective performance is: (N \u2212 1) \u00b7 R MB/s.\nRandom writes, which we have saved for last, present the most in-\nteresting case for RAID-4. Imagine we wish to overwrite block 1 i n the\nexample above. W e could just go ahead and overwrite it, but that w ould\nleave us with a problem: the parity block P0 would no longer accura tely\nre\ufb02ect the correct parity value of the stripe; in this example, P0 must also\nbe updated. How can we update it both correctly and ef\ufb01ciently?\nIt turns out there are two methods. The \ufb01rst, known as additive parity,\nrequires us to do the following. T o compute the value of the new par ity\nblock, read in all of the other data blocks in the stripe in paralle l (in the\nexample, blocks 0, 2, and 3) and XOR those with the new block (1). T he\nresult is your new parity block. T o complete the write, you can the n write\nthe new data and new parity to their respective disks, also in parallel.\nThe problem with this technique is that it scales with the numb er of\ndisks, and thus in larger RAIDs requires a high number of reads to com-\npute parity . Thus, the subtractive parity method.\nFor example, imagine this string of bits (4 data bits, one parity ):\nC0 C1 C2 C3 P\n0 0 1 1 XOR(0,0,1,1) = 0\nLet\u2019s imagine that we wish to overwrite bit C2 with a new value wh ich\nwe will call C2 new. The subtractive method works in three steps. First,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand the performance of sequential writes, we must \ufb01r st un-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "performance",
          "sequential",
          "writes",
          "must"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "RAID-4 can perform a simple optimization known as a full-stripe write.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "perform",
          "simple",
          "optimization",
          "known",
          "full",
          "stripe",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Once we understand the full-stripe write, calculating the p erformance",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "full",
          "stripe",
          "write",
          "calculating",
          "erformance"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Now let us analyze the performance of random reads. As you can also",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "analyze",
          "performance",
          "random",
          "reads",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "It turns out there are two methods. The \ufb01rst, known as additive parity,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "turns",
          "methods",
          "known",
          "additive",
          "parity"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "The problem with this technique is that it scales with the numb er of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "technique",
          "scales",
          "numb"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "pute parity . Thus, the subtractive parity method.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pute",
          "parity",
          "thus",
          "subtractive",
          "parity",
          "method"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "we will call C2 new. The subtractive method works in three steps. First,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "subtractive",
          "method",
          "works",
          "three",
          "steps",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Full-stripe W rites In RAID-4",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "full",
          "stripe",
          "rites",
          "raid"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "RE D U N D A N T AR R AY S O F IN E X P E N S I V ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "RE D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S) 13\nwe read in the old data at C2 (C2 old = 1) and the old parity (P old = 0).\nThen, we compare the old data and the new data; if they are the sam e\n(e.g., C2 new = C2 old), then we know the parity bit will also remain the\nsame (i.e., P new = P old). If, however , they are different, then we must \ufb02ip\nthe old parity bit to the opposite of its current state, that is, if (Pold == 1),\nPnew will be set to 0; if (P old == 0), P new will be set to 1. W e can express\nthis whole mess neatly with XOR (where \u2295 is the XOR operator):\nPnew = (Cold \u2295 Cnew) \u2295 Pold (38.1)\nBecause we are dealing with blocks, not bits, we perform this cal cula-\ntion over all the bits in the block (e.g., 4096 bytes in each block m ultiplied\nby 8 bits per byte). Thus, in most cases, the new block will be dif ferent\nthan the old block and thus the new parity block will too.\nY ou should now be able to \ufb01gure out when we would use the additive\nparity calculation and when we would use the subtractive method . Think\nabout how many disks would need to be in the system so that the addi tive\nmethod performs fewer I/Os than the subtractive method; what is the\ncross-over point?\nFor this performance analysis, let us assume we are using the su btrac-\ntive method. Thus, for each write, the RAID has to perform 4 physi cal\nI/Os (two reads and two writes). Now imagine there are lots of wri tes\nsubmitted to the RAID; how many can RAID-4 perform in parallel? T o\nunderstand, let us again look at the RAID-4 layout (Figure 38.6) .\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4\n0 1 2 3 P0\n\u2217 4 5 6 7 +P1\n8 9 10 11 P2\n12 \u2217 13 14 15 +P3\nFigure 38.6: Example: W rites T o 4, 13, And Respective Parity Blocks\nNow imagine there were 2 small writes submitted to the RAID-4 a t\nabout the same time, to blocks 4 and 13 (marked with \u2217 in the diagram).\nThe data for those disks is on disks 0 and 1, and thus the read and wr ite\nto data could happen in parallel, which is good. The problem that a rises\nis with the parity disk; both the requests have to read the rela ted parity\nblocks for 4 and 13, parity blocks 1 and 3 (marked with +). Hopefully , the\nissue is now clear: the parity disk is a bottleneck under this ty pe of work-\nload; we sometimes thus call this the small-write problem for parity-\nbased RAIDs. Thus, even though the data disks could be accessed in\nparallel, the parity disk prevents any parallelism from mate rializing; all\nwrites to the system will be serialized because of the parity d isk. Because\nthe parity disk has to perform two I/Os (one read, one write) per l ogical\nI/O, we can compute the performance of small random writes in RAID -4\nby computing the parity disk\u2019s performance on those two I/Os, and t hus\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Then, we compare the old data and the new data; if they are the sam e",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "data",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(e.g., C2 new = C2 old), then we know the parity bit will also remain the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "know",
          "parity",
          "also",
          "remain"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Y ou should now be able to \ufb01gure out when we would use the additive",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "would",
          "additive"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "parity calculation and when we would use the subtractive method . Think",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "parity",
          "calculation",
          "would",
          "subtractive",
          "method",
          "think"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "method performs fewer I/Os than the subtractive method; what is the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "method",
          "performs",
          "fewer",
          "subtractive",
          "method"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "tive method. Thus, for each write, the RAID has to perform 4 physi cal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tive",
          "method",
          "thus",
          "write",
          "raid",
          "perform",
          "physi"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "understand, let us again look at the RAID-4 layout (Figure 38.6) .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "look",
          "raid",
          "layout",
          "figure"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 6: Example: W rites T o 4, 13, And Respective Parity Blocks",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "example",
          "rites",
          "respective",
          "parity",
          "blocks"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand the\ncross-over point",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "cross",
          "point"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "7 RAID Level 5: Rotating Parity",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "38.7 RAID Level 5: Rotating Parity\nT o address the small-write problem (at least, partially), Pa tterson, Gib-\nson, and Katz introduced RAID-5. RAID-5 works almost identicall y to\nRAID-4, except that it rotates the parity block across drives (Figure 38.7).\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4\n0 1 2 3 P0\n5 6 7 P1 4\n10 11 P2 8 9\n15 P3 12 13 14\nP4 16 17 18 19\nFigure 38.7: RAID-5 With Rotated Parity\nAs you can see, the parity block for each stripe is now rotated across\nthe disks, in order to remove the parity-disk bottleneck for RAID -4.\nRAID-5 Analysis\nMuch of the analysis for RAID-5 is identical to RAID-4. For examp le, the\neffective capacity and failure tolerance of the two levels are identical. So\nare sequential read and write performance. The latency of a sin gle request\n(whether a read or a write) is also the same as RAID-4.\nRandom read performance is a little better , because we can now ut ilize\nall disks. Finally , random write performance improves noticeab ly over\nRAID-4, as it allows for parallelism across requests. Imagine a write to\nblock 1 and a write to block 10; this will turn into requests to di sk 1 and\ndisk 4 (for block 1 and its parity) and requests to disk 0 and disk 2 (for\nblock 10 and its parity). Thus, they can proceed in parallel. In fact, we\ncan generally assume that given a large number of random reques ts, we\nwill be able to keep all the disks about evenly busy . If that is t he case,\nthen our total bandwidth for small writes will be N\n4 \u00b7 R MB/s. The factor\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "will be able to keep all the disks about evenly busy . If that is t he case,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "keep",
          "disks",
          "evenly",
          "busy",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 7: RAID-5 With Rotated Parity",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "raid",
          "rotated",
          "parity"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand raid level 5: rotating parity",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "level",
          "rotating",
          "parity"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "8 RAID Comparison: A Summary",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "38.8 RAID Comparison: A Summary\nW e now summarize our simpli\ufb01ed comparison of RAID levels in Fig-\nure 38.8. Note that we have omitted a number of details to simplif y our\nanalysis. For example, when writing in a mirrored system, the a verage\nseek time is a little higher than when writing to just a single disk, because\nthe seek time is the max of two seeks (one on each disk). Thus, rand om\nwrite performance to two disks will generally be a little less than random\nwrite performance of a single disk. Also, when updating the pari ty disk\nin RAID-4/5, the \ufb01rst read of the old parity will likely cause a f ull seek\nand rotation, but the second write of the parity will only result in rotation.\nHowever , the comparison in Figure 38.8 does capture the essentia l dif-\nferences, and is useful for understanding tradeoffs across RAI D levels.\nFor the latency analysis, we simply use T to represent the time that a\nrequest to a single disk would take.\nT o conclude, if you strictly want performance and do not care about\nreliability , striping is obviously best. If, however , you want r andom I/O\nperformance and reliability , mirroring is the best; the cost you pay is in\nlost capacity . If capacity and reliability are your main goals, then RAID-\n5 is the winner; the cost you pay is in small-write performance. F inally ,\nif you are always doing sequential I/O and want to maximize capa city ,\nRAID-5 also makes the most sense.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ferences, and is useful for understanding tradeoffs across RAI D levels.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ferences",
          "useful",
          "understanding",
          "tradeoffs",
          "across",
          "levels"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "lost capacity . If capacity and reliability are your main goals, then RAID-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lost",
          "capacity",
          "capacity",
          "reliability",
          "main",
          "goals",
          "raid"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand raid comparison: a summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "comparison",
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "38",
    "title": "9 Other Interesting RAID Issues",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "38.9 Other Interesting RAID Issues\nThere are a number of other interesting ideas that one could (and p er-\nhaps should) discuss when thinking about RAID. Here are some thi ngs\nwe might eventually write about.\nFor example, there are many other RAID designs, including Leve ls 2\nand 3 from the original taxonomy , and Level 6 to tolerate multiple d isk\nfaults [C+04]. There is also what the RAID does when a disk fail s; some-\ntimes it has a hot spare sitting around to \ufb01ll in for the failed disk. What\nhappens to performance under failure, and performance during recon-\nstruction of the failed disk? There are also more realistic faul t models,\nto take into account latent sector errors or block corruption [B+08], and\nlots of techniques to handle such faults (see the data integrit y chapter for\ndetails). Finally , you can even build RAID as a software layer: such soft-\nware RAID systems are cheaper but have other problems, including the\nconsistent-update problem [DAA05].",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "For example, there are many other RAID designs, including Leve ls 2",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "example",
          "many",
          "raid",
          "designs",
          "including",
          "leve"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "lots of techniques to handle such faults (see the data integrit y chapter for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lots",
          "techniques",
          "handle",
          "faults",
          "data",
          "integrit",
          "chapter"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand other interesting raid issues",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "interesting",
          "raid",
          "issues"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "38",
    "title": "10 Summary",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "38.10 Summary\nW e have discussed RAID. RAID transforms a number of independen t\ndisks into a large, more capacious, and more reliable single ent ity; impor-\ntantly , it does so transparently , and thus hardware and softwa re above is\nrelatively oblivious to the change.\nThere are many possible RAID levels to choose from, and the exact\nRAID level to use depends heavily on what is important to the end -user .\nFor example, mirrored RAID is simple, reliable, and generally provides\ngood performance but at a high capacity cost. RAID-5, in contrast, is\nreliable and better from a capacity standpoint, but performs qu ite poorly\nwhen there are small writes in the workload. Picking a RAID and s etting\nits parameters (chunk size, number of disks, etc.) properly for a particular\nworkload is challenging, and remains more of an art than a science .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "RAID level to use depends heavily on what is important to the end -user .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "raid",
          "level",
          "depends",
          "heavily",
          "important",
          "user"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "good performance but at a high capacity cost. RAID-5, in contrast, is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "good",
          "performance",
          "high",
          "capacity",
          "cost",
          "raid",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "RE D U N D A N T AR R AY S O F IN E X P E N S I V ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "RE D U N D A N T AR R AY S O F IN E X P E N S I V E DI S K S (RAID S) 17\nReferences\n[B+08] \u201cAn Analysis of Data Corruption in the Storage Stack\u201d by La kshmi N. Bairavasun-\ndaram, Garth R. Goodson, Bianca Schroeder , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-\nDusseau. F AST \u201908, San Jose, CA, February 2008. Our own work analyzing how often disks actu-\nally corrupt your data. Not often, but sometimes! And thus something a reliabl e storage system must\nconsider .\n[BJ88] \u201cDisk Shadowing\u201d by D. Bitton and J. Gray . VLDB 1988. One of the \ufb01rst papers to discuss\nmirroring, therein called \u201cshadowing\u201d.\n[CL95] \u201cStriping in a RAID level 5 disk array\u201d by Peter M. Chen and Edw ard K. Lee. SIGMET-\nRICS 1995. A nice analysis of some of the important parameters in a RAID-5 disk array.\n[C+04] \u201cRow-Diagonal Parity for Double Disk Failure Correction\u201d by P . Corbett, B. English, A.\nGoel, T . Grcanac, S. Kleiman, J. Leong, S. Sankar . F AST \u201904, February 2004. Though not the \ufb01rst\npaper on a RAID system with two disks for parity, it is a recent and highly-un derstandable version of\nsaid idea. Read it to learn more.\n[DAA05] \u201cJournal-guided Resynchronization for Software RAID\u201d by Timo thy E. Denehy , A.\nArpaci-Dusseau, R. Arpaci-Dusseau. F AST 2005. Our own work on the consistent-update problem.\nHere we solve it for Software RAID by integrating the journaling machinery of the \ufb01le system above\nwith the software RAID beneath it.\n[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,\nMichael Malcolm. USENIX Winter 1994, San Francisco, California, 1994. The sparse paper intro-\nducing a landmark product in storage, the write-anywhere \ufb01le layout or W AFL \ufb01le system that underlies\nthe NetApp \ufb01le server .\n[K86] \u201cSynchronized Disk Interleaving\u201d by M.Y . Kim. IEEE T ransactions o n Computers, V ol-\nume C-35: 11, November 1986. Some of the earliest work on RAID is found here.\n[K88] \u201cSmall Disk Arrays \u2013 The Emerging Approach to High Performance\u201d b y F . Kurzweil.\nPresentation at Spring COMPCON \u201988, March 1, 1988, San Francisco, Californi a. Another early\nRAID reference.\n[P+88] \u201cRedundant Arrays of Inexpensive Disks\u201d by D. Patterson, G. Gi bson, R. Katz. SIG-\nMOD 1988. This is considered the RAID paper , written by famous authors Patterson, Gibson, and\nKatz. The paper has since won many test-of-time awards and ushered in the RAID era, i ncluding the\nname RAID itself!\n[PB86] \u201cProviding Fault T olerance in Parallel Secondary Storage Syst ems\u201d by A. Park, K. Bal-\nasubramaniam. Department of Computer Science, Princeton, CS-TR-O57-86, N ovember 1986.\nAnother early work on RAID.\n[SG86] \u201cDisk Striping\u201d by K. Salem, H. Garcia-Molina. IEEE Internati onal Conference on Data\nEngineering, 1986. And yes, another early RAID work. There are a lot of these, which kind of came\nout of the woodwork when the RAID paper was published in SIGMOD.\n[S84] \u201cByzantine Generals in Action: Implementing Fail-Stop Processor s\u201d by F .B. Schneider .\nACM T ransactions on Computer Systems, 2(2):145154, May 1984. Finally, a paper that is not\nabout RAID! This paper is actually about how systems fail, and how to make something behave in a\nfail-stop manner .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "RICS 1995. A nice analysis of some of the important parameters in a RAID-5 disk array.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rics",
          "nice",
          "analysis",
          "important",
          "parameters",
          "raid",
          "disk",
          "array"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "said idea. Read it to learn more.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "said",
          "idea",
          "read",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Here we solve it for Software RAID by integrating the journaling machinery of the \ufb01le system above",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solve",
          "software",
          "raid",
          "integrating",
          "journaling",
          "machinery",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "file",
          "system",
          "design",
          "file",
          "server",
          "appliance",
          "hitz",
          "james"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[K88] \u201cSmall Disk Arrays \u2013 The Emerging Approach to High Performance\u201d b y F . Kurzweil.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "small",
          "disk",
          "arrays",
          "emerging",
          "approach",
          "high",
          "performance",
          "kurzweil"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "[S84] \u201cByzantine Generals in Action: Implementing Fail-Stop Processor s\u201d by F .B. Schneider .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "byzantine",
          "generals",
          "action",
          "implementing",
          "fail",
          "stop",
          "processor",
          "schneider"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 35: 11, November 1986. Some of the earliest work on RAID is found here.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "35",
          "november",
          "earliest",
          "work",
          "raid",
          "found"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "Do the same as the \ufb01rst problem, but this time vary the chunk s ize",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "2. Do the same as the \ufb01rst problem, but this time vary the chunk s ize\nwith -C. How does chunk size change the mappings?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand chunk size change the mappings",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "chunk",
          "size",
          "change",
          "mappings"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Do the same as above, but use the -r \ufb02ag to reverse the nature of",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "3. Do the same as above, but use the -r \ufb02ag to reverse the nature of\neach problem.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Now use the reverse \ufb02ag but increase the size of each request w ith",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "4. Now use the reverse \ufb02ag but increase the size of each request w ith\nthe -S \ufb02ag. T ry specifying sizes of 8k, 12k, and 16k, while varying\nthe RAID level. What happens to the underlying I/O pattern wh en\nthe size of the request increases? Make sure to try this with th e\nsequential workload too ( -W sequential); for what request sizes\nare RAID-4 and RAID-5 much more I/O ef\ufb01cient?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "5",
    "title": "Use the timing mode of the simulator ( -t) to estimate the perfor-",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "5. Use the timing mode of the simulator ( -t) to estimate the perfor-\nmance of 100 random reads to the RAID, while varying the RAID\nlevels, using 4 disks.\n6. Do the same as above, but increase the number of disks. How does\nthe performance of each RAID level scale as the number of disks\nincreases?\n7. Do the same as above, but use all writes ( -w 100) instead of reads.\nHow does the performance of each RAID level scale now? Can you\ndo a rough estimate of the time it will take to complete the workload\nof 100 random writes?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the performance of each RAID level scale as the number of disks\nincreases",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "raid",
          "level",
          "scale",
          "number",
          "disks",
          "increases"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand the performance of each RAID level scale now",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "raid",
          "level",
          "scale"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "8",
    "title": "Run the timing mode one last time, but this time with a sequen-",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "8. Run the timing mode one last time, but this time with a sequen-\ntial workload ( -W sequential). How does the performance vary\nwith RAID level, and when doing reads versus writes? How about\nwhen varying the size of each request? What size should you write\nto a RAID when using RAID-4 or RAID-5?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the performance vary\nwith RAID level, and when doing reads versus writes",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "vary",
          "raid",
          "level",
          "reads",
          "versus",
          "writes"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "1 Files And Directories",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "39.1 Files And Directories\nT wo key abstractions have developed over time in the virtualiza tion\nof storage. The \ufb01rst is the \ufb01le . A \ufb01le is simply a linear array of bytes,\neach of which you can read or write. Each \ufb01le has some kind of low-level\nname, usually a number of some kind; often, the user is not aware of\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T wo key abstractions have developed over time in the virtualiza tion",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "abstractions",
          "developed",
          "time",
          "virtualiza",
          "tion"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand files and directories",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "files",
          "directories"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 I N T E R L U D E : F I L E S A N D DI R E C TO ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\n/\nfoo\nbar.txt\nbar\nfoobar\nbar.txt\nFigure 39.1: An Example Directory T ree\nthis name (as we will see). For historical reasons, the low-level name of a\n\ufb01le is often referred to as its inode number . W e\u2019ll be learning a lot more\nabout inodes in future chapters; for now , just assume that each \ufb01l e has an\ninode number associated with it.\nIn most systems, the OS does not know much about the structure of\nthe \ufb01le (e.g., whether it is a picture, or a text \ufb01le, or C code); ra ther , the\nresponsibility of the \ufb01le system is simply to store such data per sistently\non disk and make sure that when you request the data again, you get\nwhat you put there in the \ufb01rst place. Doing so is not as simple as it seems!\nThe second abstraction is that of a directory. A directory , like a \ufb01le,\nalso has a low-level name (i.e., an inode number), but its conten ts are\nquite speci\ufb01c: it contains a list of (user-readable name, low-l evel name)\npairs. For example, let\u2019s say there is a \ufb01le with the low-level na me \u201c10\u201d,\nand it is referred to by the user-readable name of \u201cfoo\u201d. The dire ctory\nthat \u201cfoo\u201d resides in thus would have an entry (\u201cfoo\u201d, \u201c10\u201d) that ma ps\nthe user-readable name to the low-level name. Each entry in a d irectory\nrefers to either \ufb01les or other directories. By placing directori es within\nother directories, users are able to build an arbitrary directory tree (or\ndirectory hierarchy ), under which all \ufb01les and directories are stored.\nThe directory hierarchy starts at a root directory (in U N I X-based sys-\ntems, the root directory is simply referred to as /) and uses some kind\nof separator to name subsequent sub-directories until the desired \ufb01le or\ndirectory is named. For example, if a user created a directory foo in the\nroot directory /, and then created a \ufb01le bar.txt in the directory foo,\nwe could refer to the \ufb01le by its absolute pathname , which in this case\nwould be /foo/bar.txt. See Figure 39.1 for a more complex directory\ntree; valid directories in the example are /, /foo, /bar, /bar/bar,\n/bar/foo and valid \ufb01les are /foo/bar.txt and /bar/foo/bar.txt.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01le is often referred to as its inode number . W e\u2019ll be learning a lot more",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "often",
          "referred",
          "inode",
          "number",
          "learning"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "In most systems, the OS does not know much about the structure of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "systems",
          "know",
          "much",
          "structure"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "other directories, users are able to build an arbitrary directory tree (or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directories",
          "users",
          "able",
          "build",
          "arbitrary",
          "directory",
          "tree"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "directory is named. For example, if a user created a directory foo in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "named",
          "example",
          "user",
          "created",
          "directory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "root directory /, and then created a \ufb01le bar.txt in the directory foo,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "root",
          "directory",
          "created",
          "directory"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 1: An Example Directory T ree",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "example",
          "directory"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "2 The File System Interface",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "39.2 The File System Interface\nLet\u2019s now discuss the \ufb01le system interface in more detail. W e\u2019ll s tart\nwith the basics of creating, accessing, and deleting \ufb01les. Y ou may think\nthis is straightforward, but along the way we\u2019ll discover the mys terious\ncall that is used to remove \ufb01les, known as unlink(). Hopefully , by the\nend of this chapter , this mystery won\u2019t be so mysterious to you!",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "call that is used to remove \ufb01les, known as unlink(). Hopefully , by the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "used",
          "remove",
          "known",
          "unlink",
          "hopefully"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the file system interface",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "system",
          "interface"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "39",
    "title": "3 Creating Files",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "39.3 Creating Files\nW e\u2019ll start with the most basic of operations: creating a \ufb01le. This can be\naccomplished with the open system call; by calling open() and passing\nit the O\nCREAT \ufb02ag, a program can create a new \ufb01le. Here is some exam-\nple code to create a \ufb01le called \u201cfoo\u201d in the current working direct ory:\nint fd = open(\"foo\", O_CREAT|O_WRONLY|O_TRUNC,\nS_IRUSR|S_IWUSR);\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "CREAT \ufb02ag, a program can create a new \ufb01le. Here is some exam-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "creat",
          "program",
          "create",
          "exam"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ple code to create a \ufb01le called \u201cfoo\u201d in the current working direct ory:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "code",
          "create",
          "called",
          "current",
          "working",
          "direct"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand creating files",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "creating",
          "files"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 I N T E R L U D E : F I L E S A N D DI R E C TO ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nAS I D E : T H E C R E A T() SY S T E M CA L L\nThe older way of creating a \ufb01le is to call creat(), as follows:\n// option: add second flag to set permissions\nint fd = creat(\"foo\");\nY ou can think of creat() as open() with the following \ufb02ags: O\nCREAT\n| O WRONLY | O TRUNC. Because open() can create a \ufb01le, the usage\nof creat() has somewhat fallen out of favor (indeed, it could just be\nimplemented as a library call to open()); however , it does hold a special\nplace in U N I X lore. Speci\ufb01cally , when Ken Thompson was asked what he\nwould do differently if he were redesigning U N I X, he replied: \u201cI\u2019d spell\ncreat with an e.\u201d\nThe routine open() takes a number of different \ufb02ags. In this exam-\nple, the second parameter creates the \ufb01le ( O CREAT) if it does not exist,\nensures that the \ufb01le can only be written to ( O WRONLY), and, if the \ufb01le\nalready exists, truncates it to a size of zero bytes thus removi ng any exist-\ning content ( O TRUNC). The third parameter speci\ufb01es permissions, in this\ncase making the \ufb01le readable and writable by the owner .\nOne important aspect of open() is what it returns: a \ufb01le descriptor . A\n\ufb01le descriptor is just an integer , private per process, and is u sed in U N I X\nsystems to access \ufb01les; thus, once a \ufb01le is opened, you use the \ufb01le de-\nscriptor to read or write the \ufb01le, assuming you have permission to do so.\nIn this way , a \ufb01le descriptor is a capability [L84], i.e., an opaque handle\nthat gives you the power to perform certain operations. Another way to\nthink of a \ufb01le descriptor is as a pointer to an object of type \ufb01le; once you\nhave such an object, you can call other \u201cmethods\u201d to access the \ufb01le , like\nread() and write() (we\u2019ll see how to do so below).\nAs stated above, \ufb01le descriptors are managed by the operating sy stem\non a per-process basis. This means some kind of simple structure ( e.g., an\narray) is kept in the proc structure on U N I X systems. Here is the relevant\npiece from the xv6 kernel [CK+08]:\nstruct proc {\n...\nstruct file *ofile[NOFILE]; // Open files\n...\n};\nA simple array (with a maximum of NOFILE open \ufb01les) tracks which\n\ufb01les are opened on a per-process basis. Each entry of the array is a ctually\njust a pointer to a struct file, which will be used to track information\nabout the \ufb01le being read or written; we\u2019ll discuss this further b elow .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "| O WRONLY | O TRUNC. Because open() can create a \ufb01le, the usage",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wronly",
          "trunc",
          "open",
          "create",
          "usage"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "implemented as a library call to open()); however , it does hold a special",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implemented",
          "library",
          "call",
          "open",
          "however",
          "hold",
          "special"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "would do differently if he were redesigning U N I X, he replied: \u201cI\u2019d spell",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "would",
          "differently",
          "redesigning",
          "replied",
          "spell"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ple, the second parameter creates the \ufb01le ( O CREAT) if it does not exist,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "second",
          "parameter",
          "creates",
          "creat",
          "exist"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "One important aspect of open() is what it returns: a \ufb01le descriptor . A",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "aspect",
          "open",
          "returns",
          "descriptor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "have such an object, you can call other \u201cmethods\u201d to access the \ufb01le , like",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "object",
          "call",
          "methods",
          "access",
          "like"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand This: some kind of simple structure ( e.g., an",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this",
          "kind",
          "simple",
          "structure"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand AS I D E: T H E C R E A T() SY S T E M CA L L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand as follows: // option: add second flag to set permissions",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as follows",
          "option",
          "second",
          "flag",
          "permissions"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "4 Reading And W riting Files",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "39.4 Reading And W riting Files\nOnce we have some \ufb01les, of course we might like to read or write them .\nLet\u2019s start by reading an existing \ufb01le. If we were typing at a com mand\nline, we might just use the program cat to dump the contents of the \ufb01le\nto the screen.\nprompt> echo hello > foo\nprompt> cat foo\nhello\nprompt>\nIn this code snippet, we redirect the output of the program echo to\nthe \ufb01le foo, which then contains the word \u201chello\u201d in it. W e then use cat\nto see the contents of the \ufb01le. But how does the cat program access the\n\ufb01le foo?\nT o \ufb01nd this out, we\u2019ll use an incredibly useful tool to trace the sy s-\ntem calls made by a program. On Linux, the tool is called strace; other\nsystems have similar tools (see dtruss on a Mac, or truss on some older\nUN I X variants). What strace does is trace every system call made by a\nprogram while it runs, and dump the trace to the screen for you to s ee.\nHere is an example of using strace to \ufb01gure out what cat is doing\n(some calls removed for readability):\nprompt> strace cat foo\n...\nopen(\"foo\", O_RDONLY|O_LARGEFILE) = 3\nread(3, \"hello\\n\", 4096) = 6\nwrite(1, \"hello\\n\", 6) = 6\nhello\nread(3, \"\", 4096) = 0\nclose(3) = 0\n...\nprompt>\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand reading and w riting files",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "riting",
          "files"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand the cat program access the\n\ufb01le foo",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "access"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 I N T E R L U D E : F I L E S A N D DI R E C TO ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nThe \ufb01rst thing that cat does is open the \ufb01le for reading. A couple\nof things we should note about this; \ufb01rst, that the \ufb01le is only opened for\nreading (not writing), as indicated by the O RDONLY \ufb02ag; second, that\nthe 64-bit offset be used ( O LARGEFILE); third, that the call to open()\nsucceeds and returns a \ufb01le descriptor , which has the value of 3.\nWhy does the \ufb01rst call to open() return 3, not 0 or perhaps 1 as you\nmight expect? As it turns out, each running process already has three\n\ufb01les open, standard input (which the process can read to receiv e input),\nstandard output (which the process can write to in order to dump i nfor-\nmation to the screen), and standard error (which the process can write\nerror messages to). These are represented by \ufb01le descriptors 0, 1, and 2,\nrespectively . Thus, when you \ufb01rst open another \ufb01le (as cat does above),\nit will almost certainly be \ufb01le descriptor 3.\nAfter the open succeeds, cat uses the read() system call to repeat-\nedly read some bytes from a \ufb01le. The \ufb01rst argument to read() is the \ufb01le\ndescriptor , thus telling the \ufb01le system which \ufb01le to read; a pr ocess can of\ncourse have multiple \ufb01les open at once, and thus the descriptor en ables\nthe operating system to know which \ufb01le a particular read refers to. The\nsecond argument points to a buffer where the result of the read() will be\nplaced; in the system-call trace above, strace shows the resul ts of the read\nin this spot (\u201chello\u201d). The third argument is the size of the buff er , which\nin this case is 4 KB. The call to read() returns successfully as well, here\nreturning the number of bytes it read (6, which includes 5 for th e letters\nin the word \u201chello\u201d and one for an end-of-line marker).\nAt this point, you see another interesting result of the strace: a single\ncall to the write() system call, to the \ufb01le descriptor 1. As we mentioned\nabove, this descriptor is known as the standard output, and thus i s used\nto write the word \u201chello\u201d to the screen as the program cat is meant to\ndo. But does it call write() directly? Maybe (if it is highly optimized).\nBut if not, what cat might do is call the library routine printf(); in-\nternally , printf() \ufb01gures out all the formatting details passed to it, and\neventually writes to standard output to print the results to t he screen.\nThe cat program then tries to read more from the \ufb01le, but since there\nare no bytes left in the \ufb01le, the read() returns 0 and the program knows\nthat this means it has read the entire \ufb01le. Thus, the program ca lls close()\nto indicate that it is done with the \ufb01le \u201cfoo\u201d, passing in the corre sponding\n\ufb01le descriptor . The \ufb01le is thus closed, and the reading of it thus complete.\nW riting a \ufb01le is accomplished via a similar set of steps. First, a \ufb01le\nis opened for writing, then the write() system call is called, perhaps\nrepeatedly for larger \ufb01les, and then close(). Use strace to trace writes\nto a \ufb01le, perhaps of a program you wrote yourself, or by tracing the dd\nutility , e.g., dd if=foo of=bar.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the operating system to know which \ufb01le a particular read refers to. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "operating",
          "system",
          "know",
          "particular",
          "read",
          "refers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "above, this descriptor is known as the standard output, and thus i s used",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "descriptor",
          "known",
          "standard",
          "output",
          "thus",
          "used"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "are no bytes left in the \ufb01le, the read() returns 0 and the program knows",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bytes",
          "left",
          "read",
          "returns",
          "program",
          "knows"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "5 Reading And W riting, But Not Sequentially",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "39.5 Reading And W riting, But Not Sequentially\nThus far , we\u2019ve discussed how to read and write \ufb01les, but all acc ess\nhas been sequential; that is, we have either read a \ufb01le from the beginning\nto the end, or written a \ufb01le out from beginning to end.\nSometimes, however , it is useful to be able to read or write to a spe -\nci\ufb01c offset within a \ufb01le; for example, if you build an index over a t ext\ndocument, and use it to look up a speci\ufb01c word, you may end up reading\nfrom some random offsets within the document. T o do so, we will use\nthe lseek() system call. Here is the function prototype:\noff_t lseek(int fildes, off_t offset, int whence);\nThe \ufb01rst argument is familiar (a \ufb01le descriptor). The second ar gu-\nment is the offset, which positions the \ufb01le offset to a particular location\nwithin the \ufb01le. The third argument, called whence for historical reasons,\ndetermines exactly how the seek is performed. From the man page:\nIf whence is SEEK_SET, the offset is set to offset bytes.\nIf whence is SEEK_CUR, the offset is set to its current\nlocation plus offset bytes.\nIf whence is SEEK_END, the offset is set to the size of\nthe file plus offset bytes.\nAs you can tell from this description, for each \ufb01le a process opens, t he\nOS tracks a \u201ccurrent\u201d offset, which determines where the next read or\nwrite will begin reading from or writing to within the \ufb01le. Thus , part\nof the abstraction of an open \ufb01le is that it has a current offset, whi ch\nis updated in one of two ways. The \ufb01rst is when a read or write of N\nbytes takes place, N is added to the current offset; thus each read or write\nimplicitly updates the offset. The second is explicitly with lseek, which\nchanges the offset as speci\ufb01ed above.\nThe offset, as you might have guessed, is kept in that struct file\nwe saw earlier , as referenced from the struct proc. Here is a (simpli-\n\ufb01ed) xv6 de\ufb01nition of the structure:\nstruct file {\nint ref;\nchar readable;\nchar writable;\nstruct inode *ip;\nuint off;\n};\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Sometimes, however , it is useful to be able to read or write to a spe -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sometimes",
          "however",
          "useful",
          "able",
          "read",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand From the man page: If whence is SEEK_SET, the offset is set to offset bytes.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "from the man page",
          "whence",
          "offset",
          "offset",
          "bytes"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand reading and w riting, but not sequentially",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "riting",
          "sequentially"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 I N T E R L U D E : F I L E S A N D DI R E C TO ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nAS I D E : C A L L I N G L S E E K() DO E S NO T PE R F O R M A D I S K SE E K\nThe poorly-named system call lseek() confuses many a student try-\ning to understand disks and how the \ufb01le systems atop them work. Do\nnot confuse the two! The lseek() call simply changes a variable in OS\nmemory that tracks, for a particular process, at which offset its next read\nor write will start. A disk seek occurs when a read or write issued to the\ndisk is not on the same track as the last read or write, and thus nec es-\nsitates a head movement. Making this even more confusing is the f act\nthat calling lseek() to read or write from/to random parts of a \ufb01le, and\nthen reading/writing to those random parts, will indeed lead t o more\ndisk seeks. Thus, calling lseek() can lead to a seek in an upcoming\nread or write, but absolutely does not cause any disk I/O to occur it self.\nAs you can see in the structure, the OS can use this to determine\nwhether the opened \ufb01le is readable or writable (or both), which un der-\nlying \ufb01le it refers to (as pointed to by the struct inode pointer ip),\nand the current offset ( off). There is also a reference count ( ref), which\nwe will discuss further below .\nThese \ufb01le structures represent all of the currently opened \ufb01le s in the\nsystem; together , they are sometimes referred to as the open \ufb01le table .\nThe xv6 kernel just keeps these as an array as well, with one lock per\nentry , as shown here:\nstruct {\nstruct spinlock lock;\nstruct file file[NFILE];\n} ftable;\nLet\u2019s make this a bit clearer with a few examples. First, let\u2019s t rack a\nprocess that opens a \ufb01le (of size 300 bytes) and reads it by callin g the\nread() system call repeatedly , each time reading 100 bytes. Here is a\ntrace of the relevant system calls, along with the values retur ned by each\nsystem call, and the value of the current offset in the open \ufb01le ta ble for\nthis \ufb01le access:\nReturn Current\nSystem Calls Code Offset\nfd = open(\"file\", O RDONLY); 3 0\nread(fd, buffer, 100); 100 100\nread(fd, buffer, 100); 100 200\nread(fd, buffer, 100); 100 300\nread(fd, buffer, 100); 0 300\nclose(fd); 0 \u2013\nThere are a couple of items of interest to note from the trace. First ,\nyou can see how the current offset gets initialized to zero when t he \ufb01le is\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ing to understand disks and how the \ufb01le systems atop them work. Do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "disks",
          "systems",
          "atop",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand lying \ufb01le it: (as pointed to by the struct inode pointer ip),",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lying \ufb01le it",
          "pointed",
          "struct",
          "inode",
          "pointer"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand AS I D E: C A L L I N G L S E E K() DO E S NO T PE R F O R M A D I S K SE E K",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "6 Shared File T able Entries: fork() And dup()",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "39.6 Shared File T able Entries: fork() And dup()\nIn many cases (as in the examples shown above), the mapping of \ufb01le\ndescriptor to an entry in the open \ufb01le table is a one-to-one mapping . For\nexample, when a process runs, it might decide to open a \ufb01le, read it, and\nthen close it; in this example, the \ufb01le will have a unique entry in the open\n\ufb01le table. Even if some other process reads the same \ufb01le at the sam e time,\neach will have its own entry in the open \ufb01le table. In this way , ea ch logical\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand shared file t able entries: fork() and dup()",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shared",
          "file",
          "able",
          "entries",
          "fork"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nint main(int argc, char *argv[]) {\nint fd = open(\"file.txt\", O_RDONLY);\nassert(fd >= 0);\nint rc = fork();\nif (rc == 0) {\nrc = lseek(fd, 10, SEEK_SET);\nprintf(\"child: offset %d\\n\", rc);\n} else if (rc > 0) {\n(void) wait(NULL);\nprintf(\"parent: offset %d\\n\",\n(int) lseek(fd, 0, SEEK_CUR));\n}\nreturn 0;\n}\nFigure 39.2: Shared Parent/Child File T able Entries ( fork-seek.c)\nreading or writing of a \ufb01le is independent, and each has its own cu rrent\noffset while it accesses the given \ufb01le.\nHowever , there are a few interesting cases where an entry in th e open\n\ufb01le table is shared. One of those cases occurs when a parent process creates\na child process with fork(). Figure 39.2 shows a small code snippet in\nwhich a parent creates a child and then waits for it to complete. The child\nadjusts the current offset via a call to lseek() and then exits. Finally the\nparent, after waiting for the child, checks the current offset and prints out\nits value.\nWhen we run this program, we see the following output:\nprompt> ./fork-seek\nchild: offset 10\nparent: offset 10\nprompt>\nFigure 39.3 shows the relationships that connect each process\u2019s p rivate\ndescriptor array , the shared open \ufb01le table entry , and the refe rence from\nit to the underlying \ufb01le-system inode. Note that we \ufb01nally make use of\nthe reference count here. When a \ufb01le table entry is shared, its reference\ncount is incremented; only when both processes close the \ufb01le (or exi t) will\nthe entry be removed.\nSharing open \ufb01le table entries across parent and child is occasion ally\nuseful. For example, if you create a number of processes that are c ooper-\natively working on a task, they can write to the same output \ufb01le wi thout\nany extra coordination. For more on what is shared by processes when\nfork() is called, please see the man pages.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01le table is shared. One of those cases occurs when a parent process creates",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "table",
          "shared",
          "cases",
          "occurs",
          "parent",
          "process",
          "creates"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "which a parent creates a child and then waits for it to complete. The child",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "parent",
          "creates",
          "child",
          "waits",
          "complete",
          "child"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "useful. For example, if you create a number of processes that are c ooper-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "useful",
          "example",
          "create",
          "number",
          "processes",
          "ooper"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand 2: Shared Parent/Child File T able Entries ( fork-seek.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "shared",
          "parent",
          "child",
          "file",
          "able",
          "entries",
          "fork",
          "seek"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "IN T E R L U D E : F I L E S A N D DI R E C TO R I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "IN T E R L U D E : F I L E S A N D DI R E C TO R I E S 11\nParent\nFile\nDescriptors\n3:\nChild\nFile\nDescriptors\n3:\nOpen File Table\nrefcnt: 2\noff: 10\ninode: \nInode #1000\n(file.txt)\nFigure 39.3: Processes Sharing An Open File T able Entry\nOne other interesting, and perhaps more useful, case of sharing occurs\nwith the dup() system call (and its cousins, dup2() and dup3()).\nThe dup() call allows a process to create a new \ufb01le descriptor that\nrefers to the same underlying open \ufb01le as an existing descript or . Figure\n39.4 shows a small code snippet that shows how dup() can be used.\nThe dup() call (and, in particular , dup2()) is useful when writing\na U N I X shell and performing operations like output redirection; spend\nsome time and think about why! And now , you are thinking: why didn\u2019t\nthey tell me this when I was doing the shell project? Oh well, you c an\u2019t get\neverything in the right order , even in an incredible book about ope rating\nsystems. Sorry!\nint main(int argc, char *argv[]) {\nint fd = open(\"README\", O_RDONLY);\nassert(fd >= 0);\nint fd2 = dup(fd);\n// now fd and fd2 can be used interchangeably\nreturn 0;\n}\nFigure 39.4: Shared File T able Entry With dup() (dup.c)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The dup() call allows a process to create a new \ufb01le descriptor that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "allows",
          "process",
          "create",
          "descriptor"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_8",
        "text": "understand 3: Processes Sharing An Open File T able Entry",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "processes",
          "sharing",
          "open",
          "file",
          "able",
          "entry"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand 4: Shared File T able Entry With dup() (dup.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "shared",
          "file",
          "able",
          "entry"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand shows a small code snippet that shows how dup() can be used.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "small",
          "code",
          "snippet",
          "shows",
          "used"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "7 W riting Immediately With fsync()",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "39.7 W riting Immediately With fsync()\nMost times when a program calls write(), it is just telling the \ufb01le\nsystem: please write this data to persistent storage, at some p oint in the\nfuture. The \ufb01le system, for performance reasons, will buffer such writes\nin memory for some time (say 5 seconds, or 30); at that later point in\ntime, the write(s) will actually be issued to the storage devi ce. From the\nperspective of the calling application, writes seem to complet e quickly ,\nand only in rare cases (e.g., the machine crashes after the write() call\nbut before the write to disk) will data be lost.\nHowever , some applications require something more than this even -\ntual guarantee. For example, in a database management system (DBMS),\ndevelopment of a correct recovery protocol requires the ability to f orce\nwrites to disk from time to time.\nT o support these types of applications, most \ufb01le systems provide s ome\nadditional control APIs. In the U N I X world, the interface provided to ap-\nplications is known as fsync(int fd). When a process calls fsync()\nfor a particular \ufb01le descriptor , the \ufb01le system responds by forci ng all dirty\n(i.e., not yet written) data to disk, for the \ufb01le referred to by t he speci\ufb01ed\n\ufb01le descriptor . The fsync() routine returns once all of these writes are\ncomplete.\nHere is a simple example of how to use fsync(). The code opens\nthe \ufb01le foo, writes a single chunk of data to it, and then calls fsync()\nto ensure the writes are forced immediately to disk. Once the fsync()\nreturns, the application can safely move on, knowing that the dat a has\nbeen persisted (if fsync() is correctly implemented, that is).\nint fd = open(\"foo\", O_CREAT|O_WRONLY|O_TRUNC,\nS_IRUSR|S_IWUSR);\nassert(fd > -1);\nint rc = write(fd, buffer, size);\nassert(rc == size);\nrc = fsync(fd);\nassert(rc == 0);\nInterestingly , this sequence does not guarantee everything t hat you\nmight expect; in some cases, you also need to fsync() the directory that\ncontains the \ufb01le foo. Adding this step ensures not only that the \ufb01le itself\nis on disk, but that the \ufb01le, if newly created, also is durably a part of the\ndirectory . Not surprisingly , this type of detail is often overlooke d, leading\nto many application-level bugs [P+13,P+14].",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "development of a correct recovery protocol requires the ability to f orce",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "development",
          "correct",
          "recovery",
          "protocol",
          "requires",
          "ability",
          "orce"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "plications is known as fsync(int fd). When a process calls fsync()",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "plications",
          "known",
          "fsync",
          "process",
          "calls",
          "fsync"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "returns, the application can safely move on, knowing that the dat a has",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "returns",
          "application",
          "safely",
          "move",
          "knowing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "been persisted (if fsync() is correctly implemented, that is).",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "persisted",
          "fsync",
          "correctly",
          "implemented"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "is on disk, but that the \ufb01le, if newly created, also is durably a part of the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "disk",
          "newly",
          "created",
          "also",
          "durably",
          "part"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand w riting immediately with fsync()",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "riting",
          "immediately",
          "fsync"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "39",
    "title": "8 Renaming Files",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "39.8 Renaming Files\nOnce we have a \ufb01le, it is sometimes useful to be able to give a \ufb01le a\ndifferent name. When typing at the command line, this is accomp lished\nwith mv command; in this example, the \ufb01le foo is renamed bar:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Once we have a \ufb01le, it is sometimes useful to be able to give a \ufb01le a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sometimes",
          "useful",
          "able",
          "give"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand renaming files",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "renaming",
          "files"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "9 Getting Information About Files",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "39.9 Getting Information About Files\nBeyond \ufb01le access, we expect the \ufb01le system to keep a fair amount\nof information about each \ufb01le it is storing. W e generally call such data\nabout \ufb01les metadata. T o see the metadata for a certain \ufb01le, we can use the\nstat() or fstat() system calls. These calls take a pathname (or \ufb01le\ndescriptor) to a \ufb01le and \ufb01ll in a stat structure as seen in Figure 39.5.\nY ou can see that there is a lot of information kept about each \ufb01le, in-\ncluding its size (in bytes), its low-level name (i.e., inode nu mber), some\nownership information, and some information about when the \ufb01le was\naccessed or modi\ufb01ed, among other things. T o see this information, y ou\ncan use the command line tool stat. In this example, we \ufb01rst create\na \ufb01le (called file) and then use the stat command line tool to learn\nsome things about the \ufb01le.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "can use the command line tool stat. In this example, we \ufb01rst create",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "command",
          "line",
          "tool",
          "stat",
          "example",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a \ufb01le (called file) and then use the stat command line tool to learn",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "called",
          "file",
          "stat",
          "command",
          "line",
          "tool",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand getting information about files",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "getting",
          "information",
          "files"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "10 Removing Files",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "39.10 Removing Files\nAt this point, we know how to create \ufb01les and access them, either s e-\nquentially or not. But how do you delete \ufb01les? If you\u2019ve used U N I X, you\nprobably think you know: just run the program rm. But what system call\ndoes rm use to remove a \ufb01le?\n1 Some \ufb01le systems call these structures similar , but slightly dif ferent, names, such as\ndnodes; the basic idea is similar however .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "At this point, we know how to create \ufb01les and access them, either s e-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "point",
          "know",
          "create",
          "access",
          "either"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "probably think you know: just run the program rm. But what system call",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "probably",
          "think",
          "know",
          "program",
          "system",
          "call"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand removing files",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "removing",
          "files"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "11 Making Directories",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "39.11 Making Directories\nBeyond \ufb01les, a set of directory-related system calls enable you t o make,\nread, and delete directories. Note you can never write to a direc tory di-\nrectly . Because the format of the directory is considered \ufb01le sys tem meta-\ndata, the \ufb01le system considers itself responsible for the integ rity of direc-\ntory data; thus, you can only update a directory indirectly by , for exam-\nple, creating \ufb01les, directories, or other object types within it . In this way ,\nthe \ufb01le system makes sure that directory contents are as expect ed.\nT o create a directory , a single system call, mkdir(), is available. The\neponymous mkdir program can be used to create such a directory . Let\u2019s\ntake a look at what happens when we run the mkdir program to make a\nsimple directory called foo:\nprompt> strace mkdir foo\n...\nmkdir(\"foo\", 0777) = 0\n...\nprompt>\nWhen such a directory is created, it is considered \u201cempty\u201d, alt hough it\ndoes have a bare minimum of contents. Speci\ufb01cally , an empty direc tory\nhas two entries: one entry that refers to itself, and one entry t hat refers\nto its parent. The former is referred to as the \u201c.\u201d (dot) director y , and the\nlatter as \u201c..\u201d (dot-dot). Y ou can see these directories by passin g a \ufb02ag ( -a)\nto the program ls:\nprompt> ls -a\n./ ../\nprompt> ls -al\ntotal 8\ndrwxr-x--- 2 remzi remzi 6 Apr 30 16:17 ./\ndrwxr-x--- 26 remzi remzi 4096 Apr 30 16:17 ../\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o create a directory , a single system call, mkdir(), is available. The",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "directory",
          "single",
          "system",
          "call",
          "mkdir",
          "available"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "eponymous mkdir program can be used to create such a directory . Let\u2019s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "eponymous",
          "mkdir",
          "program",
          "used",
          "create",
          "directory"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "When such a directory is created, it is considered \u201cempty\u201d, alt hough it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "created",
          "considered",
          "empty",
          "hough"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand one entry that: itself, and one entry t hat refers",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one entry that",
          "entry",
          "refers"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand making directories",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "making",
          "directories"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "12 Reading Directories",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "39.12 Reading Directories\nNow that we\u2019ve created a directory , we might wish to read one too.\nIndeed, that is exactly what the program ls does. Let\u2019s write our own\nlittle tool like ls and see how it is done.\nInstead of just opening a directory as if it were a \ufb01le, we instead use\na new set of calls. Below is an example program that prints the cont ents\nof a directory . The program uses three calls, opendir(), readdir(),\nand closedir(), to get the job done, and you can see how simple the\ninterface is; we just use a simple loop to read one directory entry at a time,\nand print out the name and inode number of each \ufb01le in the directory .\nint main(int argc, char *argv[]) {\nDIR *dp = opendir(\".\");\nassert(dp != NULL);\nstruct dirent *d;\nwhile ((d = readdir(dp)) != NULL) {\nprintf(\"%lu %s\\n\", (unsigned long) d->d_ino,\nd->d_name);\n}\nclosedir(dp);\nreturn 0;\n}\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now that we\u2019ve created a directory , we might wish to read one too.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "directory",
          "might",
          "wish",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand reading directories",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "directories"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "13 Deleting Directories",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "39.13 Deleting Directories\nFinally , you can delete a directory with a call to rmdir() (which is\nused by the program of the same name, rmdir). Unlike \ufb01le deletion,\nhowever , removing directories is more dangerous, as you could poten-\ntially delete a large amount of data with a single command. Thus, rmdir()\nhas the requirement that the directory be empty (i.e., only has \u201c.\u201d and \u201c..\u201d\nentries) before it is deleted. If you try to delete a non-empty di rectory , the\ncall to rmdir() simply will fail.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand deleting directories",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "deleting",
          "directories"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "39",
    "title": "14 Hard Links",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "39.14 Hard Links\nW e now come back to the mystery of why removing a \ufb01le is performed\nvia unlink(), by understanding a new way to make an entry in the\n\ufb01le system tree, through a system call known as link(). The link()\nsystem call takes two arguments, an old pathname and a new one; w hen\nyou \u201clink\u201d a new \ufb01le name to an old one, you essentially create anoth er\nway to refer to the same \ufb01le. The command-line program ln is used to\ndo this, as we see in this example:\nprompt> echo hello > file\nprompt> cat file\nhello\nprompt> ln file file2\nprompt> cat file2\nhello\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "via unlink(), by understanding a new way to make an entry in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "unlink",
          "understanding",
          "make",
          "entry"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "\ufb01le system tree, through a system call known as link(). The link()",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "tree",
          "system",
          "call",
          "known",
          "link",
          "link"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "you \u201clink\u201d a new \ufb01le name to an old one, you essentially create anoth er",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "link",
          "name",
          "essentially",
          "create",
          "anoth"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand hard links",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "hard",
          "links"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "18 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "18 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nHere we created a \ufb01le with the word \u201chello\u201d in it, and called the \ufb01 le\nfile2 . W e then create a hard link to that \ufb01le using the ln program. After\nthis, we can examine the \ufb01le by either opening file or file2.\nThe way link() works is that it simply creates another name in the\ndirectory you are creating the link to, and refers it to the same inode num-\nber (i.e., low-level name) of the original \ufb01le. The \ufb01le is not copie d in any\nway; rather , you now just have two human-readable names ( file and\nfile2) that both refer to the same \ufb01le. W e can even see this in the dire c-\ntory itself, by printing out the inode number of each \ufb01le:\nprompt> ls -i file file2\n67158084 file\n67158084 file2\nprompt>\nBy passing the -i \ufb02ag to ls, it prints out the inode number of each \ufb01le\n(as well as the \ufb01le name). And thus you can see what link really h as done:\njust make a new reference to the same exact inode number (67158 084 in\nthis example).\nBy now you might be starting to see why unlink() is called unlink().\nWhen you create a \ufb01le, you are really doing two things. First, you are\nmaking a structure (the inode) that will track virtually all r elevant infor-\nmation about the \ufb01le, including its size, where its blocks are on d isk, and\nso forth. Second, you are linking a human-readable name to that \ufb01le, and\nputting that link into a directory .\nAfter creating a hard link to a \ufb01le, to the \ufb01le system, there is no dif-\nference between the original \ufb01le name ( file) and the newly created \ufb01le\nname ( file2); indeed, they are both just links to the underlying meta-\ndata about the \ufb01le, which is found in inode number 67158084.\nThus, to remove a \ufb01le from the \ufb01le system, we call unlink(). In the\nexample above, we could for example remove the \ufb01le named file, and\nstill access the \ufb01le without dif\ufb01culty:\nprompt> rm file\nremoved \u2018file\u2019\nprompt> cat file2\nhello\nThe reason this works is because when the \ufb01le system unlinks \ufb01le , it\nchecks a reference count within the inode number . This reference count\n(sometimes called the link count ) allows the \ufb01le system to track how\nmany different \ufb01le names have been linked to this particular inode. When\nunlink() is called, it removes the \u201clink\u201d between the human-readable\n2 Note again how creative the authors of this book are. W e also used to have a cat named\n\u201cCat\u201d (true story). However , she died, and we now have a hamster named \u201c Hammy .\u201d Update:\nHammy is now dead too. The pet bodies are piling up.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Here we created a \ufb01le with the word \u201chello\u201d in it, and called the \ufb01 le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "word",
          "hello",
          "called"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "file2 . W e then create a hard link to that \ufb01le using the ln program. After",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "hard",
          "link",
          "using",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The way link() works is that it simply creates another name in the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "link",
          "works",
          "simply",
          "creates",
          "another",
          "name"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "When you create a \ufb01le, you are really doing two things. First, you are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "really",
          "things",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ference between the original \ufb01le name ( file) and the newly created \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ference",
          "original",
          "name",
          "file",
          "newly",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand Update: Hammy is now dead too. The pet bodies are piling up.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "update",
          "hammy",
          "dead",
          "bodies",
          "piling"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "15 Symbolic Links",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "39.15 Symbolic Links\nThere is one other type of link that is really useful, and it is cal led a\nsymbolic link or sometimes a soft link . Hard links are somewhat limited:\nyou can\u2019t create one to a directory (for fear that you will create a cy cle in\nthe directory tree); you can\u2019t hard link to \ufb01les in other disk part itions\n(because inode numbers are only unique within a particular \ufb01le system,\nnot across \ufb01le systems); etc. Thus, a new type of link called the s ymbolic\nlink was created [MJLF84].\nT o create such a link, you can use the same program ln, but with the\n-s \ufb02ag. Here is an example:\nprompt> echo hello > file\nprompt> ln -s file file2\nprompt> cat file2\nhello\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "you can\u2019t create one to a directory (for fear that you will create a cy cle in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "directory",
          "fear",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "link was created [MJLF84].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "link",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T o create such a link, you can use the same program ln, but with the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "link",
          "program"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Here is an example: prompt> echo hello > file",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "here is an example",
          "prompt",
          "echo",
          "hello",
          "file"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand symbolic links",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "symbolic",
          "links"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand s \ufb02ag. here is an example:",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "example"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "20 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "20 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nAs you can see, creating a soft link looks much the same, and the orig -\ninal \ufb01le can now be accessed through the \ufb01le name file as well as the\nsymbolic link name file2.\nHowever , beyond this surface similarity , symbolic links are ac tually\nquite different from hard links. The \ufb01rst difference is that a symbolic\nlink is actually a \ufb01le itself, of a different type. W e\u2019ve alread y talked about\nregular \ufb01les and directories; symbolic links are a third type t he \ufb01le system\nknows about. A stat on the symlink reveals all:\nprompt> stat file\n... regular file ...\nprompt> stat file2\n... symbolic link ...\nRunning ls also reveals this fact. If you look closely at the \ufb01rst char-\nacter of the long-form of the output from ls, you can see that the \ufb01rst\ncharacter in the left-most column is a - for regular \ufb01les, a d for directo-\nries, and an l for soft links. Y ou can also see the size of the symbolic link\n(4 bytes in this case) and what the link points to (the \ufb01le named file).\nprompt> ls -al\ndrwxr-x--- 2 remzi remzi 29 May 3 19:10 ./\ndrwxr-x--- 27 remzi remzi 4096 May 3 15:14 ../\n-rw-r----- 1 remzi remzi 6 May 3 19:10 file\nlrwxrwxrwx 1 remzi remzi 4 May 3 19:10 file2 -> file\nThe reason that file2 is 4 bytes is because the way a symbolic link is\nformed is by holding the pathname of the linked-to \ufb01le as the data of the\nlink \ufb01le. Because we\u2019ve linked to a \ufb01le named file, our link \ufb01le file2\nis small (4 bytes). If we link to a longer pathname, our link \ufb01le w ould be\nbigger:\nprompt> echo hello > alongerfilename\nprompt> ln -s alongerfilename file3\nprompt> ls -al alongerfilename file3\n-rw-r----- 1 remzi remzi 6 May 3 19:17 alongerfilename\nlrwxrwxrwx 1 remzi remzi 15 May 3 19:17 file3 ->\nalongerfilename\nFinally , because of the way symbolic links are created, they le ave the\npossibility for what is known as a dangling reference :\nprompt> echo hello > file\nprompt> ln -s file file2\nprompt> cat file2\nhello\nprompt> rm file\nprompt> cat file2\ncat: file2: No such file or directory\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "knows about. A stat on the symlink reveals all:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knows",
          "stat",
          "symlink",
          "reveals"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Finally , because of the way symbolic links are created, they le ave the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "finally",
          "symbolic",
          "links",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "possibility for what is known as a dangling reference :",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "possibility",
          "known",
          "dangling",
          "reference"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_11",
        "text": "understand cat file2\ncat: file2: No such file or directory",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cat file2\ncat",
          "file",
          "directory"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand rw-r----- 1 remzi remzi 6 may 3 19:10 file",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "remzi",
          "remzi",
          "file"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand rw-r----- 1 remzi remzi 6 may 3 19:17 alongerfilename",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "remzi",
          "remzi",
          "alongerfilename"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "16 Permission Bits And Access Control Lists",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "39.16 Permission Bits And Access Control Lists\nThe abstraction of a process provided two central virtualization s: of\nthe CPU and of memory . Each of these gave the illusion to a process th at\nit had its own private CPU and its own private memory; in reality , the OS\nunderneath used various techniques to share limited physica l resources\namong competing entities in a safe and secure manner .\nThe \ufb01le system also presents a virtual view of a disk, transform ing it\nfrom a bunch of raw blocks into much more user-friendly \ufb01les and di -\nrectories, as described within this chapter . However , the abs traction is\nnotably different from that of the CPU and memory , in that \ufb01les are com-\nmonly shared among different users and processes and are not (always)\nprivate. Thus, a more comprehensive set of mechanisms for enabli ng var-\nious degrees of sharing are usually present within \ufb01le systems .\nThe \ufb01rst form of such mechanisms is the classic U N I X permission bits .\nT o see permissions for a \ufb01le foo.txt, just type:\nprompt> ls -l foo.txt\n-rw-r--r-- 1 remzi wheel 0 Aug 24 16:29 foo.txt\nW e\u2019ll just pay attention to the \ufb01rst part of this output, namely th e\n-rw-r--r--. The \ufb01rst character here just shows the type of the \ufb01le: - for\na regular \ufb01le (which foo.txt is), d for a directory , l for a symbolic link,\nand so forth; this is (mostly) not related to permissions, so we\u2019ll ignore it\nfor now .\nW e are interested in the permission bits, which are represent ed by the\nnext nine characters ( rw-r--r--). These bits determine, for each regular\n\ufb01le, directory , and other entities, exactly who can access it a nd how .\nThe permissions consist of three groupings: what the owner of the \ufb01le\ncan do to it, what someone in a group can do to the \ufb01le, and \ufb01nally , what\nanyone (sometimes referred to as other) can do. The abilities the owner ,\ngroup member , or others can have include the ability to read the \ufb01 le, write\nit, or execute it.\nIn the example above, the \ufb01rst three characters of the output of ls\nshow that the \ufb01le is both readable and writable by the owner ( rw-), and\nonly readable by members of the group wheel and also by anyone else\nin the system ( r-- followed by r--).\nThe owner of the \ufb01le can readily change these permissions, for exa m-\nple by using the chmod command (to change the \ufb01le mode ). T o remove\nthe ability for anyone except the owner to access the \ufb01le, you could type:\nprompt> chmod 600 foo.txt\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "underneath used various techniques to share limited physica l resources",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "underneath",
          "used",
          "various",
          "techniques",
          "share",
          "limited",
          "physica",
          "resources"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "rectories, as described within this chapter . However , the abs traction is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rectories",
          "described",
          "within",
          "chapter",
          "however",
          "traction"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand just type: prompt> ls -l foo.txt",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "just type",
          "prompt"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand you could type: prompt> chmod 600 foo.txt",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "you could type",
          "prompt",
          "chmod"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand permission bits and access control lists",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "permission",
          "bits",
          "access",
          "control",
          "lists"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand rw-r--r-- 1 remzi wheel 0 aug 24 16:29 foo.txt",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "remzi",
          "wheel"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand rw-r--r--. the \ufb01rst character here just shows the type of the \ufb01le: - for",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "character",
          "shows",
          "type"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "22 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "22 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nAS I D E : S U P E R U S E R FO R FI L E SY S T E M S\nWhich user is allowed to do privileged operations to help admini ster the\n\ufb01le system? For example, if an inactive user \u2019s \ufb01les need to be de leted to\nsave space, who has the rights to do so?\nOn local \ufb01le systems, the common default is for there to be some kind of\nsuperuser (i.e., root) who can access all \ufb01les regardless of privileges. In\na distributed \ufb01le system such as AFS (which has access control l ists), a\ngroup called system:administrators contains users that are trusted\nto do so. In both cases, these trusted users represent an inhere nt secu-\nrity risk; if an attacker is able to somehow impersonate such a us er , the\nattacker can access all the information in the system, thus viol ating ex-\npected privacy and protection guarantees.\nThis command enables the readable bit (4) and writable bit (2) for the\nowner (OR\u2019ing them together yields the 6 above), but set the group a nd\nother permission bits to 0 and 0, respectively , thus setting th e permissions\nto rw-------.\nThe execute bit is particularly interesting. For regular \ufb01le s, its presence\ndetermines whether a program can be run or not. For example, if we h ave\na simple shell script called hello.csh, we may wish to run it by typing:\nprompt> ./hello.csh\nhello, from shell world.\nHowever , if we don\u2019t set the execute bit properly for this \ufb01le, the f ol-\nlowing happens:\nprompt> chmod 600 hello.csh\nprompt> ./hello.csh\n./hello.csh: Permission denied.\nFor directories, the execute bit behaves a bit differently . Spe ci\ufb01cally ,\nit enables a user (or group, or everyone) to do things like change d i-\nrectories (i.e., cd) into the given directory , and, in combination with the\nwritable bit, create \ufb01les therein. The best way to learn more a bout this:\nplay around with it yourself! Don\u2019t worry , you (probably) won\u2019t mess\nanything up too badly .\nBeyond permissions bits, some \ufb01le systems, such as the distribu ted\n\ufb01le system known as AFS (discussed in a later chapter), includ e more so-\nphisticated controls. AFS, for example, does this in the form of an access\ncontrol list (ACL) per directory . Access control lists are a more general\nand powerful way to represent exactly who can access a given re source.\nIn a \ufb01le system, this enables a user to create a very speci\ufb01c li st of who\ncan and cannot read a set of \ufb01les, in contrast to the somewhat limit ed\nowner/group/everyone model of permissions bits described above.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "rity risk; if an attacker is able to somehow impersonate such a us er , the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rity",
          "risk",
          "attacker",
          "able",
          "somehow",
          "impersonate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "writable bit, create \ufb01les therein. The best way to learn more a bout this:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "writable",
          "create",
          "therein",
          "best",
          "learn",
          "bout"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "\ufb01le system known as AFS (discussed in a later chapter), includ e more so-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "known",
          "discussed",
          "later",
          "chapter",
          "includ"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "In a \ufb01le system, this enables a user to create a very speci\ufb01c li st of who",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "enables",
          "user",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "can and cannot read a set of \ufb01les, in contrast to the somewhat limit ed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cannot",
          "read",
          "contrast",
          "somewhat",
          "limit"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "owner/group/everyone model of permissions bits described above.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "owner",
          "group",
          "everyone",
          "model",
          "permissions",
          "bits",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: S U P E R U S E R FO R FI L E SY S T E M S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand a\ngroup called system: administrators contains users that are trusted",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a\ngroup called system",
          "administrators",
          "contains",
          "users",
          "trusted"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand lowing happens: prompt> chmod 600 hello.csh",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lowing happens",
          "prompt",
          "chmod",
          "hello"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "17 Making And Mounting A File System",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "39.17 Making And Mounting A File System\nW e\u2019ve now toured the basic interfaces to access \ufb01les, directorie s, and\ncertain types of special types of links. But there is one more topic we\nshould discuss: how to assemble a full directory tree from many un der-\nlying \ufb01le systems. This task is accomplished via \ufb01rst making \ufb01 le systems,\nand then mounting them to make their contents accessible.\nT o make a \ufb01le system, most \ufb01le systems provide a tool, usually re-\nferred to as mkfs (pronounced \u201cmake fs\u201d), that performs exactly this task.\nThe idea is as follows: give the tool, as input, a device (such as a d isk par-\ntition, e.g., /dev/sda1) and a \ufb01le system type (e.g., ext3), and it simply\nwrites an empty \ufb01le system, starting with a root directory , onto t hat disk\npartition. And mkfs said, let there be a \ufb01le system!\nHowever , once such a \ufb01le system is created, it needs to be made ac -\ncessible within the uniform \ufb01le-system tree. This task is ach ieved via the\nmount program (which makes the underlying system call mount() to do\nthe real work). What mount does, quite simply is take an existing direc-\ntory as a target mount point and essentially paste a new \ufb01le system onto\nthe directory tree at that point.\nAn example here might be useful. Imagine we have an unmounted\next3 \ufb01le system, stored in device partition /dev/sda1, that has the fol-\nlowing contents: a root directory which contains two sub-directori es, a\nand b, each of which in turn holds a single \ufb01le named foo. Let\u2019s say we\nwish to mount this \ufb01le system at the mount point /home/users. W e\nwould type something like this:\n3 Married happily since 1996, if you were wondering. W e know , you weren\u2019 t.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "However , once such a \ufb01le system is created, it needs to be made ac -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "however",
          "system",
          "created",
          "needs",
          "made"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tory as a target mount point and essentially paste a new \ufb01le system onto",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tory",
          "target",
          "mount",
          "point",
          "essentially",
          "paste",
          "system",
          "onto"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Married happily since 1996, if you were wondering. W e know , you weren\u2019 t.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "married",
          "happily",
          "since",
          "wondering",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand lowing contents: a root directory which contains two sub-directori es, a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lowing contents",
          "root",
          "directory",
          "contains",
          "directori"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand making and mounting a file system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "making",
          "mounting",
          "file",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "24 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "24 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nTI P : B E WA RY OF TOCTTOU\nIn 1974, McPhee noticed a problem in computer systems. Speci\ufb01-\ncally , McPhee noted that \u201c... if there exists a time interval b etween\na validity-check and the operation connected with that validit y-check,\n[and,] through multitasking, the validity-check variables can deliberately\nbe changed during this time interval, resulting in an invali d operation be-\ning performed by the control program.\u201d W e today call this the Time Of\nCheck T o Time Of Use (TOCTTOU) problem, and alas, it still can occur .\nA simple example, as described by Bishop and Dilger [BD96], sh ows how\na user can trick a more trusted service and thus cause trouble. I magine,\nfor example, that a mail service runs as root (and thus has privil ege to\naccess all \ufb01les on a system). This service appends an incoming m essage\nto a user \u2019s inbox \ufb01le as follows. First, it calls lstat() to get informa-\ntion about the \ufb01le, speci\ufb01cally ensuring that it is actually ju st a regular\n\ufb01le owned by the target user , and not a link to another \ufb01le that the mail\nserver should not be updating. Then, after the check succeeds, the server\nupdates the \ufb01le with the new message.\nUnfortunately , the gap between the check and the update leads to a prob-\nlem: the attacker (in this case, the user who is receiving the mail, and thus\nhas permissions to access the inbox) switches the inbox \ufb01le (via a call\nto rename()) to point to a sensitive \ufb01le such as /etc/passwd (which\nholds information about users and their passwords). If this switc h hap-\npens at just the right time (between the check and the access) , the server\nwill blithely update the sensitive \ufb01le with the contents of the mail. The\nattacker can now write to the sensitive \ufb01le by sending an email , an esca-\nlation in privilege; by updating /etc/passwd, the attacker can add an\naccount with root privileges and thus gain control of the system.\nThere are not any simple and great solutions to the TOCTTOU proble m\n[T+08]. One approach is to reduce the number of services that ne ed root\nprivileges to run, which helps. The O\nNOFOLLOW \ufb02ag makes it so that\nopen() will fail if the target is a symbolic link, thus avoiding attack s\nthat require said links. More radicial approaches, such as usi ng a trans-\nactional \ufb01le system [H+18], would solve the problem, there aren\u2019t many\ntransactional \ufb01le systems in wide deployment. Thus, the usual (lame)\nadvice: careful when you write code that runs with high privile ges!\nprompt> mount -t ext3 /dev/sda1 /home/users\nIf successful, the mount would thus make this new \ufb01le system ava il-\nable. However , note how the new \ufb01le system is now accessed. T o look at\nthe contents of the root directory , we would use ls like this:\nprompt> ls /home/users/\na b\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A simple example, as described by Bishop and Dilger [BD96], sh ows how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "example",
          "described",
          "bishop",
          "dilger"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[T+08]. One approach is to reduce the number of services that ne ed root",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "reduce",
          "number",
          "services",
          "root"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "that require said links. More radicial approaches, such as usi ng a trans-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "require",
          "said",
          "links",
          "radicial",
          "approaches",
          "trans"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "actional \ufb01le system [H+18], would solve the problem, there aren\u2019t many",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "actional",
          "system",
          "would",
          "solve",
          "problem",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand lem: the attacker (in this case, the user who is receiving the mail, and thus",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lem",
          "attacker",
          "case",
          "user",
          "receiving",
          "mail",
          "thus"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand advice: careful when you write code that runs with high privile ges!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "advice",
          "careful",
          "write",
          "code",
          "runs",
          "high",
          "privile"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "39",
    "title": "18 Summary",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "39.18 Summary\nThe \ufb01le system interface in U N I X systems (and indeed, in any system)\nis seemingly quite rudimentary , but there is a lot to understa nd if you\nwish to master it. Nothing is better , of course, than simply usin g it (a lot).\nSo please do so! Of course, read more; as always, Stevens [SR05] is th e\nplace to begin.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "26 I N T E R L U D E : F I L E S A N D DI R E C TO...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "26 I N T E R L U D E : F I L E S A N D DI R E C TO R I E S\nAS I D E : K E Y FI L E SY S T E M TE R M S\n\u2022 A \ufb01le is an array of bytes which can be created, read, written, and\ndeleted. It has a low-level name (i.e., a number) that refers t o it\nuniquely . The low-level name is often called an i-number.\n\u2022 A directory is a collection of tuples, each of which contains a\nhuman-readable name and low-level name to which it maps. Each\nentry refers either to another directory or to a \ufb01le. Each direct ory\nalso has a low-level name (i-number) itself. A directory alway s has\ntwo special entries: the . entry , which refers to itself, and the ..\nentry , which refers to its parent.\n\u2022 A directory tree or directory hierarchy organizes all \ufb01les and direc-\ntories into a large tree, starting at the root.\n\u2022 T o access a \ufb01le, a process must use a system call (usually , open())\nto request permission from the operating system. If permission i s\ngranted, the OS returns a \ufb01le descriptor , which can then be used\nfor read or write access, as permissions and intent allow .\n\u2022 Each \ufb01le descriptor is a private, per-process entity , which re fers to\nan entry in the open \ufb01le table . The entry therein tracks which \ufb01le\nthis access refers to, the current offset of the \ufb01le (i.e., which part\nof the \ufb01le the next read or write will access), and other relevant\ninformation.\n\u2022 Calls to read() and write() naturally update the current offset;\notherwise, processes can use lseek() to change its value, enabling\nrandom access to different parts of the \ufb01le.\n\u2022 T o force updates to persistent media, a process must use fsync()\nor related calls. However , doing so correctly while maintaining\nhigh performance is challenging [P+14], so think carefully w hen\ndoing so.\n\u2022 T o have multiple human-readable names in the \ufb01le system refe r to\nthe same underlying \ufb01le, use hard links or symbolic links . Each\nis useful in different circumstances, so consider their stre ngths and\nweaknesses before usage. And remember , deleting a \ufb01le is just per-\nforming that one last unlink() of it from the directory hierarchy .\n\u2022 Most \ufb01le systems have mechanisms to enable and disable sharin g.\nA rudimentary form of such controls are provided by permissions\nbits; more sophisticated access control lists allow for more precise\ncontrol over exactly who can access and manipulate information.\n.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A \ufb01le is an array of bytes which can be created, read, written, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "array",
          "bytes",
          "created",
          "read",
          "written"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand AS I D E: K E Y FI L E SY S T E M TE R M S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand a directory is a collection of tuples, each of which contains a",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "collection",
          "tuples",
          "contains"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand a directory tree or directory hierarchy organizes all \ufb01les and direc-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "tree",
          "directory",
          "hierarchy",
          "organizes",
          "direc"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand t o access a \ufb01le, a process must use a system call (usually , open())",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "access",
          "process",
          "must",
          "system",
          "call",
          "usually",
          "open"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand each \ufb01le descriptor is a private, per-process entity , which re fers to",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "descriptor",
          "private",
          "process",
          "entity",
          "fers"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand calls to read() and write() naturally update the current offset;",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "calls",
          "read",
          "write",
          "naturally",
          "update",
          "current",
          "offset"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2018",
    "title": "The best paper at USENIX ATC \u201918, and a good recent place to start to learn about transactional",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "2018. The best paper at USENIX ATC \u201918, and a good recent place to start to learn about transactional\n\ufb01le systems.\n[K84] \u201cProcesses as Files\u201d by T om J. Killian. USENIX, June 1984. The paper that introduced the\n/proc \ufb01le system, where each process can be treated as a \ufb01le within a pseud o \ufb01le system. A clever idea\nthat you can still see in modern UN I X systems.\n[L84] \u201cCapability-Based Computer Systems\u201d by Henry M. Levy . Dig ital Press, 1984. A vailable:\nhttp://homes.cs.washington.edu/\u02dclevy/capabook. An excellent overview of early capability-based\nsystems.\n[MJLF84] \u201cA Fast File System for U N I X\u201d by Marshall K. McKusick, William N. Joy , Sam J.\nLef\ufb02er , Robert S. Fabry . ACM TOCS, 2:3, August 1984. We\u2019ll talk about the Fast File System (FFS)\nexplicitly later on. Here, we refer to it because of all the other random fun th ings it introduced, like long\n\ufb01le names and symbolic links. Sometimes, when you are building a system to improve one thing, you\nimprove a lot of other things along the way.\n[P+13] \u201cT owards Ef\ufb01cient, Portable Application-Level Consistency\u201d by Thanumalayan S. Pil-\nlai, Vijay Chidambaram, Joo-Y oung Hwang, Andrea C. Arpaci-Dusseau, and Remzi H. Arpaci-\nDusseau. HotDep \u201913, November 2013. Our own work that shows how readily applications can\nmake mistakes in committing data to disk; in particular , assumptions about the \ufb01le sy stem creep into\napplications and thus make the applications work correctly only if they are runnin g on a speci\ufb01c \ufb01le\nsystem.\n[P+14] \u201cAll File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent\nApplications\u201d by Thanumalayan S. Pillai, Vijay Chidambaram, Ramnat than Alagappan, Samer\nAl-Kiswany , Andrea C. Arpaci-Dusseau, and Remzi H. Arpaci-Dusseau. OSDI \u201914, Broom-\n\ufb01eld, Colorado, October 2014. The full conference paper on this topic \u2013 with many more details and\ninteresting tidbits than the \ufb01rst workshop paper above.\n[SK09] \u201cPrinciples of Computer System Design\u201d by Jerome H. Saltzer and M. Frans Kaashoek.\nMorgan-Kaufmann, 2009. This tour de force of systems is a must-read for anybody interested in the\n\ufb01eld. It\u2019s how they teach systems at MIT . Read it once, and then read it a few more times to let it all\nsoak in.\n[SR05] \u201cAdvanced Programming in the U N I X Environment\u201d by W . Richard Stevens and Stephen\nA. Rago. Addison-W esley , 2005. We have probably referenced this book a few hundred thousand\ntimes. It is that useful to you, if you care to become an awesome systems programm er .\n[T+08] \u201cPortably Solving File TOCTTOU Races with Hardness Ampli\ufb01catio n\u201d by D. T safrir , T .\nHertz, D. W agner , D. Da Silva. F AST \u201908, San Jose, California, 200 8. Not the paper that introduced\nTOCTTOU, but a recent-ish and well-done description of the problem and a w ay to solve the problem\nin a portable manner .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The best paper at USENIX ATC \u201918, and a good recent place to start to learn about transactional",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "best",
          "paper",
          "usenix",
          "good",
          "recent",
          "place",
          "start",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[P+14] \u201cAll File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "systems",
          "created",
          "equal",
          "complexity",
          "crafting",
          "crash",
          "consistent"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[SK09] \u201cPrinciples of Computer System Design\u201d by Jerome H. Saltzer and M. Frans Kaashoek.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "principles",
          "computer",
          "system",
          "design",
          "jerome",
          "saltzer",
          "frans",
          "kaashoek"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "TOCTTOU, but a recent-ish and well-done description of the problem and a w ay to solve the problem",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tocttou",
          "recent",
          "well",
          "done",
          "description",
          "problem",
          "solve",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand A vailable: http://homes.cs.washington.edu/\u02dclevy/capabook. An excellent overview of early capability-based",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "homes",
          "washington",
          "levy",
          "capabook",
          "excellent",
          "overview",
          "early"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 2: 3, August 1984. We\u2019ll talk about the Fast File System (FFS)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "august",
          "talk",
          "fast",
          "file",
          "system"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Stat: W rite your own version of the command line program stat,",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. Stat: W rite your own version of the command line program stat,\nwhich simply calls the stat() system call on a given \ufb01le or di-\nrectory . Print out \ufb01le size, number of blocks allocated, referenc e\n(link) count, and so forth. What is the link count of a directory , as\nthe number of entries in the directory changes? Useful interfa ces:\nstat(), naturally .\n2. List Files: W rite a program that lists \ufb01les in the given directory .\nWhen called without any arguments, the program should just prin t\nthe \ufb01le names. When invoked with the -l \ufb02ag, the program should\nprint out information about each \ufb01le, such as the owner , group, per-\nmissions, and other information obtained from the stat() system\ncall. The program should take one additional argument, which is\nthe directory to read, e.g., myls -l directory. If no directory is\ngiven, the program should just use the current working directory .\nUseful interfaces: stat(), opendir(), readdir(), getcwd().\n3. T ail: W rite a program that prints out the last few lines of a \ufb01le. The\nprogram should be ef\ufb01cient, in that it seeks to near the end of the\n\ufb01le, reads in a block of data, and then goes backwards until it \ufb01nd s\nthe requested number of lines; at this point, it should print out t hose\nlines from beginning to the end of the \ufb01le. T o invoke the program,\none should type: mytail -n file, where n is the number of lines\nat the end of the \ufb01le to print. Useful interfaces: stat(), lseek(),\nopen(), read(), close().",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Stat: W rite your own version of the command line program stat,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "stat",
          "rite",
          "version",
          "command",
          "line",
          "program",
          "stat"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand List Files: W rite a program that lists \ufb01les in the given directory .",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "list files",
          "rite",
          "program",
          "lists",
          "given",
          "directory"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Useful interfaces: stat(), opendir(), readdir(), getcwd().",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "useful interfaces",
          "stat",
          "opendir",
          "readdir",
          "getcwd"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand T ail: W rite a program that prints out the last few lines of a \ufb01le. The",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t ail",
          "rite",
          "program",
          "prints",
          "last",
          "lines"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand one should type: mytail -n file, where n is the number of lines",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one should type",
          "mytail",
          "file",
          "number",
          "lines"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand the link count of a directory , as\nthe number of entries in the directory changes",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "link",
          "count",
          "directory",
          "number",
          "entries",
          "directory",
          "changes"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Recursive Search: W rite a program that prints out the names of",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "4. Recursive Search: W rite a program that prints out the names of\neach \ufb01le and directory in the \ufb01le system tree, starting at a giv en\npoint in the tree. For example, when run without arguments, the\nprogram should start with the current working directory and prin t\nits contents, as well as the contents of any sub-directories, etc ., until\nthe entire tree, root at the CWD, is printed. If given a single ar gu-\nment (of a directory name), use that as the root of the tree instead.\nRe\ufb01ne your recursive search with more fun options, similar to the\npowerful find command line tool. Useful interfaces: \ufb01gure it out.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Recursive Search: W rite a program that prints out the names of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "recursive search",
          "rite",
          "program",
          "prints",
          "names"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "1 The W ay T o Think",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "40.1 The W ay T o Think\nT o think about \ufb01le systems, we usually suggest thinking about t wo\ndifferent aspects of them; if you understand both of these aspect s, you\nprobably understand how the \ufb01le system basically works.\nThe \ufb01rst is the data structures of the \ufb01le system. In other words, what\ntypes of on-disk structures are utilized by the \ufb01le system to org anize its\ndata and metadata? The \ufb01rst \ufb01le systems we\u2019ll see (including v sfs below)\nemploy simple structures, like arrays of blocks or other objects, w hereas\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "different aspects of them; if you understand both of these aspect s, you",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "aspects",
          "understand",
          "aspect"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "probably understand how the \ufb01le system basically works.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "probably",
          "understand",
          "system",
          "basically",
          "works"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the w ay t o think",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "think"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "2 Overall Organization",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "40.2 Overall Organization\nW e now develop the overall on-disk organization of the data struc-\ntures of the vsfs \ufb01le system. The \ufb01rst thing we\u2019ll need to do is di vide the\ndisk into blocks; simple \ufb01le systems use just one block size, and that\u2019s\nexactly what we\u2019ll do here. Let\u2019s choose a commonly-used size of 4 KB.\nThus, our view of the disk partition where we\u2019re building our \ufb01le sy s-\ntem is simple: a series of blocks, each of size 4 KB. The blocks are a d-\ndressed from 0 to N \u2212 1, in a partition of size N 4-KB blocks. Assume we\nhave a really small disk, with just 64 blocks:\n0 7 8 15 16 23 24 31\n32 39 40 47 48 55 56 63\nLet\u2019s now think about what we need to store in these blocks to build\na \ufb01le system. Of course, the \ufb01rst thing that comes to mind is user data.\nIn fact, most of the space in any \ufb01le system is (and should be) user data.\nLet\u2019s call the region of the disk we use for user data the data region , and,\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "W e now develop the overall on-disk organization of the data struc-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "develop",
          "overall",
          "disk",
          "organization",
          "data",
          "struc"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand tem is simple: a series of blocks, each of size 4 KB. The blocks are a d-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "tem is simple",
          "series",
          "blocks",
          "size",
          "blocks"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand overall organization",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "overall",
          "organization"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 3",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 3\nagain for simplicity , reserve a \ufb01xed portion of the disk for these b locks,\nsay the last 56 of 64 blocks on the disk:\n0 7\nD\n8\nD D D D D D D\n15\nD\n16\nD D D D D D D\n23\nD\n24\nD D D D D D D\n31\nD\n32\nD D D D D D D\n39\nD\n40\nD D D D D D D\n47\nD\n48\nD D D D D D D\n55\nD\n56\nD D D D D D D\n63\nData Region\nData Region\nAs we learned about (a little) last chapter , the \ufb01le system has to track\ninformation about each \ufb01le. This information is a key piece of metadata,\nand tracks things like which data blocks (in the data region) com prise a\n\ufb01le, the size of the \ufb01le, its owner and access rights, access and modify\ntimes, and other similar kinds of information. T o store this inform ation,\n\ufb01le systems usually have a structure called an inode (we\u2019ll read more\nabout inodes below).\nT o accommodate inodes, we\u2019ll need to reserve some space on the disk\nfor them as well. Let\u2019s call this portion of the disk the inode table , which\nsimply holds an array of on-disk inodes. Thus, our on-disk image now\nlooks like this picture, assuming that we use 5 of our 64 blocks for in odes\n(denoted by I\u2019s in the diagram):\n0\nI I I I I\n7\nD\n8\nD D D D D D D\n15\nD\n16\nD D D D D D D\n23\nD\n24\nD D D D D D D\n31\nD\n32\nD D D D D D D\n39\nD\n40\nD D D D D D D\n47\nD\n48\nD D D D D D D\n55\nD\n56\nD D D D D D D\n63\nData Region\nData Region\nInodes\nW e should note here that inodes are typically not that big, for exam ple\n128 or 256 bytes. Assuming 256 bytes per inode, a 4-KB block can hol d 16\ninodes, and our \ufb01le system above contains 80 total inodes. In our simp le\n\ufb01le system, built on a tiny 64-block partition, this number repr esents the\nmaximum number of \ufb01les we can have in our \ufb01le system; however , do\nnote that the same \ufb01le system, built on a larger disk, could simpl y allocate\na larger inode table and thus accommodate more \ufb01les.\nOur \ufb01le system thus far has data blocks (D), and inodes (I), but a few\nthings are still missing. One primary component that is still n eeded, as\nyou might have guessed, is some way to track whether inodes or data\nblocks are free or allocated. Such allocation structures are thus a requisite\nelement in any \ufb01le system.\nMany allocation-tracking methods are possible, of course. For exam -\nple, we could use a free list that points to the \ufb01rst free block, which then\npoints to the next free block, and so forth. W e instead choose a simp le and\npopular structure known as a bitmap, one for the data region (the data\nbitmap), and one for the inode table (the inode bitmap ). A bitmap is a\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "As we learned about (a little) last chapter , the \ufb01le system has to track",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learned",
          "little",
          "last",
          "chapter",
          "system",
          "track"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Many allocation-tracking methods are possible, of course. For exam -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "allocation",
          "tracking",
          "methods",
          "possible",
          "course",
          "exam"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "popular structure known as a bitmap, one for the data region (the data",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "popular",
          "structure",
          "known",
          "bitmap",
          "data",
          "region",
          "data"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "3 File Organization: The Inode",
    "document_source": "book.pdf",
    "start_line": 91,
    "type": "chapter",
    "content": "40.3 File Organization: The Inode\nOne of the most important on-disk structures of a \ufb01le system is the\ninode; virtually all \ufb01le systems have a structure similar to this. The name\ninode is short for index node , the historical name given to it in U N I X\n[RT74] and possibly earlier systems, used because these nodes were orig-\ninally arranged in an array , and the array indexed into when accessing a\nparticular inode.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One of the most important on-disk structures of a \ufb01le system is the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "disk",
          "structures",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand file organization: the inode",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "organization",
          "inode"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 5\nAS I D E : D ATA ST R U C T U R E \u2014 T H E IN O D E\nThe inode is the generic name that is used in many \ufb01le systems to de-\nscribe the structure that holds the metadata for a given \ufb01le, su ch as its\nlength, permissions, and the location of its constituent blocks. T he name\ngoes back at least as far as U N I X (and probably further back to Multics\nif not earlier systems); it is short for index node , as the inode number is\nused to index into an array of on-disk inodes in order to \ufb01nd the inod e\nof that number . As we\u2019ll see, design of the inode is one key part of \ufb01le\nsystem design. Most modern systems have some kind of structure li ke\nthis for every \ufb01le they track, but perhaps call them different things (such\nas dnodes, fnodes, etc.).\nEach inode is implicitly referred to by a number (called the i-number),\nwhich we\u2019ve earlier called the low-level name of the \ufb01le. In vsfs (and\nother simple \ufb01le systems), given an i-number , you should direct ly be able\nto calculate where on the disk the corresponding inode is located. For ex-\nample, take the inode table of vsfs as above: 20-KB in size (5 4-KB blocks)\nand thus consisting of 80 inodes (assuming each inode is 256 bytes ); fur-\nther assume that the inode region starts at 12KB (i.e, the super block starts\nat 0KB, the inode bitmap is at address 4KB, the data bitmap at 8K B, and\nthus the inode table comes right after). In vsfs, we thus have th e following\nlayout for the beginning of the \ufb01le system partition (in closeup vi ew):\nSuper i-bmap d-bmap\n0KB 4KB 8KB 12KB 16KB 20KB 24KB 28KB 32KB\nThe Inode Table (Closeup)\n0 1 2 3\n4 5 6 7\n8 9 1011\n12131415\n16171819\n20212223\n24252627\n28293031\n32333435\n36373839\n40414243\n44454647\n48495051\n52535455\n56575859\n60616263\n64656667\n68697071\n72737475\n76777879\niblock 0 iblock 1 iblock 2 iblock 3 iblock 4\nT o read inode number 32, the \ufb01le system would \ufb01rst calculate the off-\nset into the inode region ( 32 \u00b7 sizeof (inode) or 8192), add it to the start\naddress of the inode table on disk ( inodeStartAddr = 12KB), and thus\narrive upon the correct byte address of the desired block of inodes: 20KB.\nRecall that disks are not byte addressable, but rather consist of a large\nnumber of addressable sectors, usually 512 bytes. Thus, to fet ch the block\nof inodes that contains inode 32, the \ufb01le system would issue a read t o sec-\ntor 20\u00d7 1024\n512 , or 40, to fetch the desired inode block. More generally , the\nsector address sector of the inode block can be calculated as follows:\nblk = (inumber * sizeof(inode_t)) / blockSize;\nsector = ((blk * blockSize) + inodeStartAddr) / sectorSize;\nInside each inode is virtually all of the information you need about a\n\ufb01le: its type (e.g., regular \ufb01le, directory , etc.), its size, the number of blocks\nallocated to it, protection information (such as who owns the \ufb01le, as well\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "of that number . As we\u2019ll see, design of the inode is one key part of \ufb01le",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "number",
          "design",
          "inode",
          "part"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "system design. Most modern systems have some kind of structure li ke",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "design",
          "modern",
          "systems",
          "kind",
          "structure"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 FI L E SY S T E M IM P L E M E N TAT I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 FI L E SY S T E M IM P L E M E N TAT I O N\nSize Name What is this inode \ufb01eld for?\n2 mode can this \ufb01le be read/written/executed?\n2 uid who owns this \ufb01le?\n4 size how many bytes are in this \ufb01le?\n4 time what time was this \ufb01le last accessed?\n4 ctime what time was this \ufb01le created?\n4 mtime what time was this \ufb01le last modi\ufb01ed?\n4 dtime what time was this inode deleted?\n2 gid which group does this \ufb01le belong to?\n2 links\ncount how many hard links are there to this \ufb01le?\n4 blocks how many blocks have been allocated to this \ufb01le?\n4 \ufb02ags how should ext2 use this inode?\n4 osd1 an OS-dependent \ufb01eld\n60 block a set of disk pointers (15 total)\n4 generation \ufb01le version (used by NFS)\n4 \ufb01le\nacl a new permissions model beyond mode bits\n4 dir acl called access control lists\nFigure 40.1: Simpli\ufb01ed Ext2 Inode\nas who can access it), some time information, including when the \ufb01le was\ncreated, modi\ufb01ed, or last accessed, as well as information about w here its\ndata blocks reside on disk (e.g., pointers of some kind). W e refer t o all\nsuch information about a \ufb01le as metadata; in fact, any information inside\nthe \ufb01le system that isn\u2019t pure user data is often referred to as s uch. An\nexample inode from ext2 [P09] is shown in Figure 40.1 1 .\nOne of the most important decisions in the design of the inode is how\nit refers to where data blocks are. One simple approach would be t o\nhave one or more direct pointers (disk addresses) inside the inode; each\npointer refers to one disk block that belongs to the \ufb01le. Such an app roach\nis limited: for example, if you want to have a \ufb01le that is really b ig (e.g.,\nbigger than the block size multiplied by the number of direct poi nters in\nthe inode), you are out of luck.\nThe Multi-Level Index\nT o support bigger \ufb01les, \ufb01le system designers have had to introd uce dif-\nferent structures within inodes. One common idea is to have a spe cial\npointer known as an indirect pointer . Instead of pointing to a block that\ncontains user data, it points to a block that contains more pointers , each\nof which point to user data. Thus, an inode may have some \ufb01xed numbe r\nof direct pointers (e.g., 12), and a single indirect pointer . If a \ufb01le grows\nlarge enough, an indirect block is allocated (from the data-block region of\nthe disk), and the inode\u2019s slot for an indirect pointer is set to poin t to it.\nAssuming 4-KB blocks and 4-byte disk addresses, that adds anot her 1024\npointers; the \ufb01le can grow to be (12 + 1024)\u00b7 4K or 4144KB.\n1 T ype info is kept in the directory entry , and thus is not found in the inode it self.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ctime what time was this \ufb01le created?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ctime",
          "time",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "created, modi\ufb01ed, or last accessed, as well as information about w here its",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "last",
          "accessed",
          "well",
          "information"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "One of the most important decisions in the design of the inode is how",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "important",
          "decisions",
          "design",
          "inode"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "it refers to where data blocks are. One simple approach would be t o",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "refers",
          "data",
          "blocks",
          "simple",
          "approach",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "T o support bigger \ufb01les, \ufb01le system designers have had to introd uce dif-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "support",
          "bigger",
          "system",
          "designers",
          "introd"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "pointer known as an indirect pointer . Instead of pointing to a block that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pointer",
          "known",
          "indirect",
          "pointer",
          "instead",
          "pointing",
          "block"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand each\npointer: one disk block that belongs to the \ufb01le. Such an app roach",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "each\npointer",
          "disk",
          "block",
          "belongs",
          "roach"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand this inode \ufb01eld for",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "inode"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 7\nTI P : C O N S I D E R EX T E N T-B A S E D AP P R O A C H E S\nA different approach is to use extents instead of pointers. An extent is\nsimply a disk pointer plus a length (in blocks); thus, instead of requiring\na pointer for every block of a \ufb01le, all one needs is a pointer and a leng th\nto specify the on-disk location of a \ufb01le. Just a single extent is li miting, as\none may have trouble \ufb01nding a contiguous chunk of on-disk free space\nwhen allocating a \ufb01le. Thus, extent-based \ufb01le systems often al low for\nmore than one extent, thus giving more freedom to the \ufb01le system du ring\n\ufb01le allocation.\nIn comparing the two approaches, pointer-based approaches are t he most\n\ufb02exible but use a large amount of metadata per \ufb01le (particularl y for large\n\ufb01les). Extent-based approaches are less \ufb02exible but more compa ct; in par-\nticular , they work well when there is enough free space on the dis k and\n\ufb01les can be laid out contiguously (which is the goal for virtually a ny \ufb01le\nallocation policy anyhow).\nNot surprisingly , in such an approach, you might want to support\neven larger \ufb01les. T o do so, just add another pointer to the inode: t he dou-\nble indirect pointer . This pointer refers to a block that contains pointers\nto indirect blocks, each of which contain pointers to data blocks. A dou-\nble indirect block thus adds the possibility to grow \ufb01les with an additional\n1024 \u00b7 1024 or 1-million 4KB blocks, in other words supporting \ufb01les that\nare over 4GB in size. Y ou may want even more, though, and we bet you\nknow where this is headed: the triple indirect pointer .\nOverall, this imbalanced tree is referred to as the multi-level index ap-\nproach to pointing to \ufb01le blocks. Let\u2019s examine an example with tw elve\ndirect pointers, as well as both a single and a double indirect bl ock. As-\nsuming a block size of 4 KB, and 4-byte pointers, this structure c an accom-\nmodate a \ufb01le of just over 4 GB in size (i.e., (12 + 1024 + 10242) \u00d7 4 KB).\nCan you \ufb01gure out how big of a \ufb01le can be handled with the addition of\na triple-indirect block? (hint: pretty big)\nMany \ufb01le systems use a multi-level index, including commonly- used\n\ufb01le systems such as Linux ext2 [P09] and ext3, NetApp\u2019s W AFL, a s well as\nthe original U N I X \ufb01le system. Other \ufb01le systems, including SGI XFS and\nLinux ext4, use extents instead of simple pointers; see the earlier aside for\ndetails on how extent-based schemes work (they are akin to segme nts in\nthe discussion of virtual memory).\nY ou might be wondering: why use an imbalanced tree like this? Wh y\nnot a different approach? W ell, as it turns out, many researcher s have\nstudied \ufb01le systems and how they are used, and virtually every time they\n\ufb01nd certain \u201ctruths\u201d that hold across the decades. One such \ufb01nd ing is\nthat most \ufb01les are small . This imbalanced design re\ufb02ects such a reality; if\nmost \ufb01les are indeed small, it makes sense to optimize for this ca se. Thus,\nwith a small number of direct pointers (12 is a typical number), an inode\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A different approach is to use extents instead of pointers. An extent is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "approach",
          "extents",
          "instead",
          "pointers",
          "extent"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "In comparing the two approaches, pointer-based approaches are t he most",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "comparing",
          "approaches",
          "pointer",
          "based",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": ". Extent-based approaches are less \ufb02exible but more compa ct; in par-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "extent",
          "based",
          "approaches",
          "less",
          "compa"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "\ufb01les can be laid out contiguously (which is the goal for virtually a ny \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "laid",
          "contiguously",
          "goal",
          "virtually"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Not surprisingly , in such an approach, you might want to support",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "surprisingly",
          "approach",
          "might",
          "want",
          "support"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "know where this is headed: the triple indirect pointer .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "headed",
          "triple",
          "indirect",
          "pointer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "not a different approach? W ell, as it turns out, many researcher s have",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "approach",
          "turns",
          "many",
          "researcher"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "that most \ufb01les are small . This imbalanced design re\ufb02ects such a reality; if",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "small",
          "imbalanced",
          "design",
          "reality"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand This pointer: a block that contains pointers",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this pointer",
          "block",
          "contains",
          "pointers"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "4 Directory Organization",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "40.4 Directory Organization\nIn vsfs (as in many \ufb01le systems), directories have a simple orga niza-\ntion; a directory basically just contains a list of (entry name, i node num-\nber) pairs. For each \ufb01le or directory in a given directory , there i s a string\nand a number in the data block(s) of the directory . For each string , there\nmay also be a length (assuming variable-sized names).\nFor example, assume a directory dir (inode number 5) has three \ufb01les\nin it ( foo, bar, and foobar\nis a pretty longname), with inode num-\nbers 12, 13, and 24 respectively . The on-disk data for dir might look like:\ninum | reclen | strlen | name\n5 12 2 .\n2 12 3 ..\n12 12 4 foo\n13 12 4 bar\n24 36 28 foobar_is_a_pretty_longname\nIn this example, each entry has an inode number , record length ( the\ntotal bytes for the name plus any left over space), string length (the actual\nlength of the name), and \ufb01nally the name of the entry . Note that ea ch di-\nrectory has two extra entries, . \u201cdot\u201d and .. \u201cdot-dot\u201d; the dot directory\nis just the current directory (in this example, dir), whereas dot-dot is the\nparent directory (in this case, the root).\nDeleting a \ufb01le (e.g., calling unlink()) can leave an empty space in\nthe middle of the directory , and hence there should be some way to m ark\nthat as well (e.g., with a reserved inode number such as zero). Su ch a\ndelete is one reason the record length is used: a new entry may reu se an\nold, bigger entry and thus have extra space within.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand directory organization",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "organization"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 9\nAS I D E : L I N K E D -B A S E D AP P R O A C H E S\nAnother simpler approach in designing inodes is to use a linked list .\nThus, inside an inode, instead of having multiple pointers, you j ust need\none, to point to the \ufb01rst block of the \ufb01le. T o handle larger \ufb01les, ad d an-\nother pointer at the end of that data block, and so on, and thus you can\nsupport large \ufb01les.\nAs you might have guessed, linked \ufb01le allocation performs poorly for\nsome workloads; think about reading the last block of a \ufb01le, for examp le,\nor just doing random access. Thus, to make linked allocation work be tter ,\nsome systems will keep an in-memory table of link information, ins tead\nof storing the next pointers with the data blocks themselves. The table\nis indexed by the address of a data block D; the content of an entry is\nsimply D\u2019s next pointer , i.e., the address of the next block in a \ufb01le which\nfollows D. A null-value could be there too (indicating an end-of-\ufb01le), or\nsome other marker to indicate that a particular block is free. Ha ving such\na table of next pointers makes it so that a linked allocation schem e can\neffectively do random \ufb01le accesses, simply by \ufb01rst scanning t hrough the\n(in memory) table to \ufb01nd the desired block, and then accessing ( on disk)\nit directly .\nDoes such a table sound familiar? What we have described is the b asic\nstructure of what is known as the \ufb01le allocation table , or FA T\ufb01le system.\nY es, this classic old Windows \ufb01le system, before NTFS [C94], is b ased on a\nsimple linked-based allocation scheme. There are other differ ences from\na standard U N I X \ufb01le system too; for example, there are no inodes per se,\nbut rather directory entries which store metadata about a \ufb01le an d refer\ndirectly to the \ufb01rst block of said \ufb01le, which makes creating har d links\nimpossible. See Brouwer [B02] for more of the inelegant details.\nY ou might be wondering where exactly directories are stored. Oft en,\n\ufb01le systems treat directories as a special type of \ufb01le. Thus, a d irectory has\nan inode, somewhere in the inode table (with the type \ufb01eld of the in ode\nmarked as \u201cdirectory\u201d instead of \u201cregular \ufb01le\u201d). The directory has data\nblocks pointed to by the inode (and perhaps, indirect blocks); th ese data\nblocks live in the data block region of our simple \ufb01le system. Our on- disk\nstructure thus remains unchanged.\nW e should also note again that this simple linear list of director y en-\ntries is not the only way to store such information. As before, any da ta\nstructure is possible. For example, XFS [S+96] stores directorie s in B-tree\nform, making \ufb01le create operations (which have to ensure that a \ufb01 le name\nhas not been used before creating it) faster than systems with s imple lists\nthat must be scanned in their entirety .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Another simpler approach in designing inodes is to use a linked list .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "another",
          "simpler",
          "approach",
          "designing",
          "inodes",
          "linked",
          "list"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(in memory) table to \ufb01nd the desired block, and then accessing ( on disk)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "table",
          "desired",
          "block",
          "accessing",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Does such a table sound familiar? What we have described is the b asic",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "table",
          "sound",
          "familiar",
          "described",
          "asic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "structure of what is known as the \ufb01le allocation table , or FA T\ufb01le system.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "structure",
          "known",
          "allocation",
          "table",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "form, making \ufb01le create operations (which have to ensure that a \ufb01 le name",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "form",
          "making",
          "create",
          "operations",
          "ensure",
          "name"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "5 Free Space Management",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "40.5 Free Space Management\nA \ufb01le system must track which inodes and data blocks are free, an d\nwhich are not, so that when a new \ufb01le or directory is allocated, it c an \ufb01nd\nspace for it. Thus free space management is important for all \ufb01le systems.\nIn vsfs, we have two simple bitmaps for this task.\nFor example, when we create a \ufb01le, we will have to allocate an inod e\nfor that \ufb01le. The \ufb01le system will thus search through the bitmap for an in-\node that is free, and allocate it to the \ufb01le; the \ufb01le system will h ave to mark\nthe inode as used (with a 1) and eventually update the on-disk bi tmap\nwith the correct information. A similar set of activities take pl ace when a\ndata block is allocated.\nSome other considerations might also come into play when allocating\ndata blocks for a new \ufb01le. For example, some Linux \ufb01le systems, suc h\nas ext2 and ext3, will look for a sequence of blocks (say 8) that are f ree\nwhen a new \ufb01le is created and needs data blocks; by \ufb01nding such a se-\nquence of free blocks, and then allocating them to the newly-cre ated \ufb01le,\nthe \ufb01le system guarantees that a portion of the \ufb01le will be contigu ous on\nthe disk, thus improving performance. Such a pre-allocation policy is\nthus a commonly-used heuristic when allocating space for data bl ocks.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "space for it. Thus free space management is important for all \ufb01le systems.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "space",
          "thus",
          "free",
          "space",
          "management",
          "important",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "For example, when we create a \ufb01le, we will have to allocate an inod e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "create",
          "allocate",
          "inod"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "when a new \ufb01le is created and needs data blocks; by \ufb01nding such a se-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "needs",
          "data",
          "blocks"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand free space management",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "space",
          "management"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "40",
    "title": "6 Access Paths: Reading and W riting",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "40.6 Access Paths: Reading and W riting\nNow that we have some idea of how \ufb01les and directories are stored on\ndisk, we should be able to follow the \ufb02ow of operation during the activ ity\nof reading or writing a \ufb01le. Understanding what happens on this access\npath is thus the second key in developing an understanding of how a \ufb01le\nsystem works; pay attention!\nFor the following examples, let us assume that the \ufb01le system has been\nmounted and thus that the superblock is already in memory . Every thing\nelse (i.e., inodes, directories) is still on the disk.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "disk, we should be able to follow the \ufb02ow of operation during the activ ity",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "able",
          "follow",
          "operation",
          "activ"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of reading or writing a \ufb01le. Understanding what happens on this access",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "writing",
          "understanding",
          "happens",
          "access"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "path is thus the second key in developing an understanding of how a \ufb01le",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "path",
          "thus",
          "second",
          "developing",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand access paths: reading and w riting",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "access",
          "paths",
          "reading",
          "riting"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 11\ndata inode root foo bar root foo bar bar bar\nbitmap bitmap inode inode inode data data data data data\n[0] [1] [2]\nread\nread\nopen(bar) read\nread\nread\nread\nread() read\nwrite\nread\nread() read\nwrite\nread\nread() read\nwrite\nFigure 40.3: File Read Timeline (Time Increasing Downward)\nReading A File From Disk\nIn this simple example, let us \ufb01rst assume that you want to simp ly open\na \ufb01le (e.g., /foo/bar), read it, and then close it. For this simple example,\nlet\u2019s assume the \ufb01le is just 12KB in size (i.e., 3 blocks).\nWhen you issue an open(\"/foo/bar\", O\nRDONLY) call, the \ufb01le sys-\ntem \ufb01rst needs to \ufb01nd the inode for the \ufb01le bar, to obtain some basic in-\nformation about the \ufb01le (permissions information, \ufb01le size, etc.) . T o do so,\nthe \ufb01le system must be able to \ufb01nd the inode, but all it has right now is\nthe full pathname. The \ufb01le system must traverse the pathname and thus\nlocate the desired inode.\nAll traversals begin at the root of the \ufb01le system, in the root directory\nwhich is simply called /. Thus, the \ufb01rst thing the FS will read from disk\nis the inode of the root directory . But where is this inode? T o \ufb01nd an\ninode, we must know its i-number . Usually , we \ufb01nd the i-number of a \ufb01le\nor directory in its parent directory; the root has no parent (by de\ufb01 nition).\nThus, the root inode number must be \u201cwell known\u201d; the FS must know\nwhat it is when the \ufb01le system is mounted. In most U N I X \ufb01le systems,\nthe root inode number is 2. Thus, to begin the process, the FS reads in the\nblock that contains inode number 2 (the \ufb01rst inode block).\nOnce the inode is read in, the FS can look inside of it to \ufb01nd pointers to\ndata blocks, which contain the contents of the root directory . The FS will\nthus use these on-disk pointers to read through the directory , in this case\nlooking for an entry for foo. By reading in one or more directory data\nblocks, it will \ufb01nd the entry for foo; once found, the FS will also hav e\nfound the inode number of foo (say it is 44) which it will need next.\nThe next step is to recursively traverse the pathname until t he desired\ninode is found. In this example, the FS reads the block containing the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the \ufb01le system must be able to \ufb01nd the inode, but all it has right now is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "must",
          "able",
          "inode",
          "right"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "inode, we must know its i-number . Usually , we \ufb01nd the i-number of a \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "inode",
          "must",
          "know",
          "number",
          "usually",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Thus, the root inode number must be \u201cwell known\u201d; the FS must know",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "root",
          "inode",
          "number",
          "must",
          "well",
          "known",
          "must"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 3: File Read Timeline (Time Increasing Downward)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "file",
          "read",
          "timeline",
          "time",
          "increasing",
          "downward"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 FI L E SY S T E M IM P L E M E N TAT I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 FI L E SY S T E M IM P L E M E N TAT I O N\nAS I D E : R E A D S DO N\u2019 T AC C E S S AL L O C AT I O N ST R U C T U R E S\nW e\u2019ve seen many students get confused by allocation structures s uch as\nbitmaps. In particular , many often think that when you are simp ly read-\ning a \ufb01le, and not allocating any new blocks, that the bitmap will still\nbe consulted. This is not true! Allocation structures, such as bi tmaps,\nare only accessed when allocation is needed. The inodes, director ies, and\nindirect blocks have all the information they need to complete a r ead re-\nquest; there is no need to make sure a block is allocated when the inode\nalready points to it.\ninode of foo and then its directory data, \ufb01nally \ufb01nding the inode number\nof bar. The \ufb01nal step of open() is to read bar\u2019s inode into memory; the\nFS then does a \ufb01nal permissions check, allocates a \ufb01le descriptor for this\nprocess in the per-process open-\ufb01le table, and returns it to the user .\nOnce open, the program can then issue a read() system call to read\nfrom the \ufb01le. The \ufb01rst read (at offset 0 unless lseek() has been called)\nwill thus read in the \ufb01rst block of the \ufb01le, consulting the inode to \ufb01nd\nthe location of such a block; it may also update the inode with a new l ast-\naccessed time. The read will further update the in-memory open \ufb01le table\nfor this \ufb01le descriptor , updating the \ufb01le offset such that the ne xt read will\nread the second \ufb01le block, etc.\nAt some point, the \ufb01le will be closed. There is much less work to be\ndone here; clearly , the \ufb01le descriptor should be deallocated, bu t for now ,\nthat is all the FS really needs to do. No disk I/Os take place.\nA depiction of this entire process is found in Figure 40.3 (page 11 );\ntime increases downward in the \ufb01gure. In the \ufb01gure, the open cau ses\nnumerous reads to take place in order to \ufb01nally locate the inode of t he \ufb01le.\nAfterwards, reading each block requires the \ufb01le system to \ufb01rs t consult the\ninode, then read the block, and then update the inode\u2019s last-acce ssed-time\n\ufb01eld with a write. Spend some time and understand what is going on.\nAlso note that the amount of I/O generated by the open is propor-\ntional to the length of the pathname. For each additional director y in the\npath, we have to read its inode as well as its data. Making this w orse\nwould be the presence of large directories; here, we only have to r ead one\nblock to get the contents of a directory , whereas with a large dire ctory , we\nmight have to read many data blocks to \ufb01nd the desired entry . Y e s, life\ncan get pretty bad when reading a \ufb01le; as you\u2019re about to \ufb01nd out, wr iting\nout a \ufb01le (and especially , creating a new one) is even worse.\nW riting A File T o Disk\nW riting to a \ufb01le is a similar process. First, the \ufb01le must be open ed (as\nabove). Then, the application can issue write() calls to update the \ufb01le\nwith new contents. Finally , the \ufb01le is closed.\nUnlike reading, writing to the \ufb01le may also allocate a block (unless\nthe block is being overwritten, for example). When writing out a n ew\n\ufb01le, each write not only has to write data to disk but has to \ufb01rst d ecide\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01eld with a write. Spend some time and understand what is going on.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "write",
          "spend",
          "time",
          "understand",
          "going"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 13\ndata inode root foo bar root foo bar bar bar\nbitmap bitmap inode inode inode data data data data data\n[0] [1] [2]\nread\nread\nread\nread\ncreate read\n(/foo/bar) write\nwrite\nread\nwrite\nwrite\nread\nread\nwrite() write\nwrite\nwrite\nread\nread\nwrite() write\nwrite\nwrite\nread\nread\nwrite() write\nwrite\nwrite\nFigure 40.4: File Creation Timeline (Time Increasing Downward)\nwhich block to allocate to the \ufb01le and thus update other structur es of the\ndisk accordingly (e.g., the data bitmap and inode). Thus, each write to a\n\ufb01le logically generates \ufb01ve I/Os: one to read the data bitmap (w hich is\nthen updated to mark the newly-allocated block as used), one to w rite the\nbitmap (to re\ufb02ect its new state to disk), two more to read and th en write\nthe inode (which is updated with the new block\u2019s location), and \ufb01na lly\none to write the actual block itself.\nThe amount of write traf\ufb01c is even worse when one considers a sim-\nple and common operation such as \ufb01le creation. T o create a \ufb01le, the \ufb01 le\nsystem must not only allocate an inode, but also allocate space wit hin\nthe directory containing the new \ufb01le. The total amount of I/O traf\ufb01 c to\ndo so is quite high: one read to the inode bitmap (to \ufb01nd a free inod e),\none write to the inode bitmap (to mark it allocated), one write to t he new\ninode itself (to initialize it), one to the data of the directory ( to link the\nhigh-level name of the \ufb01le to its inode number), and one read and w rite\nto the directory inode to update it. If the directory needs to grow to ac-\ncommodate the new entry , additional I/Os (i.e., to the data bitm ap, and\nthe new directory block) will be needed too. All that just to creat e a \ufb01le!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "create read",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ple and common operation such as \ufb01le creation. T o create a \ufb01le, the \ufb01 le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "operation",
          "creation",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 4: File Creation Timeline (Time Increasing Downward)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "file",
          "creation",
          "timeline",
          "time",
          "increasing",
          "downward"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Os: one to read the data bitmap (w hich is",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "os",
          "read",
          "data",
          "bitmap",
          "hich"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "7 Caching and Buffering",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "40.7 Caching and Buffering\nAs the examples above show , reading and writing \ufb01les can be expe n-\nsive, incurring many I/Os to the (slow) disk. T o remedy what wou ld\nclearly be a huge performance problem, most \ufb01le systems aggress ively\nuse system memory (DRAM) to cache important blocks.\nImagine the open example above: without caching, every \ufb01le open\nwould require at least two reads for every level in the directory hierarchy\n(one to read the inode of the directory in question, and at least one t o read\nits data). With a long pathname (e.g., /1/2/3/ ... /100/\ufb01le.t xt), the \ufb01le\nsystem would literally perform hundreds of reads just to open the \ufb01le!\nEarly \ufb01le systems thus introduced a \ufb01xed-size cache to hold popular\nblocks. As in our discussion of virtual memory , strategies such as LRU\nand different variants would decide which blocks to keep in cac he. This\n\ufb01xed-size cache would usually be allocated at boot time to be rough ly\n10% of total memory .\nThis static partitioning of memory , however , can be wasteful; what\nif the \ufb01le system doesn\u2019t need 10% of memory at a given point in time?\nWith the \ufb01xed-size approach described above, unused pages in t he \ufb01le\ncache cannot be re-purposed for some other use, and thus go to waste .\nModern systems, in contrast, employ a dynamic partitioning approach.\nSpeci\ufb01cally , many modern operating systems integrate virtual memory\npages and \ufb01le system pages into a uni\ufb01ed page cache [S00]. In this way ,\nmemory can be allocated more \ufb02exibly across virtual memory and \ufb01le\nsystem, depending on which needs more memory at a given time.\nNow imagine the \ufb01le open example with caching. The \ufb01rst open may\ngenerate a lot of I/O traf\ufb01c to read in directory inode and data, bu t sub-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "use system memory (DRAM) to cache important blocks.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "memory",
          "dram",
          "cache",
          "important",
          "blocks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "With the \ufb01xed-size approach described above, unused pages in t he \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "size",
          "approach",
          "described",
          "unused",
          "pages"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Modern systems, in contrast, employ a dynamic partitioning approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "modern",
          "systems",
          "contrast",
          "employ",
          "dynamic",
          "partitioning",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand caching and buffering",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "caching",
          "buffering"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 15\nTI P : U N D E R S TA N D STAT I C VS. D Y N A M I C PA RT I T I O N I N G\nWhen dividing a resource among different clients/users, you ca n use\neither static partitioning or dynamic partitioning . The static approach\nsimply divides the resource into \ufb01xed proportions once; for exampl e, if\nthere are two possible users of memory , you can give some \ufb01xed fract ion\nof memory to one user , and the rest to the other . The dynamic approac h\nis more \ufb02exible, giving out differing amounts of the resource over t ime;\nfor example, one user may get a higher percentage of disk bandwid th for\na period of time, but then later , the system may switch and decid e to give\na different user a larger fraction of available disk bandwidth .\nEach approach has its advantages. Static partitioning ensures each user\nreceives some share of the resource, usually delivers more predi ctable\nperformance, and is often easier to implement. Dynamic partit ioning can\nachieve better utilization (by letting resource-hungry user s consume oth-\nerwise idle resources), but can be more complex to implement, an d can\nlead to worse performance for users whose idle resources get consum ed\nby others and then take a long time to reclaim when needed. As is of -\nten the case, there is no best method; rather , you should think ab out the\nproblem at hand and decide which approach is most suitable. Inde ed,\nshouldn\u2019t you always be doing that?\nsequent \ufb01le opens of that same \ufb01le (or \ufb01les in the same directory) w ill\nmostly hit in the cache and thus no I/O is needed.\nLet us also consider the effect of caching on writes. Whereas rea d I/O\ncan be avoided altogether with a suf\ufb01ciently large cache, writ e traf\ufb01c has\nto go to disk in order to become persistent. Thus, a cache does not s erve\nas the same kind of \ufb01lter on write traf\ufb01c that it does for reads. Tha t said,\nwrite buffering (as it is sometimes called) certainly has a number of per-\nformance bene\ufb01ts. First, by delaying writes, the \ufb01le system c an batch\nsome updates into a smaller set of I/Os; for example, if an inode bi tmap\nis updated when one \ufb01le is created and then updated moments late r as\nanother \ufb01le is created, the \ufb01le system saves an I/O by delaying the write\nafter the \ufb01rst update. Second, by buffering a number of writes in memory ,\nthe system can then schedule the subsequent I/Os and thus increase per-\nformance. Finally , some writes are avoided altogether by delayi ng them;\nfor example, if an application creates a \ufb01le and then deletes it , delaying\nthe writes to re\ufb02ect the \ufb01le creation to disk avoids them entirely . In this\ncase, laziness (in writing blocks to disk) is a virtue.\nFor the reasons above, most modern \ufb01le systems buffer writes in mem -\nory for anywhere between \ufb01ve and thirty seconds, representing y et an-\nother trade-off: if the system crashes before the updates have b een prop-\nagated to disk, the updates are lost; however , by keeping write s in mem-\nory longer , performance can be improved by batching, scheduling , and\neven avoiding writes.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "either static partitioning or dynamic partitioning . The static approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "either",
          "static",
          "partitioning",
          "dynamic",
          "partitioning",
          "static",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Each approach has its advantages. Static partitioning ensures each user",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "advantages",
          "static",
          "partitioning",
          "ensures",
          "user"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "performance, and is often easier to implement. Dynamic partit ioning can",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "performance",
          "often",
          "easier",
          "implement",
          "dynamic",
          "partit",
          "ioning"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "erwise idle resources), but can be more complex to implement, an d can",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "erwise",
          "idle",
          "resources",
          "complex",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ten the case, there is no best method; rather , you should think ab out the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "case",
          "best",
          "method",
          "rather",
          "think"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "problem at hand and decide which approach is most suitable. Inde ed,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "hand",
          "decide",
          "approach",
          "suitable",
          "inde"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "is updated when one \ufb01le is created and then updated moments late r as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "updated",
          "created",
          "updated",
          "moments",
          "late"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "another \ufb01le is created, the \ufb01le system saves an I/O by delaying the write",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "created",
          "system",
          "saves",
          "delaying",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "for example, if an application creates a \ufb01le and then deletes it , delaying",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "application",
          "creates",
          "deletes",
          "delaying"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand off: if the system crashes before the updates have b een prop-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "off",
          "system",
          "crashes",
          "updates",
          "prop"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "40",
    "title": "8 Summary",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "40.8 Summary\nW e have seen the basic machinery required in building a \ufb01le sy stem.\nThere needs to be some information about each \ufb01le (metadata), usu ally\nstored in a structure called an inode. Directories are just a spe ci\ufb01c type\nof \ufb01le that store name \u2192inode-number mappings. And other structures\nare needed too; for example, \ufb01le systems often use a structure suc h as a\nbitmap to track which inodes or data blocks are free or allocated.\nThe terri\ufb01c aspect of \ufb01le system design is its freedom; the \ufb01le s ystems\nwe explore in the coming chapters each take advantage of this fre edom\nto optimize some aspect of the \ufb01le system. There are also clearly many\npolicy decisions we have left unexplored. For example, when a new \ufb01le\nis created, where should it be placed on disk? This policy and othe rs will\nalso be the subject of future chapters. Or will they? 3\n2 T ake a database class to learn more about old-school databases and their former insis-\ntence on avoiding the OS and controlling everything themselves. But watch o ut! Those\ndatabase types are always trying to bad mouth the OS. Shame on you, database people. Shame.\n3 Cue mysterious music that gets you even more intrigued about the topic of \ufb01le systems.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The terri\ufb01c aspect of \ufb01le system design is its freedom; the \ufb01le s ystems",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "aspect",
          "system",
          "design",
          "freedom",
          "ystems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "is created, where should it be placed on disk? This policy and othe rs will",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "placed",
          "disk",
          "policy",
          "othe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "T ake a database class to learn more about old-school databases and their former insis-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "database",
          "class",
          "learn",
          "school",
          "databases",
          "former",
          "insis"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FI L E SY S T E M IM P L E M E N TAT I O N 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FI L E SY S T E M IM P L E M E N TAT I O N 17\nReferences\n[A+07] \u201cA Five-Y ear Study of File-System Metadata\u201d by Nitin Agra wal, William J. Bolosky ,\nJohn R. Douceur , Jacob R. Lorch. F AST \u201907, San Jose, California, Februar y 2007. An excellent\nrecent analysis of how \ufb01le systems are actually used. Use the bibliography within to follow the trail of\n\ufb01le-system analysis papers back to the early 1980s.\n[B07] \u201cZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. A vailable from:\nhttp://www.ostep.org/Citations/zfs_last.pdf. One of the most recent important \ufb01le\nsystems, full of features and awesomeness. We should have a chapter on it, and perhaps soon will.\n[B02] \u201cThe F A T File System\u201d by Andries Brouwer . September , 2002. A vailable online at:\nhttp://www.win.tue.nl/\u02dcaeb/linux/fs/fat/fat.html. A nice clean description of\nF AT . The \ufb01le system kind, not the bacon kind. Though you have to admit, bacon fat p robably tastes\nbetter .\n[C94] \u201cInside the Windows NT File System\u201d by Helen Custer . Microsoft Press, 1994. A short\nbook about NTFS; there are probably ones with more technical details elsewher e.\n[H+88] \u201cScale and Performance in a Distributed File System\u201d by John H. H oward, Michael\nL. Kazar , Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Rober t N. Sidebotham,\nMichael J. W est.. ACM TOCS, V olume 6:1, February 1988. A classic distributed \ufb01le system; we\u2019ll\nbe learning more about it later , don\u2019t worry.\n[P09] \u201cThe Second Extended File System: Internal Layout\u201d by Dave Poirie r . 2009. A vailable:\nhttp://www.nongnu.org/ext2-doc/ext2.html. Some details on ext2, a very simple Linux\n\ufb01le system based on FFS, the Berkeley Fast File System. We\u2019ll be readin g about it in the next chapter .\n[RT74] \u201cThe U N I X Time-Sharing System\u201d by M. Ritchie, K. Thompson. CACM V olume 17:7,\n1974. The original paper about UN I X. Read it to see the underpinnings of much of modern operating\nsystems.\n[S00] \u201cUBC: An Ef\ufb01cient Uni\ufb01ed I/O and Memory Caching Subsystem for NetB SD\u201d by Chuck\nSilvers. FREENIX, 2000. A nice paper about NetBSD\u2019s integration of \ufb01le-system buffer caching and\nthe virtual-memory page cache. Many other systems do the same type of thing.\n[S+96] \u201cScalability in the XFS File System\u201d by Adan Sweeney , Doug Doucette, W ei Hu, Curtis\nAnderson, Mike Nishimoto, Geoff Peck. USENIX \u201996, January 1996, San D iego, California.\nThe \ufb01rst attempt to make scalability of operations, including things like havin g millions of \ufb01les in a\ndirectory, a central focus. A great example of pushing an idea to the extrem e. The key idea behind this\n\ufb01le system: everything is a tree. We should have a chapter on this \ufb01le sys tem too.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "http://www.ostep.org/Citations/zfs_last.pdf. One of the most recent important \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "ostep",
          "citations",
          "recent",
          "important"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "be learning more about it later , don\u2019t worry.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learning",
          "later",
          "worry"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand ZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. A vailable from:",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "zfs",
          "last",
          "file",
          "systems",
          "jeff",
          "bonwick",
          "bill",
          "moor",
          "vailable"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand http: //www.ostep.org/Citations/zfs_last.pdf. One of the most recent important \ufb01le",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "ostep",
          "citations",
          "recent",
          "important"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable online at: http://www.win.tue.nl/\u02dcaeb/linux/fs/fat/fat.html. A nice clean description of",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online at",
          "http",
          "linux",
          "html",
          "nice",
          "clean",
          "description"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 6: 1, February 1988. A classic distributed \ufb01le system; we\u2019ll",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 6",
          "february",
          "classic",
          "distributed",
          "system"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand http: //www.nongnu.org/ext2-doc/ext2.html. Some details on ext2, a very simple Linux",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "nongnu",
          "html",
          "details",
          "simple",
          "linux"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand UBC: An Ef\ufb01cient Uni\ufb01ed I/O and Memory Caching Subsystem for NetB SD\u201d by Chuck",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ubc",
          "memory",
          "caching",
          "subsystem",
          "netb",
          "chuck"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Run the simulator with some different random seeds (say 17, 18 , 19,",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "1. Run the simulator with some different random seeds (say 17, 18 , 19,\n20), and see if you can \ufb01gure out which operations must have taken\nplace between each state change.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now do the same, using different random seeds (say 21, 22, 23,",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "2. Now do the same, using different random seeds (say 21, 22, 23,\n24), except run with the -r \ufb02ag, thus making you guess the state\nchange while being shown the operation. What can you conclude\nabout the inode and data-block allocation algorithms, in terms of\nwhich blocks they prefer to allocate?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "about the inode and data-block allocation algorithms, in terms of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "inode",
          "data",
          "block",
          "allocation",
          "algorithms",
          "terms"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Now reduce the number of data blocks in the \ufb01le system, to very",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "3. Now reduce the number of data blocks in the \ufb01le system, to very\nlow numbers (say two), and run the simulator for a hundred or so\nrequests. What types of \ufb01les end up in the \ufb01le system in this hig hly-\nconstrained layout? What types of operations would fail?\n4. Now do the same, but with inodes. With very few inodes, what\ntypes of operations can succeed? Which will usually fail? What i s\nthe \ufb01nal state of the \ufb01le system likely to be?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "1 The Problem: Poor Performance",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "41.1 The Problem: Poor Performance\nThe problem: performance was terrible. As measured by Kirk McK u-\nsick and his colleagues at Berkeley [MJLF84], performance sta rted off bad\nand got worse over time, to the point where the \ufb01le system was deliv ering\nonly 2% of overall disk bandwidth!\nThe main issue was that the old U N I X \ufb01le system treated the disk like it\nwas a random-access memory; data was spread all over the place wi thout\nregard to the fact that the medium holding the data was a disk, a nd thus\nhad real and expensive positioning costs. For example, the data b locks of\na \ufb01le were often very far away from its inode, thus inducing an exp ensive\nseek whenever one \ufb01rst read the inode and then the data blocks of a \ufb01 le\n(a pretty common operation).\n1",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand The problem: performance was terrible. As measured by Kirk McK u-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the problem",
          "performance",
          "terrible",
          "measured",
          "kirk"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the problem: poor performance",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "poor",
          "performance"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 L O C A L I T Y A N D TH E FA S T FI L E SY S T ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 L O C A L I T Y A N D TH E FA S T FI L E SY S T E M\nW orse, the \ufb01le system would end up getting quite fragmented, as the\nfree space was not carefully managed. The free list would end up point-\ning to a bunch of blocks spread across the disk, and as \ufb01les got alloc ated,\nthey would simply take the next free block. The result was that a logi-\ncally contiguous \ufb01le would be accessed by going back and forth acros s\nthe disk, thus reducing performance dramatically .\nFor example, imagine the following data block region, which contai ns\nfour \ufb01les (A, B, C, and D), each of size 2 blocks:\nA1 A2 B1 B2 C1 C2 D1 D2\nIf B and D are deleted, the resulting layout is:\nA1 A2 C1 C2\nAs you can see, the free space is fragmented into two chunks of tw o\nblocks, instead of one nice contiguous chunk of four . Let\u2019s say you now\nwish to allocate a \ufb01le E, of size four blocks:\nA1 A2 E1 E2 C1 C2 E3 E4\nY ou can see what happens: E gets spread across the disk, and as a\nresult, when accessing E, you don\u2019t get peak (sequential) perfor mance\nfrom the disk. Rather , you \ufb01rst read E1 and E2, then seek, then re ad E3\nand E4. This fragmentation problem happened all the time in the old\nUN I X \ufb01le system, and it hurt performance. A side note: this problem is\nexactly what disk defragmentation tools help with; they reorganize on-\ndisk data to place \ufb01les contiguously and make free space for one or a few\ncontiguous regions, moving data around and then rewriting inodes a nd\nsuch to re\ufb02ect the changes.\nOne other problem: the original block size was too small (512 bytes ).\nThus, transferring data from the disk was inherently inef\ufb01ci ent. Smaller\nblocks were good because they minimized internal fragmentation (waste\nwithin the block), but bad for transfer as each block might requi re a posi-\ntioning overhead to reach it. Thus, the problem:\nTH E CR U X :\nHO W TO OR G A N I Z E ON-D I S K DATA TO IM P R O V E PE R F O R M A N C E\nHow can we organize \ufb01le system data structures so as to improve pe r-\nformance? What types of allocation policies do we need on top of those\ndata structures? How do we make the \ufb01le system \u201cdisk aware\u201d?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand of size four blocks: A1 A2 E1 E2 C1 C2 E3 E4",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "of size four blocks"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand One other problem: the original block size was too small (512 bytes ).",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one other problem",
          "original",
          "block",
          "size",
          "small",
          "bytes"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "2 FFS: Disk A wareness Is The Solution",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "41.2 FFS: Disk A wareness Is The Solution\nA group at Berkeley decided to build a better , faster \ufb01le syste m, which\nthey cleverly called the Fast File System (FFS) . The idea was to design\nthe \ufb01le system structures and allocation policies to be \u201cdisk aw are\u201d and\nthus improve performance, which is exactly what they did. FFS t hus ush-\nered in a new era of \ufb01le system research; by keeping the same interface\nto the \ufb01le system (the same APIs, including open(), read(), write(),\nclose(), and other \ufb01le system calls) but changing the internal implemen-\ntation, the authors paved the path for new \ufb01le system construction, work\nthat continues today . Virtually all modern \ufb01le systems adhere t o the ex-\nisting interface (and thus preserve compatibility with appl ications) while\nchanging their internals for performance, reliability , or othe r reasons.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "they cleverly called the Fast File System (FFS) . The idea was to design",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "cleverly",
          "called",
          "fast",
          "file",
          "system",
          "idea",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 2 FFS: Disk A wareness Is The Solution",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2 ffs",
          "disk",
          "wareness",
          "solution"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "41",
    "title": "3 Organizing Structure: The Cylinder Group",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "41.3 Organizing Structure: The Cylinder Group\nThe \ufb01rst step was to change the on-disk structures. FFS divide s the\ndisk into a number of cylinder groups . A single cylinder is a set of tracks\non different surfaces of a hard drive that are the same distance from the\ncenter of the drive; it is called a cylinder because of its clear resemblance\nto the so-called geometrical shape. FFS aggregates N consecutive cylin-\nders into a group, and thus the entire disk can thus be viewed as a collec-\ntion of cylinder groups. Here is a simple example, showing the four outer\nmost tracks of a drive with six platters, and a cylinder group tha t consists\nof three cylinders:\nSingle track (e.g., dark gray)\nCylinder:\nTracks at same distance from center\nof drive across different surfaces\n[all tracks with same color]\nCylinder Group:\nSet of N consecutive cylinders\n[if N=3, first group does\nnot include black track]\nNote that modern drives do not export enough information for the\n\ufb01le system to truly understand whether a particular cylinde r is in use;\nas discussed previously [AD14a], disks export a logical addres s space of\nblocks and hide details of their geometry from clients. Thus, mode rn \ufb01le\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01le system to truly understand whether a particular cylinde r is in use;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "truly",
          "understand",
          "whether",
          "particular",
          "cylinde"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Cylinder: Tracks at same distance from center",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cylinder",
          "tracks",
          "distance",
          "center"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Cylinder Group: Set of N consecutive cylinders",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cylinder group",
          "consecutive",
          "cylinders"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand organizing structure: the cylinder group",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "organizing",
          "structure",
          "cylinder",
          "group"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 L O C A L I T Y A N D TH E FA S T FI L E SY S T ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 L O C A L I T Y A N D TH E FA S T FI L E SY S T E M\nsystems (such as Linux ext2, ext3, and ext4) instead organize the drive\ninto block groups , each of which is just a consecutive portion of the disk\u2019s\naddress space. The picture below illustrates an example wher e every 8\nblocks are organized into a different block group (note that real g roups\nwould consist of many more blocks):\nGroup 0 Group 1 Group 2\nWhether you call them cylinder groups or block groups, these groups\nare the central mechanism that FFS uses to improve performance . Crit-\nically , by placing two \ufb01les within the same group, FFS can ensu re that\naccessing one after the other will not result in long seeks across t he disk.\nT o use these groups to store \ufb01les and directories, FFS needs to ha ve the\nability to place \ufb01les and directories into a group, and track al l necessary\ninformation about them therein. T o do so, FFS includes all the str uctures\nyou might expect a \ufb01le system to have within each group, e.g., sp ace for\ninodes, data blocks, and some structures to track whether each of those\nare allocated or free. Here is a depiction of what FFS keeps within a single\ncylinder group:\nS ib db Inodes Data\nLet\u2019s now examine the components of this single cylinder group in\nmore detail. FFS keeps a copy of the super block (S) in each group for\nreliability reasons. The super block is needed to mount the \ufb01le s ystem;\nby keeping multiple copies, if one copy becomes corrupt, you can sti ll\nmount and access the \ufb01le system by using a working replica.\nWithin each group, FFS needs to track whether the inodes and dat a\nblocks of the group are allocated. A per-group inode bitmap (ib) and\ndata bitmap (db) serve this role for inodes and data blocks in each group.\nBitmaps are an excellent way to manage free space in a \ufb01le syst em be-\ncause it is easy to \ufb01nd a large chunk of free space and allocate it to a \ufb01le,\nperhaps avoiding some of the fragmentation problems of the free lis t in\nthe old \ufb01le system.\nFinally , the inode and data block regions are just like those in the pre-\nvious very-simple \ufb01le system (VSFS). Most of each cylinder group, a s\nusual, is comprised of data blocks.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "4 Policies: How T o Allocate Files and Directories",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "41.4 Policies: How T o Allocate Files and Directories\nWith this group structure in place, FFS now has to decide how to pl ace\n\ufb01les and directories and associated metadata on disk to improve p erfor-\nmance. The basic mantra is simple: keep related stuff together (and its corol-\nlary , keep unrelated stuff far apart ).\nThus, to obey the mantra, FFS has to decide what is \u201crelated\u201d an d\nplace it within the same block group; conversely , unrelated ite ms should\nbe placed into different block groups. T o achieve this end, FFS makes use\nof a few simple placement heuristics.\nThe \ufb01rst is the placement of directories. FFS employs a simple ap -\nproach: \ufb01nd the cylinder group with a low number of allocated direc -\ntories (to balance directories across groups) and a high number of free\ninodes (to subsequently be able to allocate a bunch of \ufb01les), and put the\ndirectory data and inode in that group. Of course, other heuristic s could\nbe used here (e.g., taking into account the number of free data b locks).\nFor \ufb01les, FFS does two things. First, it makes sure (in the gener al case)\nto allocate the data blocks of a \ufb01le in the same group as its inode, th us\npreventing long seeks between inode and data (as in the old \ufb01le sy stem).\nSecond, it places all \ufb01les that are in the same directory in the cy linder\ngroup of the directory they are in. Thus, if a user creates four \ufb01le s, /a/b,\n/a/c, /a/d, and b/f, FFS would try to place the \ufb01rst three near one\nanother (same group) and the fourth far away (in some other group).\nLet\u2019s look at an example of such an allocation. In the example, as-\nsume that there are only 10 inodes and 10 data blocks in each group ( both\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "inodes (to subsequently be able to allocate a bunch of \ufb01les), and put the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "inodes",
          "subsequently",
          "able",
          "allocate",
          "bunch"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "group of the directory they are in. Thus, if a user creates four \ufb01le s, /a/b,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "group",
          "directory",
          "thus",
          "user",
          "creates",
          "four"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 4 Policies: How T o Allocate Files and Directories",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4 policies",
          "allocate",
          "files",
          "directories"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand proach: \ufb01nd the cylinder group with a low number of allocated direc -",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "proach",
          "cylinder",
          "group",
          "number",
          "allocated",
          "direc"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 L O C A L I T Y A N D TH E FA S T FI L E SY S T ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 L O C A L I T Y A N D TH E FA S T FI L E SY S T E M\nunrealistically small numbers), and that the three director ies (the root di-\nrectory /, /a, and /b) and four \ufb01les ( /a/c, /a/d, /a/e, /b/f) are\nplaced within them per the FFS policies. Assume the regular \ufb01l es are each\ntwo blocks in size, and that the directories have just a single b lock of data.\nFor this \ufb01gure, we use the obvious symbols for each \ufb01le or directory (i .e.,\n/ for the root directory , a for /a, f for /b/f, and so forth).\ngroup inodes data\n0 /--------- /---------\n1 acde------ accddee---\n2 bf-------- bff-------\n3 ---------- ----------\n4 ---------- ----------\n5 ---------- ----------\n6 ---------- ----------\n7 ---------- ----------\nNote that the FFS policy does two positive things: the data blocks of\neach \ufb01le are near each \ufb01le\u2019s inode, and \ufb01les in the same directory are\nnear one another (namely , /a/c, /a/d, and /a/e are all in Group 1, and\ndirectory /b and its \ufb01le /b/f are near one another in Group 2).\nIn contrast, let\u2019s now look at an inode allocation policy that simply\nspreads inodes across groups, trying to ensure that no group\u2019s inod e table\n\ufb01lls up quickly . The \ufb01nal allocation might thus look something lik e this:\ngroup inodes data\n0 /--------- /---------\n1 a--------- a---------\n2 b--------- b---------\n3 c--------- cc--------\n4 d--------- dd--------\n5 e--------- ee--------\n6 f--------- ff--------\n7 ---------- ----------\nAs you can see from the \ufb01gure, while this policy does indeed keep \ufb01l e\n(and directory) data near its respective inode, \ufb01les within a d irectory are\narbitrarily spread around the disk, and thus name-based local ity is not\npreserved. Access to \ufb01les /a/c, /a/d, and /a/e now spans three groups\ninstead of one as per the FFS approach.\nThe FFS policy heuristics are not based on extensive studies of \ufb01l e-\nsystem traf\ufb01c or anything particularly nuanced; rather , the y are based on\ngood old-fashioned common sense (isn\u2019t that what CS stands for after\nall?)1 . Files in a directory are often accessed together: imagine compil-\ning a bunch of \ufb01les and then linking them into a single executab le. Be-\n1 Some people refer to common sense as horse sense , especially people who work regu-\nlarly with horses. However , we have a feeling that this idiom may be l ost as the \u201cmechanized\nhorse\u201d, a.k.a. the car , gains in popularity . What will they invent next ? A \ufb02ying machine??!!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In contrast, let\u2019s now look at an inode allocation policy that simply",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "contrast",
          "look",
          "inode",
          "allocation",
          "policy",
          "simply"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "instead of one as per the FFS approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "instead",
          "approach"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "5 Measuring File Locality",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "41.5 Measuring File Locality\nT o understand better whether these heuristics make sense, l et\u2019s ana-\nlyze some traces of \ufb01le system access and see if indeed there is n amespace\nlocality . For some reason, there doesn\u2019t seem to be a good study of this\ntopic in the literature.\nSpeci\ufb01cally , we\u2019ll use the SEER traces [K94] and analyze how \u201cfar\naway\u201d \ufb01le accesses were from one another in the directory tree. For ex-\nample, if \ufb01le f is opened, and then re-opened next in the trace (before\nany other \ufb01les are opened), the distance between these two opens in the\ndirectory tree is zero (as they are the same \ufb01le). If a \ufb01le f in directory\ndir (i.e., dir/f) is opened, and followed by an open of \ufb01le g in the same\ndirectory (i.e., dir/g), the distance between the two \ufb01le accesses is one,\nas they share the same directory but are not the same \ufb01le. Our dis tance\nmetric, in other words, measures how far up the directory tree you h ave\nto travel to \ufb01nd the common ancestor of two \ufb01les; the closer they are in the\ntree, the lower the metric.\nFigure 41.1 shows the locality observed in the SEER traces over all\nworkstations in the SEER cluster over the entirety of all traces. T he graph\nplots the difference metric along the x-axis, and shows the cumu lative\npercentage of \ufb01le opens that were of that difference along the y-a xis.\nSpeci\ufb01cally , for the SEER traces (marked \u201cT race\u201d in the graph), you can\nsee that about 7% of \ufb01le accesses were to the \ufb01le that was opened pr evi-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand better whether these heuristics make sense, l et\u2019s ana-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "better",
          "whether",
          "heuristics",
          "make",
          "sense"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Speci\ufb01cally , we\u2019ll use the SEER traces [K94] and analyze how \u201cfar",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "seer",
          "traces",
          "analyze"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand measuring file locality",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "measuring",
          "file",
          "locality"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "6 The Large-File Exception",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "41.6 The Large-File Exception\nIn FFS, there is one important exception to the general policy of \ufb01le\nplacement, and it arises for large \ufb01les. Without a different ru le, a large\n\ufb01le would entirely \ufb01ll the block group it is \ufb01rst placed within (a nd maybe\nothers). Filling a block group in this manner is undesirable, as it prevents\nsubsequent \u201crelated\u201d \ufb01les from being placed within this block group, and\nthus may hurt \ufb01le-access locality .\nThus, for large \ufb01les, FFS does the following. After some number of\nblocks are allocated into the \ufb01rst block group (e.g., 12 blocks, or t he num-\nber of direct pointers available within an inode), FFS places th e next \u201clarge\u201d\nchunk of the \ufb01le (e.g., those pointed to by the \ufb01rst indirect block ) in an-\nother block group (perhaps chosen for its low utilization). Then, th e next\nchunk of the \ufb01le is placed in yet another different block group, an d so on.\nLet\u2019s look at some diagrams to understand this policy better . With out\nthe large-\ufb01le exception, a single large \ufb01le would place all of it s blocks into\none part of the disk. W e investigate a small example of a \ufb01le ( /a) with 30\nblocks in an FFS con\ufb01gured with 10 inodes and 40 data blocks per grou p.\nHere is the depiction of FFS without the large-\ufb01le exception:\ngroup inodes data\n0 /a-------- /aaaaaaaaa aaaaaaaaaa aaaaaaaaaa a---------\n1 ---------- ---------- ---------- ---------- ----------\n2 ---------- ---------- ---------- ---------- ----------\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In FFS, there is one important exception to the general policy of \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "exception",
          "general",
          "policy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Let\u2019s look at some diagrams to understand this policy better . With out",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "look",
          "diagrams",
          "understand",
          "policy",
          "better"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand the large-file exception",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "large",
          "file",
          "exception"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M 9\nAs you can see in the picture, /a \ufb01lls up most of the data blocks in\nGroup 0, whereas other groups remain empty . If some other \ufb01les are n ow\ncreated in the root directory ( /), there is not much room for their data in\nthe group.\nWith the large-\ufb01le exception (here set to \ufb01ve blocks in each chu nk), FFS\ninstead spreads the \ufb01le spread across groups, and the resultin g utilization\nwithin any one group is not too high:\ngroup inodes data\n0 /a-------- /aaaaa---- ---------- ---------- ----------\n1 ---------- aaaaa----- ---------- ---------- ----------\n2 ---------- aaaaa----- ---------- ---------- ----------\n3 ---------- aaaaa----- ---------- ---------- ----------\n4 ---------- aaaaa----- ---------- ---------- ----------\n5 ---------- aaaaa----- ---------- ---------- ----------\n6 ---------- ---------- ---------- ---------- ----------\nThe astute reader (that\u2019s you) will note that spreading blocks of a \ufb01le\nacross the disk will hurt performance, particularly in the rel atively com-\nmon case of sequential \ufb01le access (e.g., when a user or applicati on reads\nchunks 0 through 29 in order). And you are right, oh astute reader of\nours! But you can address this problem by choosing chunk size caref ully .\nSpeci\ufb01cally , if the chunk size is large enough, the \ufb01le system w ill spend\nmost of its time transferring data from disk and just a (relative ly) little\ntime seeking between chunks of the block. This process of reducin g an\noverhead by doing more work per overhead paid is called amortization\nand is a common technique in computer systems.\nLet\u2019s do an example: assume that the average positioning time (i .e.,\nseek and rotation) for a disk is 10 ms. Assume further that the dis k trans-\nfers data at 40 MB/s. If your goal was to spend half our time seekin g\nbetween chunks and half our time transferring data (and thus a chieve\n50% of peak disk performance), you would thus need to spend 10 ms\ntransferring data for every 10 ms positioning. So the question bec omes:\nhow big does a chunk have to be in order to spend 10 ms in transfer?\nEasy , just use our old friend, math, in particular the dimension al analysis\nmentioned in the chapter on disks [AD14a]:\n40 \u2718\u2718MB\n\u271f\u271fsec \u00b7 1024 KB\n1 \u2718\u2718MB \u00b7 1 \u271f\u271fsec\n1000 \u271f\u271fms \u00b7 10 \u271f\u271fms = 409.6 KB (41.1)\nBasically , what this equation says is this: if you transfer dat a at 40\nMB/s, you need to transfer only 409.6KB every time you seek in orde r to\nspend half your time seeking and half your time transferring. Si milarly ,\nyou can compute the size of the chunk you would need to achieve 90%\nof peak bandwidth (turns out it is about 3.69MB), or even 99% of peak\nbandwidth (40.6MB!). As you can see, the closer you want to get to p eak,\nthe bigger these chunks get (see Figure 41.2 for a plot of these va lues).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "created in the root directory ( /), there is not much room for their data in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "root",
          "directory",
          "much",
          "room",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "and is a common technique in computer systems.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "common",
          "technique",
          "computer",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "fers data at 40 MB/s. If your goal was to spend half our time seekin g",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fers",
          "data",
          "goal",
          "spend",
          "half",
          "time",
          "seekin"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand s do an example: assume that the average positioning time (i .e.,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s do an example",
          "assume",
          "average",
          "positioning",
          "time"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "7 A Few Other Things About FFS",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "41.7 A Few Other Things About FFS\nFFS introduced a few other innovations too. In particular , the desi gn-\ners were extremely worried about accommodating small \ufb01les; as it turned\nout, many \ufb01les were 2KB or so in size back then, and using 4KB block s,\nwhile good for transferring data, was not so good for space ef\ufb01ciency .\nThis internal fragmentation could thus lead to roughly half the disk be-\ning wasted for a typical \ufb01le system.\nThe solution the FFS designers hit upon was simple and solved the\nproblem. They decided to introduce sub-blocks, which were 512-byte\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The solution the FFS designers hit upon was simple and solved the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "solution",
          "designers",
          "upon",
          "simple",
          "solved"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a few other things about ffs",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "things"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M 11\n0\n11\n1098\n7\n6\n5\n4 3 2\n1\nSpindle\n0\n11\n5104\n9\n3\n8\n2 7 1\n6\nSpindle\nFigure 41.3: FFS: Standard V ersus Parameterized Placement\nlittle blocks that the \ufb01le system could allocate to \ufb01les. Thus, i f you created\na small \ufb01le (say 1KB in size), it would occupy two sub-blocks and t hus not\nwaste an entire 4KB block. As the \ufb01le grew , the \ufb01le system will c ontinue\nallocating 512-byte blocks to it until it acquires a full 4KB of d ata. At that\npoint, FFS will \ufb01nd a 4KB block, copy the sub-blocks into it, and free the\nsub-blocks for future use.\nY ou might observe that this process is inef\ufb01cient, requiring a l ot of ex-\ntra work for the \ufb01le system (in particular , a lot of extra I/O to per form the\ncopy). And you\u2019d be right again! Thus, FFS generally avoided this pes-\nsimal behavior by modifying the libc library; the library would buffer\nwrites and then issue them in 4KB chunks to the \ufb01le system, thu s avoid-\ning the sub-block specialization entirely in most cases.\nA second neat thing that FFS introduced was a disk layout that was\noptimized for performance. In those times (before SCSI and other more\nmodern device interfaces), disks were much less sophisticate d and re-\nquired the host CPU to control their operation in a more hands-on way .\nA problem arose in FFS when a \ufb01le was placed on consecutive sectors of\nthe disk, as on the left in Figure 41.3.\nIn particular , the problem arose during sequential reads. FFS would\n\ufb01rst issue a read to block 0; by the time the read was complete, an d FFS\nissued a read to block 1, it was too late: block 1 had rotated under t he\nhead and now the read to block 1 would incur a full rotation.\nFFS solved this problem with a different layout, as you can see on th e\nright in Figure 41.3. By skipping over every other block (in the e xample),\nFFS has enough time to request the next block before it went past t he\ndisk head. In fact, FFS was smart enough to \ufb01gure out for a particu lar\ndisk how many blocks it should skip in doing layout in order to avoid the\nextra rotations; this technique was called parameterization, as FFS would\n\ufb01gure out the speci\ufb01c performance parameters of the disk and use those\nto decide on the exact staggered layout scheme.\nY ou might be thinking: this scheme isn\u2019t so great after all. In f act, you\nwill only get 50% of peak bandwidth with this type of layout, becau se\nyou have to go around each track twice just to read each block once. For-\ntunately , modern disks are much smarter: they internally rea d the entire\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "little blocks that the \ufb01le system could allocate to \ufb01les. Thus, i f you created",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "little",
          "blocks",
          "system",
          "could",
          "allocate",
          "thus",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "FFS solved this problem with a different layout, as you can see on th e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solved",
          "problem",
          "different",
          "layout"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "extra rotations; this technique was called parameterization, as FFS would",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "extra",
          "rotations",
          "technique",
          "called",
          "parameterization",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 3: FFS: Standard V ersus Parameterized Placement",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "standard",
          "ersus",
          "parameterized",
          "placement"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand it was too late: block 1 had rotated under t he",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it was too late",
          "block",
          "rotated"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "41",
    "title": "8 Summary",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "41.8 Summary\nThe introduction of FFS was a watershed moment in \ufb01le system his-\ntory , as it made clear that the problem of \ufb01le management was one of t he\nmost interesting issues within an operating system, and showed how one\nmight begin to deal with that most important of devices, the hard disk.\nSince that time, hundreds of new \ufb01le systems have developed, but still\ntoday many \ufb01le systems take cues from FFS (e.g., Linux ext2 and e xt3 are\nobvious intellectual descendants). Certainly all modern syst ems account\nfor the main lesson of FFS: treat the disk like it\u2019s a disk.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "might begin to deal with that most important of devices, the hard disk.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "might",
          "begin",
          "deal",
          "important",
          "devices",
          "hard",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Since that time, hundreds of new \ufb01le systems have developed, but still",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "since",
          "time",
          "hundreds",
          "systems",
          "developed",
          "still"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO C A L I T Y A N D TH E FA S T FI L E SY S T E M 13\nReferences\n[AD14a] \u201cOperating Systems: Three Easy Pieces\u201d (Chapter: Hard Disk Dr ives) by Remzi\nArpaci-Dusseau and Andrea Arpaci-Dusseau. Arpaci-Dusseau Books, 2 014. There is no way\nyou should be reading about FFS without having \ufb01rst understood hard drives in some detail. If you try\nto do so, please instead go directly to jail; do not pass go, and, critically, d o not collect 200 much-needed\nsimoleons.\n[AD14b] \u201cOperating Systems: Three Easy Pieces\u201d (Chapter: File System Implementation) by\nRemzi Arpaci-Dusseau and Andrea Arpaci-Dusseau . Arpaci-Dusseau Bo oks, 2014. As above,\nit makes little sense to read this chapter unless you have read (and understood) th e chapter on \ufb01le\nsystem implementation. Otherwise, we\u2019ll be throwing around terms like \u201ci node\u201d and \u201cindirect block\u201d\nand you\u2019ll be like \u201chuh?\u201d and that is no fun for either of us.\n[K94] \u201cThe Design of the SEER Predictive Caching System\u201d by G. H. Kuenning. MOBICOMM\n\u201994, Santa Cruz, California, December 1994. According to Kuenning, this is the best overview of the\nSEER project, which led to (among other things) the collection of these traces.\n[MJLF84] \u201cA Fast File System for U N I X\u201d by Marshall K. McKusick, William N. Joy , Sam J.\nLef\ufb02er , Robert S. Fabry . ACM TOCS, 2:3, August 1984. McKusick was recently honored with the\nIEEE Reynold B. Johnson award for his contributions to \ufb01le systems, much of whi ch was based on\nhis work building FFS. In his acceptance speech, he discussed the ori ginal FFS software: only 1200\nlines of code! Modern versions are a little more complex, e.g., the BSD FF S descendant now is in the\n50-thousand lines-of-code range.\n[P98] \u201cHardware T echnology T rends and Database Opportunities\u201d by Dav id A. Patterson.\nKeynote Lecture at SIGMOD \u201998, June 1998. A great and simple overview of disk technology trends\nand how they change over time.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to do so, please instead go directly to jail; do not pass go, and, critically, d o not collect 200 much-needed",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "please",
          "instead",
          "directly",
          "jail",
          "pass",
          "critically",
          "collect",
          "much"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[AD14b] \u201cOperating Systems: Three Easy Pieces\u201d (Chapter: File System Implementation) by",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "operating",
          "systems",
          "three",
          "easy",
          "pieces",
          "chapter",
          "file",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "system implementation. Otherwise, we\u2019ll be throwing around terms like \u201ci node\u201d and \u201cindirect block\u201d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "system",
          "implementation",
          "otherwise",
          "throwing",
          "around",
          "terms",
          "like",
          "node"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[K94] \u201cThe Design of the SEER Predictive Caching System\u201d by G. H. Kuenning. MOBICOMM",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "seer",
          "predictive",
          "caching",
          "system",
          "kuenning",
          "mobicomm"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Operating Systems: Three Easy Pieces\u201d (Chapter: Hard Disk Dr ives) by Remzi",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "operating systems",
          "three",
          "easy",
          "pieces",
          "chapter",
          "hard",
          "disk",
          "ives",
          "remzi"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 2: 3, August 1984. McKusick was recently honored with the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "august",
          "mckusick",
          "recently",
          "honored"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "7",
    "title": "Which group should FFS place inode of a new directory in? The d efault",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "7. Which group should FFS place inode of a new directory in? The d efault\n(simulator) policy looks for the group with the most free inodes. A different\npolicy looks for a set of groups with the most free inodes. For exa mple, if\nyou run with -A 2, when allocating a new directory , the simulator will look\nat groups in pairs and pick the best pair for the allocation. Run ./ffs.py\n-f in.manyfiles -I 5 -A 2 -c to see how allocation changes with\nthis strategy . How does it affect dirspan? Why might this poli cy be good?\n8. One last policy change we will explore relates to \ufb01le fragmen tation. Run\n./ffs.py -f in.fragmented -v and see if you can predict how the\n\ufb01les that remain are allocated. Run with -c to con\ufb01rm your answer . What\nis interesting about the data layout of \ufb01le /i? Why is it problematic?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "this strategy . How does it affect dirspan? Why might this poli cy be good?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "strategy",
          "affect",
          "dirspan",
          "might",
          "poli",
          "good"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand f in.manyfiles -i 5 -a 2 -c to see how allocation changes with",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "manyfiles",
          "allocation",
          "changes"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand interesting about the data layout of \ufb01le /i",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "interesting",
          "data",
          "layout"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand it affect dirspan",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "affect",
          "dirspan"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_3",
        "text": "understand it problematic",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "problematic"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "9",
    "title": "A new policy , which we call contiguous allocation (-C), tries to ensure that",
    "document_source": "book.pdf",
    "start_line": 42,
    "type": "chapter",
    "content": "9. A new policy , which we call contiguous allocation (-C), tries to ensure that\neach \ufb01le is allocated contiguously . Speci\ufb01cally , with -C n, the \ufb01le system\ntries to ensure that n contiguous blocks are free within a group before al-\nlocating a block. Run ./ffs.py -f in.fragmented -v -C 2 -c to\nsee the difference. How does layout change as the parameter pas sed to -C\nincreases? Finally , how does -C affect \ufb01lespan and dirspan?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand layout change as the parameter pas sed to -C\nincreases",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "layout",
          "change",
          "parameter",
          "increases"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand -C affect \ufb01lespan and dirspan",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "affect",
          "dirspan"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "i",
    "title": "e., they must survive over the long haul, stored on devices that retain",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "i.e., they must survive over the long haul, stored on devices that retain\ndata despite power loss (such as hard disks or \ufb02ash-based SSDs).\nOne major challenge faced by a \ufb01le system is how to update persis -\ntent data structures despite the presence of a power loss or system crash .\nSpeci\ufb01cally , what happens if, right in the middle of updating on -disk\nstructures, someone trips over the power cord and the machine loses\npower? Or the operating system encounters a bug and crashes? Bec ause\nof power losses and crashes, updating a persistent data structu re can be\nquite tricky , and leads to a new and interesting problem in \ufb01le system\nimplementation, known as the crash-consistency problem .\nThis problem is quite simple to understand. Imagine you have to up-\ndate two on-disk structures, A and B, in order to complete a particular\noperation. Because the disk only services a single request at a t ime, one\nof these requests will reach the disk \ufb01rst (either A or B). If the system\ncrashes or loses power after one write completes, the on-disk struc ture\nwill be left in an inconsistent state. And thus, we have a problem that all\n\ufb01le systems need to solve:\nTH E CR U X : H O W TO UP D AT E TH E DI S K DE S P I T E CR A S H E S\nThe system may crash or lose power between any two writes, and\nthus the on-disk state may only partially get updated. After th e crash,\nthe system boots and wishes to mount the \ufb01le system again (in order to\naccess \ufb01les and such). Given that crashes can occur at arbitra ry points\nin time, how do we ensure the \ufb01le system keeps the on-disk image i n a\nreasonable state?\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "implementation, known as the crash-consistency problem .",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation",
          "known",
          "crash",
          "consistency",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "This problem is quite simple to understand. Imagine you have to up-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "quite",
          "simple",
          "understand",
          "imagine"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "\ufb01le systems need to solve:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "systems",
          "need",
          "solve"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "42",
    "title": "1 A Detailed Example",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "42.1 A Detailed Example\nT o kick off our investigation of journaling, let\u2019s look at an example.\nW e\u2019ll need to use a workload that updates on-disk structures in some\nway . Assume here that the workload is simple: the append of a sing le\ndata block to an existing \ufb01le. The append is accomplished by open ing the\n\ufb01le, calling lseek() to move the \ufb01le offset to the end of the \ufb01le, and then\nissuing a single 4KB write to the \ufb01le before closing it.\nLet\u2019s also assume we are using standard simple \ufb01le system stru ctures\non the disk, similar to \ufb01le systems we have seen before. This tin y example\nincludes an inode bitmap (with just 8 bits, one per inode), a data bitmap\n(also 8 bits, one per data block), inodes (8 total, numbered 0 to 7, and\nspread across four blocks), and data blocks (8 total, numbered 0 to 7).\nHere is a diagram of this \ufb01le system:\nBitmaps\nInode Data Inodes Data BlocksI[v1] Da\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7\nIf you look at the structures in the picture, you can see that a sing le inode\nis allocated (inode number 2), which is marked in the inode bitma p, and a\nsingle allocated data block (data block 4), also marked in the da ta bitmap.\nThe inode is denoted I[v1], as it is the \ufb01rst version of this inode; i t will\nsoon be updated (due to the workload described above).\nLet\u2019s peek inside this simpli\ufb01ed inode too. Inside of I[v1], we see :\nowner : remzi\npermissions : read-write\nsize : 1\npointer : 4\npointer : null\npointer : null\npointer : null\nIn this simpli\ufb01ed inode, the size of the \ufb01le is 1 (it has one block al-\nlocated), the \ufb01rst direct pointer points to block 4 (the \ufb01rst data block of\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "soon be updated (due to the workload described above).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "soon",
          "updated",
          "workload",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a detailed example",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "detailed",
          "example"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G 3\nthe \ufb01le, Da), and all three other direct pointers are set to null (indicating\nthat they are not used). Of course, real inodes have many more \ufb01eld s; see\nprevious chapters for more information.\nWhen we append to the \ufb01le, we are adding a new data block to it, an d\nthus must update three on-disk structures: the inode (which mu st point\nto the new block and record the new larger size due to the append) , the\nnew data block Db, and a new version of the data bitmap (call it B[v 2]) to\nindicate that the new data block has been allocated.\nThus, in the memory of the system, we have three blocks which we\nmust write to disk. The updated inode (inode version 2, or I[v2] for short)\nnow looks like this:\nowner : remzi\npermissions : read-write\nsize : 2\npointer : 4\npointer : 5\npointer : null\npointer : null\nThe updated data bitmap (B[v2]) now looks like this: 00001100. F inally ,\nthere is the data block (Db), which is just \ufb01lled with whatever it is users\nput into \ufb01les. Stolen music perhaps?\nWhat we would like is for the \ufb01nal on-disk image of the \ufb01le system to\nlook like this:\nBitmaps\nInode Data Inodes Data BlocksI[v2] Da Db\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7\nT o achieve this transition, the \ufb01le system must perform three s epa-\nrate writes to the disk, one each for the inode (I[v2]), bitmap (B [v2]), and\ndata block (Db). Note that these writes usually don\u2019t happen imme di-\nately when the user issues a write() system call; rather , the dirty in-\node, bitmap, and new data will sit in main memory (in the page cache\nor buffer cache ) for some time \ufb01rst; then, when the \ufb01le system \ufb01nally\ndecides to write them to disk (after say 5 seconds or 30 seconds), the \ufb01le\nsystem will issue the requisite write requests to the disk. U nfortunately ,\na crash may occur and thus interfere with these updates to the d isk. In\nparticular , if a crash happens after one or two of these writes ha ve taken\nplace, but not all three, the \ufb01le system could be left in a funny s tate.\nCrash Scenarios\nT o understand the problem better , let\u2019s look at some example crash sce-\nnarios. Imagine only a single write succeeds; there are thus th ree possible\noutcomes, which we list here:\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand the problem better , let\u2019s look at some example crash sce-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "problem",
          "better",
          "look",
          "example",
          "crash"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "outcomes, which we list here:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "outcomes",
          "list"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand disk structures: the inode (which mu st point",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "disk structures",
          "inode",
          "point"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_12",
        "text": "understand which we list here: c\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which we list here"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 C R A S H CO N S I S T E N C Y: FSCK A N D JO U ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\n\u2022 Just the data block (Db) is written to disk. In this case, the data is\non disk, but there is no inode that points to it and no bitmap that\neven says the block is allocated. Thus, it is as if the write neve r\noccurred. This case is not a problem at all, from the perspective of\n\ufb01le-system crash consistency 1 .\n\u2022 Just the updated inode (I[v2]) is written to disk. In this case, the\ninode points to the disk address (5) where Db was about to be writ-\nten, but Db has not yet been written there. Thus, if we trust tha t\npointer , we will read garbage data from the disk (the old contents\nof disk address 5).\nFurther , we have a new problem, which we call a \ufb01le-system in-\nconsistency. The on-disk bitmap is telling us that data block 5 has\nnot been allocated, but the inode is saying that it has. The disag ree-\nment between the bitmap and the inode is an inconsistency in the\ndata structures of the \ufb01le system; to use the \ufb01le system, we mus t\nsomehow resolve this problem (more on that below).\n\u2022 Just the updated bitmap (B[v2]) is written to disk. In this case, the\nbitmap indicates that block 5 is allocated, but there is no inode that\npoints to it. Thus the \ufb01le system is inconsistent again; if left unre-\nsolved, this write would result in a space leak , as block 5 would\nnever be used by the \ufb01le system.\nThere are also three more crash scenarios in this attempt to wri te three\nblocks to disk. In these cases, two writes succeed and the last one fails:\n\u2022 The inode (I[v2]) and bitmap (B[v2]) are written to disk, but not\ndata (Db). In this case, the \ufb01le system metadata is completely con-\nsistent: the inode has a pointer to block 5, the bitmap indicates that\n5 is in use, and thus everything looks OK from the perspective of\nthe \ufb01le system\u2019s metadata. But there is one problem: 5 has garbag e\nin it again.\n\u2022 The inode (I[v2]) and the data block (Db) are written, but not the\nbitmap (B[v2]). In this case, we have the inode pointing to the cor-\nrect data on disk, but again have an inconsistency between the i n-\node and the old version of the bitmap (B1). Thus, we once again\nneed to resolve the problem before using the \ufb01le system.\n\u2022 The bitmap (B[v2]) and data block (Db) are written, but not th e\ninode (I[v2]). In this case, we again have an inconsistency between\nthe inode and the data bitmap. However , even though the block\nwas written and the bitmap indicates its usage, we have no ide a\nwhich \ufb01le it belongs to, as no inode points to the \ufb01le.\n1 However , it might be a problem for the user , who just lost some data !\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "somehow resolve this problem (more on that below).",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "somehow",
          "resolve",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "solved, this write would result in a space leak , as block 5 would",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solved",
          "write",
          "would",
          "result",
          "space",
          "leak",
          "block",
          "would"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "need to resolve the problem before using the \ufb01le system.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "need",
          "resolve",
          "problem",
          "using",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand sistent: the inode has a pointer to block 5, the bitmap indicates that",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sistent",
          "inode",
          "pointer",
          "block",
          "bitmap",
          "indicates"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand just the data block (db) is written to disk. in this case, the data is",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "data",
          "block",
          "written",
          "disk",
          "case",
          "data"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand just the updated inode (i[v2]) is written to disk. in this case, the",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "updated",
          "inode",
          "written",
          "disk",
          "case"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand just the updated bitmap (b[v2]) is written to disk. in this case, the",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "updated",
          "bitmap",
          "written",
          "disk",
          "case"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand the inode (i[v2]) and bitmap (b[v2]) are written to disk, but not",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "inode",
          "bitmap",
          "written",
          "disk"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand the inode (i[v2]) and the data block (db) are written, but not the",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "inode",
          "data",
          "block",
          "written"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand the bitmap (b[v2]) and data block (db) are written, but not th e",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "bitmap",
          "data",
          "block",
          "written"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "42",
    "title": "2 Solution #1: The File System Checker",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "42.2 Solution #1: The File System Checker\nEarly \ufb01le systems took a simple approach to crash consistency . Ba si-\ncally , they decided to let inconsistencies happen and then \ufb01x them later\n(when rebooting). A classic example of this lazy approach is found in a\ntool that does this: fsck2 . fsck is a U N I X tool for \ufb01nding such inconsis-\ntencies and repairing them [M86]; similar tools to check and re pair a disk\npartition exist on different systems. Note that such an approach can\u2019t \ufb01x\nall problems; consider , for example, the case above where the \ufb01le system\nlooks consistent but the inode points to garbage data. The only real goal\nis to make sure the \ufb01le system metadata is internally consiste nt.\nThe tool fsck operates in a number of phases, as summarized in\nMcKusick and Kowalski\u2019s paper [MK96]. It is run before the \ufb01le system\nis mounted and made available ( fsck assumes that no other \ufb01le-system\nactivity is on-going while it runs); once \ufb01nished, the on-disk \ufb01l e system\nshould be consistent and thus can be made accessible to users.\nHere is a basic summary of what fsck does:\n\u2022 Superblock: fsck \ufb01rst checks if the superblock looks reasonable,\nmostly doing sanity checks such as making sure the \ufb01le system si ze\nis greater than the number of blocks that have been allocated. Us u-\nally the goal of these sanity checks is to \ufb01nd a suspect (corrupt)\nsuperblock; in this case, the system (or administrator) may dec ide\nto use an alternate copy of the superblock.\n\u2022 Free blocks: Next, fsck scans the inodes, indirect blocks, double\nindirect blocks, etc., to build an understanding of which block s are\ncurrently allocated within the \ufb01le system. It uses this knowle dge\nto produce a correct version of the allocation bitmaps; thus, if the re\nis any inconsistency between bitmaps and inodes, it is resolved by\ntrusting the information within the inodes. The same type of chec k\nis performed for all the inodes, making sure that all inodes that l ook\nlike they are in use are marked as such in the inode bitmaps.\n2 Pronounced either \u201ceff-ess-see-kay\u201d, \u201ceff-ess-check\u201d, or , if you don\u2019t like the tool, \u201ceff-\nsuck\u201d. Y es, serious professional people use this term.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Early \ufb01le systems took a simple approach to crash consistency . Ba si-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "early",
          "systems",
          "took",
          "simple",
          "approach",
          "crash",
          "consistency"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(when rebooting). A classic example of this lazy approach is found in a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rebooting",
          "classic",
          "example",
          "lazy",
          "approach",
          "found"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "partition exist on different systems. Note that such an approach can\u2019t \ufb01x",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "partition",
          "exist",
          "different",
          "systems",
          "note",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "looks consistent but the inode points to garbage data. The only real goal",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "looks",
          "consistent",
          "inode",
          "points",
          "garbage",
          "data",
          "real",
          "goal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ally the goal of these sanity checks is to \ufb01nd a suspect (corrupt)",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ally",
          "goal",
          "sanity",
          "checks",
          "suspect",
          "corrupt"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "indirect blocks, etc., to build an understanding of which block s are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "indirect",
          "blocks",
          "build",
          "understanding",
          "block"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "currently allocated within the \ufb01le system. It uses this knowle dge",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "currently",
          "allocated",
          "within",
          "system",
          "uses",
          "knowle"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "is any inconsistency between bitmaps and inodes, it is resolved by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "inconsistency",
          "bitmaps",
          "inodes",
          "resolved"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: The File System Checker",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "file",
          "system",
          "checker"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Free blocks: Next, fsck scans the inodes, indirect blocks, double",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "free blocks",
          "next",
          "fsck",
          "scans",
          "inodes",
          "indirect",
          "blocks",
          "double"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand superblock: fsck \ufb01rst checks if the superblock looks reasonable,",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "superblock",
          "fsck",
          "checks",
          "superblock",
          "looks",
          "reasonable"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 C R A S H CO N S I S T E N C Y: FSCK A N D JO U ...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\n\u2022 Inode state: Each inode is checked for corruption or other prob-\nlems. For example, fsck makes sure that each allocated inode has\na valid type \ufb01eld (e.g., regular \ufb01le, directory , symbolic link , etc.). If\nthere are problems with the inode \ufb01elds that are not easily \ufb01xed, the\ninode is considered suspect and cleared by fsck; the inode bitmap\nis correspondingly updated.\n\u2022 Inode links: fsck also veri\ufb01es the link count of each allocated in-\node. As you may recall, the link count indicates the number of dif-\nferent directories that contain a reference (i.e., a link) to t his par-\nticular \ufb01le. T o verify the link count, fsck scans through the en-\ntire directory tree, starting at the root directory , and builds i ts own\nlink counts for every \ufb01le and directory in the \ufb01le system. If ther e\nis a mismatch between the newly-calculated count and that foun d\nwithin an inode, corrective action must be taken, usually by \ufb01xi ng\nthe count within the inode. If an allocated inode is discovered but\nno directory refers to it, it is moved to the lost+found directory .\n\u2022 Duplicates: fsck also checks for duplicate pointers, i.e., cases where\ntwo different inodes refer to the same block. If one inode is obvi-\nously bad, it may be cleared. Alternately , the pointed-to block could\nbe copied, thus giving each inode its own copy as desired.\n\u2022 Bad blocks: A check for bad block pointers is also performed while\nscanning through the list of all pointers. A pointer is considered\n\u201cbad\u201d if it obviously points to something outside its valid range,\ne.g., it has an address that refers to a block greater than the p arti-\ntion size. In this case, fsck can\u2019t do anything too intelligent; it just\nremoves (clears) the pointer from the inode or indirect block.\n\u2022 Directory checks: fsck does not understand the contents of user\n\ufb01les; however , directories hold speci\ufb01cally formatted informat ion\ncreated by the \ufb01le system itself. Thus, fsck performs additional\nintegrity checks on the contents of each directory , making sure t hat\n\u201c.\u201d and \u201c..\u201d are the \ufb01rst entries, that each inode referred to i n a\ndirectory entry is allocated, and ensuring that no directory is linked\nto more than once in the entire hierarchy .\nAs you can see, building a working fsck requires intricate knowledge\nof the \ufb01le system; making sure such a piece of code works correctly i n all\ncases can be challenging [G+08]. However , fsck (and similar a pproaches)\nhave a bigger and perhaps more fundamental problem: they are too slow .\nWith a very large disk volume, scanning the entire disk to \ufb01nd a ll the\nallocated blocks and read the entire directory tree may take man y minutes\nor hours. Performance of fsck, as disks grew in capacity and RAIDs\ngrew in popularity , became prohibitive (despite recent advan ces [M+13]).\nAt a higher level, the basic premise of fsck seems just a tad irra-\ntional. Consider our example above, where just three blocks are wr itten\nto the disk; it is incredibly expensive to scan the entire dis k to \ufb01x prob-\nlems that occurred during an update of just three blocks. This si tuation is\nakin to dropping your keys on the \ufb02oor in your bedroom, and then com-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Directory checks: fsck does not understand the contents of user",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "checks",
          "fsck",
          "understand",
          "contents",
          "user"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "created by the \ufb01le system itself. Thus, fsck performs additional",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "system",
          "thus",
          "fsck",
          "performs",
          "additional"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "As you can see, building a working fsck requires intricate knowledge",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "building",
          "working",
          "fsck",
          "requires",
          "intricate",
          "knowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "have a bigger and perhaps more fundamental problem: they are too slow .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bigger",
          "perhaps",
          "fundamental",
          "problem",
          "slow"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand Inode state: Each inode is checked for corruption or other prob-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "inode state",
          "inode",
          "checked",
          "corruption",
          "prob"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Inode links: fsck also veri\ufb01es the link count of each allocated in-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "inode links",
          "fsck",
          "also",
          "link",
          "count",
          "allocated"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Duplicates: fsck also checks for duplicate pointers, i.e., cases where",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "duplicates",
          "fsck",
          "also",
          "checks",
          "duplicate",
          "pointers",
          "cases"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Bad blocks: A check for bad block pointers is also performed while",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "bad blocks",
          "check",
          "block",
          "pointers",
          "also",
          "performed"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "42",
    "title": "3 Solution #2: Journaling (or W rite-Ahead Logging)",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "42.3 Solution #2: Journaling (or W rite-Ahead Logging)\nProbably the most popular solution to the consistent update problem\nis to steal an idea from the world of database management systems . That\nidea, known as write-ahead logging , was invented to address exactly this\ntype of problem. In \ufb01le systems, we usually call write-ahead log ging jour-\nnaling for historical reasons. The \ufb01rst \ufb01le system to do this was Cedar\n[H87], though many modern \ufb01le systems use the idea, including L inux\next3 and ext4, reiserfs, IBM\u2019s JFS, SGI\u2019s XFS, and Windows NTFS.\nThe basic idea is as follows. When updating the disk, before over-\nwriting the structures in place, \ufb01rst write down a little note ( somewhere\nelse on the disk, in a well-known location) describing what you are about\nto do. W riting this note is the \u201cwrite ahead\u201d part, and we write i t to a\nstructure that we organize as a \u201clog\u201d; hence, write-ahead loggi ng.\nBy writing the note to disk, you are guaranteeing that if a crash takes\nplaces during the update (overwrite) of the structures you are u pdating,\nyou can go back and look at the note you made and try again; thus, you\nwill know exactly what to \ufb01x (and how to \ufb01x it) after a crash, inst ead\nof having to scan the entire disk. By design, journaling thus ad ds a bit\nof work during updates to greatly reduce the amount of work require d\nduring recovery .\nW e\u2019ll now describe how Linux ext3 , a popular journaling \ufb01le system,\nincorporates journaling into the \ufb01le system. Most of the on-disk st ruc-\ntures are identical to Linux ext2 , e.g., the disk is divided into block groups,\nand each block group contains an inode bitmap, data bitmap, inodes , and\ndata blocks. The new key structure is the journal itself, which occupies\nsome small amount of space within the partition or on another device.\nThus, an ext2 \ufb01le system (without journaling) looks like this:\nSuper Group 0 Group 1 . . . Group N\nAssuming the journal is placed within the same \ufb01le system imag e\n(though sometimes it is placed on a separate device, or as a \ufb01le wit hin\nthe \ufb01le system), an ext3 \ufb01le system with a journal looks like this :\nSuper Journal Group 0 Group 1 . . . Group N\nThe real difference is just the presence of the journal, and of cou rse,\nhow it is used.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "idea, known as write-ahead logging , was invented to address exactly this",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "idea",
          "known",
          "write",
          "ahead",
          "logging",
          "invented",
          "address",
          "exactly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "else on the disk, in a well-known location) describing what you are about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "else",
          "disk",
          "well",
          "known",
          "location",
          "describing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "will know exactly what to \ufb01x (and how to \ufb01x it) after a crash, inst ead",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "exactly",
          "crash",
          "inst"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "of having to scan the entire disk. By design, journaling thus ad ds a bit",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "scan",
          "entire",
          "disk",
          "design",
          "journaling",
          "thus"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "W e\u2019ll now describe how Linux ext3 , a popular journaling \ufb01le system,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "describe",
          "linux",
          "popular",
          "journaling",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 2: Journaling (or W rite-Ahead Logging)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "journaling",
          "rite",
          "ahead",
          "logging"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand looks like this: Super Group 0 Group 1 . . . Group N",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "looks like this",
          "super",
          "group",
          "group",
          "group"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Journal write: W rite the transaction, including a transaction-begin",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "1. Journal write: W rite the transaction, including a transaction-begin\nblock, all pending data and metadata updates, and a transacti on-\nend block, to the log; wait for these writes to complete.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal write: W rite the transaction, including a transaction-begin",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal write",
          "rite",
          "transaction",
          "including",
          "transaction",
          "begin"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Checkpoint: W rite the pending metadata and data updates to their",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "2. Checkpoint: W rite the pending metadata and data updates to their\n\ufb01nal locations in the \ufb01le system.\nIn our example, we would write TxB, I[v2], B[v2], Db, and TxE to t he\njournal \ufb01rst. When these writes complete, we would complete the u pdate\nby checkpointing I[v2], B[v2], and Db, to their \ufb01nal locations on disk.\nThings get a little trickier when a crash occurs during the wri tes to\nthe journal. Here, we are trying to write the set of blocks in the t ransac-\ntion (e.g., TxB, I[v2], B[v2], Db, TxE) to disk. One simple way to do this\nwould be to issue each one at a time, waiting for each to complete, a nd\nthen issuing the next. However , this is slow . Ideally , we\u2019d like to issue\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Checkpoint: W rite the pending metadata and data updates to their",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "checkpoint",
          "rite",
          "pending",
          "metadata",
          "data",
          "updates"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G 9\nAS I D E : F O R C I N G WR I T E S TO DI S K\nT o enforce ordering between two disk writes, modern \ufb01le systems have\nto take a few extra precautions. In olden times, forcing ordering between\ntwo writes, A and B, was easy: just issue the write of A to the disk, wait\nfor the disk to interrupt the OS when the write is complete, and t hen issue\nthe write of B.\nThings got slightly more complex due to the increased use of write caches\nwithin disks. With write buffering enabled (sometimes calle d immediate\nreporting), a disk will inform the OS the write is complete when it simply\nhas been placed in the disk\u2019s memory cache, and has not yet reache d\ndisk. If the OS then issues a subsequent write, it is not guaran teed to\nreach the disk after previous writes; thus ordering between wr ites is not\npreserved. One solution is to disable write buffering. However , more\nmodern systems take extra precautions and issue explicit write barriers ;\nsuch a barrier , when it completes, guarantees that all writes issued before\nthe barrier will reach disk before any writes issued after the barrier .\nAll of this machinery requires a great deal of trust in the correc t oper-\nation of the disk. Unfortunately , recent research shows that some disk\nmanufacturers, in an effort to deliver \u201chigher performing\u201d di sks, explic-\nitly ignore write-barrier requests, thus making the disks se emingly run\nfaster but at the risk of incorrect operation [C+13, R+11]. As Kah an said,\nthe fast almost always beats out the slow , even if the fast is wrong .\nall \ufb01ve block writes at once, as this would turn \ufb01ve writes into a s ingle\nsequential write and thus be faster . However , this is unsafe, for the fol-\nlowing reason: given such a big write, the disk internally may p erform\nscheduling and complete small pieces of the big write in any orde r . Thus,\nthe disk internally may (1) write TxB, I[v2], B[v2], and TxE a nd only later\n(2) write Db. Unfortunately , if the disk loses power between (1) and (2),\nthis is what ends up on disk:\nJournal\nTxB\nid=1\nI[v2] B[v2] ?? TxE\nid=1\nWhy is this a problem? W ell, the transaction looks like a valid tra ns-\naction (it has a begin and an end with matching sequence number s). Fur-\nther , the \ufb01le system can\u2019t look at that fourth block and know it is wron g;\nafter all, it is arbitrary user data. Thus, if the system now re boots and\nruns recovery , it will replay this transaction, and ignorantly copy the con-\ntents of the garbage block \u2019??\u2019 to the location where Db is supposed t o\nlive. This is bad for arbitrary user data in a \ufb01le; it is much wors e if it hap-\npens to a critical piece of \ufb01le system, such as the superblock, w hich could\nrender the \ufb01le system unmountable.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ther , the \ufb01le system can\u2019t look at that fourth block and know it is wron g;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ther",
          "system",
          "look",
          "fourth",
          "block",
          "know",
          "wron"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "pens to a critical piece of \ufb01le system, such as the superblock, w hich could",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pens",
          "critical",
          "piece",
          "system",
          "superblock",
          "hich",
          "could"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: F O R C I N G WR I T E S TO DI S K",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand was easy: just issue the write of A to the disk, wait",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "was easy",
          "issue",
          "write",
          "disk",
          "wait"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand lowing reason: given such a big write, the disk internally may p erform",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "lowing reason",
          "given",
          "write",
          "disk",
          "internally",
          "erform"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand this a problem",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 C R A S H CO N S I S T E N C Y: FSCK A N D JO U...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\nAS I D E : O P T I M I Z I N G LO G WR I T E S\nY ou may have noticed a particular inef\ufb01ciency of writing to the l og.\nNamely , the \ufb01le system \ufb01rst has to write out the transaction-be gin block\nand contents of the transaction; only after these writes complete can the\n\ufb01le system send the transaction-end block to disk. The performa nce im-\npact is clear , if you think about how a disk works: usually an extra rota-\ntion is incurred (think about why).\nOne of our former graduate students, Vijayan Prabhakaran, had a simple\nidea to \ufb01x this problem [P+05]. When writing a transaction to th e journal,\ninclude a checksum of the contents of the journal in the begin and e nd\nblocks. Doing so enables the \ufb01le system to write the entire tran saction at\nonce, without incurring a wait; if, during recovery , the \ufb01le sys tem sees\na mismatch in the computed checksum versus the stored checksum in\nthe transaction, it can conclude that a crash occurred during th e write\nof the transaction and thus discard the \ufb01le-system update. Thu s, with a\nsmall tweak in the write protocol and recovery system, a \ufb01le syste m can\nachieve faster common-case performance; on top of that, the system is\nslightly more reliable, as any reads from the journal are now prote cted by\na checksum.\nThis simple \ufb01x was attractive enough to gain the notice of Linux \ufb01 le sys-\ntem developers, who then incorporated it into the next generati on Linux\n\ufb01le system, called (you guessed it!) Linux ext4 . It now ships on mil-\nlions of machines worldwide, including the Android handheld pla tform.\nThus, every time you write to disk on many Linux-based systems, a little\ncode developed at Wisconsin makes your system a little faster and more\nreliable.\nT o avoid this problem, the \ufb01le system issues the transactional w rite in\ntwo steps. First, it writes all blocks except the TxE block to th e journal,\nissuing these writes all at once. When these writes complete, t he journal\nwill look something like this (assuming our append workload again) :\nJournal\nTxB\nid=1\nI[v2] B[v2] Db\nWhen those writes complete, the \ufb01le system issues the write of th e TxE\nblock, thus leaving the journal in this \ufb01nal, safe state:\nJournal\nTxB\nid=1\nI[v2] B[v2] Db TxE\nid=1\nAn important aspect of this process is the atomicity guarantee pr o-\nvided by the disk. It turns out that the disk guarantees that an y 512-byte\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "tem developers, who then incorporated it into the next generati on Linux",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "developers",
          "incorporated",
          "next",
          "generati",
          "linux"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "code developed at Wisconsin makes your system a little faster and more",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "code",
          "developed",
          "wisconsin",
          "makes",
          "system",
          "little",
          "faster"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "An important aspect of this process is the atomicity guarantee pr o-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "aspect",
          "process",
          "atomicity",
          "guarantee"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand AS I D E: O P T I M I Z I N G LO G WR I T E S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "as i d e"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Journal write: W rite the contents of the transaction (including TxB,",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "1. Journal write: W rite the contents of the transaction (including TxB,\nmetadata, and data) to the log; wait for these writes to complete .",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal write: W rite the contents of the transaction (including TxB,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal write",
          "rite",
          "contents",
          "transaction",
          "including"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Journal commit: W rite the transaction commit block (containing",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "2. Journal commit: W rite the transaction commit block (containing\nTxE) to the log; wait for write to complete; transaction is said to be\ncommitted.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal commit: W rite the transaction commit block (containing",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal commit",
          "rite",
          "transaction",
          "commit",
          "block",
          "containing"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Checkpoint: W rite the contents of the update (metadata and data)",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "3. Checkpoint: W rite the contents of the update (metadata and data)\nto their \ufb01nal on-disk locations.\nRecovery\nLet\u2019s now understand how a \ufb01le system can use the contents of the jour -\nnal to recover from a crash. A crash may happen at any time during this\nsequence of updates. If the crash happens before the transacti on is writ-\nten safely to the log (i.e., before Step 2 above completes), then our job\nis easy: the pending update is simply skipped. If the crash ha ppens af-\nter the transaction has committed to the log, but before the check point is\ncomplete, the \ufb01le system can recover the update as follows. When the\nsystem boots, the \ufb01le system recovery process will scan the log and look\nfor transactions that have committed to the disk; these transac tions are\nthus replayed (in order), with the \ufb01le system again attempting to write\nout the blocks in the transaction to their \ufb01nal on-disk locations. T his form\nof logging is one of the simplest forms there is, and is called redo logging .\nBy recovering the committed transactions in the journal, the \ufb01le system\nensures that the on-disk structures are consistent, and thus c an proceed\nby mounting the \ufb01le system and readying itself for new requests .\nNote that it is \ufb01ne for a crash to happen at any point during check-\npointing, even after some of the updates to the \ufb01nal locations of the blocks\nhave completed. In the worst case, some of these updates are simpl y per-\nformed again during recovery . Because recovery is a rare operati on (only\ntaking place after an unexpected system crash), a few redund ant writes\nare nothing to worry about 3 .\nBatching Log Updates\nY ou might have noticed that the basic protocol could add a lot of extra\ndisk traf\ufb01c. For example, imagine we create two \ufb01les in a row , ca lled\nfile1 and file2, in the same directory . T o create one \ufb01le, one has\nto update a number of on-disk structures, minimally including : the in-\node bitmap (to allocate a new inode), the newly-created inode of th e \ufb01le,\n3 Unless you worry about everything, in which case we can\u2019t help you. Stop worrying so\nmuch, it is unhealthy! But now you\u2019re probably worried about over-wo rrying.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s now understand how a \ufb01le system can use the contents of the jour -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "system",
          "contents",
          "jour"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "disk traf\ufb01c. For example, imagine we create two \ufb01les in a row , ca lled",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "example",
          "imagine",
          "create",
          "lled"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "file1 and file2, in the same directory . T o create one \ufb01le, one has",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ode bitmap (to allocate a new inode), the newly-created inode of th e \ufb01le,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bitmap",
          "allocate",
          "inode",
          "newly",
          "created",
          "inode"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Checkpoint: W rite the contents of the update (metadata and data)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "checkpoint",
          "rite",
          "contents",
          "update",
          "metadata",
          "data"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 C R A S H CO N S I S T E N C Y: FSCK A N D JO U...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\nthe data block of the parent directory containing the new director y en-\ntry , and the parent directory inode (which now has a new modi\ufb01cati on\ntime). With journaling, we logically commit all of this informati on to\nthe journal for each of our two \ufb01le creations; because the \ufb01les are i n the\nsame directory , and assuming they even have inodes within the s ame in-\node block, this means that if we\u2019re not careful, we\u2019ll end up writin g these\nsame blocks over and over .\nT o remedy this problem, some \ufb01le systems do not commit each update\nto disk one at a time (e.g., Linux ext3); rather , one can buffer a ll updates\ninto a global transaction. In our example above, when the two \ufb01les are\ncreated, the \ufb01le system just marks the in-memory inode bitmap, inodes\nof the \ufb01les, directory data, and directory inode as dirty , and add s them to\nthe list of blocks that form the current transaction. When it is \ufb01n ally time\nto write these blocks to disk (say , after a timeout of 5 seconds), t his single\nglobal transaction is committed containing all of the updates des cribed\nabove. Thus, by buffering updates, a \ufb01le system can avoid exces sive write\ntraf\ufb01c to disk in many cases.\nMaking The Log Finite\nW e thus have arrived at a basic protocol for updating \ufb01le-system on -disk\nstructures. The \ufb01le system buffers updates in memory for some ti me;\nwhen it is \ufb01nally time to write to disk, the \ufb01le system \ufb01rst car efully writes\nout the details of the transaction to the journal (a.k.a. write-a head log);\nafter the transaction is complete, the \ufb01le system checkpoints t hose blocks\nto their \ufb01nal locations on disk.\nHowever , the log is of a \ufb01nite size. If we keep adding transactions to\nit (as in this \ufb01gure), it will soon \ufb01ll. What do you think happens t hen?\nJournal\nTx1 Tx2 Tx3 Tx4 Tx5 ...\nT wo problems arise when the log becomes full. The \ufb01rst is simpler ,\nbut less critical: the larger the log, the longer recovery will t ake, as the\nrecovery process must replay all the transactions within the log (in order)\nto recover . The second is more of an issue: when the log is full (or nea rly\nfull), no further transactions can be committed to the disk, th us making\nthe \ufb01le system \u201cless than useful\u201d (i.e., useless).\nT o address these problems, journaling \ufb01le systems treat the log as a\ncircular data structure, re-using it over and over; this is why the journal\nis sometimes referred to as a circular log . T o do so, the \ufb01le system must\ntake action some time after a checkpoint. Speci\ufb01cally , once a tran saction\nhas been checkpointed, the \ufb01le system should free the space it w as occu-\npying within the journal, allowing the log space to be reused. Th ere are\nmany ways to achieve this end; for example, you could simply mark the\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "created, the \ufb01le system just marks the in-memory inode bitmap, inodes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "created",
          "system",
          "marks",
          "memory",
          "inode",
          "bitmap",
          "inodes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "but less critical: the larger the log, the longer recovery will t ake, as the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "less",
          "critical",
          "larger",
          "longer",
          "recovery"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand this: that if we\u2019re not careful, we\u2019ll end up writin g these",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "this",
          "careful",
          "writin"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Journal write: W rite the contents of the transaction (containing TxB",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "1. Journal write: W rite the contents of the transaction (containing TxB\nand the contents of the update) to the log; wait for these writes to\ncomplete.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal write: W rite the contents of the transaction (containing TxB",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal write",
          "rite",
          "contents",
          "transaction",
          "containing"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Journal commit: W rite the transaction commit block (containing",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "2. Journal commit: W rite the transaction commit block (containing\nTxE) to the log; wait for the write to complete; the transaction is\nnow committed.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal commit: W rite the transaction commit block (containing",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal commit",
          "rite",
          "transaction",
          "commit",
          "block",
          "containing"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Checkpoint: W rite the contents of the update to their \ufb01nal locations",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "3. Checkpoint: W rite the contents of the update to their \ufb01nal locations\nwithin the \ufb01le system.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Checkpoint: W rite the contents of the update to their \ufb01nal locations",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "checkpoint",
          "rite",
          "contents",
          "update",
          "locations"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Free: Some time later , mark the transaction free in the journal by",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "4. Free: Some time later , mark the transaction free in the journal by\nupdating the journal superblock.\nThus we have our \ufb01nal data journaling protocol. But there is still a\nproblem: we are writing each data block to the disk twice, which is a\nheavy cost to pay , especially for something as rare as a system cr ash. Can\nyou \ufb01gure out a way to retain consistency without writing data twi ce?\nMetadata Journaling\nAlthough recovery is now fast (scanning the journal and replayin g a few\ntransactions as opposed to scanning the entire disk), normal oper ation\nof the \ufb01le system is slower than we might desire. In particular , for each\nwrite to disk, we are now also writing to the journal \ufb01rst, thus d oubling\nwrite traf\ufb01c; this doubling is especially painful during seq uential write\nworkloads, which now will proceed at half the peak write bandwidt h of\nthe drive. Further , between writes to the journal and writes t o the main\n\ufb01le system, there is a costly seek, which adds noticeable overhe ad for\nsome workloads.\nBecause of the high cost of writing every data block to disk twice, peo-\nple have tried a few different things in order to speed up perfor mance.\nFor example, the mode of journaling we described above is often call ed\ndata journaling (as in Linux ext3), as it journals all user data (in addition\nto the metadata of the \ufb01le system). A simpler (and more common) form\nof journaling is sometimes called ordered journaling (or just metadata\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "For example, the mode of journaling we described above is often call ed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "mode",
          "journaling",
          "described",
          "often",
          "call"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Free: Some time later , mark the transaction free in the journal by",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "time",
          "later",
          "mark",
          "transaction",
          "free",
          "journal"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Data write: W rite data to \ufb01nal location; wait for completion",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "1. Data write: W rite data to \ufb01nal location; wait for completion\n(the wait is optional; see below for details).",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Data write: W rite data to \ufb01nal location; wait for completion",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "data write",
          "rite",
          "data",
          "location",
          "wait",
          "completion"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Journal metadata write: W rite the begin block and metadata to the",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "2. Journal metadata write: W rite the begin block and metadata to the\nlog; wait for writes to complete.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal metadata write: W rite the begin block and metadata to the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal metadata write",
          "rite",
          "begin",
          "block",
          "metadata"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Journal commit: W rite the transaction commit block (containing",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "3. Journal commit: W rite the transaction commit block (containing\nTxE) to the log; wait for the write to complete; the transaction (i n-\ncluding data) is now committed.",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Journal commit: W rite the transaction commit block (containing",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "journal commit",
          "rite",
          "transaction",
          "commit",
          "block",
          "containing"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Checkpoint metadata: W rite the contents of the metadata update",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "4. Checkpoint metadata: W rite the contents of the metadata update\nto their \ufb01nal locations within the \ufb01le system.\n5. Free: Later , mark the transaction free in journal superblock.\nBy forcing the data write \ufb01rst, a \ufb01le system can guarantee that a pointer\nwill never point to garbage. Indeed, this rule of \u201cwrite the poin ted-to\nobject before the object that points to it\u201d is at the core of crash cons is-\ntency , and is exploited even further by other crash consistency schemes\n[GP94] (see below for details).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand Checkpoint metadata: W rite the contents of the metadata update",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "checkpoint metadata",
          "rite",
          "contents",
          "metadata",
          "update"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Free: Later , mark the transaction free in journal superblock.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "free",
          "later",
          "mark",
          "transaction",
          "free",
          "journal",
          "superblock"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G 15\nIn most systems, metadata journaling (akin to ordered journalin g of\next3) is more popular than full data journaling. For example, Win dows\nNTFS and SGI\u2019s XFS both use some form of metadata journaling. Linux\next3 gives you the option of choosing either data, ordered, or unordere d\nmodes (in unordered mode, data can be written at any time). All of t hese\nmodes keep metadata consistent; they vary in their semantics f or data.\nFinally , note that forcing the data write to complete (Step 1) bef ore is-\nsuing writes to the journal (Step 2) is not required for correctnes s, as indi-\ncated in the protocol above. Speci\ufb01cally , it would be \ufb01ne to concurre ntly\nissue writes to data, the transaction-begin block, and journal ed metadata;\nthe only real requirement is that Steps 1 and 2 complete before the issuing\nof the journal commit block (Step 3).\nT ricky Case: Block Reuse\nThere are some interesting corner cases that make journaling mor e tricky ,\nand thus are worth discussing. A number of them revolve around bloc k\nreuse; as Stephen T weedie (one of the main forces behind ext3) sai d:\n\u201cWhat\u2019s the hideous part of the entire system? ... It\u2019s deletin g \ufb01les.\nEverything to do with delete is hairy . Everything to do with d elete...\nyou have nightmares around what happens if blocks get deleted a nd\nthen reallocated.\u201d [T00]\nThe particular example T weedie gives is as follows. Suppose you ar e\nusing some form of metadata journaling (and thus data blocks for \ufb01le s\nare not journaled). Let\u2019s say you have a directory called foo. The user\nadds an entry to foo (say by creating a \ufb01le), and thus the contents of\nfoo (because directories are considered metadata) are written to the log;\nassume the location of the foo directory data is block 1000. The log thus\ncontains something like this:\nJournal\nTxB\nid=1\nI[foo]\nptr:1000\nD[foo]\n[final addr:1000]\nTxE\nid=1\nAt this point, the user deletes everything in the directory and the di-\nrectory itself, freeing up block 1000 for reuse. Finally , the us er creates a\nnew \ufb01le (say bar), which ends up reusing the same block (1000) that used\nto belong to foo. The inode of bar is committed to disk, as is its data;\nnote, however , because metadata journaling is in use, only the in ode of\nbar is committed to the journal; the newly-written data in block 100 0 in\nthe \ufb01le bar is not journaled.\nJournal\nTxB\nid=1\nI[foo]\nptr:1000\nD[foo]\n[final addr:1000]\nTxE\nid=1\nTxB\nid=2\nI[bar]\nptr:1000\nTxE\nid=2\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "rectory itself, freeing up block 1000 for reuse. Finally , the us er creates a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rectory",
          "freeing",
          "block",
          "reuse",
          "finally",
          "creates"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand sai d: \u201cWhat\u2019s the hideous part of the entire system? ... It\u2019s deletin g \ufb01les.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sai d",
          "hideous",
          "part",
          "entire",
          "system",
          "deletin"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 C R A S H CO N S I S T E N C Y: FSCK A N D JO U...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\nJournal File System\nTxB Contents TxE Metadata Data\n(metadata) (data)\nissue issue issue\ncomplete\ncomplete\ncomplete\nissue\ncomplete\nissue issue\ncomplete\ncomplete\nFigure 42.1: Data Journaling Timeline\nNow assume a crash occurs and all of this information is still in the\nlog. During replay , the recovery process simply replays everyt hing in the\nlog, including the write of directory data in block 1000; the repl ay thus\noverwrites the user data of current \ufb01le bar with old directory contents!\nClearly this is not a correct recovery action, and certainly it wi ll be a sur-\nprise to the user when reading the \ufb01le bar.\nThere are a number of solutions to this problem. One could, for ex-\nample, never reuse blocks until the delete of said blocks is chec kpointed\nout of the journal. What Linux ext3 does instead is to add a new type\nof record to the journal, known as a revoke record. In the case above,\ndeleting the directory would cause a revoke record to be written t o the\njournal. When replaying the journal, the system \ufb01rst scans for s uch re-\nvoke records; any such revoked data is never replayed, thus avoid ing the\nproblem mentioned above.\nW rapping Up Journaling: A Timeline\nBefore ending our discussion of journaling, we summarize the protoc ols\nwe have discussed with timelines depicting each of them. Figu re 42.1\nshows the protocol when journaling data and metadata, whereas Fig ure\n42.2 shows the protocol when journaling only metadata.\nIn each \ufb01gure, time increases in the downward direction, and ea ch row\nin the \ufb01gure shows the logical time that a write can be issued or mi ght\ncomplete. For example, in the data journaling protocol (Figure 42. 1), the\nwrites of the transaction begin block (TxB) and the contents of the trans-\naction can logically be issued at the same time, and thus can be c ompleted\nin any order; however , the write to the transaction end block (TxE ) must\nnot be issued until said previous writes complete. Similarly , th e check-\npointing writes to data and metadata blocks cannot begin until t he trans-\naction end block has committed. Horizontal dashed lines show where\nwrite-ordering requirements must be obeyed.\nA similar timeline is shown for the metadata journaling protocol. N ote\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "of record to the journal, known as a revoke record. In the case above,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "record",
          "journal",
          "known",
          "revoke",
          "record",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand 1: Data Journaling Timeline",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "data",
          "journaling",
          "timeline"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand shows the protocol when journaling only metadata.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "protocol",
          "journaling",
          "metadata"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "42",
    "title": "4 Solution #3: Other Approaches",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "42.4 Solution #3: Other Approaches\nW e\u2019ve thus far described two options in keeping \ufb01le system metad ata\nconsistent: a lazy approach based on fsck, and a more active approach\nknown as journaling. However , these are not the only two approaches .\nOne such approach, known as Soft Updates [GP94], was introduced by\nGanger and Patt. This approach carefully orders all writes to t he \ufb01le sys-\ntem to ensure that the on-disk structures are never left in an i nconsis-\ntent state. For example, by writing a pointed-to data block to di sk before\nthe inode that points to it, we can ensure that the inode never poin ts to\ngarbage; similar rules can be derived for all the structures of the \ufb01le sys-\ntem. Implementing Soft Updates can be a challenge, however; whe reas\nthe journaling layer described above can be implemented with r elatively\nlittle knowledge of the exact \ufb01le system structures, Soft Update s requires\nintricate knowledge of each \ufb01le system data structure and thus adds a fair\namount of complexity to the system.\nAnother approach is known as copy-on-write (yes, COW), and is used\nin a number of popular \ufb01le systems, including Sun\u2019s ZFS [B07]. Thi s tech-\nnique never overwrites \ufb01les or directories in place; rather , it places new\nupdates to previously unused locations on disk. After a number of u p-\ndates are completed, COW \ufb01le systems \ufb02ip the root structure of the \ufb01le\nsystem to include pointers to the newly updated structures. D oing so\nmakes keeping the \ufb01le system consistent straightforward. W e\u2019l l be learn-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Solution #3: Other Approaches",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "W e\u2019ve thus far described two options in keeping \ufb01le system metad ata",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "described",
          "options",
          "keeping",
          "system",
          "metad"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "consistent: a lazy approach based on fsck, and a more active approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "consistent",
          "lazy",
          "approach",
          "based",
          "fsck",
          "active",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "known as journaling. However , these are not the only two approaches .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "journaling",
          "however",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "One such approach, known as Soft Updates [GP94], was introduced by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "known",
          "soft",
          "updates",
          "introduced"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Ganger and Patt. This approach carefully orders all writes to t he \ufb01le sys-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ganger",
          "patt",
          "approach",
          "carefully",
          "orders",
          "writes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "tem. Implementing Soft Updates can be a challenge, however; whe reas",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "soft",
          "updates",
          "challenge",
          "however",
          "reas"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "the journaling layer described above can be implemented with r elatively",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "journaling",
          "layer",
          "described",
          "implemented",
          "elatively"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "little knowledge of the exact \ufb01le system structures, Soft Update s requires",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "little",
          "knowledge",
          "exact",
          "system",
          "structures",
          "soft",
          "update",
          "requires"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "intricate knowledge of each \ufb01le system data structure and thus adds a fair",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "intricate",
          "knowledge",
          "system",
          "data",
          "structure",
          "thus",
          "adds",
          "fair"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand solution #3: other approaches",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "approaches"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "42",
    "title": "5 Summary",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "42.5 Summary\nW e have introduced the problem of crash consistency , and discuss ed\nvarious approaches to attacking this problem. The older approach of\nbuilding a \ufb01le system checker works but is likely too slow to recov er on\nmodern systems. Thus, many \ufb01le systems now use journaling. Journ aling\nreduces recovery time from O(size-of-the-disk-volume) to O(si ze-of-the-\nlog), thus speeding recovery substantially after a crash and r estart. For\nthis reason, many modern \ufb01le systems use journaling. W e have als o seen\nthat journaling can come in many different forms; the most commonly\nused is ordered metadata journaling, which reduces the amount of traf\ufb01c\nto the journal while still preserving reasonable consistency g uarantees for\nboth \ufb01le system metadata and user data. In the end, strong guara ntees\non user data are probably one of the most important things to provide;\noddly enough, as recent research has shown, this area remains a w ork in\nprogress [P+14].\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "various approaches to attacking this problem. The older approach of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "various",
          "approaches",
          "attacking",
          "problem",
          "older",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "on user data are probably one of the most important things to provide;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "user",
          "data",
          "probably",
          "important",
          "things",
          "provide"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "CR A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G 19\nReferences\n[B07] \u201cZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. A vailable online:\nhttp://www.ostep.org/Citations/zfs_last.pdf. ZFS uses copy-on-write and journal-\ning, actually, as in some cases, logging writes to disk will perform better .\n[C+12] \u201cConsistency Without Ordering\u201d by Vijay Chidambaram, T ushar S harma, Andrea C.\nArpaci-Dusseau, Remzi H. Arpaci-Dusseau. F AST \u201912, San Jose, Cal ifornia. A recent paper of\nours about a new form of crash consistency based on back pointers. Read it for the exciting details!\n[C+13] \u201cOptimistic Crash Consistency\u201d by Vijay Chidambaram, Thanu S. Pillai, Andrea C.\nArpaci-Dusseau, Remzi H. Arpaci-Dusseau . SOSP \u201913, Nemacolin W oo dlands Resort, P A,\nNovember 2013. Our work on a more optimistic and higher performance journaling protocol. For\nworkloads that call fsync() a lot, performance can be greatly improved.\n[GP94] \u201cMetadata Update Performance in File Systems\u201d by Gregory R. G anger and Y ale N.\nPatt. OSDI \u201994. A clever paper about using careful ordering of writes as the main way to achie ve\nconsistency. Implemented later in BSD-based systems.\n[G+08] \u201cSQCK: A Declarative File System Checker \u201d by Haryadi S. Guna wi, Abhishek Ra-\njimwale, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau. OSDI \u201908, San Diego, Califor-\nnia. Our own paper on a new and better way to build a \ufb01le system checker using SQL queries. We also\nshow some problems with the existing checker , \ufb01nding numerous bugs and odd behaviors, a direct result\nof the complexity of fsck.\n[H87] \u201cReimplementing the Cedar File System Using Logging and Group Commit\u201d by Robert\nHagmann. SOSP \u201987, Austin, T exas, November 1987. The \ufb01rst work (that we know of) that applied\nwrite-ahead logging (a.k.a. journaling) to a \ufb01le system.\n[M+13] \u201cffsck: The Fast File System Checker \u201d by Ao Ma, Chris Dragga, Andre a C. Arpaci-\nDusseau, Remzi H. Arpaci-Dusseau. F AST \u201913, San Jose, California , February 2013. A recent\npaper of ours detailing how to make fsck an order of magnitude faster . Some of the ide as have already\nbeen incorporated into the BSD \ufb01le system checker [MK96] and are deployed tod ay.\n[MK96] \u201cFsck \u2013 The U N I X File System Check Program\u201d by Marshall Kirk McKusick and T . J.\nKowalski. Revised in 1996. Describes the \ufb01rst comprehensive \ufb01le-system checking tool, the epony-\nmous fsck. Written by some of the same people who brought you FFS.\n[MJLF84] \u201cA Fast File System for UNIX\u201d by Marshall K. McKusick, William N. Joy , Sam J.\nLef\ufb02er , Robert S. Fabry . ACM T ransactions on Computing Systems, V olume 2:3, August 1984.\nY ou already know enough about FFS, right? But come on, it is OK to re-referenc e important papers.\n[P+14] \u201cAll File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent\nApplications\u201d by Thanumalayan Sankaranarayana Pillai, Vijay Chidamb aram, Ramnatthan\nAlagappan, Samer Al-Kiswany , Andrea C. Arpaci-Dusseau, Remzi H. A rpaci-Dusseau. OSDI\n\u201914, Broom\ufb01eld, Colorado, October 2014. A paper in which we study what \ufb01le systems guarantee\nafter crashes, and show that applications expect something different, leadi ng to all sorts of interesting\nproblems.\n[P+05] \u201cIRON File Systems\u201d by Vijayan Prabhakaran, Lakshmi N. Baira vasundaram, Nitin\nAgrawal, Haryadi S. Gunawi, Andrea C. Arpaci-Dusseau, Remzi H. A rpaci-Dusseau. SOSP\n\u201905, Brighton, England, October 2005. A paper mostly focused on studying how \ufb01le systems react\nto disk failures. T owards the end, we introduce a transaction checksum to spe ed up logging, which was\neventually adopted into Linux ext4.\n[P AA05] \u201cAnalysis and Evolution of Journaling File Systems\u201d by Vij ayan Prabhakaran, Andrea\nC. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau. USENIX \u201905, Anaheim, California, April 2005.\nAn early paper we wrote analyzing how journaling \ufb01le systems work.\n[R+11] \u201cCoerced Cache Eviction and Discreet-Mode Journaling\u201d by Abhishek R ajimwale, Vijay\nChidambaram, Deepak Ramamurthi, Andrea C. Arpaci-Dusseau, Remz i H. Arpaci-Dusseau.\nDSN \u201911, Hong Kong, China, June 2011. Our own paper on the problem of disks that buffer writes in\na memory cache instead of forcing them to disk, even when explicitly told not to do that! Our solution\nto overcome this problem: if you want A to be written to disk before B, \ufb01rst write A, then send a lot of\n\u201cdummy\u201d writes to disk, hopefully causing A to be forced to disk to make room for them in the cache. A\nneat if impractical solution.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "consistency. Implemented later in BSD-based systems.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "consistency",
          "implemented",
          "later",
          "based",
          "systems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[H87] \u201cReimplementing the Cedar File System Using Logging and Group Commit\u201d by Robert",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "reimplementing",
          "cedar",
          "file",
          "system",
          "using",
          "logging",
          "group",
          "commit"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Hagmann. SOSP \u201987, Austin, T exas, November 1987. The \ufb01rst work (that we know of) that applied",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "hagmann",
          "sosp",
          "austin",
          "exas",
          "november",
          "work",
          "know",
          "applied"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Kowalski. Revised in 1996. Describes the \ufb01rst comprehensive \ufb01le-system checking tool, the epony-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "kowalski",
          "revised",
          "describes",
          "comprehensive",
          "system",
          "checking",
          "tool",
          "epony"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Y ou already know enough about FFS, right? But come on, it is OK to re-referenc e important papers.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "already",
          "know",
          "enough",
          "right",
          "come",
          "referenc",
          "important",
          "papers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "[P+14] \u201cAll File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "systems",
          "created",
          "equal",
          "complexity",
          "crafting",
          "crash",
          "consistent"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand ZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. A vailable online:",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "zfs",
          "last",
          "file",
          "systems",
          "jeff",
          "bonwick",
          "bill",
          "moor",
          "vailable"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand http: //www.ostep.org/Citations/zfs_last.pdf. ZFS uses copy-on-write and journal-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "ostep",
          "citations",
          "uses",
          "copy",
          "write",
          "journal"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand SQCK: A Declarative File System Checker \u201d by Haryadi S. Guna wi, Abhishek Ra-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "sqck",
          "declarative",
          "file",
          "system",
          "checker",
          "haryadi",
          "guna",
          "abhishek"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand ffsck: The Fast File System Checker \u201d by Ao Ma, Chris Dragga, Andre a C. Arpaci-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ffsck",
          "fast",
          "file",
          "system",
          "checker",
          "chris",
          "dragga",
          "andre",
          "arpaci"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "20 C R A S H CO N S I S T E N C Y: FSCK A N D JO U...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "20 C R A S H CO N S I S T E N C Y: FSCK A N D JO U R N A L I N G\n[T98] \u201cJournaling the Linux ext2fs File System\u201d by Stephen C. T weedie. The Fourth Annual\nLinux Expo, May 1998. T weedie did much of the heavy lifting in adding journaling to the Linux e xt2\n\ufb01le system; the result, not surprisingly, is called ext3. Some nice d esign decisions include the strong\nfocus on backwards compatibility, e.g., you can just add a journaling \ufb01le to an e xisting ext2 \ufb01le system\nand then mount it as an ext3 \ufb01le system.\n[T00] \u201cEXT3, Journaling Filesystem\u201d by Stephen T weedie. T alk at the Ot tawa Linux Sympo-\nsium, July 2000. olstrans.sourceforge.net/release/OLS2000-ext 3/OLS2000-ext3.html A tran-\nscript of a talk given by T weedie on ext3.\n[T01] \u201cThe Linux ext2 File System\u201d by Theodore T s\u2019o, June, 2001.. A vail able online here:\nhttp://e2fsprogs.sourceforge.net/ext2.html. A simple Linux \ufb01le system based on\nthe ideas found in FFS. For a while it was quite heavily used; now it is re ally just in the kernel as an\nexample of a simple \ufb01le system.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "3",
    "title": "Change the seed to -S 3 or -S 19; which inconsistency do you",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "3. Change the seed to -S 3 or -S 19; which inconsistency do you\nsee? Use -c to check your answer . What is different in these two\ncases?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand different in these two\ncases",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "cases"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Change the seed to -S 5; which inconsistency do you see? How",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "4. Change the seed to -S 5; which inconsistency do you see? How\nhard would it be to \ufb01x this problem in an automatic way? Use -c to\ncheck your answer . Then, introduce a similar inconsistency wit h -S\n38; is this harder/possible to detect? Finally , use -S 642; is this\ninconsistency detectable? If so, how would you \ufb01x the \ufb01le system?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Change the seed to -S 6 or -S 13; which inconsistency do you",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "5. Change the seed to -S 6 or -S 13; which inconsistency do you\nsee? Use -c to check your answer . What is the difference across\nthese two cases? What should the repair tool do when encountering\nsuch a situation?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the difference across\nthese two cases",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "difference",
          "across",
          "cases"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Change the seed to -S 9; which inconsistency do you see? Use -c",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "6. Change the seed to -S 9; which inconsistency do you see? Use -c\nto check your answer . Which piece of information should a check-\nand-repair tool trust in this case?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "7",
    "title": "Change the seed to -S 15; which inconsistency do you see? Use",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "7. Change the seed to -S 15; which inconsistency do you see? Use\n-c to check your answer . What can a repair tool do in this case? If\nno repair is possible, how much data is lost?",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand c to check your answer . what can a repair tool do in this case? if",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "check",
          "answer",
          "repair",
          "tool",
          "case"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "8",
    "title": "Change the seed to -S 10; which inconsistency do you see? Use",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "8. Change the seed to -S 10; which inconsistency do you see? Use\n-c to check your answer . Is there redundancy in the \ufb01le system\nstructure here that can help a repair?",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand c to check your answer . is there redundancy in the \ufb01le system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "check",
          "answer",
          "redundancy",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_7",
    "number": "9",
    "title": "Change the seed to -S 16 and -S 20; which inconsistency do you",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "9. Change the seed to -S 16 and -S 20; which inconsistency do you\nsee? Use -c to check your answer . How should the repair tool \ufb01x\nthe problem?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "43\nLog-structured File Systems\nIn the early 90\u2019s, a group at Berkeley led by Professor John Ousterh out\nand graduate student Mendel Rosenblum developed a new \ufb01le syst em\nknown as the log-structured \ufb01le system [RO91]. Their motivation to do\nso was based on the following observations:\n\u2022 System memories are growing : As memory gets bigger , more data\ncan be cached in memory . As more data is cached, disk traf\ufb01c in-\ncreasingly consists of writes, as reads are serviced by the cac he.\nThus, \ufb01le system performance is largely determined by its wri te\nperformance.\n\u2022 There is a large gap between random I/O performance and se-\nquential I/O performance : Hard-drive transfer bandwidth has in-\ncreased a great deal over the years [P98]; as more bits are packe d\ninto the surface of a drive, the bandwidth when accessing said bits\nincreases. Seek and rotational delay costs, however , have decrea sed\nslowly; it is challenging to make cheap and small motors spin the\nplatters faster or move the disk arm more quickly . Thus, if you are\nable to use disks in a sequential manner , you gain a sizeable pe rfor-\nmance advantage over approaches that cause seeks and rotations.\n\u2022 Existing \ufb01le systems perform poorly on many common workload s:\nFor example, FFS [MJLF84] would perform a large number of writes\nto create a new \ufb01le of size one block: one for a new inode, one to\nupdate the inode bitmap, one to the directory data block that the\n\ufb01le is in, one to the directory inode to update it, one to the new dat a\nblock that is a part of the new \ufb01le, and one to the data bitmap to\nmark the data block as allocated. Thus, although FFS places all of\nthese blocks within the same block group, FFS incurs many short\nseeks and subsequent rotational delays and thus performance fa lls\nfar short of peak sequential bandwidth.\n\u2022 File systems are not RAID-aware : For example, both RAID-4 and\nRAID-5 have the small-write problem where a logical write to a\nsingle block causes 4 physical I/Os to take place. Existing \ufb01l e sys-\ntems do not try to avoid this worst-case RAID writing behavior .\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "and graduate student Mendel Rosenblum developed a new \ufb01le syst em",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "graduate",
          "student",
          "mendel",
          "rosenblum",
          "developed",
          "syst"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "known as the log-structured \ufb01le system [RO91]. Their motivation to do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "structured",
          "system",
          "motivation"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "able to use disks in a sequential manner , you gain a sizeable pe rfor-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "disks",
          "sequential",
          "manner",
          "gain",
          "sizeable",
          "rfor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "mance advantage over approaches that cause seeks and rotations.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mance",
          "advantage",
          "approaches",
          "cause",
          "seeks",
          "rotations"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "to create a new \ufb01le of size one block: one for a new inode, one to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "size",
          "block",
          "inode"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand O performance: Hard-drive transfer bandwidth has in-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "o performance",
          "hard",
          "drive",
          "transfer",
          "bandwidth"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand aware: For example, both RAID-4 and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "aware",
          "example",
          "raid"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand system memories are growing : as memory gets bigger , more data",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "memories",
          "growing",
          "memory",
          "gets",
          "bigger",
          "data"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand there is a large gap between random i/o performance and se-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "large",
          "random",
          "performance"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand existing \ufb01le systems perform poorly on many common workload s:",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "existing",
          "systems",
          "perform",
          "poorly",
          "many",
          "common",
          "workload"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand file systems are not raid-aware : for example, both raid-4 and",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "systems",
          "raid",
          "aware",
          "example",
          "raid"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "1 W riting T o Disk Sequentially",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "43.1 W riting T o Disk Sequentially\nW e thus have our \ufb01rst challenge: how do we transform all updates t o\n\ufb01le-system state into a series of sequential writes to disk? T o understand\nthis better , let\u2019s use a simple example. Imagine we are writin g a data block\nD to a \ufb01le. W riting the data block to disk might result in the follow ing\non-disk layout, with D written at disk address A0:\nD\nA0\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "\ufb01le-system state into a series of sequential writes to disk? T o understand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "state",
          "series",
          "sequential",
          "writes",
          "disk",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand w riting t o disk sequentially",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "riting",
          "disk",
          "sequentially"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "2 W riting Sequentially And Effectively",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "43.2 W riting Sequentially And Effectively\nUnfortunately , writing to disk sequentially is not (alone) enou gh to\nguarantee ef\ufb01cient writes. For example, imagine if we wrote a s ingle\nblock to address A, at time T . W e then wait a little while, and write to\nthe disk at address A + 1 (the next block address in sequential order),\nbut at time T + \u03b4. In-between the \ufb01rst and second writes, unfortunately ,\nthe disk has rotated; when you issue the second write, it will thu s wait\nfor most of a rotation before being committed (speci\ufb01cally , if the rot ation\ntakes time Trotation, the disk will wait Trotation \u2212 \u03b4 before it can commit\nthe second write to the disk surface). And thus you can hopefully see\nthat simply writing to disk in sequential order is not enough to a chieve\npeak performance; rather , you must issue a large number of contiguous\nwrites (or one large write) to the drive in order to achieve good wri te\nperformance.\nT o achieve this end, LFS uses an ancient technique known as write\nbuffering1 . Before writing to the disk, LFS keeps track of updates in\nmemory; when it has received a suf\ufb01cient number of updates, it w rites\nthem to disk all at once, thus ensuring ef\ufb01cient use of the disk.\nThe large chunk of updates LFS writes at one time is referred to b y\nthe name of a segment. Although this term is over-used in computer\nsystems, here it just means a large-ish chunk which LFS uses t o group\nwrites. Thus, when writing to disk, LFS buffers updates in an in-memory\n1 Indeed, it is hard to \ufb01nd a good citation for this idea, since it was like ly invented by many\nand very early on in the history of computing. For a study of the bene\ufb01t s of write buffering,\nsee Solworth and Orji [SO90]; to learn about its potential harms, see Mogul [M94].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o achieve this end, LFS uses an ancient technique known as write",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "achieve",
          "uses",
          "ancient",
          "technique",
          "known",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "see Solworth and Orji [SO90]; to learn about its potential harms, see Mogul [M94].",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "solworth",
          "orji",
          "learn",
          "potential",
          "harms",
          "mogul"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand here it just: a large-ish chunk which LFS uses t o group",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "here it just",
          "large",
          "chunk",
          "uses",
          "group"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand w riting sequentially and effectively",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "riting",
          "sequentially",
          "effectively"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "3 How Much T o Buffer?",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "43.3 How Much T o Buffer?\nThis raises the following question: how many updates should LFS\nbuffer before writing to disk? The answer , of course, depends on t he disk\nitself, speci\ufb01cally how high the positioning overhead is in compa rison to\nthe transfer rate; see the FFS chapter for a similar analysis.\nFor example, assume that positioning (i.e., rotation and seek over -\nheads) before each write takes roughly Tposition seconds. Assume further\nthat the disk transfer rate is Rpeak MB/s. How much should LFS buffer\nbefore writing when running on such a disk?\nThe way to think about this is that every time you write, you pay a\n\ufb01xed overhead of the positioning cost. Thus, how much do you have\nto write in order to amortize that cost? The more you write, the better\n(obviously), and the closer you get to achieving peak bandwidth.\nT o obtain a concrete answer , let\u2019s assume we are writing out D MB.\nThe time to write out this chunk of data ( Twrite ) is the positioning time\nTposition plus the time to transfer D ( D\nRpeak\n), or:\nTwrite = Tposition + D\nRpeak\n(43.1)\nAnd thus the effective rate of writing ( Reffective ), which is just the\namount of data written divided by the total time to write it, is:\nReffective = D\nTwrite\n= D\nTposition + D\nRpeak\n. (43.2)\nWhat we\u2019re interested in is getting the effective rate ( Reffective ) close\nto the peak rate. Speci\ufb01cally , we want the effective rate to be some fraction\nF of the peak rate, where 0 < F < 1 (a typical F might be 0.9, or 90% of\nthe peak rate). In mathematical form, this means we want Reffective =\nF \u00d7 Rpeak.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand or: Twrite = Tposition + D",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "or",
          "twrite",
          "tposition"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand how much t o buffer?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "much",
          "buffer"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "0",
    "title": "1 \u00d7",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "0.1 \u00d7\n100 MB/s \u00d7 0. 01 seconds = 9 MB . T ry some different values to see\nhow much we need to buffer in order to approach peak bandwidth. How\nmuch is needed to reach 95% of peak? 99%?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "how much we need to buffer in order to approach peak bandwidth. How",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "much",
          "need",
          "buffer",
          "order",
          "approach",
          "peak",
          "bandwidth"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "43",
    "title": "4 Problem: Finding Inodes",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "43.4 Problem: Finding Inodes\nT o understand how we \ufb01nd an inode in LFS, let us brie\ufb02y review how\nto \ufb01nd an inode in a typical U N I X \ufb01le system. In a typical \ufb01le system such\nas FFS, or even the old U N I X \ufb01le system, \ufb01nding inodes is easy , because\nthey are organized in an array and placed on disk at \ufb01xed locations .\nFor example, the old U N I X \ufb01le system keeps all inodes at a \ufb01xed por-\ntion of the disk. Thus, given an inode number and the start addres s, to\n\ufb01nd a particular inode, you can calculate its exact disk addres s simply by\nmultiplying the inode number by the size of an inode, and adding t hat\nto the start address of the on-disk array; array-based indexin g, given an\ninode number , is fast and straightforward.\nFinding an inode given an inode number in FFS is only slightly more\ncomplicated, because FFS splits up the inode table into chunks and places\na group of inodes within each cylinder group. Thus, one must know how\nbig each chunk of inodes is and the start addresses of each. After that, the\ncalculations are similar and also easy .\nIn LFS, life is more dif\ufb01cult. Why? W ell, we\u2019ve managed to scatte r the\ninodes all throughout the disk! W orse, we never overwrite in place , and\nthus the latest version of an inode (i.e., the one we want) keeps mov ing.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o understand how we \ufb01nd an inode in LFS, let us brie\ufb02y review how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "inode",
          "review"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "a group of inodes within each cylinder group. Thus, one must know how",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "group",
          "inodes",
          "within",
          "cylinder",
          "group",
          "thus",
          "must",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand problem: finding inodes",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "finding",
          "inodes"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "43",
    "title": "5 Solution Through Indirection: The Inode Map",
    "document_source": "book.pdf",
    "start_line": 40,
    "type": "chapter",
    "content": "43.5 Solution Through Indirection: The Inode Map\nT o remedy this, the designers of LFS introduced a level of indirection\nbetween inode numbers and the inodes through a data structure ca lled\nthe inode map (imap) . The imap is a structure that takes an inode number\nas input and produces the disk address of the most recent version of the\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o remedy this, the designers of LFS introduced a level of indirection",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "remedy",
          "designers",
          "introduced",
          "level",
          "indirection"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand solution through indirection: the inode map",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "solution",
          "indirection",
          "inode"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 LO G-S T R U C T U R E D FI L E SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 LO G-S T R U C T U R E D FI L E SY S T E M S\nTI P : U S E A L E V E L OF IN D I R E C T I O N\nPeople often say that the solution to all problems in Computer Scienc e is\nsimply a level of indirection . This is clearly not true; it is just the solution\nto most problems (yes, this is still too strong of a comment, but you get the\npoint). Y ou certainly can think of every virtualization we have s tudied,\ne.g., virtual memory , or the notion of a \ufb01le, as simply a level of indi rection.\nAnd certainly the inode map in LFS is a virtualization of inode num bers.\nHopefully you can see the great power of indirection in these examp les,\nallowing us to freely move structures around (such as pages in th e VM\nexample, or inodes in LFS) without having to change every referen ce to\nthem. Of course, indirection can have a downside too: extra overhead. So\nnext time you have a problem, try solving it with indirection, but make\nsure to think about the overheads of doing so \ufb01rst. As Wheeler famou sly\nsaid, \u201cAll problems in computer science can be solved by another l evel of\nindirection, except of course for the problem of too many indirection s.\u201d\ninode. Thus, you can imagine it would often be implemented as a sim ple\narray, with 4 bytes (a disk pointer) per entry . Any time an inode is wri tten\nto disk, the imap is updated with its new location.\nThe imap, unfortunately , needs to be kept persistent (i.e., w ritten to\ndisk); doing so allows LFS to keep track of the locations of inodes acr oss\ncrashes, and thus operate as desired. Thus, a question: where s hould the\nimap reside on disk?\nIt could live on a \ufb01xed part of the disk, of course. Unfortunately , as it\ngets updated frequently , this would then require updates to \ufb01 le structures\nto be followed by writes to the imap, and hence performance would s uffer\n(i.e., there would be more disk seeks, between each update and t he \ufb01xed\nlocation of the imap).\nInstead, LFS places chunks of the inode map right next to where i t is\nwriting all of the other new information. Thus, when appending a d ata\nblock to a \ufb01le k, LFS actually writes the new data block, its inode, and a\npiece of the inode map all together onto the disk, as follows:\nD\nA0\nI[k]\nb[0]:A0\nA1\nimap\nm[k]:A1\nIn this picture, the piece of the imap array stored in the block ma rked\nimap tells LFS that the inode k is at disk address A1; this inode, in turn,\ntells LFS that its data block D is at address A0.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "said, \u201cAll problems in computer science can be solved by another l evel of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "said",
          "problems",
          "computer",
          "science",
          "solved",
          "another",
          "evel"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "inode. Thus, you can imagine it would often be implemented as a sim ple",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "inode",
          "thus",
          "imagine",
          "would",
          "often",
          "implemented"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "6 Completing The Solution: The Checkpoint Region",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "43.6 Completing The Solution: The Checkpoint Region\nThe clever reader (that\u2019s you, right?) might have noticed a probl em\nhere. How do we \ufb01nd the inode map, now that pieces of it are also now\nspread across the disk? In the end, there is no magic: the \ufb01le sy stem must\nhave some \ufb01xed and known location on disk to begin a \ufb01le lookup.\nLFS has just such a \ufb01xed place on disk for this, known as the check-\npoint region (CR) . The checkpoint region contains pointers to (i.e., ad-\ndresses of) the latest pieces of the inode map, and thus the inode m ap\npieces can be found by reading the CR \ufb01rst. Note the checkpoint re gion\nis only updated periodically (say every 30 seconds or so), and thus perfor-\nmance is not ill-affected. Thus, the overall structure of the on- disk layout\ncontains a checkpoint region (which points to the latest pieces of the in-\node map); the inode map pieces each contain addresses of the inodes ; the\ninodes point to \ufb01les (and directories) just like typical U N I X \ufb01le systems.\nHere is an example of the checkpoint region (note it is all the way a t\nthe beginning of the disk, at address 0), and a single imap chun k, inode,\nand data block. A real \ufb01le system would of course have a much bigger\nCR (indeed, it would have two, as we\u2019ll come to understand later), many\nimap chunks, and of course many more inodes, data blocks, etc.\nimap\n[k...k+N]:\nA2\nCR\n0\nD\nA0\nI[k]\nb[0]:A0\nA1\nimap\nm[k]:A1\nA2",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "have some \ufb01xed and known location on disk to begin a \ufb01le lookup.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "location",
          "disk",
          "begin",
          "lookup"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "LFS has just such a \ufb01xed place on disk for this, known as the check-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "place",
          "disk",
          "known",
          "check"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "CR (indeed, it would have two, as we\u2019ll come to understand later), many",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "indeed",
          "would",
          "come",
          "understand",
          "later",
          "many"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 6 Completing The Solution: The Checkpoint Region",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6 completing the solution",
          "checkpoint",
          "region"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "43",
    "title": "7 Reading A File From Disk: A Recap",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "43.7 Reading A File From Disk: A Recap\nT o make sure you understand how LFS works, let us now walk through\nwhat must happen to read a \ufb01le from disk. Assume we have nothing i n\nmemory to begin. The \ufb01rst on-disk data structure we must read is the\ncheckpoint region. The checkpoint region contains pointers (i.e. , disk ad-\ndresses) to the entire inode map, and thus LFS then reads in the entire in-\node map and caches it in memory . After this point, when given an in ode\nnumber of a \ufb01le, LFS simply looks up the inode-number to inode-disk -\naddress mapping in the imap, and reads in the most recent versi on of the\ninode. T o read a block from the \ufb01le, at this point, LFS proceeds exac tly\nas a typical U N I X \ufb01le system, by using direct pointers or indirect pointers\nor doubly-indirect pointers as need be. In the common case, LFS shou ld\nperform the same number of I/Os as a typical \ufb01le system when read ing a\n\ufb01le from disk; the entire imap is cached and thus the extra work L FS does\nduring a read is to look up the inode\u2019s address in the imap.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "T o make sure you understand how LFS works, let us now walk through",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "make",
          "sure",
          "understand",
          "works",
          "walk"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand reading a file from disk: a recap",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reading",
          "file",
          "disk",
          "recap"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "8 What About Directories?",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "43.8 What About Directories?\nThus far , we\u2019ve simpli\ufb01ed our discussion a bit by only considering in-\nodes and data blocks. However , to access a \ufb01le in a \ufb01le system (suc h as\n/home/remzi/foo, one of our favorite fake \ufb01le names), some directo-\nries must be accessed too. So how does LFS store directory data?\nFortunately , directory structure is basically identical to c lassic U N I X\n\ufb01le systems, in that a directory is just a collection of (name, inod e number)\nmappings. For example, when creating a \ufb01le on disk, LFS must both write\na new inode, some data, as well as the directory data and its inode t hat\nrefer to this \ufb01le. Remember that LFS will do so sequentially on the disk\n(after buffering the updates for some time). Thus, creating a \ufb01 le foo in a\ndirectory would lead to the following new structures on disk:\nDk\nA0\nI[k]\nb[0]:A0\nA1\n(foo, k)\nDdir\nA2\nI[dir]\nb[0]:A2\nA3\nm[k]:A1\nm[dir]:A3\nimap\nThe piece of the inode map contains the information for the location of\nboth the directory \ufb01le dir as well as the newly-created \ufb01le f. Thus, when\naccessing \ufb01le foo (with inode number k), you would \ufb01rst look in the\ninode map (usually cached in memory) to \ufb01nd the location of the inode\nof directory dir (A3); you then read the directory inode, which gives you\nthe location of the directory data ( A2); reading this data block gives you\nthe name-to-inode-number mapping of ( foo, k). Y ou then consult the\ninode map again to \ufb01nd the location of inode number k (A1), and \ufb01nally\nread the desired data block at address A0.\nThere is one other serious problem in LFS that the inode map solves,\nknown as the recursive update problem [Z+12]. The problem arises\nin any \ufb01le system that never updates in place (such as LFS), but rather\nmoves updates to new locations on the disk.\nSpeci\ufb01cally , whenever an inode is updated, its location on disk ch anges.\nIf we hadn\u2019t been careful, this would have also entailed an upda te to\nthe directory that points to this \ufb01le, which then would have mand ated\na change to the parent of that directory , and so on, all the way up t he \ufb01le\nsystem tree.\nLFS cleverly avoids this problem with the inode map. Even though\nthe location of an inode may change, the change is never re\ufb02ected i n the\ndirectory itself; rather , the imap structure is updated whil e the directory\nholds the same name-to-inode-number mapping. Thus, through ind irec-\ntion, LFS avoids the recursive update problem.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "both the directory \ufb01le dir as well as the newly-created \ufb01le f. Thus, when",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "directory",
          "well",
          "newly",
          "created",
          "thus"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "There is one other serious problem in LFS that the inode map solves,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "serious",
          "problem",
          "inode",
          "solves"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "known as the recursive update problem [Z+12]. The problem arises",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "recursive",
          "update",
          "problem",
          "problem",
          "arises"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand what about directories?",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "directories"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand LFS store directory data",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "store",
          "directory",
          "data"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "9 A New Problem: Garbage Collection",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "43.9 A New Problem: Garbage Collection\nY ou may have noticed another problem with LFS; it repeatedly write s\nthe latest version of a \ufb01le (including its inode and data) to new l ocations\non disk. This process, while keeping writes ef\ufb01cient, implies that LFS\nleaves old versions of \ufb01le structures scattered throughout the di sk. W e\n(rather unceremoniously) call these old versions garbage.\nFor example, let\u2019s imagine the case where we have an existing \ufb01l e re-\nferred to by inode number k, which points to a single data block D0.\nW e now update that block, generating both a new inode and a new data\nblock. The resulting on-disk layout of LFS would look something like t his\n(note we omit the imap and other structures for simplicity; a new c hunk\nof imap would also have to be written to disk to point to the new inod e):\nD0\nA0\nI[k]\nb[0]:A0\n(garbage)\nD0\nA4\nI[k]\nb[0]:A4\nIn the diagram, you can see that both the inode and data block have\ntwo versions on disk, one old (the one on the left) and one current and\nthus live (the one on the right). By the simple act of (logically) updating\na data block, a number of new structures must be persisted by LFS, thus\nleaving old versions of said blocks on the disk.\nAs another example, imagine we instead append a block to that ori g-\ninal \ufb01le k. In this case, a new version of the inode is generated, but the\nold data block is still pointed to by the inode. Thus, it is still li ve and very\nmuch part of the current \ufb01le system:\nD0\nA0\nI[k]\nb[0]:A0\n(garbage)\nD1\nA4\nb[0]:A0\nb[1]:A4\nI[k]\nSo what should we do with these older versions of inodes, data blocks,\nand so forth? One could keep those older versions around and allow\nusers to restore old \ufb01le versions (for example, when they acciden tally\noverwrite or delete a \ufb01le, it could be quite handy to do so); such a \ufb01 le\nsystem is known as a versioning \ufb01le system because it keeps track of the\ndifferent versions of a \ufb01le.\nHowever , LFS instead keeps only the latest live version of a \ufb01le; t hus\n(in the background), LFS must periodically \ufb01nd these old dead ve rsions\nof \ufb01le data, inodes, and other structures, and clean them; cleaning should\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "system is known as a versioning \ufb01le system because it keeps track of the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "known",
          "versioning",
          "system",
          "keeps",
          "track"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a new problem: garbage collection",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "garbage",
          "collection"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "10 Determining Block Liveness",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "43.10 Determining Block Liveness\nW e address the mechanism \ufb01rst. Given a data block D within an on-\ndisk segment S, LFS must be able to determine whether D is live. T o do\nso, LFS adds a little extra information to each segment that desc ribes each\nblock. Speci\ufb01cally , LFS includes, for each data block D, its inode number\n(which \ufb01le it belongs to) and its offset (which block of the \ufb01le this is). This\ninformation is recorded in a structure at the head of the segment k nown\nas the segment summary block .\nGiven this information, it is straightforward to determine whe ther a\nblock is live or dead. For a block D located on disk at address A, look\nin the segment summary block and \ufb01nd its inode number N and offset\nT . Next, look in the imap to \ufb01nd where N lives and read N from disk\n(perhaps it is already in memory , which is even better). Final ly , using\nthe offset T , look in the inode (or some indirect block) to see where the\ninode thinks the Tth block of this \ufb01le is on disk. If it points exactl y to disk\naddress A, LFS can conclude that the block D is live. If it points anywhere\nelse, LFS can conclude that D is not in use (i.e., it is dead) and thus know\nthat this version is no longer needed. Here is a pseudocode summar y:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "disk segment S, LFS must be able to determine whether D is live. T o do",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "segment",
          "must",
          "able",
          "determine",
          "whether",
          "live"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "else, LFS can conclude that D is not in use (i.e., it is dead) and thus know",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "else",
          "conclude",
          "dead",
          "thus",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand determining block liveness",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "determining",
          "block",
          "liveness"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "11 A Policy Question: Which Blocks T o Clean, And When?",
    "document_source": "book.pdf",
    "start_line": 27,
    "type": "chapter",
    "content": "43.11 A Policy Question: Which Blocks T o Clean, And When?\nOn top of the mechanism described above, LFS must include a set of\npolicies to determine both when to clean and which blocks are wort h\ncleaning. Determining when to clean is easier; either period ically , dur-\ning idle time, or when you have to because the disk is full.\nDetermining which blocks to clean is more challenging, and has been\nthe subject of many research papers. In the original LFS paper [ RO91], the\nauthors describe an approach which tries to segregate hot and cold seg-\nments. A hot segment is one in which the contents are being freque ntly\nover-written; thus, for such a segment, the best policy is to wai t a long\ntime before cleaning it, as more and more blocks are getting over-w ritten\n(in new segments) and thus being freed for use. A cold segment, i n con-\ntrast, may have a few dead blocks but the rest of its contents are r elatively\nstable. Thus, the authors conclude that one should clean cold segm ents\nsooner and hot segments later , and develop a heuristic that does ex actly\nthat. However , as with most policies, this policy isn\u2019t perfect; l ater ap-\nproaches show how to do better [MR+97].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "On top of the mechanism described above, LFS must include a set of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mechanism",
          "described",
          "must",
          "include"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "authors describe an approach which tries to segregate hot and cold seg-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "authors",
          "describe",
          "approach",
          "tries",
          "segregate",
          "cold"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "sooner and hot segments later , and develop a heuristic that does ex actly",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "sooner",
          "segments",
          "later",
          "develop",
          "heuristic",
          "actly"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 11 A Policy Question: Which Blocks T o Clean, And When?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "11 a policy question",
          "blocks",
          "clean"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "43",
    "title": "12 Crash Recovery And The Log",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "43.12 Crash Recovery And The Log\nOne \ufb01nal problem: what happens if the system crashes while LFS is\nwriting to disk? As you may recall in the previous chapter about j our-\nnaling, crashes during updates are tricky for \ufb01le systems, an d thus some-\nthing LFS must consider as well.\nDuring normal operation, LFS buffers writes in a segment, and th en\n(when the segment is full, or when some amount of time has elapsed) ,\nwrites the segment to disk. LFS organizes these writes in a log, i.e., the\ncheckpoint region points to a head and tail segment, and each seg ment\npoints to the next segment to be written. LFS also periodically updates the\ncheckpoint region. Crashes could clearly happen during either of these\noperations (write to a segment, write to the CR). So how does LFS han dle\ncrashes during writes to these structures?\nLet\u2019s cover the second case \ufb01rst. T o ensure that the CR update hap pens\natomically , LFS actually keeps two CRs, one at either end of the d isk, and\nwrites to them alternately . LFS also implements a careful pr otocol when\nupdating the CR with the latest pointers to the inode map and othe r infor-\nmation; speci\ufb01cally , it \ufb01rst writes out a header (with timesta mp), then the\nbody of the CR, and then \ufb01nally one last block (also with a timestam p). If\nthe system crashes during a CR update, LFS can detect this by s eeing an\ninconsistent pair of timestamps. LFS will always choose to use th e most\nrecent CR that has consistent timestamps, and thus consistent update of\nthe CR is achieved.\nLet\u2019s now address the \ufb01rst case. Because LFS writes the CR every 30\nseconds or so, the last consistent snapshot of the \ufb01le system may be q uite\nold. Thus, upon reboot, LFS can easily recover by simply reading in the\ncheckpoint region, the imap pieces it points to, and subsequent \ufb01 les and\ndirectories; however , the last many seconds of updates would be los t.\nT o improve upon this, LFS tries to rebuild many of those segments\nthrough a technique known as roll forward in the database community .\nThe basic idea is to start with the last checkpoint region, \ufb01nd t he end of\nthe log (which is included in the CR), and then use that to read t hrough\nthe next segments and see if there are any valid updates withi n it. If there\nare, LFS updates the \ufb01le system accordingly and thus recovers m uch of\nthe data and metadata written since the last checkpoint. See Ros enblum\u2019s\naward-winning dissertation for details [R92].",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "writes to them alternately . LFS also implements a careful pr otocol when",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "writes",
          "alternately",
          "also",
          "implements",
          "careful",
          "otocol"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "through a technique known as roll forward in the database community .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "technique",
          "known",
          "roll",
          "forward",
          "database",
          "community"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand crash recovery and the log",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "crash",
          "recovery"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand LFS han dle\ncrashes during writes to these structures",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "crashes",
          "writes",
          "structures"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "43",
    "title": "13 Summary",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "43.13 Summary\nLFS introduces a new approach to updating the disk. Instead of ove r-\nwriting \ufb01les in places, LFS always writes to an unused portion of the\ndisk, and then later reclaims that old space through cleaning. This ap-\nproach, which in database systems is called shadow paging [L77] and in\n\ufb01le-system-speak is sometimes called copy-on-write, enables highly ef\ufb01-\ncient writing, as LFS can gather all updates into an in-memory segment\nand then write them out together sequentially .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "LFS introduces a new approach to updating the disk. Instead of ove r-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "introduces",
          "approach",
          "updating",
          "disk",
          "instead"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "LO G-S T R U C T U R E D FI L E SY S T E M S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "LO G-S T R U C T U R E D FI L E SY S T E M S 13\nTI P : T U R N FL AW S IN TO VI RT U E S\nWhenever your system has a fundamental \ufb02aw , see if you can turn i t\naround into a feature or something useful. NetApp\u2019s W AFL does this\nwith old \ufb01le contents; by making old versions available, W AFL no l onger\nhas to worry about cleaning quite so often (though it does delete old ver-\nsions, eventually , in the background), and thus provides a cool fe ature\nand removes much of the LFS cleaning problem all in one wonderful\ntwist. Are there other examples of this in systems? Undoubtedly , but\nyou\u2019ll have to think of them yourself, because this chapter is over with a\ncapital \u201cO\u201d. Over . Done. Kaput. W e\u2019re out. Peace!\nThe large writes that LFS generates are excellent for performa nce on\nmany different devices. On hard drives, large writes ensure that posi-\ntioning time is minimized; on parity-based RAIDs, such as RAID -4 and\nRAID-5, they avoid the small-write problem entirely . Recent r esearch\nhas even shown that large I/Os are required for high performance on\nFlash-based SSDs [H+17]; thus, perhaps surprisingly , LFS-sty le \ufb01le sys-\ntems may be an excellent choice even for these new mediums.\nThe downside to this approach is that it generates garbage; old c opies\nof the data are scattered throughout the disk, and if one wants to r e-\nclaim such space for subsequent usage, one must clean old segmen ts pe-\nriodically . Cleaning became the focus of much controversy in LFS, a nd\nconcerns over cleaning costs [SS+95] perhaps limited LFS\u2019s initial impact\non the \ufb01eld. However , some modern commercial \ufb01le systems, includi ng\nNetApp\u2019s W AFL [HLM94], Sun\u2019s ZFS [B07], and Linux btrfs [R+13], and\neven modern \ufb02ash-based SSDs [AD14], adopt a similar copy-on-write\napproach to writing to disk, and thus the intellectual legacy of LFS lives\non in these modern \ufb01le systems. In particular , W AFL got around cle an-\ning problems by turning them into a feature; by providing old ver sions of\nthe \ufb01le system via snapshots, users could access old \ufb01les whenever they\ndeleted current ones accidentally .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Whenever your system has a fundamental \ufb02aw , see if you can turn i t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "whenever",
          "system",
          "fundamental",
          "turn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The downside to this approach is that it generates garbage; old c opies",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "downside",
          "approach",
          "generates",
          "garbage",
          "opies"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "approach to writing to disk, and thus the intellectual legacy of LFS lives",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "writing",
          "disk",
          "thus",
          "intellectual",
          "legacy",
          "lives"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 LO G-S T R U C T U R E D FI L E SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 LO G-S T R U C T U R E D FI L E SY S T E M S\nReferences\n[AD14] \u201cOperating Systems: Three Easy Pieces\u201d (Chapter: Flash-based So lid State Drives)\nby Remzi Arpaci-Dusseau and Andrea Arpaci-Dusseau. Arpaci-Dusseau Books, 2014. A bit\ngauche to refer you to another chapter in this very book, but who are we to judge?\n[B07] \u201cZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. Copy A vailable:\nhttp://www.ostep.org/Citations/zfs_last.pdf. Slides on ZFS; unfortunately, there\nis no great ZFS paper (yet). Maybe you will write one, so we can cite it here?\n[H+17] \u201cThe Unwritten Contract of of Solid State Drives\u201d by Jun He, Su darsun Kannan, An-\ndrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau. EuroSys \u201917, A pril 2017. Which unwritten\nrules one must follow to extract high performance from an SSD? Interestingl y, both request scale (large\nor parallel requests) and locality still matter , even on SSDs. The more things change ...\n[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,\nMichael Malcolm. USENIX Spring \u201994. W AFL takes many ideas from LFS and RAID and puts it\ninto a high-speed NFS appliance for the multi-billion dollar storage company N etApp.\n[L77] \u201cPhysical Integrity in a Large Segmented Database\u201d by R. Lori e. ACM T ransactions on\nDatabases, V olume 2:1, 1977. The original idea of shadow paging is presented here.\n[MJLF84] \u201cA Fast File System for UNIX\u201d by Marshall K. McKusick, William N. Joy , Sam J.\nLef\ufb02er , Robert S. Fabry . ACM TOCS, V olume 2:3, August 1984. The original FFS paper; see the\nchapter on FFS for more details.\n[MR+97] \u201cImproving the Performance of Log-structured File Systems wit h Adaptive Meth-\nods\u201d by Jeanna Neefe Matthews, Drew Roselli, Adam M. Costello, Randol ph Y . W ang, Thomas\nE. Anderson. SOSP 1997, pages 238-251, October , Saint Malo, France. A more recent paper detail-\ning better policies for cleaning in LFS.\n[M94] \u201cA Better Update Policy\u201d by Jeffrey C. Mogul. USENIX A TC \u201994, June 1 994. In this paper ,\nMogul \ufb01nds that read workloads can be harmed by buffering writes for too long and then sending them\nto the disk in a big burst. Thus, he recommends sending writes more fr equently and in smaller batches.\n[P98] \u201cHardware T echnology T rends and Database Opportunities\u201d by Dav id A. Patterson.\nACM SIGMOD \u201998 Keynote, 1998. A vailable online here: http://www.cs.berkeley.edu/\n\u02dcpattrsn/talks/keynote.html. A great set of slides on technology trends in computer sys-\ntems. Hopefully, Patterson will create another of these sometime soon.\n[R+13] \u201cBTRFS: The Linux B-T ree Filesystem\u201d by Ohad Rodeh, Josef Bacik, C hris Mason. ACM\nT ransactions on Storage, V olume 9 Issue 3, August 2013. Finally, a good paper on BTRFS, a\nmodern take on copy-on-write \ufb01le systems.\n[RO91] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosen-\nblum and John Ousterhout. SOSP \u201991, Paci\ufb01c Grove, CA, October 1991. The original SOSP\npaper about LFS, which has been cited by hundreds of other papers and insp ired many real systems.\n[R92] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosenblum.\nhttp://www .eecs.berkeley .edu/Pubs/T echRpts/1992/CSD-92-696.pdf. The award-winning dis-\nsertation about LFS, with many of the details missing from the paper .\n[SS+95] \u201cFile system logging versus clustering: a performance compa rison\u201d by Margo Seltzer ,\nKeith A. Smith, Hari Balakrishnan, Jacqueline Chang, Sara McMains, V enkata Padmanabhan.\nUSENIX 1995 T echnical Conference, New Orleans, Louisiana, 1995. A paper that showed the LFS\nperformance sometimes has problems, particularly for workloads with many call s to fsync() (such as\ndatabase workloads). The paper was controversial at the time.\n[SO90] \u201cW rite-Only Disk Caches\u201d by Jon A. Solworth, Cyril U. Orji. SIGMOD \u2019 90, Atlantic\nCity , New Jersey , May 1990. An early study of write buffering and its bene\ufb01ts. However , buffering\nfor too long can be harmful: see Mogul [M94] for details.\n[Z+12] \u201cDe-indirection for Flash-based SSDs with Nameless W rites\u201d by Yiying Zhang, Leo\nPrasath Arulraj, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusse au. F AST \u201913, San Jose,\nCalifornia, February 2013. Our paper on a new way to build \ufb02ash-based storage devices, to avoid\nredundant mappings in the \ufb01le system and FTL. The idea is for the devic e to pick the physical location\nof a write, and return the address to the \ufb01le system, which stores the mapping .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "is no great ZFS paper (yet). Maybe you will write one, so we can cite it here?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "great",
          "paper",
          "maybe",
          "write",
          "cite"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "file",
          "system",
          "design",
          "file",
          "server",
          "appliance",
          "hitz",
          "james"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "tems. Hopefully, Patterson will create another of these sometime soon.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tems",
          "hopefully",
          "patterson",
          "create",
          "another",
          "sometime",
          "soon"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[RO91] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosen-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "implementation",
          "structured",
          "file",
          "syste",
          "mendel",
          "rosen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[R92] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosenblum.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "implementation",
          "structured",
          "file",
          "syste",
          "mendel",
          "rosenblum"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Operating Systems: Three Easy Pieces\u201d (Chapter: Flash-based So lid State Drives)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "operating systems",
          "three",
          "easy",
          "pieces",
          "chapter",
          "flash",
          "based",
          "state",
          "drives"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand ZFS: The Last W ord in File Systems\u201d by Jeff Bonwick and Bill Moor e. Copy A vailable:",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "zfs",
          "last",
          "file",
          "systems",
          "jeff",
          "bonwick",
          "bill",
          "moor",
          "copy"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand http: //www.ostep.org/Citations/zfs_last.pdf. Slides on ZFS; unfortunately, there",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "ostep",
          "citations",
          "slides",
          "unfortunately"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand V olume 2: 1, 1977. The original idea of shadow paging is presented here.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 2",
          "original",
          "idea",
          "shadow",
          "paging",
          "presented"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand V olume 2: 3, August 1984. The original FFS paper; see the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 2",
          "august",
          "original",
          "paper"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A vailable online here: http://www.cs.berkeley.edu/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable online here",
          "http",
          "berkeley"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand BTRFS: The Linux B-T ree Filesystem\u201d by Ohad Rodeh, Josef Bacik, C hris Mason. ACM",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "btrfs",
          "linux",
          "filesystem",
          "ohad",
          "rodeh",
          "josef",
          "bacik",
          "hris",
          "mason"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand http: //www .eecs.berkeley .edu/Pubs/T echRpts/1992/CSD-92-696.pdf. The award-winning dis-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "eecs",
          "berkeley",
          "pubs",
          "echrpts",
          "award",
          "winning"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2",
    "title": "If you \ufb01nd the above painful, you can help yourself a little bit b y",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "2. If you \ufb01nd the above painful, you can help yourself a little bit b y\nshowing the set of updates caused by each speci\ufb01c command. T o do\nso, run ./lfs.py -n 3 -i. Now see if it is easier to understand\nwhat each command must have been. Change the random seed to\nget different commands to interpret (e.g., -s 1, -s 2, -s 3, etc.).",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "so, run ./lfs.py -n 3 -i. Now see if it is easier to understand",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "easier",
          "understand"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "T o further test your ability to \ufb01gure out what updates are mad e to",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "3. T o further test your ability to \ufb01gure out what updates are mad e to\ndisk by each command, run the following: ./lfs.py -o -F -s\n100 (and perhaps a few other random seeds). This just shows a\nset of commands and does NOT show you the \ufb01nal state of the \ufb01le\nsystem. Can you reason about what the \ufb01nal state of the \ufb01le system\nmust be?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "4",
    "title": "Now see if you can determine which \ufb01les and directories are liv e",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "4. Now see if you can determine which \ufb01les and directories are liv e\nafter a number of \ufb01le and directory operations. Run tt ./lfs.py\n-n 20 -s 1 and then examine the \ufb01nal \ufb01le system state. Can you\n\ufb01gure out which pathnames are valid? Run tt ./lfs.py -n 20\n-s 1 -c -v to see the results. Run with -o to see if your answers\nmatch up given the series of random commands. Use different ran-\ndom seeds to get more problems.\n5. Now let\u2019s issue some speci\ufb01c commands. First, let\u2019s create a \ufb01le\nand write to it repeatedly . T o do so, use the -L \ufb02ag, which lets you\nspecify speci\ufb01c commands to execute. Let\u2019s create the \ufb01le \u201d/foo\u201d\nand write to it four times:\n-L c,/foo:w,/foo,0,1:w,/foo,1,1:w,/foo,2,1:w,/foo,3,1\n-o. See if you can determine the liveness of the \ufb01nal \ufb01le system\nstate; use -c to check your answers.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now let\u2019s issue some speci\ufb01c commands. First, let\u2019s create a \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "issue",
          "commands",
          "first",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "specify speci\ufb01c commands to execute. Let\u2019s create the \ufb01le \u201d/foo\u201d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "specify",
          "commands",
          "execute",
          "create"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand n 20 -s 1 and then examine the \ufb01nal \ufb01le system state. can you",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "examine",
          "system",
          "state"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand s 1 -c -v to see the results. run with -o to see if your answers",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "results",
          "answers"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand l c,/foo:w,/foo,0,1:w,/foo,1,1:w,/foo,2,1:w,/foo,3,1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand o. see if you can determine the liveness of the \ufb01nal \ufb01le system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "determine",
          "liveness",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Now , let\u2019s do the same thing, but with a single write operation i n-",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "6. Now , let\u2019s do the same thing, but with a single write operation i n-\nstead of four . Run ./lfs.py -o -L c,/foo:w,/foo,0,4 to\ncreate \ufb01le \u201d/foo\u201d and write 4 blocks with a single write operation.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "create \ufb01le \u201d/foo\u201d and write 4 blocks with a single write operation.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "write",
          "blocks",
          "single",
          "write",
          "operation"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "11",
    "title": "One last thing we\u2019ve been assuming is that the LFS simulator al-",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "11. One last thing we\u2019ve been assuming is that the LFS simulator al-\nways updates the checkpoint region after each update. In the re al\nLFS, that isn\u2019t the case: it is updated periodically to avoid long\nseeks. Run ./lfs.py -N -i -o -s 1000 to see some opera-\ntions and the intermediate and \ufb01nal states of the \ufb01le system whe n\nthe checkpoint region isn\u2019t forced to disk. What would happen if\nthe checkpoint region is never updated? What if it is updated pe ri-\nodically? Could you \ufb01gure out how to recover the \ufb01le system to the\nlatest state by rolling forward in the log?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand t the case: it is updated periodically to avoid long",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "t the case",
          "updated",
          "periodically",
          "avoid",
          "long"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "1 Storing a Single Bit",
    "document_source": "book.pdf",
    "start_line": 22,
    "type": "chapter",
    "content": "44.1 Storing a Single Bit\nFlash chips are designed to store one or more bits in a single trans is-\ntor; the level of charge trapped within the transistor is mapped to a binary\nvalue. In a single-level cell (SLC) \ufb02ash, only a single bit is stored within\na transistor (i.e., 1 or 0); with a multi-level cell (MLC) \ufb02ash, two bits are\nencoded into different levels of charge, e.g., 00, 01, 10, and 1 1 are repre-\nsented by low , somewhat low , somewhat high, and high levels. Ther e is\neven triple-level cell (TLC) \ufb02ash, which encodes 3 bits per cell. Overall,\nSLC chips achieve higher performance and are more expensive.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Flash chips are designed to store one or more bits in a single trans is-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "flash",
          "chips",
          "designed",
          "store",
          "bits",
          "single",
          "trans"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand storing a single bit",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "storing",
          "single"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "2 From Bits to Banks/Planes",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "44.2 From Bits to Banks/Planes\nAs they say in ancient Greece, storing a single bit (or a few) does not\na storage system make. Hence, \ufb02ash chips are organized into banks or\nplanes which consist of a large number of cells.\nA bank is accessed in two different sized units: blocks (sometimes\ncalled erase blocks ), which are typically of size 128 KB or 256 KB, and\npages, which are a few KB in size (e.g., 4KB). Within each bank there are\na large number of blocks; within each block, there are a large num ber of\npages. When thinking about \ufb02ash, you must remember this new ter mi-\nnology , which is different than the blocks we refer to in disks an d RAIDs\nand the pages we refer to in virtual memory .\nFigure 44.1 shows an example of a \ufb02ash plane with blocks and pages ;\nthere are three blocks, each containing four pages, in this simp le exam-\nple. W e\u2019ll see below why we distinguish between blocks and pages ; it\nturns out this distinction is critical for \ufb02ash operations such as reading\nand writing, and even more so for the overall performance of the dev ice.\nThe most important (and weird) thing you will learn is that to wri te to\na page within a block, you \ufb01rst have to erase the entire block; thi s tricky\ndetail makes building a \ufb02ash-based SSD an interesting and worth while\nchallenge, and the subject of the second-half of the chapter .\n0 1 2Block:\nPage:\nContent:\n00 01 02 03 04 05 06 07 08 09 10 11\nFigure 44.1: A Simple Flash Chip: Pages Within Blocks\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "turns out this distinction is critical for \ufb02ash operations such as reading",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "turns",
          "distinction",
          "critical",
          "operations",
          "reading"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The most important (and weird) thing you will learn is that to wri te to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "weird",
          "thing",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Content: 00 01 02 03 04 05 06 07 08 09 10 11",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "content"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 1: A Simple Flash Chip: Pages Within Blocks",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "simple",
          "flash",
          "chip",
          "pages",
          "within",
          "blocks"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand from bits to banks/planes",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "bits",
          "banks",
          "planes"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "3 Basic Flash Operations",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "44.3 Basic Flash Operations\nGiven this \ufb02ash organization, there are three low-level operati ons that\na \ufb02ash chip supports. The read command is used to read a page from the\n\ufb02ash; erase and program are used in tandem to write. The details:\n\u2022 Read (a page) : A client of the \ufb02ash chip can read any page (e.g.,\n2KB or 4KB), simply by specifying the read command and appro-\npriate page number to the device. This operation is typically q uite\nfast, 10s of microseconds or so, regardless of location on the device,\nand (more or less) regardless of the location of the previous request\n(quite unlike a disk). Being able to access any location uniform ly\nquickly means the device is a random access device.\n\u2022 Erase (a block): Before writing to a page within a \ufb02ash, the nature\nof the device requires that you \ufb01rst erase the entire block the page\nlies within. Erase, importantly , destroys the contents of the bl ock\n(by setting each bit to the value 1); therefore, you must be sure that\nany data you care about in the block has been copied elsewhere\n(to memory , or perhaps to another \ufb02ash block) before executing the\nerase. The erase command is quite expensive, taking a few mill isec-\nonds to complete. Once \ufb01nished, the entire block is reset and eac h\npage is ready to be programmed.\n\u2022 Program (a page): Once a block has been erased, the program com-\nmand can be used to change some of the 1\u2019s within a page to 0\u2019s,\nand write the desired contents of a page to the \ufb02ash. Program-\nming a page is less expensive than erasing a block, but more costl y\nthan reading a page, usually taking around 100s of microseconds\non modern \ufb02ash chips.\nOne way to think about \ufb02ash chips is that each page has a state as so-\nciated with it. Pages start in an INVALID state. By erasing the block that\na page resides within, you set the state of the page (and all page s within\nthat block) to ERASED, which resets the content of each page in the block\nbut also (importantly) makes them programmable. When you progra m a\npage, its state changes to VALID, meaning its contents have been set and\ncan be read. Reads do not affect these states (although you should only\nread from pages that have been programmed). Once a page has been pro-\ngrammed, the only way to change its contents is to erase the enti re block\nwithin which the page resides. Here is an example of states tra nsition\nafter various erase and program operations within a 4-page block:\niiii Initial: pages in block are invalid (i)\nErase() \u2192 EEEE State of pages in block set to erased (E)\nProgram(0) \u2192 VEEE Program page 0; state set to valid (V)\nProgram(0) \u2192 error Cannot re-program page after programming\nProgram(1) \u2192 VVEE Program page 1\nErase() \u2192 EEEE Contents erased; all pages programmable\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "(quite unlike a disk). Being able to access any location uniform ly",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "quite",
          "unlike",
          "disk",
          "able",
          "access",
          "location",
          "uniform"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "lies within. Erase, importantly , destroys the contents of the bl ock",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lies",
          "within",
          "erase",
          "importantly",
          "destroys",
          "contents"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "but also (importantly) makes them programmable. When you progra m a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "also",
          "importantly",
          "makes",
          "programmable",
          "progra"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand The details: \u2022 Read (a page) : A client of the \ufb02ash chip can read any page (e.g.,",
        "type": "key_term",
        "difficulty": "intermediate",
        "keywords": [
          "the details",
          "read",
          "page",
          "client",
          "chip",
          "read",
          "page"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand page block: iiii Initial: pages in block are invalid (i)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "page block",
          "iiii",
          "initial",
          "pages",
          "block",
          "invalid"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand basic flash operations",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "flash",
          "operations"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand erase (a block): before writing to a page within a \ufb02ash, the nature",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "erase",
          "block",
          "writing",
          "page",
          "within",
          "nature"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand program (a page): once a block has been erased, the program com-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "program",
          "page",
          "block",
          "erased",
          "program"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 FL A S H -B A S E D SSD S\nA Detailed Example\nBecause the process of writing (i.e., erasing and programming) is so un-\nusual, let\u2019s go through a detailed example to make sure it makes sense.\nIn this example, imagine we have the following four 8-bit pages, within\na 4-page block (both unrealistically small sizes, but useful w ithin this ex-\nample); each page is VALID as each has been previously programmed.\nPage 0 Page 1 Page 2 Page 3\n00011000 11001110 00000001 00111111\nVALID VALID VALID VALID\nNow say we wish to write to page 0, \ufb01lling it with new contents. T o\nwrite any page, we must \ufb01rst erase the entire block. Let\u2019s assum e we do\nso, thus leaving the block in this state:\nPage 0 Page 1 Page 2 Page 3\n11111111 11111111 11111111 11111111\nERASED ERASED ERASED ERASED\nGood news! W e could now go ahead and program page 0, for exam-\nple with the contents 00000011, overwriting the old page 0 (contents\n00011000) as desired. After doing so, our block looks like this:\nPage 0 Page 1 Page 2 Page 3\n00000011 11111111 11111111 11111111\nVALID ERASED ERASED ERASED\nAnd now the bad news: the previous contents of pages 1, 2, and 3\nare all gone! Thus, before overwriting any page within a block, we must\n\ufb01rst move any data we care about to another location (e.g., memory , or\nelsewhere on the \ufb02ash). The nature of erase will have a strong imp act on\nhow we design \ufb02ash-based SSDs, as we\u2019ll soon learn about.\nSummary\nT o summarize, reading a page is easy: just read the page. Flas h chips\ndo this quite well, and quickly; in terms of performance, they of fer the\npotential to greatly exceed the random read performance of modern disk\ndrives, which are slow due to mechanical seek and rotation costs.\nW riting a page is trickier; the entire block must \ufb01rst be erase d (taking\ncare to \ufb01rst move any data we care about to another location), and th en\nthe desired page programmed. Not only is this expensive, but fre quent\nrepetitions of this program/erase cycle can lead to the biggest reliability\nproblem \ufb02ash chips have: wear out . When designing a storage system\nwith \ufb02ash, the performance and reliability of writing is a cent ral focus.\nW e\u2019ll soon learn more about how modern SSDs attack these issues, deliv-\nering excellent performance and reliability despite these l imitations.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "how we design \ufb02ash-based SSDs, as we\u2019ll soon learn about.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "based",
          "ssds",
          "soon",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "problem \ufb02ash chips have: wear out . When designing a storage system",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "problem",
          "chips",
          "wear",
          "designing",
          "storage",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "W e\u2019ll soon learn more about how modern SSDs attack these issues, deliv-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "soon",
          "learn",
          "modern",
          "ssds",
          "attack",
          "issues",
          "deliv"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "4 Flash Performance And Reliability",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "44.4 Flash Performance And Reliability\nBecause we\u2019re interested in building a storage device out of raw \ufb02 ash\nchips, it is worthwhile to understand their basic performance character-\nistics. Figure 44.2 presents a rough summary of some numbers foun d in\nthe popular press [V12]. Therein, the author presents the basi c operation\nlatency of reads, programs, and erases across SLC, MLC, and TLC \ufb02a sh,\nwhich store 1, 2, and 3 bits of information per cell, respectively .\nAs we can see from the table, read latencies are quite good, takin g just\n10s of microseconds to complete. Program latency is higher and more\nvariable, as low as 200 microseconds for SLC, but higher as you pack\nmore bits into each cell; to get good write performance, you will ha ve\nto make use of multiple \ufb02ash chips in parallel. Finally , erase s are quite\nexpensive, taking a few milliseconds typically . Dealing wit h this cost is\ncentral to modern \ufb02ash storage design.\nLet\u2019s now consider reliability of \ufb02ash chips. Unlike mechanical disks,\nwhich can fail for a wide variety of reasons (including the grues ome and\nquite physical head crash , where the drive head actually makes contact\nwith the recording surface), \ufb02ash chips are pure silicon and in that sense\nhave fewer reliability issues to worry about. The primary conce rn is wear\nout; when a \ufb02ash block is erased and programmed, it slowly accrues a\nlittle bit of extra charge. Over time, as that extra charge bui lds up, it\nbecomes increasingly dif\ufb01cult to differentiate between a 0 a nd a 1. At the\npoint where it becomes impossible, the block becomes unusable.\nThe typical lifetime of a block is currently not well known. Manuf ac-\nturers rate MLC-based blocks as having a 10,000 P/E (Program/E rase)\ncycle lifetime; that is, each block can be erased and programme d 10,000\ntimes before failing. SLC-based chips, because they store only a single bit\nper transistor , are rated with a longer lifetime, usually 100, 000 P/E cycles.\nHowever , recent research has shown that lifetimes are much long er than\nexpected [BD10].\nOne other reliability problem within \ufb02ash chips is known as distur-\nbance. When accessing a particular page within a \ufb02ash, it is possibl e that\nsome bits get \ufb02ipped in neighboring pages; such bit \ufb02ips are know n as\nread disturbs or program disturbs , depending on whether the page is\nbeing read or programmed, respectively .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "chips, it is worthwhile to understand their basic performance character-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "chips",
          "worthwhile",
          "understand",
          "basic",
          "performance",
          "character"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "more bits into each cell; to get good write performance, you will ha ve",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bits",
          "cell",
          "good",
          "write",
          "performance"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "central to modern \ufb02ash storage design.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "central",
          "modern",
          "storage",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "The typical lifetime of a block is currently not well known. Manuf ac-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "typical",
          "lifetime",
          "block",
          "currently",
          "well",
          "known",
          "manuf"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "One other reliability problem within \ufb02ash chips is known as distur-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "reliability",
          "problem",
          "within",
          "chips",
          "known",
          "distur"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "some bits get \ufb02ipped in neighboring pages; such bit \ufb02ips are know n as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bits",
          "neighboring",
          "pages",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand flash performance and reliability",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "flash",
          "performance",
          "reliability"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "5 From Raw Flash to Flash-Based SSDs",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "44.5 From Raw Flash to Flash-Based SSDs\nGiven our basic understanding of \ufb02ash chips, we now face our next\ntask: how to turn a basic set of \ufb02ash chips into something that looks like\na typical storage device. The standard storage interface is a s imple block-\nbased one, where blocks (sectors) of size 512 bytes (or larger) can be read\nor written, given a block address. The task of the \ufb02ash-based SSD is to\nprovide that standard block interface atop the raw \ufb02ash chips in side it.\nInternally , an SSD consists of some number of \ufb02ash chips (for persis-\ntent storage). An SSD also contains some amount of volatile (i.e., non-\npersistent) memory (e.g., SRAM); such memory is useful for cachi ng and\nbuffering of data as well as for mapping tables, which we\u2019ll lear n about\nbelow . Finally , an SSD contains control logic to orchestrate device op era-\ntion. See Agrawal et. al for details [A+08]; a simpli\ufb01ed block dia gram is\nseen in Figure 44.3 (page 7).\nOne of the essential functions of this control logic is to satisfy cl ient\nreads and writes, turning them into internal \ufb02ash operations a s need be.\nThe \ufb02ash translation layer , or FTL, provides exactly this functionality .\nThe FTL takes read and write requests on logical blocks (that comprise the\ndevice interface) and turns them into low-level read, erase, and program\ncommands on the underlying physical blocks and physical pages (that com-\nprise the actual \ufb02ash device). The FTL should accomplish this t ask with\nthe goal of delivering excellent performance and high reliabil ity .\nExcellent performance, as we\u2019ll see, can be realized through a c om-\nbination of techniques. One key will be to utilize multiple \ufb02as h chips\nin parallel; although we won\u2019t discuss this technique much further , suf-\n\ufb01ce it to say that all modern SSDs use multiple chips internally t o obtain\nhigher performance. Another performance goal will be to reduce write\nampli\ufb01cation , which is de\ufb01ned as the total write traf\ufb01c (in bytes) issued\nto the \ufb02ash chips by the FTL divided by the total write traf\ufb01c (i n bytes) is-\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Given our basic understanding of \ufb02ash chips, we now face our next",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "given",
          "basic",
          "understanding",
          "chips",
          "face",
          "next"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "One of the essential functions of this control logic is to satisfy cl ient",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "essential",
          "functions",
          "control",
          "logic",
          "satisfy",
          "ient"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the goal of delivering excellent performance and high reliabil ity .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goal",
          "delivering",
          "excellent",
          "performance",
          "high",
          "reliabil"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "bination of techniques. One key will be to utilize multiple \ufb02as h chips",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "bination",
          "techniques",
          "utilize",
          "multiple",
          "chips"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "in parallel; although we won\u2019t discuss this technique much further , suf-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "parallel",
          "although",
          "discuss",
          "technique",
          "much"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "higher performance. Another performance goal will be to reduce write",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "higher",
          "performance",
          "another",
          "performance",
          "goal",
          "reduce",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand from raw flash to flash-based ssds",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "flash",
          "flash",
          "based",
          "ssds"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "6 FTL Organization: A Bad Approach",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "44.6 FTL Organization: A Bad Approach\nThe simplest organization of an FTL would be something we call di-\nrect mapped . In this approach, a read to logical page N is mapped di-\nrectly to a read of physical page N. A write to logical page N is more\ncomplicated; the FTL \ufb01rst has to read in the entire block that pa ge N is\ncontained within; it then has to erase the block; \ufb01nally , the FT L programs\nthe old pages as well as the new one.\nAs you can probably guess, the direct-mapped FTL has many prob-\nlems, both in terms of performance as well as reliability . The pe rformance\nproblems come on each write: the device has to read in the entire b lock\n(costly), erase it (quite costly), and then program it (costly). The end re-\nsult is severe write ampli\ufb01cation (proportional to the number of p ages\nin a block) and as a result, terrible write performance, even sl ower than\ntypical hard drives with their mechanical seeks and rotationa l delays.\nEven worse is the reliability of this approach. If \ufb01le system met adata\nor user \ufb01le data is repeatedly overwritten, the same block is era sed and\nprogrammed, over and over , rapidly wearing it out and potentially los-\ning data. The direct mapped approach simply gives too much contr ol\nover wear out to the client workload; if the workload does not spread\nwrite load evenly across its logical blocks, the underlying phys ical blocks\ncontaining popular data will quickly wear out. For both reliabili ty and\nperformance reasons, a direct-mapped FTL is a bad idea.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "FTL Organization: A Bad Approach",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "organization",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "rect mapped . In this approach, a read to logical page N is mapped di-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rect",
          "mapped",
          "approach",
          "read",
          "logical",
          "page",
          "mapped"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Even worse is the reliability of this approach. If \ufb01le system met adata",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "even",
          "worse",
          "reliability",
          "approach",
          "system",
          "adata"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ing data. The direct mapped approach simply gives too much contr ol",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "data",
          "direct",
          "mapped",
          "approach",
          "simply",
          "gives",
          "much",
          "contr"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "7 A Log-Structured FTL",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "44.7 A Log-Structured FTL\nFor these reasons, most FTLs today are log structured , an idea useful\nin both storage devices (as we\u2019ll see now) and \ufb01le systems above the m (as\nwe\u2019ll see in the chapter on log-structured \ufb01le systems ). Upon a write to\nlogical block N, the device appends the write to the next free spot in the\ncurrently-being-written-to block; we call this style of writ ing logging. T o\nallow for subsequent reads of block N, the device keeps a mapping table\n(in its memory , and persistent, in some form, on the device); this table\nstores the physical address of each logical block in the system.\nLet\u2019s go through an example to make sure we understand how the\nbasic log-based approach works. T o the client, the device looks li ke a\ntypical disk, in which it can read and write 512-byte sectors ( or groups of\nsectors). For simplicity , assume that the client is reading or w riting 4-KB\nsized chunks. Let us further assume that the SSD contains some lar ge\nnumber of 16-KB sized blocks, each divided into four 4-KB pages; these\nparameters are unrealistic (\ufb02ash blocks usually consist of more pages) but\nwill serve our didactic purposes quite well.\nAssume the client issues the following sequence of operations:\n\u2022 W rite(100) with contents a1\n\u2022 W rite(101) with contents a2\n\u2022 W rite(2000) with contents b1\n\u2022 W rite(2001) with contents b2\nThese logical block addresses (e.g., 100) are used by the client of the\nSSD (e.g., a \ufb01le system) to remember where information is located.\nInternally , the device must transform these block writes into the erase\nand program operations supported by the raw hardware, and somehow\nrecord, for each logical block address, which physical page of the SSD\nstores its data. Assume that all blocks of the SSD are currently not v alid,\nand must be erased before any page can be programmed. Here we show\nthe initial state of our SSD, with all pages marked INVALID (i):\n0 1 2Block:\nPage:\nContent:\nState:\n00\ni\n01\ni\n02\ni\n03\ni\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nWhen the \ufb01rst write is received by the SSD (to logical block 100), t he\nFTL decides to write it to physical block 0, which contains four p hysical\npages: 0, 1, 2, and 3. Because the block is not erased, we cannot wr ite to\nit yet; the device must \ufb01rst issue an erase command to block 0. Doi ng so\nleads to the following state:\n0 1 2Block:\nPage:\nContent:\nState:\n00\nE\n01\nE\n02\nE\n03\nE\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Let\u2019s go through an example to make sure we understand how the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "make",
          "sure",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "basic log-based approach works. T o the client, the device looks li ke a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "based",
          "approach",
          "works",
          "client",
          "device",
          "looks"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand a log-structured ftl",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "structured"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand w rite(100) with contents a1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "contents"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand w rite(101) with contents a2",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "contents"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand w rite(2000) with contents b1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "contents"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand w rite(2001) with contents b2",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "contents"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FL A S H -B A S E D SSD S 9",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FL A S H -B A S E D SSD S 9\nBlock 0 is now ready to be programmed. Most SSDs will write pages\nin order (i.e., low to high), reducing reliability problems rel ated to pro-\ngram disturbance . The SSD then directs the write of logical block 100\ninto physical page 0:\n0 1 2Block:\nPage:\nContent:\nState:\n00\na1\nV\n01\nE\n02\nE\n03\nE\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nBut what if the client wants to read logical block 100? How can it \ufb01nd\nwhere it is? The SSD must transform a read issued to logical block 10 0\ninto a read of physical page 0. T o accommodate such functionality , when\nthe FTL writes logical block 100 to physical page 0, it records th is fact in\nan in-memory mapping table . W e will track the state of this mapping\ntable in the diagrams as well:\nMemory\nFlash\nChip\nTable: 100 0\n0 1 2Block:\nPage:\nContent:\nState:\n00\na1\nV\n01\nE\n02\nE\n03\nE\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nNow you can see what happens when the client writes to the SSD.\nThe SSD \ufb01nds a location for the write, usually just picking the next free\npage; it then programs that page with the block\u2019s contents, and re cords\nthe logical-to-physical mapping in its mapping table. Subsequ ent reads\nsimply use the table to translate the logical block address presented by\nthe client into the physical page number required to read the data.\nLet\u2019s now examine the rest of the writes in our example write strea m:\n101, 2000, and 2001. After writing these blocks, the state of th e device is:\nMemory\nFlash\nChip\nTable: 100 0 101 1 2000 2 2001 3\n0 1 2Block:\nPage:\nContent:\nState:\n00\na1\nV\n01\na2\nV\n02\nb1\nV\n03\nb2\nV\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nThe log-based approach by its nature improves performance (eras es\nonly being required once in a while, and the costly read-modify-w rite of\nthe direct-mapped approach avoided altogether), and greatly e nhances\nreliability . The FTL can now spread writes across all pages, pe rforming\nwhat is called wear leveling and increasing the lifetime of the device;\nwe\u2019ll discuss wear leveling further below .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "simply use the table to translate the logical block address presented by",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simply",
          "table",
          "translate",
          "logical",
          "block",
          "address",
          "presented"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The log-based approach by its nature improves performance (eras es",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "based",
          "approach",
          "nature",
          "improves",
          "performance",
          "eras"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "the direct-mapped approach avoided altogether), and greatly e nhances",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "direct",
          "mapped",
          "approach",
          "avoided",
          "altogether",
          "greatly",
          "nhances"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_9",
        "text": "understand Memory\nFlash\nChip\nTable: 100 0 101 1 2000 2 2001 3",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "memory\nflash\nchip\ntable"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "8 Garbage Collection",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "44.8 Garbage Collection\nThe \ufb01rst cost of any log-structured approach such as this one is tha t\ngarbage is created, and therefore garbage collection (i.e., dead-block recla-\nmation) must be performed. Let\u2019s use our continued example to make\nsense of this. Recall that logical blocks 100, 101, 2000, and 200 1 have been\nwritten to the device.\nNow , let\u2019s assume that blocks 100 and 101 are written to again, wi th\ncontents c1 and c2. The writes are written to the next free pages (in this\ncase, physical pages 4 and 5), and the mapping table is update d accord-\ningly . Note that the device must have \ufb01rst erased block 1 to make such\nprogramming possible:\nMemory\nFlash\nChip\nTable: 100 4 101 5 2000 2 2001 3\n0 1 2Block:\nPage:\nContent:\nState:\n00\na1\nV\n01\na2\nV\n02\nb1\nV\n03\nb2\nV\n04\nc1\nV\n05\nc2\nV\n06\nE\n07\nE\n08\ni\n09\ni\n10\ni\n11\ni\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The \ufb01rst cost of any log-structured approach such as this one is tha t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cost",
          "structured",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "garbage is created, and therefore garbage collection (i.e., dead-block recla-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "garbage",
          "created",
          "therefore",
          "garbage",
          "collection",
          "dead",
          "block",
          "recla"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Flash\nChip\nTable: 100 4 101 5 2000 2 2001 3",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "flash\nchip\ntable"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand garbage collection",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "garbage",
          "collection"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FL A S H -B A S E D SSD S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FL A S H -B A S E D SSD S 11\nThe problem we have now should be obvious: physical pages 0 and\n1, although marked VALID, have garbage in them, i.e., the old versions\nof blocks 100 and 101. Because of the log-structured nature of the d e-\nvice, overwrites create garbage blocks, which the device must reclaim to\nprovide free space for new writes to take place.\nThe process of \ufb01nding garbage blocks (also called dead blocks ) and\nreclaiming them for future use is called garbage collection , and it is an\nimportant component of any modern SSD. The basic process is simple:\n\ufb01nd a block that contains one or more garbage pages, read in the live\n(non-garbage) pages from that block, write out those live pages to the\nlog, and (\ufb01nally) reclaim the entire block for use in writing.\nLet\u2019s now illustrate with an example. The device decides it wan ts to\nreclaim any dead pages within block 0 above. Block 0 has two dead b locks\n(pages 0 and 1) and two lives blocks (pages 2 and 3, which contain blocks\n2000 and 2001, respectively). T o do so, the device will:\n\u2022 Read live data (pages 2 and 3) from block 0\n\u2022 W rite live data to end of the log\n\u2022 Erase block 0 (freeing it for later usage)\nFor the garbage collector to function, there must be enough informa -\ntion within each block to enable the SSD to determine whether each page\nis live or dead. One natural way to achieve this end is to store, a t some\nlocation within each block, information about which logical blocks a re\nstored within each page. The device can then use the mapping ta ble to\ndetermine whether each page within the block holds live data or n ot.\nFrom our example above (before the garbage collection has taken pla ce),\nblock 0 held logical blocks 100, 101, 2000, 2001. By checking the mapping\ntable (which, before garbage collection, contained 100->4, 101->5,\n2000->2, 2001->3), the device can readily determine whether each of\nthe pages within the SSD block holds live information. For example, 2 000\nand 2001 clearly are still pointed to by the map; 100 and 101 are not and\ntherefore are candidates for garbage collection.\nWhen this garbage collection process is complete in our example, t he\nstate of the device is:\nMemory\nFlash\nChip\nTable: 100 4 101 5 2000 6 2001 7\n0 1 2Block:\nPage:\nContent:\nState:\n00\nE\n01\nE\n02\nE\n03\nE\n04\nc1\nV\n05\nc2\nV\n06\nb1\nV\n07\nb2\nV\n08\ni\n09\ni\n10\ni\n11\ni\nAs you can see, garbage collection can be expensive, requiring r eading\nand rewriting of live data. The ideal candidate for reclamation is a block\nthat consists of only dead pages; in this case, the block can immed iately\nbe erased and used for new data, without expensive data migrati on.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "vice, overwrites create garbage blocks, which the device must reclaim to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "vice",
          "overwrites",
          "create",
          "garbage",
          "blocks",
          "device",
          "must",
          "reclaim"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "important component of any modern SSD. The basic process is simple:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "component",
          "modern",
          "basic",
          "process",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand the device will: \u2022 Read live data (pages 2 and 3) from block 0",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the device will",
          "read",
          "live",
          "data",
          "pages",
          "block"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Flash\nChip\nTable: 100 4 101 5 2000 6 2001 7",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "flash\nchip\ntable"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand read live data (pages 2 and 3) from block 0",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "live",
          "data",
          "pages",
          "block"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand w rite live data to end of the log",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "rite",
          "live",
          "data"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand erase block 0 (freeing it for later usage)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "erase",
          "block",
          "freeing",
          "later",
          "usage"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "9 Mapping T able Size",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "44.9 Mapping T able Size\nThe second cost of log-structuring is the potential for extremely l arge\nmapping tables, with one entry for each 4-KB page of the device. W ith a\nlarge 1-TB SSD, for example, a single 4-byte entry per 4-KB page r esults\nin 1 GB of memory needed the device, just for these mappings! Thus , this\npage-level FTL scheme is impractical.\nBlock-Based Mapping\nOne approach to reduce the costs of mapping is to only keep a pointer per\nblock of the device, instead of per page, reducing the amount of mapping\ninformation by a factor of Sizeblock\nSizepage\n. This block-level FTL is akin to having\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One approach to reduce the costs of mapping is to only keep a pointer per",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "reduce",
          "costs",
          "mapping",
          "keep",
          "pointer"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand mapping t able size",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "mapping",
          "able",
          "size"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FL A S H -B A S E D SSD S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FL A S H -B A S E D SSD S 13\nbigger page sizes in a virtual memory system; in that case, you u se fewer\nbits for the VPN and have a larger offset in each virtual address .\nUnfortunately , using a block-based mapping inside a log-based FTL\ndoes not work very well for performance reasons. The biggest problem\narises when a \u201csmall write\u201d occurs (i.e., one that is less than t he size of\na physical block). In this case, the FTL must read a large amount of live\ndata from the old block and copy it into a new one (along with the data\nfrom the small write). This data copying increases write ampli \ufb01cation\ngreatly and thus decreases performance.\nT o make this issue more clear , let\u2019s look at an example. Assume the\nclient previously wrote out logical blocks 2000, 2001, 2002, and 2 003 (with\ncontents, a, b, c, d), and that they are located within physical block\n1 at physical pages 4, 5, 6, and 7. With per-page mappings, the transla-\ntion table would have to record four mappings for these logical block s:\n2000\u21924, 2001 \u21925, 2002 \u21926, 2003 \u21927.\nIf, instead, we use block-level mapping, the FTL only needs to r ecord\na single address translation for all of this data. The address ma pping,\nhowever , is slightly different than our previous examples. Spec i\ufb01cally ,\nwe think of the logical address space of the device as being choppe d into\nchunks that are the size of the physical blocks within the \ufb02ash. Thus,\nthe logical block address consists of two portions: a chunk number a nd\nan offset. Because we are assuming four logical blocks \ufb01t within e ach\nphysical block, the offset portion of the logical addresses requir es 2 bits;\nthe remaining (most signi\ufb01cant) bits form the chunk number .\nLogical blocks 2000, 2001, 2002, and 2003 all have the same chun k\nnumber (500), and have different offsets (0, 1, 2, and 3, respe ctively).\nThus, with a block-level mapping, the FTL records that chunk 50 0 maps\nto block 1 (starting at physical page 4), as shown in this diagra m:\nMemory\nFlash\nChip\nTable: 500 4\n0 1 2Block:\nPage:\nContent:\nState:\n00\ni\n01\ni\n02\ni\n03\ni\n04\na\nV\n05\nb\nV\n06\nc\nV\n07\nd\nV\n08\ni\n09\ni\n10\ni\n11\ni\nIn a block-based FTL, reading is easy . First, the FTL extracts the chunk\nnumber from the logical block address presented by the client, b y taking\nthe topmost bits out of the address. Then, the FTL looks up the chunk-\nnumber to physical-page mapping in the table. Finally , the F TL computes\nthe address of the desired \ufb02ash page by adding the offset from the logical\naddress to the physical address of the block.\nFor example, if the client issues a read to logical address 2002 , the de-\nvice extracts the logical chunk number (500), looks up the trans lation in\nthe mapping table (\ufb01nding 4), and adds the offset from the logica l ad-\ndress (2) to the translation (4). The resulting physical-pag e address (6) is\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 FL A S H -B A S E D SSD S\nwhere the data is located; the FTL can then issue the read to tha t physical\naddress and obtain the desired data ( c).\nBut what if the client writes to logical block 2002 (with content s c\u2019)?\nIn this case, the FTL must read in 2000, 2001, and 2003, and the n write\nout all four logical blocks in a new location, updating the mapping t able\naccordingly . Block 1 (where the data used to reside) can then be erased\nand reused, as shown here.\nMemory\nFlash\nChip\nTable: 500 8\n0 1 2Block:\nPage:\nContent:\nState:\n00\ni\n01\ni\n02\ni\n03\ni\n04\nE\n05\nE\n06\nE\n07\nE\n08\na\nV\n09\nb\nV\n10\nc\u2019\nV\n11\nd\nV\nAs you can see from this example, while block level mappings grea tly\nreduce the amount of memory needed for translations, they cause si gnif-\nicant performance problems when writes are smaller than the ph ysical\nblock size of the device; as real physical blocks can be 256KB or la rger ,\nsuch writes are likely to happen quite often. Thus, a better sol ution is\nneeded. Can you sense that this is the part of the chapter where w e tell\nyou what that solution is? Better yet, can you \ufb01gure it out yourself, before\nreading on?\nHybrid Mapping\nT o enable \ufb02exible writing but also reduce mapping costs, many modern\nFTLs employ a hybrid mapping technique. With this approach, the FTL\nkeeps a few blocks erased and directs all writes to them; these are called\nlog blocks . Because the FTL wants to be able to write any page to any\nlocation within the log block without all the copying required by a p ure\nblock-based mapping, it keeps per-page mappings for these log blocks.\nThe FTL thus logically has two types of mapping table in its memor y: a\nsmall set of per-page mappings in what we\u2019ll call the log table , and a larger\nset of per-block mappings in the data table . When looking for a particular\nlogical block, the FTL will \ufb01rst consult the log table; if the logic al block\u2019s\nlocation is not found there, the FTL will then consult the data tabl e to \ufb01nd\nits location and then access the requested data.\nThe key to the hybrid mapping strategy is keeping the number of log\nblocks small. T o keep the number of log blocks small, the FTL has to pe-\nriodically examine log blocks (which have a pointer per page) and switch\nthem into blocks that can be pointed to by only a single block pointe r .\nThis switch is accomplished by one of three main techniques, bas ed on\nthe contents of the block [KK+02].\nFor example, let\u2019s say the FTL had previously written out logical p ages\n1000, 1001, 1002, and 1003, and placed them in physical block 2 (physical\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "FTLs employ a hybrid mapping technique. With this approach, the FTL",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ftls",
          "employ",
          "hybrid",
          "mapping",
          "technique",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "log blocks . Because the FTL wants to be able to write any page to any",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "blocks",
          "wants",
          "able",
          "write",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The key to the hybrid mapping strategy is keeping the number of log",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hybrid",
          "mapping",
          "strategy",
          "keeping",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "This switch is accomplished by one of three main techniques, bas ed on",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "switch",
          "accomplished",
          "three",
          "main",
          "techniques"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "FL A S H -B A S E D SSD S 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "FL A S H -B A S E D SSD S 15\npages 8, 9, 10, 11); assume the contents of the writes to 1000, 10 01, 1002,\nand 1003 are a, b, c, and d, respectively .\nMemory\nFlash\nChip\nLog Table:\nData Table: 250 8\n0 1 2Block:\nPage:\nContent:\nState:\n00\ni\n01\ni\n02\ni\n03\ni\n04\ni\n05\ni\n06\ni\n07\ni\n08\na\nV\n09\nb\nV\n10\nc\nV\n11\nd\nV\nNow assume that the client overwrites each of these blocks (with d ata\na\u2019, b\u2019, c\u2019, and d\u2019), in the exact same order , in one of the currently avail-\nable log blocks, say physical block 0 (physical pages 0, 1, 2, and 3). In this\ncase, the FTL will have the following state:\nMemory\nFlash\nChip\nLog Table: 1000 0 1001 1 1002 2 1003 3\nData Table: 250 8\n0 1 2Block:\nPage:\nContent:\nState:\n00\na\u2019\nV\n01\nb\u2019\nV\n02\nc\u2019\nV\n03\nd\u2019\nV\n04\ni\n05\ni\n06\ni\n07\ni\n08\na\nV\n09\nb\nV\n10\nc\nV\n11\nd\nV\nBecause these blocks have been written exactly in the same man ner as\nbefore, the FTL can perform what is known as a switch merge . In this\ncase, the log block (0) now becomes the storage location for blocks 0, 1, 2,\nand 3, and is pointed to by a single block pointer; the old block (2) i s now\nerased and used as a log block. In this best case, all the per-pag e pointers\nrequired replaced by a single block pointer .\nMemory\nFlash\nChip\nLog Table:\nData Table: 250 0\n0 1 2Block:\nPage:\nContent:\nState:\n00\na\u2019\nV\n01\nb\u2019\nV\n02\nc\u2019\nV\n03\nd\u2019\nV\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nThis switch merge is the best case for a hybrid FTL. Unfortunate ly ,\nsometimes the FTL is not so lucky . Imagine the case where we have\nthe same initial conditions (logical blocks 1000 ... 1003 stored i n physi-\ncal block 2) but then the client overwrites logical blocks 1000 an d 1001.\nWhat do you think happens in this case? Why is it more challengin g\nto handle? (think before looking at the result on the next page)\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "before, the FTL can perform what is known as a switch merge . In this",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "perform",
          "known",
          "switch",
          "merge"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand Flash\nChip\nLog Table: 1000 0 1001 1 1002 2 1003 3",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "flash\nchip\nlog table"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand known as a switch merge . In this\ncase, the log block (0) now becomes the storage location for blocks 0, 1, 2,\nand 3, and is pointed to by a single block pointer; the old block (2) i s now\nerased and used as a log block. In this best case, all the per-pag e pointers\nrequired replaced by a single block pointer .\nMemory\nFlash\nChip\nLog Table:\nData Table: 250 0\n0 1 2Block:\nPage:\nContent:\nState:\n00\na\u2019\nV\n01\nb\u2019\nV\n02\nc\u2019\nV\n03\nd\u2019\nV\n04\ni\n05\ni\n06\ni\n07\ni\n08\ni\n09\ni\n10\ni\n11\ni\nThis switch merge is the best case for a hybrid FTL. Unfortunate ly ,\nsometimes the FTL is not so lucky . Imagine the case where we have\nthe same initial conditions (logical blocks 1000 ... 1003 stored i n physi-\ncal block 2) but then the client overwrites logical blocks 1000 an d 1001.\nWhat do you think happens in this case",
        "type": "question_concept",
        "difficulty": "advanced",
        "keywords": [
          "known",
          "switch",
          "merge",
          "case",
          "block",
          "becomes",
          "storage",
          "location"
        ],
        "confidence": 0.5
      },
      {
        "id": "question_concept_2",
        "text": "understand it more challengin g\nto handle",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "challengin",
          "handle"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 FL A S H -B A S E D SSD S\nMemory\nFlash\nChip\nLog Table: 1000 0 1001 1\nData Table: 250 8\n0 1 2Block:\nPage:\nContent:\nState:\n00\na\u2019\nV\n01\nb\u2019\nV\n02\ni\n03\ni\n04\ni\n05\ni\n06\ni\n07\ni\n08\na\nV\n09\nb\nV\n10\nc\nV\n11\nd\nV\nT o reunite the other pages of this physical block, and thus be abl e to re-\nfer to them by only a single block pointer , the FTL performs what is called\na partial merge . In this operation, logical blocks 1002 and 1003 are read\nfrom physical block 2, and then appended to the log. The resultin g state\nof the SSD is the same as the switch merge above; however , in this cas e,\nthe FTL had to perform extra I/O to achieve its goals, thus incre asing\nwrite ampli\ufb01cation.\nThe \ufb01nal case encountered by the FTL known as a full merge , and re-\nquires even more work. In this case, the FTL must pull together pa ges\nfrom many other blocks to perform cleaning. For example, imagine t hat\nlogical blocks 0, 4, 8, and 12 are written to log block A. T o switch this log\nblock into a block-mapped page, the FTL must \ufb01rst create a data b lock\ncontaining logical blocks 0, 1, 2, and 3, and thus the FTL must rea d 1, 2,\nand 3 from elsewhere and then write out 0, 1, 2, and 3 together . Nex t, the\nmerge must do the same for logical block 4, \ufb01nding 5, 6, and 7 and re con-\nciling them into a single physical block. The same must be done f or logi-\ncal blocks 8 and 12, and then (\ufb01nally), the log block A can be freed. Fre-\nquent full merges, as is not surprising, can seriously harm per formance\nand thus should be avoided when at all possible [GY+09].\nPage Mapping Plus Caching\nGiven the complexity of the hybrid approach above, others have sug -\ngested simpler ways to reduce the memory load of page-mapped FTL s.\nProbably the simplest is just to cache only the active parts of th e FTL in\nmemory , thus reducing the amount of memory needed [GY+09].\nThis approach can work well. For example, if a given workload only\naccesses a small set of pages, the translations of those pages wil l be stored\nin the in-memory FTL, and performance will be excellent without high\nmemory cost. Of course, the approach can also perform poorly . If mem-\nory cannot contain the working set of necessary translations, each access\nwill minimally require an extra \ufb02ash read to \ufb01rst bring in the missing\nmapping before being able to access the data itself. Even worse , to make\nroom for the new mapping, the FTL might have to evict an old map-\nping, and if that mapping is dirty (i.e., not yet written to the \ufb02ash per-\nsistently), an extra write will also be incurred. However , in many cases,\nthe workload will display locality , and this caching approach wi ll both\nreduce memory overheads and keep performance high.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the FTL had to perform extra I/O to achieve its goals, thus incre asing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "perform",
          "extra",
          "achieve",
          "goals",
          "thus",
          "incre",
          "asing"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The \ufb01nal case encountered by the FTL known as a full merge , and re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "case",
          "encountered",
          "known",
          "full",
          "merge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "block into a block-mapped page, the FTL must \ufb01rst create a data b lock",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "block",
          "block",
          "mapped",
          "page",
          "must",
          "create",
          "data",
          "lock"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Given the complexity of the hybrid approach above, others have sug -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "given",
          "complexity",
          "hybrid",
          "approach",
          "others"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "This approach can work well. For example, if a given workload only",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "work",
          "well",
          "example",
          "given",
          "workload"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "memory cost. Of course, the approach can also perform poorly . If mem-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "memory",
          "cost",
          "course",
          "approach",
          "also",
          "perform",
          "poorly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "mapping before being able to access the data itself. Even worse , to make",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mapping",
          "able",
          "access",
          "data",
          "even",
          "worse",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "the workload will display locality , and this caching approach wi ll both",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "workload",
          "display",
          "locality",
          "caching",
          "approach"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "10 W ear Leveling",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "44.10 W ear Leveling\nFinally , a related background activity that modern FTLs must i mple-\nment is wear leveling , as introduced above. The basic idea is simple:\nbecause multiple erase/program cycles will wear out a \ufb02ash bloc k, the\nFTL should try its best to spread that work across all the blocks of t he de-\nvice evenly . In this manner , all blocks will wear out at roughly t he same\ntime, instead of a few \u201cpopular \u201d blocks quickly becoming unusabl e.\nThe basic log-structuring approach does a good initial job of spread ing\nout write load, and garbage collection helps as well. However , some times\na block will be \ufb01lled with long-lived data that does not get over-wr itten;\nin this case, garbage collection will never reclaim the block, a nd thus it\ndoes not receive its fair share of the write load.\nT o remedy this problem, the FTL must periodically read all the l ive\ndata out of such blocks and re-write it elsewhere, thus making th e block\navailable for writing again. This process of wear leveling incr eases the\nwrite ampli\ufb01cation of the SSD, and thus decreases performance as e xtra\nI/O is required to ensure that all blocks wear at roughly the sam e rate.\nMany different algorithms exist in the literature [A+08, M+1 4]; read more\nif you are interested.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The basic log-structuring approach does a good initial job of spread ing",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "structuring",
          "approach",
          "good",
          "initial",
          "spread"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Many different algorithms exist in the literature [A+08, M+1 4]; read more",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "many",
          "different",
          "algorithms",
          "exist",
          "literature",
          "read"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand w ear leveling",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "leveling"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "44",
    "title": "11 SSD Performance And Cost",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "44.11 SSD Performance And Cost\nBefore closing, let\u2019s examine the performance and cost of modern SSDs,\nto better understand how they will likely be used in persisten t storage\nsystems. In both cases, we\u2019ll compare to classic hard-disk driv es (HDDs),\nand highlight the biggest differences between the two.\nPerformance\nUnlike hard disk drives, \ufb02ash-based SSDs have no mechanical com po-\nnents, and in fact are in many ways more similar to DRAM, in that they\nare \u201crandom access\u201d devices. The biggest difference in perfor mance, as\ncompared to disk drives, is realized when performing random rea ds and\nwrites; while a typical disk drive can only perform a few hundre d ran-\ndom I/Os per second, SSDs can do much better . Here, we use some data\nfrom modern SSDs to see just how much better SSDs perform; we\u2019re par-\nticularly interested in how well the FTLs hide the performance issues of\nthe raw chips.\nT able 44.4 shows some performance data for three different SSDs and\none top-of-the-line hard drive; the data was taken from a few diff erent\nonline sources [S13, T15]. The left two columns show random I/O per-\nformance, and the right two columns sequential; the \ufb01rst three rows show\ndata for three different SSDs (from Samsung, Seagate, and Intel), a nd the\nlast row shows performance for a hard disk drive (or HDD), in this case\na Seagate high-end drive.\nW e can learn a few interesting facts from the table. First, and most\ndramatic, is the difference in random I/O performance between the SSDs\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to better understand how they will likely be used in persisten t storage",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "better",
          "understand",
          "likely",
          "used",
          "persisten",
          "storage"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "systems. In both cases, we\u2019ll compare to classic hard-disk driv es (HDDs),",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "systems",
          "cases",
          "compare",
          "classic",
          "hard",
          "disk",
          "driv",
          "hdds"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "compared to disk drives, is realized when performing random rea ds and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compared",
          "disk",
          "drives",
          "realized",
          "performing",
          "random"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "W e can learn a few interesting facts from the table. First, and most",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "interesting",
          "facts",
          "table",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand ssd performance and cost",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "cost"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "18 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "18 FL A S H -B A S E D SSD S\nRandom Sequential\nReads W rites Reads W rites\nDevice (MB/s) (MB/s) (MB/s) (MB/s)\nSamsung 840 Pro SSD 103 287 421 384\nSeagate 600 SSD 84 252 424 374\nIntel SSD 335 SSD 39 222 344 354\nSeagate Savvio 15K.3 HDD 2 2 223 223\nFigure 44.4: SSDs And Hard Drives: Performance Comparison\nand the lone hard drive. While the SSDs obtain tens or even hundreds of\nMB/s in random I/Os, this \u201chigh performance\u201d hard drive has a pe ak of\njust a couple MB/s (in fact, we rounded up to get to 2 MB/s). Second, you\ncan see that in terms of sequential performance, there is much l ess of a dif-\nference; while the SSDs perform better , a hard drive is still a good choice\nif sequential performance is all you need. Third, you can see tha t SSD ran-\ndom read performance is not as good as SSD random write performance.\nThe reason for such unexpectedly good random-write performance is\ndue to the log-structured design of many SSDs, which transforms ra n-\ndom writes into sequential ones and improves performance. Final ly , be-\ncause SSDs exhibit some performance difference between sequent ial and\nrandom I/Os, many of the techniques we will learn in subsequent chap-\nters about how to build \ufb01le systems for hard drives are still appl icable to\nSSDs; although the magnitude of difference between sequential a nd ran-\ndom I/Os is smaller , there is enough of a gap to carefully consider how\nto design \ufb01le systems to reduce random I/Os.\nCost\nAs we saw above, the performance of SSDs greatly outstrips modern har d\ndrives, even when performing sequential I/O. So why haven\u2019t SSDs c om-\npletely replaced hard drives as the storage medium of choice? Th e an-\nswer is simple: cost, or more speci\ufb01cally , cost per unit of capacit y . Cur-\nrently [A15], an SSD costs something like $150 for a 250-GB drive; s uch\nan SSD costs 60 cents per GB. A typical hard drive costs roughly $50 f or\n1-TB of storage, which means it costs 5 cents per GB. There is stil l more\nthan a 10 \u00d7 difference in cost between these two storage media.\nThese performance and cost differences dictate how large-scal e stor-\nage systems are built. If performance is the main concern, SSDs ar e a\nterri\ufb01c choice, particularly if random read performance is imp ortant. If,\non the other hand, you are assembling a large data center and wish to\nstore massive amounts of information, the large cost difference wi ll drive\nyou towards hard drives. Of course, a hybrid approach can make sen se\n\u2013 some storage systems are being assembled with both SSDs and hard\ndrives, using a smaller number of SSDs for more popular \u201chot\u201d data and\ndelivering high performance, while storing the rest of the \u201ccold er \u201d (less\nused) data on hard drives to save on cost. As long as the price gap ex ists,\nhard drives are here to stay .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "due to the log-structured design of many SSDs, which transforms ra n-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "structured",
          "design",
          "many",
          "ssds",
          "transforms"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "random I/Os, many of the techniques we will learn in subsequent chap-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "random",
          "many",
          "techniques",
          "learn",
          "subsequent",
          "chap"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "ters about how to build \ufb01le systems for hard drives are still appl icable to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ters",
          "build",
          "systems",
          "hard",
          "drives",
          "still",
          "appl",
          "icable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "to design \ufb01le systems to reduce random I/Os.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "systems",
          "reduce",
          "random"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "you towards hard drives. Of course, a hybrid approach can make sen se",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "towards",
          "hard",
          "drives",
          "course",
          "hybrid",
          "approach",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand which: it costs 5 cents per GB. There is stil l more",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "which",
          "costs",
          "cents",
          "stil"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 4: SSDs And Hard Drives: Performance Comparison",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "ssds",
          "hard",
          "drives",
          "performance",
          "comparison"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand swer is simple: cost, or more speci\ufb01cally , cost per unit of capacit y . Cur-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "swer is simple",
          "cost",
          "cost",
          "unit",
          "capacit"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "44",
    "title": "12 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "44.12 Summary\nFlash-based SSDs are becoming a common presence in laptops, desk-\ntops, and servers inside the datacenters that power the world\u2019s e conomy .\nThus, you should probably know something about them, right?\nHere\u2019s the bad news: this chapter (like many in this book) is just the\n\ufb01rst step in understanding the state of the art. Some places to ge t some\nmore information about the raw technology include research on actua l\ndevice performance (such as that by Chen et al. [CK+09] and Gru pp et\nal. [GC+09]), issues in FTL design (including works by Agrawa l et al.\n[A+08], Gupta et al. [GY+09], Huang et al. [H+14], Kim et al. [ KK+02],\nLee et al. [L+07], and Zhang et al. [Z+12]), and even distribu ted systems\ncomprised of \ufb02ash (including Gordon [CG+09] and CORFU [B+12]). A nd,\nif we may say so, a really good overview of all the things you need to do\nto extract high performance from an SSD can be found in a paper on the\n\u201cunwritten contract\u201d [HK+17].\nDon\u2019t just read academic papers; also read about recent advance s in\nthe popular press (e.g., [V12]). Therein you\u2019ll learn more pract ical (but\nstill useful) information, such as Samsung\u2019s use of both TLC and SLC c ells\nwithin the same SSD to maximize performance (SLC can buffer write s\nquickly) as well as capacity (TLC can store more bits per cell). And this\nis, as they say , just the tip of the iceberg. Dive in and learn mor e about\nthis \u201ciceberg\u201d of research on your own, perhaps starting with Ma e t al.\u2019s\nexcellent (and recent) survey [M+14]. Be careful though; ice bergs can sink\neven the mightiest of ships [W15].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus, you should probably know something about them, right?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "probably",
          "know",
          "something",
          "right"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "\ufb01rst step in understanding the state of the art. Some places to ge t some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "step",
          "understanding",
          "state",
          "places"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "al. [GC+09]), issues in FTL design (including works by Agrawa l et al.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "issues",
          "design",
          "including",
          "works",
          "agrawa"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "the popular press (e.g., [V12]). Therein you\u2019ll learn more pract ical (but",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "popular",
          "press",
          "therein",
          "learn",
          "pract",
          "ical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "is, as they say , just the tip of the iceberg. Dive in and learn mor e about",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "iceberg",
          "dive",
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand s the bad news: this chapter (like many in this book) is just the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s the bad news",
          "chapter",
          "like",
          "many",
          "book"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "20 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "20 FL A S H -B A S E D SSD S\nAS I D E : K E Y SSD T E R M S\n\u2022 A \ufb02ash chip consists of many banks, each of which is organized into\nerase blocks (sometimes just called blocks). Each block is further\nsubdivided into some number of pages.\n\u2022 Blocks are large (128KB\u20132MB) and contain many pages, which are\nrelatively small (1KB\u20138KB).\n\u2022 T o read from \ufb02ash, issue a read command with an address and\nlength; this allows a client to read one or more pages.\n\u2022 W riting \ufb02ash is more complex. First, the client must erase the en-\ntire block (which deletes all information within the block). The n,\nthe client can program each page exactly once, thus completing the\nwrite.\n\u2022 A new trim operation is useful to tell the device when a particular\nblock (or range of blocks) is no longer needed.\n\u2022 Flash reliability is mostly determined by wear out ; if a block is\nerased and programmed too often, it will become unusable.\n\u2022 A \ufb02ash-based solid-state storage device (SSD) behaves as if it were\na normal block-based read/write disk; by using a \ufb02ash translation\nlayer (FTL), it transforms reads and writes from a client into reads,\nerases, and programs to underlying \ufb02ash chips.\n\u2022 Most FTLs are log-structured, which reduces the cost of writing\nby minimizing erase/program cycles. An in-memory translation\nlayer tracks where logical writes were located within the phys ical\nmedium.\n\u2022 One key problem with log-structured FTLs is the cost of garbage\ncollection, which leads to write ampli\ufb01cation .\n\u2022 Another problem is the size of the mapping table, which can be-\ncome quite large. Using a hybrid mapping or just caching hot\npieces of the FTL are possible remedies.\n\u2022 One last problem is wear leveling ; the FTL must occasionally mi-\ngrate data from blocks that are mostly read in order to ensure said\nblocks also receive their share of the erase/program load.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand a \ufb02ash chip consists of many banks, each of which is organized into",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "chip",
          "consists",
          "many",
          "banks",
          "organized"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand blocks are large (128kb\u20132mb) and contain many pages, which are",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "blocks",
          "large",
          "contain",
          "many",
          "pages"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand t o read from \ufb02ash, issue a read command with an address and",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "read",
          "issue",
          "read",
          "command",
          "address"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand w riting \ufb02ash is more complex. first, the client must erase the en-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "riting",
          "complex",
          "first",
          "client",
          "must",
          "erase"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand a new trim operation is useful to tell the device when a particular",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "trim",
          "operation",
          "useful",
          "tell",
          "device",
          "particular"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand flash reliability is mostly determined by wear out ; if a block is",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "flash",
          "reliability",
          "mostly",
          "determined",
          "wear",
          "block"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "2014",
    "title": "Recent work showing how to really get the most out of worn-out \ufb02ash blocks; neat!",
    "document_source": "book.pdf",
    "start_line": 50,
    "type": "chapter",
    "content": "2014. Recent work showing how to really get the most out of worn-out \ufb02ash blocks; neat!\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "22 FL A S H -B A S E D SSD S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "22 FL A S H -B A S E D SSD S\n[J10] \u201cFailure Mechanisms and Models for Semiconductor Devices\u201d by Unknown a uthor . Re-\nport JEP122F , November 2010. A vailable on the internet at this excit ing so-called web site:\nhttp://www.jedec.org/sites/default/files/docs/JEP122F.pdf. A highly detailed\ndiscussion of what is going on at the device level and how such devices fai l. Only for those not faint of\nheart. Or physicists. Or both.\n[KK+02] \u201cA Space-Ef\ufb01cient Flash T ranslation Layer For Compact Flas h Systems\u201d by Jesung\nKim, Jong Min Kim, Sam H. Noh, Sang Lyul Min, Y ookun Cho. IEEE T ransactions on Con-\nsumer Electronics, V olume 48, Number 2, May 2002. One of the earliest proposals to suggest\nhybrid mappings.\n[L+07] \u201cA Log Buffer-Based Flash T ranslation Layer by Using Fully -Associative Sector T rans-\nlation. \u201d Sang-won Lee, T ae-Sun Chung, Dong-Ho Lee, Sangwon Park, Ha-Joo S ong. ACM\nT ransactions on Embedded Computing Systems, V olume 6, Number 3, July 2007 A terri\ufb01c paper\nabout how to build hybrid log/block mappings.\n[M+14] \u201cA Survey of Address T ranslation T echnologies for Flash Memor ies\u201d by Dongzhe Ma,\nJianhua Feng, Guoliang Li. ACM Computing Surveys, V olume 46, Numbe r 3, January 2014.\nProbably the best recent survey of \ufb02ash and related technologies.\n[S13] \u201cThe Seagate 600 and 600 Pro SSD Review\u201d by Anand Lal Shimpi. AnandT ech, May 7,\n2013. A vailable: http://www.anandtech.com/show/6935/seagate-600-ssd-review.\nOne of many SSD performance measurements available on the internet. Haven\u2019t heard of the internet?\nNo problem. Just go to your web browser and type \u201cinternet\u201d into the search tool . Y ou\u2019ll be amazed at\nwhat you can learn.\n[T15] \u201cPerformance Charts Hard Drives\u201d by T om\u2019s Hardware. January 201 5. A vailable here:\nhttp://www.tomshardware.com/charts/enterprise-hdd-charts. Y et another site\nwith performance data, this time focusing on hard drives.\n[V12] \u201cUnderstanding TLC Flash\u201d by Kristian V atto. AnandT ech, Septemb er , 2012. A vailable:\nhttp://www.anandtech.com/show/5067/understanding-tlc-nand. A short descrip-\ntion about TLC \ufb02ash and its characteristics.\n[W15] \u201cList of Ships Sunk by Icebergs\u201d by Many authors. A vailable at t his location on the\n\u201cweb\u201d: http://en.wikipedia.org/wiki/List\nof ships sunk by icebergs. Y es, there\nis a wikipedia page about ships sunk by icebergs. It is a really boring page and basically everyone knows\nthe only ship the iceberg-sinking-ma\ufb01a cares about is the Titanic.\n[Z+12] \u201cDe-indirection for Flash-based SSDs with Nameless W rites\u201d by Yiying Zhang, Leo\nPrasath Arulraj, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusse au. F AST \u201913, San Jose,\nCalifornia, February 2013. Our research on a new idea to reduce mapping table space; the key is to\nre-use the pointers in the \ufb01le system above to store locations of blocks, instead of add ing another level of\nindirection.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[J10] \u201cFailure Mechanisms and Models for Semiconductor Devices\u201d by Unknown a uthor . Re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "failure",
          "mechanisms",
          "models",
          "semiconductor",
          "devices",
          "unknown",
          "uthor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "what you can learn.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[V12] \u201cUnderstanding TLC Flash\u201d by Kristian V atto. AnandT ech, Septemb er , 2012. A vailable:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understanding",
          "flash",
          "kristian",
          "atto",
          "anandt",
          "septemb",
          "vailable"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "http://www.anandtech.com/show/5067/understanding-tlc-nand. A short descrip-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "anandtech",
          "show",
          "understanding",
          "nand",
          "short",
          "descrip"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "is a wikipedia page about ships sunk by icebergs. It is a really boring page and basically everyone knows",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wikipedia",
          "page",
          "ships",
          "sunk",
          "icebergs",
          "really",
          "boring",
          "page"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand called web site: http://www.jedec.org/sites/default/files/docs/JEP122F.pdf. A highly detailed",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "called web site",
          "http",
          "jedec",
          "sites",
          "default",
          "files",
          "docs",
          "highly",
          "detailed"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand A vailable: http://www.anandtech.com/show/6935/seagate-600-ssd-review.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "anandtech",
          "show",
          "seagate",
          "review"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand A vailable here: http://www.tomshardware.com/charts/enterprise-hdd-charts. Y et another site",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable here",
          "http",
          "tomshardware",
          "charts",
          "enterprise",
          "charts",
          "another",
          "site"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand A vailable: http://www.anandtech.com/show/5067/understanding-tlc-nand. A short descrip-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "anandtech",
          "show",
          "understanding",
          "nand",
          "short",
          "descrip"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand http: //en.wikipedia.org/wiki/List",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "http",
          "wikipedia",
          "wiki",
          "list"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand going on at the device level and how such devices fai l. Only for those not faint of\nheart. Or physicists. Or both.\n[KK+02] \u201cA Space-Ef\ufb01cient Flash T ranslation Layer For Compact Flas h Systems\u201d by Jesung\nKim, Jong Min Kim, Sam H. Noh, Sang Lyul Min, Y ookun Cho. IEEE T ransactions on Con-\nsumer Electronics, V olume 48, Number 2, May 2002. One of the earliest proposals to suggest\nhybrid mappings.\n[L+07] \u201cA Log Buffer-Based Flash T ranslation Layer by Using Fully -Associative Sector T rans-\nlation. \u201d Sang-won Lee, T ae-Sun Chung, Dong-Ho Lee, Sangwon Park, Ha-Joo S ong. ACM\nT ransactions on Embedded Computing Systems, V olume 6, Number 3, July 2007 A terri\ufb01c paper\nabout how to build hybrid log/block mappings.\n[M+14] \u201cA Survey of Address T ranslation T echnologies for Flash Memor ies\u201d by Dongzhe Ma,\nJianhua Feng, Guoliang Li. ACM Computing Surveys, V olume 46, Numbe r 3, January 2014.\nProbably the best recent survey of \ufb02ash and related technologies.\n[S13] \u201cThe Seagate 600 and 600 Pro SSD Review\u201d by Anand Lal Shimpi. AnandT ech, May 7,\n2013. A vailable: http://www.anandtech.com/show/6935/seagate-600-ssd-review.\nOne of many SSD performance measurements available on the internet. Haven\u2019t heard of the internet",
        "type": "question_concept",
        "difficulty": "advanced",
        "keywords": [
          "going",
          "device",
          "level",
          "devices",
          "faint",
          "heart",
          "physicists",
          "space"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "The homework will mostly focus on the log-structured SSD, which",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "1. The homework will mostly focus on the log-structured SSD, which\nis simulated with the \u201c-T log\u201d \ufb02ag. W e\u2019ll use the other types of\nSSDs for comparison. First, run with \ufb02ags -T log -s 1 -n 10\n-q. Can you \ufb01gure out which operations took place? Use -c to\ncheck your answers (or just use -C instead of -q -c). Use different\nvalues of -s to generate different random workloads.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand q. can you \ufb01gure out which operations took place? use -c to",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "operations",
          "took",
          "place"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now just show the commands and see if you can \ufb01gure out the",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "2. Now just show the commands and see if you can \ufb01gure out the\nintermediate states of the Flash. Run with \ufb02ags -T log -s 2 -n\n10 -C to show each command. Now , determine the state of the\nFlash between each command; use -F to show the states and see if\nyou were right. Use different random seeds to test your burgeonin g\nexpertise.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Let\u2019s make this problem ever so slightly more interesting by a dding",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "3. Let\u2019s make this problem ever so slightly more interesting by a dding\nthe -r 20 \ufb02ag. What differences does this cause in the commands?\nUse -c again to check your answers.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Performance is determined by the number of erases, programs, and",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "4. Performance is determined by the number of erases, programs, and\nreads (we assume here that trims are free). Run the same workloa d\nagain as above, but without showing any intermediate states (e. g.,\n-T log -s 1 -n 10). Can you estimate how long this workload\nwill take to complete? (default erase time is 1000 microseconds ,\nprogram time is 40, and read time is 10) Use the -S \ufb02ag to check\nyour answer . Y ou can also change the erase, program, and read\ntimes with the -E, -W, -R \ufb02ags.",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand t log -s 1 -n 10). can you estimate how long this workload",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "estimate",
          "long",
          "workload"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "5",
    "title": "Now , compare performance of the log-structured approach and the",
    "document_source": "book.pdf",
    "start_line": 31,
    "type": "chapter",
    "content": "5. Now , compare performance of the log-structured approach and the\n(very bad) direct approach ( -T direct instead of -T log). First,\nestimate how you think the direct approach will perform, then che ck\nyour answer with the -S \ufb02ag. In general, how much better will the\nlog-structured approach perform than the direct one?\n6. Let us next explore the behavior of the garbage collector . T o do\nso, we have to set the high ( -G) and low ( -g) watermarks appro-\npriately . First, let\u2019s observe what happens when you run a large r\nworkload to the log-structured SSD but without any garbage col-\nlection. T o do this, run with \ufb02ags -T log -n 1000 (the high wa-\n1 Now you might complain, \u201cBut I\u2019m a dog person!\u201d T o this, we say , too b ad! Get a cat,\nput it on your lap, and do the homework! How else will you learn, if y ou can\u2019t even follow\nthe most basic of instructions?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now , compare performance of the log-structured approach and the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "performance",
          "structured",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "(very bad) direct approach ( -T direct instead of -T log). First,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "direct",
          "approach",
          "direct",
          "instead",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "estimate how you think the direct approach will perform, then che ck",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "estimate",
          "think",
          "direct",
          "approach",
          "perform"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "log-structured approach perform than the direct one?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "structured",
          "approach",
          "perform",
          "direct"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "put it on your lap, and do the homework! How else will you learn, if y ou can\u2019t even follow",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "homework",
          "else",
          "learn",
          "even",
          "follow"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "8",
    "title": "One other useful \ufb02ag is -J, which shows what the collector is doing",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "8. One other useful \ufb02ag is -J, which shows what the collector is doing\nwhen it runs. Run with \ufb02ags -T log -n 1000 -C -J to see both\nthe commands and the GC behavior . What do you notice about the\nGC? The \ufb01nal effect of GC, of course, is performance. Use -S to\nlook at \ufb01nal statistics; how many extra reads and writes occur due\nto garbage collection? Compare this to the ideal SSD ( -T ideal);\nhow much extra reading, writing, and erasing is there due to th e\nnature of Flash? Compare it also to the direct approach; in what\nway (erases, reads, programs) is the log-structured approach s upe-\nrior?\n9. One last aspect to explore is workload skew . Adding skew to the\nworkload changes writes such that more writes occur to some smalle r\nfraction of the logical block space. For example, running with -K\n80/20 makes 80% of the writes go to 20% of the blocks. Pick some\ndifferent skews and perform many randomly-chosen operations (e. g.,\n-n 1000), using \ufb01rst -T direct to understand the skew , and then\n-T log to see the impact on a log-structured device. What do you\nexpect will happen? One other small skew control to explore is -k\n100; by adding this \ufb02ag to a skewed workload, the \ufb01rst 100 writes\nare not skewed. The idea is to \ufb01rst create a lot of data, but then onl y\nupdate some of it. What impact might that have upon a garbage\ncollector?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to garbage collection? Compare this to the ideal SSD ( -T ideal);",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "garbage",
          "collection",
          "compare",
          "ideal",
          "ideal"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "nature of Flash? Compare it also to the direct approach; in what",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "nature",
          "flash",
          "compare",
          "also",
          "direct",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "way (erases, reads, programs) is the log-structured approach s upe-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "erases",
          "reads",
          "programs",
          "structured",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "n 1000), using \ufb01rst -T direct to understand the skew , and then",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "direct",
          "understand",
          "skew"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "are not skewed. The idea is to \ufb01rst create a lot of data, but then onl y",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "skewed",
          "idea",
          "create",
          "data"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_2",
        "text": "understand t log to see the impact on a log-structured device. what do you",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "impact",
          "structured",
          "device"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "1 Disk Failure Modes",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "45.1 Disk Failure Modes\nAs you learned in the chapter about RAID, disks are not perfect, a nd\ncan fail (on occasion). In early RAID systems, the model of failure was\nquite simple: either the entire disk is working, or it fails comp letely , and\nthe detection of such a failure is straightforward. This fail-stop model of\ndisk failure makes building RAID relatively simple [S90].\nWhat you didn\u2019t learn is about all of the other types of failure modes\nmodern disks exhibit. Speci\ufb01cally , as Bairavasundaram et al. studied\nin great detail [B+07, B+08], modern disks will occasionally se em to be\nmostly working but have trouble successfully accessing one or more blocks.\nSpeci\ufb01cally , two types of single-block failures are common and wor thy of\nconsideration: latent-sector errors (LSEs) and block corruption . W e\u2019ll\nnow discuss each in more detail.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "As you learned in the chapter about RAID, disks are not perfect, a nd",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learned",
          "chapter",
          "raid",
          "disks",
          "perfect"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "What you didn\u2019t learn is about all of the other types of failure modes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "learn",
          "types",
          "failure",
          "modes"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand disk failure modes",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "disk",
          "failure",
          "modes"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 D ATA IN T E G R I T Y A N D PR O T E C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 D ATA IN T E G R I T Y A N D PR O T E C T I O N\nCheap Costly\nLSEs 9.40% 1.40%\nCorruption 0.50% 0.05%\nFigure 45.1: Frequency Of LSEs And Block Corruption\nLSEs arise when a disk sector (or group of sectors) has been damaged\nin some way . For example, if the disk head touches the surface for s ome\nreason (a head crash , something which shouldn\u2019t happen during nor-\nmal operation), it may damage the surface, making the bits unre adable.\nCosmic rays can also \ufb02ip bits, leading to incorrect contents. For tunately ,\nin-disk error correcting codes (ECC) are used by the drive to determine\nwhether the on-disk bits in a block are good, and in some cases, to \ufb01x\nthem; if they are not good, and the drive does not have enough informa-\ntion to \ufb01x the error , the disk will return an error when a request i s issued\nto read them.\nThere are also cases where a disk block becomes corrupt in a way not\ndetectable by the disk itself. For example, buggy disk \ufb01rmwar e may write\na block to the wrong location; in such a case, the disk ECC indicate s the\nblock contents are \ufb01ne, but from the client\u2019s perspective the wron g block\nis returned when subsequently accessed. Similarly , a block ma y get cor-\nrupted when it is transferred from the host to the disk across a fa ulty bus;\nthe resulting corrupt data is stored by the disk, but it is not wha t the client\ndesires. These types of faults are particularly insidious bec ause they are\nsilent faults ; the disk gives no indication of the problem when returning\nthe faulty data.\nPrabhakaran et al. describes this more modern view of disk failu re as\nthe fail-partial disk failure model [P+05]. In this view , disks can still fail\nin their entirety (as was the case in the traditional fail-stop model); how-\never , disks can also seemingly be working and have one or more block s\nbecome inaccessible (i.e., LSEs) or hold the wrong contents (i.e., corrup-\ntion). Thus, when accessing a seemingly-working disk, once in a while\nit may either return an error when trying to read or write a given block\n(a non-silent partial fault), and once in a while it may simply r eturn the\nwrong data (a silent partial fault).\nBoth of these types of faults are somewhat rare, but just how rare? F ig-\nure 45.1 summarizes some of the \ufb01ndings from the two Bairavasund aram\nstudies [B+07,B+08].\nThe \ufb01gure shows the percent of drives that exhibited at least one LSE\nor block corruption over the course of the study (about 3 years, over\n1.5 million disk drives). The \ufb01gure further sub-divides the r esults into\n\u201ccheap\u201d drives (usually SA T A drives) and \u201ccostly\u201d drives (usu ally SCSI\nor FibreChannel). As you can see, while buying better drives re duces\nthe frequency of both types of problem (by about an order of magnitude ),\nthey still happen often enough that you need to think carefully a bout how\nto handle them in your storage system.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Prabhakaran et al. describes this more modern view of disk failu re as",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "prabhakaran",
          "describes",
          "modern",
          "view",
          "disk",
          "failu"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: Frequency Of LSEs And Block Corruption",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "frequency",
          "lses",
          "block",
          "corruption"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand million disk drives). the \ufb01gure further sub-divides the r esults into",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "million",
          "disk",
          "drives",
          "divides",
          "esults"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "2 Handling Latent Sector Errors",
    "document_source": "book.pdf",
    "start_line": 23,
    "type": "chapter",
    "content": "45.2 Handling Latent Sector Errors\nGiven these two new modes of partial disk failure, we should now tr y\nto see what we can do about them. Let\u2019s \ufb01rst tackle the easier of th e two,\nnamely latent sector errors.\nCR U X : H O W TO HA N D L E LAT E N T SE C TO R ER R O R S\nHow should a storage system handle latent sector errors? How much\nextra machinery is needed to handle this form of partial failur e?\nAs it turns out, latent sector errors are rather straightforward to han-\ndle, as they are (by de\ufb01nition) easily detected. When a storage system\ntries to access a block, and the disk returns an error , the storag e system\nshould simply use whatever redundancy mechanism it has to ret urn the\ncorrect data. In a mirrored RAID, for example, the system should a ccess\nthe alternate copy; in a RAID-4 or RAID-5 system based on parity , the\nsystem should reconstruct the block from the other blocks in the par ity\ngroup. Thus, easily detected problems such as LSEs are readily r ecovered\nthrough standard redundancy mechanisms.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand CR U X: H O W TO HA N D L E LAT E N T SE C TO R ER R O R S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cr u x"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand handling latent sector errors",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "handling",
          "latent",
          "sector",
          "errors"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "3 Detecting Corruption: The Checksum",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "45.3 Detecting Corruption: The Checksum\nLet\u2019s now tackle the more challenging problem, that of silent fail ures\nvia data corruption. How can we prevent users from getting bad dat a\nwhen corruption arises, and thus leads to disks returning bad d ata?\nCR U X : H O W TO PR E S E RV E DATA IN T E G R I T Y DE S P I T E CO R R U P T I O N\nGiven the silent nature of such failures, what can a storage sys tem do\nto detect when corruption arises? What techniques are needed? How can\none implement them ef\ufb01ciently?\nUnlike latent sector errors, detection of corruption is a key problem.\nHow can a client tell that a block has gone bad? Once it is known that a\nparticular block is bad, recovery is the same as before: you need to have\nsome other copy of the block around (and hopefully , one that is not cor-\nrupt!). Thus, we focus here on detection techniques.\nThe primary mechanism used by modern storage systems to preser ve\ndata integrity is called the checksum. A checksum is simply the result\nof a function that takes a chunk of data (say a 4KB block) as input an d\ncomputes a function over said data, producing a small summary of th e\ncontents of the data (say 4 or 8 bytes). This summary is referred t o as the\nchecksum. The goal of such a computation is to enable a system to de tect\nif data has somehow been corrupted or altered by storing the checks um\nwith the data and then con\ufb01rming upon later access that the data \u2019s cur-\nrent checksum matches the original storage value.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "to detect when corruption arises? What techniques are needed? How can",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "detect",
          "corruption",
          "arises",
          "techniques",
          "needed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "one implement them ef\ufb01ciently?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "How can a client tell that a block has gone bad? Once it is known that a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "tell",
          "block",
          "gone",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "rupt!). Thus, we focus here on detection techniques.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "rupt",
          "thus",
          "focus",
          "detection",
          "techniques"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "checksum. The goal of such a computation is to enable a system to de tect",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "checksum",
          "goal",
          "computation",
          "enable",
          "system",
          "tect"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand CR U X: H O W TO PR E S E RV E DATA IN T E G R I T Y DE S P I T E CO R R U P T I O N",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cr u x",
          "data"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand detecting corruption: the checksum",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "detecting",
          "corruption",
          "checksum"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DATA IN T E G R I T Y A N D PR O T E C T I O N 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DATA IN T E G R I T Y A N D PR O T E C T I O N 5\nTI P : T H E R E \u2019 S NO FR E E LU N C H\nThere\u2019s No Such Thing As A Free Lunch, or TNST AAFL for short, is\nan old American idiom that implies that when you are seemingly ge t-\nting something for free, in actuality you are likely paying some c ost for\nit. It comes from the old days when diners would advertise a free lu nch\nfor customers, hoping to draw them in; only when you went in, did you\nrealize that to acquire the \u201cfree\u201d lunch, you had to purchase on e or more\nalcoholic beverages. Of course, this may not actually be a problem , partic-\nularly if you are an aspiring alcoholic (or typical undergraduat e student).\nCommon Checksum Functions\nA number of different functions are used to compute checksums, a nd\nvary in strength (i.e., how good they are at protecting data integ rity) and\nspeed (i.e., how quickly can they be computed). A trade-off that is com-\nmon in systems arises here: usually , the more protection you get, t he\ncostlier it is. There is no such thing as a free lunch.\nOne simple checksum function that some use is based on exclusive\nor (XOR). With XOR-based checksums, the checksum is computed b y\nXOR\u2019ing each chunk of the data block being checksummed, thus prod uc-\ning a single value that represents the XOR of the entire block.\nT o make this more concrete, imagine we are computing a 4-byte che ck-\nsum over a block of 16 bytes (this block is of course too small to really be a\ndisk sector or block, but it will serve for the example). The 16 dat a bytes,\nin hex, look like this:\n365e c4cd ba14 8a92 ecef 2c3a 40be f666\nIf we view them in binary , we get the following:\n0011 0110 0101 1110 1100 0100 1100 1101\n1011 1010 0001 0100 1000 1010 1001 0010\n1110 1100 1110 1111 0010 1100 0011 1010\n0100 0000 1011 1110 1111 0110 0110 0110\nBecause we\u2019ve lined up the data in groups of 4 bytes per row , it is ea sy\nto see what the resulting checksum will be: perform an XOR over e ach\ncolumn to get the \ufb01nal checksum value:\n0010 0000 0001 1011 1001 0100 0000 0011\nThe result, in hex, is 0x201b9403.\nXOR is a reasonable checksum but has its limitations. If, for exa mple,\ntwo bits in the same position within each checksummed unit chan ge, the\nchecksum will not detect the corruption. For this reason, people ha ve\ninvestigated other checksum functions.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand look like this: 365e c4cd ba14 8a92 ecef 2c3a 40be f666",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "look like this",
          "ecef"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand we get the following: 0011 0110 0101 1110 1100 0100 1100 1101",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "we get the following"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 D ATA IN T E G R I T Y A N D PR O T E C T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 D ATA IN T E G R I T Y A N D PR O T E C T I O N\nAnother basic checksum function is addition. This approach has t he\nadvantage of being fast; computing it just requires performing 2\u2019s-complement\naddition over each chunk of the data, ignoring over\ufb02ow . It can detec t\nmany changes in data, but is not good if the data, for example, is sh ifted.\nA slightly more complex algorithm is known as the Fletcher check-\nsum, named (as you might guess) for the inventor , John G. Fletcher [F8 2].\nIt is quite simple to compute and involves the computation of two ch eck\nbytes, s1 and s2. Speci\ufb01cally , assume a block D consists of bytes d1 ...\ndn; s1 is de\ufb01ned as follows: s1 = (s1 +di) mod 255 (computed over all\ndi); s2 in turn is: s2 = (s2 +s1) mod 255 (again over all di) [F04]. The\nFletcher checksum is almost as strong as the CRC (see below), det ecting\nall single-bit, double-bit errors, and many burst errors [F04] .\nOne \ufb01nal commonly-used checksum is known as a cyclic redundancy\ncheck (CRC). Assume you wish to compute the checksum over a data\nblock D. All you do is treat D as if it is a large binary number (it is just\na string of bits after all) and divide it by an agreed upon value ( k). The\nremainder of this division is the value of the CRC. As it turns out, one\ncan implement this binary modulo operation rather ef\ufb01ciently , and hence\nthe popularity of the CRC in networking as well. See elsewhere for m ore\ndetails [M13].\nWhatever the method used, it should be obvious that there is no per -\nfect checksum: it is possible two data blocks with non-identica l contents\nwill have identical checksums, something referred to as a collision. This\nfact should be intuitive: after all, computing a checksum is ta king some-\nthing large (e.g., 4KB) and producing a summary that is much sm aller\n(e.g., 4 or 8 bytes). In choosing a good checksum function, we are thu s\ntrying to \ufb01nd one that minimizes the chance of collisions while re main-\ning easy to compute.\nChecksum Layout\nNow that you understand a bit about how to compute a checksum, let\u2019s\nnext analyze how to use checksums in a storage system. The \ufb01rst q uestion\nwe must address is the layout of the checksum, i.e., how should che ck-\nsums be stored on disk?\nThe most basic approach simply stores a checksum with each disk s ec-\ntor (or block). Given a data block D, let us call the checksum over that\ndata C(D). Thus, without checksums, the disk layout looks like this:\nD0 D1 D2 D3 D4 D5 D6\nWith checksums, the layout adds a single checksum for every bloc k:\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Another basic checksum function is addition. This approach has t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "basic",
          "checksum",
          "function",
          "addition",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "A slightly more complex algorithm is known as the Fletcher check-",
        "type": "explicit_objective",
        "difficulty": "advanced",
        "keywords": [
          "slightly",
          "complex",
          "algorithm",
          "known",
          "fletcher",
          "check"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "One \ufb01nal commonly-used checksum is known as a cyclic redundancy",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "commonly",
          "used",
          "checksum",
          "known",
          "cyclic",
          "redundancy"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "can implement this binary modulo operation rather ef\ufb01ciently , and hence",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "binary",
          "modulo",
          "operation",
          "rather",
          "hence"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "Whatever the method used, it should be obvious that there is no per -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "whatever",
          "method",
          "used",
          "obvious"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Now that you understand a bit about how to compute a checksum, let\u2019s",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "understand",
          "compute",
          "checksum"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "next analyze how to use checksums in a storage system. The \ufb01rst q uestion",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "next",
          "analyze",
          "checksums",
          "storage",
          "system",
          "uestion"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "The most basic approach simply stores a checksum with each disk s ec-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "approach",
          "simply",
          "stores",
          "checksum",
          "disk"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand s2 in turn is: s2 = (s2 +s1) mod 255 (again over all di) [F04]. The",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s2 in turn is"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand fect checksum: it is possible two data blocks with non-identica l contents",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "fect checksum",
          "possible",
          "data",
          "blocks",
          "identica",
          "contents"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "4 Using Checksums",
    "document_source": "book.pdf",
    "start_line": 33,
    "type": "chapter",
    "content": "45.4 Using Checksums\nWith a checksum layout decided upon, we can now proceed to actu-\nally understand how to use the checksums. When reading a block D, the\nclient (i.e., \ufb01le system or storage controller) also reads its ch ecksum from\ndisk Cs(D), which we call the stored checksum (hence the subscript Cs).\nThe client then computes the checksum over the retrieved block D, which\nwe call the computed checksum Cc(D). At this point, the client com-\npares the stored and computed checksums; if they are equal (i.e ., Cs(D)\n== Cc(D), the data has likely not been corrupted, and thus can be safely\nreturned to the user . If they do not match (i.e., Cs(D) != Cc(D)), this im-\nplies the data has changed since the time it was stored (since t he stored\nchecksum re\ufb02ects the value of the data at that time). In this ca se, we have\na corruption, which our checksum has helped us to detect.\nGiven a corruption, the natural question is what should we do about\nit? If the storage system has a redundant copy , the answer is eas y: try to\nuse it instead. If the storage system has no such copy , the likel y answer is\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ally understand how to use the checksums. When reading a block D, the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ally",
          "understand",
          "checksums",
          "reading",
          "block"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand using checksums",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "checksums"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "5 A New Problem: Misdirected W rites",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "45.5 A New Problem: Misdirected W rites\nThe basic scheme described above works well in the general case of\ncorrupted blocks. However , modern disks have a couple of unusual fa il-\nure modes that require different solutions.\nThe \ufb01rst failure mode of interest is called a misdirected write . This\narises in disk and RAID controllers which write the data to disk correctly ,\nexcept in the wrong location. In a single-disk system, this means that the\ndisk wrote block Dx not to address x (as desired) but rather to address\ny (thus \u201ccorrupting\u201d Dy); in addition, within a multi-disk system, the\ncontroller may also write Di,x not to address x of disk i but rather to\nsome other disk j. Thus our question:\nCR U X : H O W TO HA N D L E MI S D I R E C T E D WR I T E S\nHow should a storage system or disk controller detect misdirected\nwrites? What additional features are required from the checks um?\nThe answer , not surprisingly , is simple: add a little more infor mation\nto each checksum. In this case, adding a physical identi\ufb01er (physical ID )\nis quite helpful. For example, if the stored information now contai ns the\nchecksum C(D) and both the disk and sector numbers of the block, it is\neasy for the client to determine whether the correct information resides\nwithin a particular locale. Speci\ufb01cally , if the client is read ing block 4 on\ndisk 10 ( D10,4), the stored information should include that disk number\nand sector offset, as shown below . If the information does not match, a\nmisdirected write has taken place, and a corruption is now detec ted. Here\nis an example of what this added information would look like on a two-\ndisk system. Note that this \ufb01gure, like the others before it, is n ot to scale,\nas the checksums are usually small (e.g., 8 bytes) whereas th e blocks are\nmuch larger (e.g., 4 KB or bigger):\nDisk 0\nDisk 1\nC[D0]\ndisk=0\nblock=0\nD0\nC[D1]\ndisk=0\nblock=1\nD1\nC[D2]\ndisk=0\nblock=2\nD2\nC[D0]\ndisk=1\nblock=0\nD0\nC[D1]\ndisk=1\nblock=1\nD1\nC[D2]\ndisk=1\nblock=2\nD2\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The basic scheme described above works well in the general case of",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "scheme",
          "described",
          "works",
          "well",
          "general",
          "case"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Thus our question: CR U X : H O W TO HA N D L E MI S D I R E C T E D WR I T E S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "thus our question"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand is simple: add a little more infor mation",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "is simple",
          "little",
          "infor",
          "mation"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a new problem: misdirected w rites",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problem",
          "misdirected",
          "rites"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "6 One Last Problem: Lost W rites",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "45.6 One Last Problem: Lost W rites\nUnfortunately , misdirected writes are not the last problem we w ill\naddress. Speci\ufb01cally , some modern storage devices also have an i ssue\nknown as a lost write , which occurs when the device informs the up-\nper layer that a write has completed but in fact it never is pers isted; thus,\nwhat remains is the old contents of the block rather than the updat ed new\ncontents.\nThe obvious question here is: do any of our checksumming strategie s\nfrom above (e.g., basic checksums, or physical identity) help t o detect\nlost writes? Unfortunately , the answer is no: the old block likely has a\nmatching checksum, and the physical ID used above (disk numbe r and\nblock offset) will also be correct. Thus our \ufb01nal problem:\nCR U X : H O W TO HA N D L E LO S T WR I T E S\nHow should a storage system or disk controller detect lost writes?\nWhat additional features are required from the checksum?\nThere are a number of possible solutions that can help [K+08]. One\nclassic approach [BS04] is to perform a write verify or read-after-write;\nby immediately reading back the data after a write, a system c an ensure\nthat the data indeed reached the disk surface. This approach, however , is\nquite slow , doubling the number of I/Os needed to complete a write .\nSome systems add a checksum elsewhere in the system to detect los t\nwrites. For example, Sun\u2019s Zettabyte File System (ZFS) includes a check-\nsum in each \ufb01le system inode and indirect block for every block inc luded\nwithin a \ufb01le. Thus, even if the write to a data block itself is los t, the check-\nsum within the inode will not match the old data. Only if the write s to\nboth the inode and the data are lost simultaneously will such a sch eme\nfail, an unlikely (but unfortunately , possible!) situation.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "known as a lost write , which occurs when the device informs the up-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "lost",
          "write",
          "occurs",
          "device",
          "informs"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "classic approach [BS04] is to perform a write verify or read-after-write;",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "classic",
          "approach",
          "perform",
          "write",
          "verify",
          "read",
          "write"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "that the data indeed reached the disk surface. This approach, however , is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "data",
          "indeed",
          "reached",
          "disk",
          "surface",
          "approach",
          "however"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand the answer is no: the old block likely has a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the answer is no",
          "block",
          "likely"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Thus our \ufb01nal problem: CR U X : H O W TO HA N D L E LO S T WR I T E S",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "thus our \ufb01nal problem"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand one last problem: lost w rites",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "last",
          "problem",
          "lost",
          "rites"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "45",
    "title": "7 Scrubbing",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "45.7 Scrubbing\nGiven all of this discussion, you might be wondering: when do thes e\nchecksums actually get checked? Of course, some amount of checki ng\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand scrubbing",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "scrubbing"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "8 Overheads Of Checksumming",
    "document_source": "book.pdf",
    "start_line": 10,
    "type": "chapter",
    "content": "45.8 Overheads Of Checksumming\nBefore closing, we now discuss some of the overheads of using check-\nsums for data protection. There are two distinct kinds of overhead s, as is\ncommon in computer systems: space and time.\nSpace overheads come in two forms. The \ufb01rst is on the disk (or other\nstorage medium) itself; each stored checksum takes up room on the d isk,\nwhich can no longer be used for user data. A typical ratio might b e an 8-\nbyte checksum per 4 KB data block, for a 0.19% on-disk space overhe ad.\nThe second type of space overhead comes in the memory of the sys-\ntem. When accessing data, there must now be room in memory for the\nchecksums as well as the data itself. However , if the system si mply checks\nthe checksum and then discards it once done, this overhead is shor t-lived\nand not much of a concern. Only if checksums are kept in memory (for\nan added level of protection against memory corruption [Z+13]) wil l this\nsmall overhead be observable.\nWhile space overheads are small, the time overheads induced by check-\nsumming can be quite noticeable. Minimally , the CPU must compu te the\nchecksum over each block, both when the data is stored (to determi ne the\nvalue of the stored checksum) and when it is accessed (to compute the\nchecksum again and compare it against the stored checksum). On e ap-\nproach to reducing CPU overheads, employed by many systems that use\nchecksums (including network stacks), is to combine data copyi ng and\nchecksumming into one streamlined activity; because the copy is needed\nanyhow (e.g., to copy the data from the kernel page cache into a us er\nbuffer), combined copying/checksumming can be quite effecti ve.\nBeyond CPU overheads, some checksumming schemes can induce ex-\ntra I/O overheads, particularly when checksums are stored dis tinctly from\nthe data (thus requiring extra I/Os to access them), and for an y extra I/O\nneeded for background scrubbing. The former can be reduced by de sign;\nthe latter can be tuned and thus its impact limited, perhaps b y control-\nling when such scrubbing activity takes place. The middle of t he night,\nwhen most (not all!) productive workers have gone to bed, may be a\ngood time to perform such scrubbing activity and increase the rob ustness\nof the storage system.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "checksum again and compare it against the stored checksum). On e ap-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "checksum",
          "compare",
          "stored",
          "checksum"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand overheads of checksumming",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "overheads",
          "checksumming"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "45",
    "title": "9 Summary",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "45.9 Summary\nW e have discussed data protection in modern storage systems, focu s-\ning on checksum implementation and usage. Different checksum s protect\nagainst different types of faults; as storage devices evolve, n ew failure\nmodes will undoubtedly arise. Perhaps such change will force th e re-\nsearch community and industry to revisit some of these basic app roaches,\nor invent entirely new approaches altogether . Time will tell. O r it won\u2019t.\nTime is funny that way .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ing on checksum implementation and usage. Different checksum s protect",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "checksum",
          "implementation",
          "usage",
          "different",
          "checksum",
          "protect"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "or invent entirely new approaches altogether . Time will tell. O r it won\u2019t.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "invent",
          "entirely",
          "approaches",
          "altogether",
          "time",
          "tell"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 D ATA IN T E G R I T Y A N D PR O T E C T I O N...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 D ATA IN T E G R I T Y A N D PR O T E C T I O N\nReferences\n[B+07] \u201cAn Analysis of Latent Sector Errors in Disk Drives\u201d by L. B airavasundaram, G. Good-\nson, S. Pasupathy , J. Schindler . SIGMETRICS \u201907, San Diego, CA. The \ufb01rst paper to study latent\nsector errors in detail. The paper also won the Kenneth C. Sevcik Outstandin g Student Paper award,\nnamed after a brilliant researcher and wonderful guy who passed away too soon . T o show the OSTEP\nauthors it was possible to move from the U.S. to Canada, Ken once sang us the Canadian national\nanthem, standing up in the middle of a restaurant to do so. We chose the U.S., b ut got this memory.\n[B+08] \u201cAn Analysis of Data Corruption in the Storage Stack\u201d by La kshmi N. Bairavasun-\ndaram, Garth R. Goodson, Bianca Schroeder , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-\nDusseau. F AST \u201908, San Jose, CA, February 2008. The \ufb01rst paper to truly study disk corruption in\ngreat detail, focusing on how often such corruption occurs over three years for over 1.5 million drives.\n[BS04] \u201cCommercial Fault T olerance: A T ale of T wo Systems\u201d by W end y Bartlett, Lisa Spainhower .\nIEEE T ransactions on Dependable and Secure Computing, V ol. 1:1, Janua ry 2004. This classic\nin building fault tolerant systems is an excellent overview of the state of th e art from both IBM and\nT andem. Another must read for those interested in the area.\n[C+04] \u201cRow-Diagonal Parity for Double Disk Failure Correction\u201d by P . Corbett, B. English, A.\nGoel, T . Grcanac, S. Kleiman, J. Leong, S. Sankar . F AST \u201904, San Jose, C A, February 2004. An\nearly paper on how extra redundancy helps to solve the combined full-disk-f ailure/partial-disk-failure\nproblem. Also a nice example of how to mix more theoretical work with practical .\n[F04] \u201cChecksums and Error Control\u201d by Peter M. Fenwick. Copy availabl e online here:\nhttp://www.ostep.org/Citations/checksums-03.pdf. A great simple tutorial on check-\nsums, available to you for the amazing cost of free.\n[F82] \u201cAn Arithmetic Checksum for Serial T ransmissions\u201d by John G. Fle tcher . IEEE T rans-\nactions on Communication, V ol. 30:1, January 1982. Fletcher\u2019s original work on his eponymous\nchecksum. He didn\u2019t call it the Fletcher checksum, rather he just did n\u2019t call it anything; later , others\nnamed it after him. So don\u2019t blame old Fletch for this seeming act of braggadoc io. This anecdote might\nremind you of Rubik; Rubik never called it \u201c Rubik\u2019s cube\u201d; rather , he just called it \u201cmy cube.\u201d\n[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,\nMichael Malcolm. USENIX Spring \u201994. The pioneering paper that describes the ideas and product at\nthe heart of NetApp\u2019s core. Based on this system, NetApp has grown into a multi -billion dollar storage\ncompany. T o learn more about NetApp, read Hitz\u2019s autobiography \u201cHow to Castrate a Bul l\u201d (which is\nthe actual title, no joking). And you thought you could avoid bull castration by going i nto CS.\n[K+08] \u201cParity Lost and Parity Regained\u201d by Andrew Krioukov , Lakshm i N. Bairavasun-\ndaram, Garth R. Goodson, Kiran Srinivasan, Randy Thelen, Andrea C. Ar paci-Dusseau, Remzi\nH. Arpaci-Dusseau. F AST \u201908, San Jose, CA, February 2008. This work explores how different\nchecksum schemes work (or don\u2019t work) in protecting data. We reveal a number of interesting \ufb02aws in\ncurrent protection strategies.\n[M13] \u201cCyclic Redundancy Checks\u201d by unknown. A vailable: http://www.mathpages.com/\nhome/kmath458.htm. A super clear and concise description of CRCs. The internet is full of i nfor-\nmation, as it turns out.\n[P+05] \u201cIRON File Systems\u201d by V . Prabhakaran, L. Bairavasundaram, N . Agrawal, H. Gunawi,\nA. Arpaci-Dusseau, R. Arpaci-Dusseau. SOSP \u201905, Brighton, England. Our paper on how disks\nhave partial failure modes, and a detailed study of how modern \ufb01le systems reac t to such failures. As it\nturns out, rather poorly! We found numerous bugs, design \ufb02aws, and other oddi ties in this work. Some\nof this has fed back into the Linux community, thus improving \ufb01le system re liability. Y ou\u2019re welcome!\n[RO91] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosen-\nblum and John Ousterhout. SOSP \u201991, Paci\ufb01c Grove, CA, October 1991. So cool we cite it again.\n[S90] \u201cImplementing Fault-T olerant Services Using The State Machine Appr oach: A T utorial\u201d\nby Fred B. Schneider . ACM Surveys, V ol. 22, No. 4, December 1990. How to build fault tolerant\nservices. A must read for those building distributed systems.\n[Z+13] \u201cZettabyte Reliability with Flexible End-to-end Data Inte grity\u201d by Y . Zhang, D. Myers,\nA. Arpaci-Dusseau, R. Arpaci-Dusseau. MSST \u201913, Long Beach, Californi a, May 2013. How to\nadd data protection to the page cache of a system. Out of space, otherwise we would w rite something...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "early paper on how extra redundancy helps to solve the combined full-disk-f ailure/partial-disk-failure",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "early",
          "paper",
          "extra",
          "redundancy",
          "helps",
          "solve",
          "combined",
          "full"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "sums, available to you for the amazing cost of free.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sums",
          "available",
          "amazing",
          "cost",
          "free"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "file",
          "system",
          "design",
          "file",
          "server",
          "appliance",
          "hitz",
          "james"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Michael Malcolm. USENIX Spring \u201994. The pioneering paper that describes the ideas and product at",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "michael",
          "malcolm",
          "usenix",
          "spring",
          "pioneering",
          "paper",
          "describes",
          "ideas"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "company. T o learn more about NetApp, read Hitz\u2019s autobiography \u201cHow to Castrate a Bul l\u201d (which is",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "company",
          "learn",
          "netapp",
          "read",
          "hitz",
          "autobiography",
          "castrate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "[M13] \u201cCyclic Redundancy Checks\u201d by unknown. A vailable: http://www.mathpages.com/",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cyclic",
          "redundancy",
          "checks",
          "unknown",
          "vailable",
          "http",
          "mathpages"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "turns out, rather poorly! We found numerous bugs, design \ufb02aws, and other oddi ties in this work. Some",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "turns",
          "rather",
          "poorly",
          "found",
          "numerous",
          "bugs",
          "design",
          "oddi"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "[RO91] \u201cDesign and Implementation of the Log-structured File Syste m\u201d by Mendel Rosen-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "implementation",
          "structured",
          "file",
          "syste",
          "mendel",
          "rosen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "[S90] \u201cImplementing Fault-T olerant Services Using The State Machine Appr oach: A T utorial\u201d",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "fault",
          "olerant",
          "services",
          "using",
          "state",
          "machine",
          "appr"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Commercial Fault T olerance: A T ale of T wo Systems\u201d by W end y Bartlett, Lisa Spainhower .",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "commercial fault t olerance",
          "systems",
          "bartlett",
          "lisa",
          "spainhower"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 1: 1, Janua ry 2004. This classic",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "janua",
          "classic"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 30: 1, January 1982. Fletcher\u2019s original work on his eponymous",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "30",
          "january",
          "fletcher",
          "original",
          "work",
          "eponymous"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand A vailable: http://www.mathpages.com/",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a vailable",
          "http",
          "mathpages"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "3",
    "title": "Sometimes the additive and XOR-based checksums produce the",
    "document_source": "book.pdf",
    "start_line": 9,
    "type": "chapter",
    "content": "3. Sometimes the additive and XOR-based checksums produce the\nsame checksum (e.g., if the data value is all zeroes). Can you pa ss\nin a 4-byte data value (using the -D \ufb02ag, e.g., -D a,b,c,d) that\ndoes not contain only zeroes and leads the additive and XOR-based\nchecksum having the same value? In general, when does this oc-\ncur? Check that you are correct with the -c \ufb02ag.",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Now pass in a 4-byte value that you know will produce a different",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "4. Now pass in a 4-byte value that you know will produce a different\nchecksum values for additive and XOR. In general, when does thi s\noccur?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now pass in a 4-byte value that you know will produce a different",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "pass",
          "byte",
          "value",
          "know",
          "produce",
          "different"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "Use the simulator to compute checksums twice (once each for a di f-",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "5. Use the simulator to compute checksums twice (once each for a di f-\nferent set of numbers). The two number strings should be differ ent\n(e.g., -D a1,b1,c1,d1 the \ufb01rst time and -D a2,b2,c2,d2 the\nsecond) but should produce the same additive checksum. In gen-\neral, when will the additive checksum be the same, even though the\ndata values are different? Check your speci\ufb01c answer with the -c\n\ufb02ag.\n6. Now do the same for the XOR checksum.\n7. Now let\u2019s look at a speci\ufb01c set of data values. The \ufb01rst is: -D\n1,2,3,4. What will the different checksums (additive, XOR, Fletche r)\nbe for this data? Now compare it to computing these checksums\nover -D 4,3,2,1. What do you notice about these three check-\nsums? How does Fletcher compare to the other two? How is Fletcher\ngenerally \u201cbetter \u201d than something like the simple additive c heck-\nsum?\n8. No checksum is perfect. Given a particular input of your choosi ng,\ncan you \ufb01nd other data values that lead to the same Fletcher chec k-\nsum? When, in general, does this occur? Start with a simple data\nstring (e.g., -D 0,1,2,3) and see if you can replace one of those\nnumbers but end up with the same Fletcher checksum. As always ,\nuse -c to check your answers.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "be for this data? Now compare it to computing these checksums",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "data",
          "compare",
          "computing",
          "checksums"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "sums? How does Fletcher compare to the other two? How is Fletcher",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "sums",
          "fletcher",
          "compare",
          "fletcher"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand Fletcher compare to the other two",
        "type": "question_concept",
        "difficulty": "intermediate",
        "keywords": [
          "fletcher",
          "compare"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "3",
    "title": "Now compare the performance of both: is one faster than the other?",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "3. Now compare the performance of both: is one faster than the other?\nHow does performance change as the size of the input \ufb01le changes?\nUse internal calls to gettimeofday to time the programs. Which\nshould you use if you care about performance? About checking\nability?\n4. Read about the 16-bit CRC and then implement it. T est it on a nu m-\nber of different inputs to ensure that it works. How is its perfor-\nmance as compared to the simple XOR and Fletcher? How about\nits checking ability?\n5. Now build a tool ( create-csum.c) that computes a single-byte\nchecksum for every 4KB block of a \ufb01le, and records the results in\nan output \ufb01le (speci\ufb01ed on the command line). Build a related tool\n(check-csum.c) that reads a \ufb01le, computes the checksums over\neach block, and compares the results to the stored checksums stor ed\nin another \ufb01le. If there is a problem, the program should print tha t\nthe \ufb01le has been corrupted. T est the program by manually corrupt -\ning the \ufb01le.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Now compare the performance of both: is one faster than the other?",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "compare",
          "performance",
          "faster"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Read about the 16-bit CRC and then implement it. T est it on a nu m-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "read",
          "implement"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "mance as compared to the simple XOR and Fletcher? How about",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "mance",
          "compared",
          "simple",
          "fletcher"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Now build a tool ( create-csum.c) that computes a single-byte",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "build",
          "tool",
          "create",
          "csum",
          "computes",
          "single",
          "byte"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "each block, and compares the results to the stored checksums stor ed",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "block",
          "compares",
          "results",
          "stored",
          "checksums",
          "stor"
        ],
        "confidence": 0.9
      },
      {
        "id": "question_concept_1",
        "text": "understand performance change as the size of the input \ufb01le changes",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "change",
          "size",
          "input",
          "changes"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "46\nSummary Dialogue on Persistence\nStudent: Wow, \ufb01le systems seem interesting(!), and yet complicated.\nProfessor: That\u2019s why my spouse and I do our research in this space.\nStudent: Hold on. Are you one of the professors who wrote this book? I thoug ht\nwe were both just fake constructs, used to summarize some main poin ts, and\nperhaps add a little levity in the study of operating systems.\nProfessor: Uh... er ... maybe. And none of your business! And who did you\nthink was writing these things? (sighs) Anyhow, let\u2019s get on with it: w hat did\nyou learn?\nStudent: Well, I think I got one of the main points, which is that it is much\nharder to manage data for a long time (persistently) than it is to mana ge data\nthat isn\u2019t persistent (like the stuff in memory). After all, if your mach ines crashes,\nmemory contents disappear! But the stuff in the \ufb01le system needs to live forever .\nProfessor: Well, as my friend Kevin Hultquist used to say, \u201cForever is a long\ntime\u201d; while he was talking about plastic golf tees, it\u2019s especially true fo r the\ngarbage that is found in most \ufb01le systems.\nStudent: Well, you know what I mean! For a long time at least. And even simple\nthings, such as updating a persistent storage device, are complica ted, because you\nhave to care what happens if you crash. Recovery, something I ha d never even\nthought of when we were virtualizing memory, is now a big deal!\nProfessor: T oo true. Updates to persistent storage have always been, and r e-\nmain, a fun and challenging problem.\nStudent: I also learned about cool things like disk scheduling, and about data\nprotection techniques like RAID and even checksums. That stuff is c ool.\nProfessor: I like those topics too. Though, if you really get into it, they can get a\nlittle mathematical. Check out some the latest on erasure codes if yo u want your\nbrain to hurt.\nStudent: I\u2019ll get right on that.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_2",
        "text": "Student: Well, you know what I mean! For a long time at least. And even simple",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "know",
          "mean",
          "long",
          "time",
          "least",
          "even"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Student: I also learned about cool things like disk scheduling, and about data",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "also",
          "learned",
          "cool",
          "things",
          "like",
          "disk",
          "scheduling"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "protection techniques like RAID and even checksums. That stuff is c ool.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "protection",
          "techniques",
          "like",
          "raid",
          "even",
          "checksums",
          "stuff"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Professor: That\u2019s why my spouse and I do our research in this space.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "spouse",
          "research",
          "space"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Hold on. Are you one of the professors who wrote this book? I thoug ht",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "hold",
          "professors",
          "wrote",
          "book",
          "thoug"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: Uh... er ... maybe. And none of your business! And who did you",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "maybe",
          "none",
          "business"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Student: Well, I think I got one of the main points, which is that it is much",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "think",
          "main",
          "points",
          "much"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Professor: Well, as my friend Kevin Hultquist used to say, \u201cForever is a long",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "friend",
          "kevin",
          "hultquist",
          "used",
          "forever",
          "long"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_9",
        "text": "understand Professor: T oo true. Updates to persistent storage have always been, and r e-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "true",
          "updates",
          "persistent",
          "storage",
          "always"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S U M M A RYDI A L O G U E O NPE R S I S T E N C...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S U M M A RYDI A L O G U E O NPE R S I S T E N C E\nProfessor: (frowns) I think you\u2019re being sarcastic. Well, what else did you like?\nStudent: And I also liked all the thought that has gone into building technology-\naware systems, like FFS and LFS. Neat stuff! Being disk aware seems c ool. But\nwill it matter anymore, with Flash and all the newest, latest technolo gies?\nProfessor: Good question! And a reminder to get working on that Flash chap-\nter ... (scribbles note down to self) ... But yes, even with Flash, all of this stuff\nis still relevant, amazingly. For example, Flash T ranslation Layers (F TLs) use\nlog-structuring internally, to improve performance and reliability of F lash-based\nSSDs. And thinking about locality is always useful. So while the technolog y\nmay be changing, many of the ideas we have studied will continue to be useful,\nfor a while at least.\nStudent: That\u2019s good. I just spent all this time learning it, and I didn\u2019t want it\nto all be for no reason!\nProfessor: Professors wouldn\u2019t do that to you, would they?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: That\u2019s good. I just spent all this time learning it, and I didn\u2019t want it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "good",
          "spent",
          "time",
          "learning",
          "want"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Student: And I also liked all the thought that has gone into building technology-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "also",
          "liked",
          "thought",
          "gone",
          "building",
          "technology"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: Good question! And a reminder to get working on that Flash chap-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "good",
          "question",
          "reminder",
          "working",
          "flash",
          "chap"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Professor: Professors wouldn\u2019t do that to you, would they?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "professors",
          "would"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "47\nA Dialogue on Distribution\nProfessor: And thus we reach our \ufb01nal little piece in the world of operating\nsystems: distributed systems. Since we can\u2019t cover much here, w e\u2019ll sneak in a\nlittle intro here in the section on persistence, and focus mostly on dist ributed \ufb01le\nsystems. Hope that is OK!\nStudent: Sounds OK. But what is a distributed system exactly, oh glorious and\nall-knowing professor?\nProfessor: Well, I bet you know how this is going to go...\nStudent: There\u2019s a peach?\nProfessor: Exactly! But this time, it\u2019s far away from you, and may take some\ntime to get the peach. And there are a lot of them! Even worse, som etimes a\npeach becomes rotten. But you want to make sure that when anyb ody bites into\na peach, they will get a mouthful of deliciousness.\nStudent: This peach analogy is working less and less for me.\nProfessor: Come on! It\u2019s the last one, just go with it.\nStudent: Fine.\nProfessor: So anyhow, forget about the peaches. Building distributed systems\nis hard, because things fail all the time. Messages get lost, machines go down,\ndisks corrupt data. It\u2019s like the whole world is working against you!\nStudent: But I use distributed systems all the time, right?\nProfessor: Y es! Y ou do. And... ?\nStudent: Well, it seems like they mostly work. After all, when I send a search\nrequest to Google, it usually comes back in a snap, with some great re sults! Same\nthing when I use Facebook, Amazon, and so forth.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "all-knowing professor?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowing",
          "professor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Professor: Well, I bet you know how this is going to go...",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "well",
          "know",
          "going"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand systems: distributed systems. Since we can\u2019t cover much here, w e\u2019ll sneak in a",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "systems",
          "distributed",
          "systems",
          "since",
          "cover",
          "much",
          "sneak"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand Student: Sounds OK. But what is a distributed system exactly, oh glorious and",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "distributed",
          "system",
          "exactly",
          "glorious"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand Professor: Exactly! But this time, it\u2019s far away from you, and may take some",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "exactly",
          "time",
          "away",
          "take"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: This peach analogy is working less and less for me.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "peach",
          "analogy",
          "working",
          "less",
          "less"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_8",
        "text": "understand Professor: Come on! It\u2019s the last one, just go with it.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "come",
          "last"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_10",
        "text": "understand Professor: So anyhow, forget about the peaches. Building distributed systems",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "anyhow",
          "forget",
          "peaches",
          "building",
          "distributed",
          "systems"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Student: But I use distributed systems all the time, right?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "distributed",
          "systems",
          "time",
          "right"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand a distributed system exactly, oh glorious and\nall-knowing professor",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "distributed",
          "system",
          "exactly",
          "glorious",
          "knowing",
          "professor"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 A D I A L O G U E O NDI S T R I B U T I O N",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 A D I A L O G U E O NDI S T R I B U T I O N\nProfessor: Y es, it is amazing. And that\u2019s despite all of those failures taking\nplace! Those companies build a huge amount of machinery into their sy stems so\nas to ensure that even though some machines have failed, the entire system stays\nup and running. They use a lot of techniques to do this: replication, r etry, and\nvarious other tricks people have developed over time to detect and recover from\nfailures.\nStudent: Sounds interesting. Time to learn something for real?\nProfessor: It does seem so. Let\u2019s get to work! But \ufb01rst things \ufb01rst ...\n(bites into peach he has been holding, which unfortunately is rotten)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "up and running. They use a lot of techniques to do this: replication, r etry, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "running",
          "techniques",
          "replication",
          "etry"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "various other tricks people have developed over time to detect and recover from",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "various",
          "tricks",
          "people",
          "developed",
          "time",
          "detect",
          "recover"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Student: Sounds interesting. Time to learn something for real?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "sounds",
          "interesting",
          "time",
          "learn",
          "something",
          "real"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand Professor: It does seem so. Let\u2019s get to work! But \ufb01rst things \ufb01rst ...",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "seem",
          "work",
          "things"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "48\nDistributed Systems\nDistributed systems have changed the face of the world. When you r web\nbrowser connects to a web server somewhere else on the planet, it i s par-\nticipating in what seems to be a simple form of a client/server distributed\nsystem. When you contact a modern web service such as Google or Face-\nbook, you are not just interacting with a single machine, however; be-\nhind the scenes, these complex services are built from a large c ollection\n(i.e., thousands) of machines, each of which cooperate to provide t he par-\nticular service of the site. Thus, it should be clear what makes studying\ndistributed systems interesting. Indeed, it is worthy of an en tire class;\nhere, we just introduce a few of the major topics.\nA number of new challenges arise when building a distributed s ystem.\nThe major one we focus on is failure; machines, disks, networks, and\nsoftware all fail from time to time, as we do not (and likely , will never)\nknow how to build \u201cperfect\u201d components and systems. However , when\nwe build a modern web service, we\u2019d like it to appear to clients a s if it\nnever fails; how can we accomplish this task?\nTH E CR U X :\nHO W TO BU I L D SY S T E M S TH AT WO R K WH E N CO M P O N E N T S FA I L\nHow can we build a working system out of parts that don\u2019t work correctly\nall the time? The basic question should remind you of some of the topic s\nwe discussed in RAID storage arrays; however , the problems here tend\nto be more complex, as are the solutions.\nInterestingly , while failure is a central challenge in const ructing dis-\ntributed systems, it also represents an opportunity . Y es, mac hines fail;\nbut the mere fact that a machine fails does not imply the entire s ystem\nmust fail. By collecting together a set of machines, we can build a sys-\ntem that appears to rarely fail, despite the fact that its comp onents fail\nregularly . This reality is the central beauty and value of dis tributed sys-\ntems, and why they underly virtually every modern web service you use,\nincluding Google, Facebook, etc.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "know how to build \u201cperfect\u201d components and systems. However , when",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "build",
          "perfect",
          "components",
          "systems",
          "however"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "1 Communication Basics",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "48.1 Communication Basics\nThe central tenet of modern networking is that communication is fu n-\ndamentally unreliable. Whether in the wide-area Internet, or a local-area\nhigh-speed network such as In\ufb01niband, packets are regularly lost, cor-\nrupted, or otherwise do not reach their destination.\nThere are a multitude of causes for packet loss or corruption. Some-\ntimes, during transmission, some bits get \ufb02ipped due to electr ical or other\nsimilar problems. Sometimes, an element in the system, such as a net-\nwork link or packet router or even the remote host, are somehow dam-\naged or otherwise not working correctly; network cables do acciden tally\nget severed, at least sometimes.\nMore fundamental however is packet loss due to lack of buffering\nwithin a network switch, router , or endpoint. Speci\ufb01cally , even i f we\ncould guarantee that all links worked correctly , and that all th e compo-\nnents in the system (switches, routers, end hosts) were up and r unning as\nexpected, loss is still possible, for the following reason. Imagin e a packet\narrives at a router; for the packet to be processed, it must be pla ced in\nmemory somewhere within the router . If many such packets arrive at\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "More fundamental however is packet loss due to lack of buffering",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "fundamental",
          "however",
          "packet",
          "loss",
          "lack",
          "buffering"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand communication basics",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "communication",
          "basics"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "2 Unreliable Communication Layers",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "48.2 Unreliable Communication Layers\nOne simple way is this: we don\u2019t deal with it. Because some appli-\ncations know how to deal with packet loss, it is sometimes useful to let\nthem communicate with a basic unreliable messaging layer , an example\nof the end-to-end argument one often hears about (see the Aside at end\nof chapter). One excellent example of such an unreliable layer is found\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "cations know how to deal with packet loss, it is sometimes useful to let",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "cations",
          "know",
          "deal",
          "packet",
          "loss",
          "sometimes",
          "useful"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand unreliable communication layers",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "unreliable",
          "communication",
          "layers"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "4 DI S T R I B U T E D SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "4 DI S T R I B U T E D SY S T E M S\nint UDP_Open(int port) {\nint sd;\nif ((sd = socket(AF_INET, SOCK_DGRAM, 0)) == -1)\nreturn -1;\nstruct sockaddr_in myaddr;\nbzero(&myaddr, sizeof(myaddr));\nmyaddr.sin_family = AF_INET;\nmyaddr.sin_port = htons(port);\nmyaddr.sin_addr.s_addr = INADDR_ANY;\nif (bind(sd, (struct sockaddr *) &myaddr,\nsizeof(myaddr)) == -1) {\nclose(sd);\nreturn -1;\n}\nreturn sd;\n}\nint UDP_FillSockAddr(struct sockaddr_in *addr,\nchar *hostname, int port) {\nbzero(addr, sizeof(struct sockaddr_in));\naddr->sin_family = AF_INET; // host byte order\naddr->sin_port = htons(port); // network byte order\nstruct in_addr *in_addr;\nstruct hostent *host_entry;\nif ((host_entry = gethostbyname(hostname)) == NULL)\nreturn -1;\nin_addr = (struct in_addr *) host_entry->h_addr;\naddr->sin_addr = *in_addr;\nreturn 0;\n}\nint UDP_Write(int sd, struct sockaddr_in *addr,\nchar *buffer, int n) {\nint addr_len = sizeof(struct sockaddr_in);\nreturn sendto(sd, buffer, n, 0, (struct sockaddr *)\naddr, addr_len);\n}\nint UDP_Read(int sd, struct sockaddr_in *addr,\nchar *buffer, int n) {\nint len = sizeof(struct sockaddr_in);\nreturn recvfrom(sd, buffer, n, 0, (struct sockaddr *)\naddr, (socklen_t *) &len);\n}\nFigure 48.2: A Simple UDP Library (udp.c)\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 2: A Simple UDP Library (udp.c)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "simple",
          "library"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "3 Reliable Communication Layers",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "48.3 Reliable Communication Layers\nT o build a reliable communication layer , we need some new mech-\nanisms and techniques to handle packet loss. Let us consider a s imple\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "anisms and techniques to handle packet loss. Let us consider a s imple",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "anisms",
          "techniques",
          "handle",
          "packet",
          "loss",
          "consider",
          "imple"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand reliable communication layers",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reliable",
          "communication",
          "layers"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 DI S T R I B U T E D SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 DI S T R I B U T E D SY S T E M S\nSender\n[send message]\nReceiver\n[receive message]\n[send ack]\n[receive ack]\nFigure 48.3: Message Plus Acknowledgment\nSender\n[send message;\n keep copy;\n set timer]\nReceiver\n...\n (waiting for ack)\n...\n[timer goes off;\n set timer/retry]\n[receive message]\n[send ack]\n[receive ack;\n delete copy/timer off]\nFigure 48.4: Message Plus Acknowledgment: Dropped Request\nexample in which a client is sending a message to a server over a n unreli-\nable connection. The \ufb01rst question we must answer: how does the sen der\nknow that the receiver has actually received the message?\nThe technique that we will use is known as an acknowledgment, or\nack for short. The idea is simple: the sender sends a message to the r e-\nceiver; the receiver then sends a short message back to acknowledge its\nreceipt. Figure 48.3 depicts the process.\nWhen the sender receives an acknowledgment of the message, it c an\nthen rest assured that the receiver did indeed receive the ori ginal mes-\nsage. However , what should the sender do if it does not receive an a c-\nknowledgment?\nT o handle this case, we need an additional mechanism, known as a\ntimeout. When the sender sends a message, the sender now sets a timer\nto go off after some period of time. If, in that time, no acknowledgm ent\nhas been received, the sender concludes that the message has b een lost.\nThe sender then simply performs a retry of the send, sending the same\nmessage again with hopes that this time, it will get through. For this\napproach to work, the sender must keep a copy of the message around,\nin case it needs to send it again. The combination of the timeout an d\nthe retry have led some to call the approach timeout/retry; pretty clever\ncrowd, those networking types, no? Figure 48.4 shows an example.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Figure 48.3: Message Plus Acknowledgment",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "figure",
          "message",
          "plus",
          "acknowledgment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Figure 48.4: Message Plus Acknowledgment: Dropped Request",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "figure",
          "message",
          "plus",
          "acknowledgment",
          "dropped",
          "request"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "know that the receiver has actually received the message?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "receiver",
          "actually",
          "received",
          "message"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "The technique that we will use is known as an acknowledgment, or",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "technique",
          "known",
          "acknowledgment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "ceiver; the receiver then sends a short message back to acknowledge its",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ceiver",
          "receiver",
          "sends",
          "short",
          "message",
          "back",
          "acknowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "When the sender receives an acknowledgment of the message, it c an",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sender",
          "receives",
          "acknowledgment",
          "message"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "knowledgment?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "knowledgment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "T o handle this case, we need an additional mechanism, known as a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "handle",
          "case",
          "need",
          "additional",
          "mechanism",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "to go off after some period of time. If, in that time, no acknowledgm ent",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "period",
          "time",
          "time",
          "acknowledgm"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_10",
        "text": "approach to work, the sender must keep a copy of the message around,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "work",
          "sender",
          "must",
          "keep",
          "copy",
          "message",
          "around"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 3: Message Plus Acknowledgment",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "message",
          "plus",
          "acknowledgment"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 4: Message Plus Acknowledgment: Dropped Request",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "message",
          "plus",
          "acknowledgment",
          "dropped",
          "request"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand The idea is simple: the sender sends a message to the r e-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the idea is simple",
          "sender",
          "sends",
          "message"
        ],
        "confidence": 0.8
      },
      {
        "id": "question_concept_1",
        "text": "understand the sen der\nknow that the receiver has actually received the message",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "receiver",
          "actually",
          "received",
          "message"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DI S T R I B U T E D SY S T E M S 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DI S T R I B U T E D SY S T E M S 7\nSender\n[send message;\n keep copy;\n set timer]\nReceiver\n[receive message]\n[send ack]\n...\n (waiting for ack)\n...\n[timer goes off;\n set timer/retry]\n[receive message]\n[send ack]\n[receive ack;\n delete copy/timer off]\nFigure 48.5: Message Plus Acknowledgment: Dropped Reply\nUnfortunately , timeout/retry in this form is not quite enough. Fi gure\n48.5 shows an example of packet loss which could lead to trouble. In this\nexample, it is not the original message that gets lost, but the ac knowledg-\nment. From the perspective of the sender , the situation seems th e same:\nno ack was received, and thus a timeout and retry are in order . Bu t from\nthe perspective of the receiver , it is quite different: now the same message\nhas been received twice! While there may be cases where this i s OK, in\ngeneral it is not; imagine what would happen when you are downloadi ng\na \ufb01le and extra packets are repeated inside the download. Thus, when we\nare aiming for a reliable message layer , we also usually want t o guarantee\nthat each message is received exactly once by the receiver .\nT o enable the receiver to detect duplicate message transmis sion, the\nsender has to identify each message in some unique way , and the receiver\nneeds some way to track whether it has already seen each messag e be-\nfore. When the receiver sees a duplicate transmission, it simp ly acks the\nmessage, but (critically) does not pass the message to the application that\nreceives the data. Thus, the sender receives the ack but the m essage is not\nreceived twice, preserving the exactly-once semantics ment ioned above.\nThere are myriad ways to detect duplicate messages. For examp le, the\nsender could generate a unique ID for each message; the receive r could\ntrack every ID it has ever seen. This approach could work, but it i s pro-\nhibitively costly , requiring unbounded memory to track all IDs .\nA simpler approach, requiring little memory , solves this proble m, and\nthe mechanism is known as a sequence counter. With a sequence counter ,\nthe sender and receiver agree upon a start value (e.g., 1) for a c ounter\nthat each side will maintain. Whenever a message is sent, the current\nvalue of the counter is sent along with the message; this counter v alue\n(N) serves as an ID for the message. After the message is sent, the sender\nthen increments the value (to N + 1).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Figure 48.5: Message Plus Acknowledgment: Dropped Reply",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "figure",
          "message",
          "plus",
          "acknowledgment",
          "dropped",
          "reply"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "example, it is not the original message that gets lost, but the ac knowledg-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "example",
          "original",
          "message",
          "gets",
          "lost",
          "knowledg"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "sender has to identify each message in some unique way , and the receiver",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sender",
          "identify",
          "message",
          "unique",
          "receiver"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "message, but (critically) does not pass the message to the application that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "message",
          "critically",
          "pass",
          "message",
          "application"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "track every ID it has ever seen. This approach could work, but it i s pro-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "track",
          "every",
          "ever",
          "seen",
          "approach",
          "could",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "A simpler approach, requiring little memory , solves this proble m, and",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simpler",
          "approach",
          "requiring",
          "little",
          "memory",
          "solves",
          "proble"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "the mechanism is known as a sequence counter. With a sequence counter ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "mechanism",
          "known",
          "sequence",
          "counter",
          "sequence",
          "counter"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 5: Message Plus Acknowledgment: Dropped Reply",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "message",
          "plus",
          "acknowledgment",
          "dropped",
          "reply"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand shows an example of packet loss which could lead to trouble. in this",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "shows",
          "example",
          "packet",
          "loss",
          "could",
          "lead",
          "trouble"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "4 Communication Abstractions",
    "document_source": "book.pdf",
    "start_line": 37,
    "type": "chapter",
    "content": "48.4 Communication Abstractions\nGiven a basic messaging layer , we now approach the next question\nin this chapter: what abstraction of communication should we use w hen\nbuilding a distributed system?\nThe systems community developed a number of approaches over the\nyears. One body of work took OS abstractions and extended them to\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Given a basic messaging layer , we now approach the next question",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "given",
          "basic",
          "messaging",
          "layer",
          "approach",
          "next",
          "question"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The systems community developed a number of approaches over the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "systems",
          "community",
          "developed",
          "number",
          "approaches"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand communication abstractions",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "communication",
          "abstractions"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "5 Remote Procedure Call (RPC)",
    "document_source": "book.pdf",
    "start_line": 30,
    "type": "chapter",
    "content": "48.5 Remote Procedure Call (RPC)\nWhile OS abstractions turned out to be a poor choice for building dis -\ntributed systems, programming language (PL) abstractions ma ke much\nmore sense. The most dominant abstraction is based on the idea of a re-\nmote procedure call, or RPC for short [BN84] 1 .\nRemote procedure call packages all have a simple goal: to make th e\nprocess of executing code on a remote machine as simple and straigh t-\nforward as calling a local function. Thus, to a client, a procedur e call is\nmade, and some time later , the results are returned. The serve r simply\nde\ufb01nes some routines that it wishes to export. The rest of the magi c is\nhandled by the RPC system, which in general has two pieces: a stub gen-\nerator (sometimes called a protocol compiler), and the run-time library.\nW e\u2019ll now take a look at each of these pieces in more detail.\n1 In modern programming languages, we might instead say remote method invocation\n(RMI), but who likes these languages anyhow , with all of their fancy objects?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Remote procedure call packages all have a simple goal: to make th e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "remote",
          "procedure",
          "call",
          "packages",
          "simple",
          "goal",
          "make"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "In modern programming languages, we might instead say remote method invocation",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "modern",
          "programming",
          "languages",
          "might",
          "instead",
          "remote",
          "method",
          "invocation"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand remote procedure call (rpc)",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "remote",
          "procedure",
          "call"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 DI S T R I B U T E D SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 DI S T R I B U T E D SY S T E M S\nStub Generator\nThe stub generator \u2019s job is simple: to remove some of the pain of packi ng\nfunction arguments and results into messages by automating it . Numer-\nous bene\ufb01ts arise: one avoids, by design, the simple mistakes th at occur\nin writing such code by hand; further , a stub compiler can perha ps opti-\nmize such code and thus improve performance.\nThe input to such a compiler is simply the set of calls a server wi shes\nto export to clients. Conceptually , it could be something as simp le as this:\ninterface {\nint func1(int arg1);\nint func2(int arg1, int arg2);\n};\nThe stub generator takes an interface like this and generates a few dif-\nferent pieces of code. For the client, a client stub is generated, which\ncontains each of the functions speci\ufb01ed in the interface; a clie nt program\nwishing to use this RPC service would link with this client stu b and call\ninto it in order to make RPCs.\nInternally , each of these functions in the client stub do all of t he work\nneeded to perform the remote procedure call. T o the client, the c ode just\nappears as a function call (e.g., the client calls func1(x)); internally , the\ncode in the client stub for func1() does this:\n\u2022 Create a message buffer. A message buffer is usually just a con-\ntiguous array of bytes of some size.\n\u2022 Pack the needed information into the message buffer. This infor-\nmation includes some kind of identi\ufb01er for the function to be calle d,\nas well as all of the arguments that the function needs (e.g., in our\nexample above, one integer for func1). The process of putting all\nof this information into a single contiguous buffer is sometimes re -\nferred to as the marshaling of arguments or the serialization of the\nmessage.\n\u2022 Send the message to the destination RPC server. The communi-\ncation with the RPC server , and all of the details required to ma ke\nit operate correctly , are handled by the RPC run-time library , de-\nscribed further below .\n\u2022 W ait for the reply .Because function calls are usually synchronous,\nthe call will wait for its completion.\n\u2022 Unpack return code and other arguments. If the function just re-\nturns a single return code, this process is straightforward; how ever ,\nmore complex functions might return more complex results (e.g., a\nlist), and thus the stub might need to unpack those as well. Thi s\nstep is also known as unmarshaling or deserialization.\n\u2022 Return to the caller. Finally , just return from the client stub back\ninto the client code.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ous bene\ufb01ts arise: one avoids, by design, the simple mistakes th at occur",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "arise",
          "avoids",
          "design",
          "simple",
          "mistakes",
          "occur"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to export to clients. Conceptually , it could be something as simp le as this:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "export",
          "clients",
          "conceptually",
          "could",
          "something",
          "simp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Create a message buffer. A message buffer is usually just a con-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "message",
          "buffer",
          "message",
          "buffer",
          "usually"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "step is also known as unmarshaling or deserialization.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "step",
          "also",
          "known",
          "unmarshaling",
          "deserialization"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand s job is simple: to remove some of the pain of packi ng",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "s job is simple",
          "remove",
          "pain",
          "packi"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand does this: \u2022 Create a message buffer. A message buffer is usually just a con-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "does this",
          "create",
          "message",
          "buffer",
          "message",
          "buffer",
          "usually"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_2",
        "text": "understand pack the needed information into the message buffer. this infor-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "pack",
          "needed",
          "information",
          "message",
          "buffer",
          "infor"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand send the message to the destination rpc server. the communi-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "send",
          "message",
          "destination",
          "server",
          "communi"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand w ait for the reply .because function calls are usually synchronous,",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "reply",
          "function",
          "calls",
          "usually",
          "synchronous"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand unpack return code and other arguments. if the function just re-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "unpack",
          "return",
          "code",
          "arguments",
          "function"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand return to the caller. finally , just return from the client stub back",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "return",
          "caller",
          "finally",
          "return",
          "client",
          "stub",
          "back"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DI S T R I B U T E D SY S T E M S 11",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DI S T R I B U T E D SY S T E M S 11\nFor the server , code is also generated. The steps taken on the ser ver\nare as follows:\n\u2022 Unpack the message. This step, called unmarshaling or deserial-\nization, takes the information out of the incoming message. The\nfunction identi\ufb01er and arguments are extracted.\n\u2022 Call into the actual function. Finally! W e have reached the point\nwhere the remote function is actually executed. The RPC runtim e\ncalls into the function speci\ufb01ed by the ID and passes in the des ired\narguments.\n\u2022 Package the results. The return argument(s) are marshaled back\ninto a single reply buffer .\n\u2022 Send the reply .The reply is \ufb01nally sent to the caller .\nThere are a few other important issues to consider in a stub compil er .\nThe \ufb01rst is complex arguments, i.e., how does one package and send\na complex data structure? For example, when one calls the write()\nsystem call, one passes in three arguments: an integer \ufb01le des criptor , a\npointer to a buffer , and a size indicating how many bytes (start ing at the\npointer) are to be written. If an RPC package is passed a pointer , it needs\nto be able to \ufb01gure out how to interpret that pointer , and perform t he\ncorrect action. Usually this is accomplished through either wel l-known\ntypes (e.g., a buffer\nt that is used to pass chunks of data given a size,\nwhich the RPC compiler understands), or by annotating the data s truc-\ntures with more information, enabling the compiler to know which b ytes\nneed to be serialized.\nAnother important issue is the organization of the server with reg ards\nto concurrency . A simple server just waits for requests in a sim ple loop,\nand handles each request one at a time. However , as you might have\nguessed, this can be grossly inef\ufb01cient; if one RPC call blocks ( e.g., on\nI/O), server resources are wasted. Thus, most servers are const ructed in\nsome sort of concurrent fashion. A common organization is a thread pool.\nIn this organization, a \ufb01nite set of threads are created when the server\nstarts; when a message arrives, it is dispatched to one of these worker\nthreads, which then does the work of the RPC call, eventually rep lying;\nduring this time, a main thread keeps receiving other request s, and per-\nhaps dispatching them to other workers. Such an organization enab les\nconcurrent execution within the server , thus increasing its u tilization; the\nstandard costs arise as well, mostly in programming complexity , as the\nRPC calls may now need to use locks and other synchronization primi -\ntives in order to ensure their correct operation.\nRun-Time Library\nThe run-time library handles much of the heavy lifting in an RP C system;\nmost performance and reliability issues are handled herein. W e\u2019ll now\ndiscuss some of the major challenges in building such a run-time layer .\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "There are a few other important issues to consider in a stub compil er .",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "issues",
          "consider",
          "stub",
          "compil"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to be able to \ufb01gure out how to interpret that pointer , and perform t he",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "interpret",
          "pointer",
          "perform"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "correct action. Usually this is accomplished through either wel l-known",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "correct",
          "action",
          "usually",
          "accomplished",
          "either",
          "known"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "which the RPC compiler understands), or by annotating the data s truc-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "compiler",
          "understands",
          "annotating",
          "data",
          "truc"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "tures with more information, enabling the compiler to know which b ytes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tures",
          "information",
          "enabling",
          "compiler",
          "know",
          "ytes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "Another important issue is the organization of the server with reg ards",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "another",
          "important",
          "issue",
          "organization",
          "server",
          "ards"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "In this organization, a \ufb01nite set of threads are created when the server",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "organization",
          "threads",
          "created",
          "server"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand unpack the message. this step, called unmarshaling or deserial-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "unpack",
          "message",
          "step",
          "called",
          "unmarshaling",
          "deserial"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand call into the actual function. finally! w e have reached the point",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "call",
          "actual",
          "function",
          "finally",
          "reached",
          "point"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand package the results. the return argument(s) are marshaled back",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "package",
          "results",
          "return",
          "argument",
          "marshaled",
          "back"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_4",
        "text": "understand send the reply .the reply is \ufb01nally sent to the caller .",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "send",
          "reply",
          "reply",
          "sent",
          "caller"
        ],
        "confidence": 0.7
      },
      {
        "id": "question_concept_1",
        "text": "understand one package and send\na complex data structure",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "package",
          "send",
          "complex",
          "data",
          "structure"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 DI S T R I B U T E D SY S T E M S",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 DI S T R I B U T E D SY S T E M S\nOne of the \ufb01rst challenges we must overcome is how to locate a re-\nmote service. This problem, of naming, is a common one in distributed\nsystems, and in some sense goes beyond the scope of our current discu s-\nsion. The simplest of approaches build on existing naming system s, e.g.,\nhostnames and port numbers provided by current internet protocols . In\nsuch a system, the client must know the hostname or IP address of th e\nmachine running the desired RPC service, as well as the port nu mber it is\nusing (a port number is just a way of identifying a particular com munica-\ntion activity taking place on a machine, allowing multiple commu nication\nchannels at once). The protocol suite must then provide a mechanis m to\nroute packets to a particular address from any other machine in t he sys-\ntem. For a good discussion of naming, you\u2019ll have to look elsewhere, e.g .,\nread about DNS and name resolution on the Internet, or better yet ju st\nread the excellent chapter in Saltzer and Kaashoek\u2019s book [SK09].\nOnce a client knows which server it should talk to for a particula r re-\nmote service, the next question is which transport-level protocol should\nRPC be built upon. Speci\ufb01cally , should the RPC system use a relia ble pro-\ntocol such as TCP/IP , or be built upon an unreliable communication l ayer\nsuch as UDP/IP?\nNaively the choice would seem easy: clearly we would like for a re-\nquest to be reliably delivered to the remote server , and clear ly we would\nlike to reliably receive a reply . Thus we should choose the relia ble trans-\nport protocol such as TCP , right?\nUnfortunately , building RPC on top of a reliable communication lay er\ncan lead to a major inef\ufb01ciency in performance. Recall from the d iscus-\nsion above how reliable communication layers work: with acknowledg -\nments plus timeout/retry . Thus, when the client sends an RPC r equest\nto the server , the server responds with an acknowledgment so th at the\ncaller knows the request was received. Similarly , when the ser ver sends\nthe reply to the client, the client acks it so that the server k nows it was\nreceived. By building a request/response protocol (such as RPC) on top\nof a reliable communication layer , two \u201cextra\u201d messages are sen t.\nFor this reason, many RPC packages are built on top of unreliable com -\nmunication layers, such as UDP . Doing so enables a more ef\ufb01cient RPC\nlayer , but does add the responsibility of providing reliability to the RPC\nsystem. The RPC layer achieves the desired level of responsibi lity by us-\ning timeout/retry and acknowledgments much like we described above.\nBy using some form of sequence numbering, the communication layer\ncan guarantee that each RPC takes place exactly once (in the ca se of no\nfailure), or at most once (in the case where failure arises).\nOther Issues\nThere are some other issues an RPC run-time must handle as well. For\nexample, what happens when a remote call takes a long time to com-\nplete? Given our timeout machinery , a long-running remote call m ight\nappear as a failure to a client, thus triggering a retry , and t hus the need\nfor some care here. One solution is to use an explicit acknowledgme nt\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "sion. The simplest of approaches build on existing naming system s, e.g.,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sion",
          "simplest",
          "approaches",
          "build",
          "existing",
          "naming",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "such a system, the client must know the hostname or IP address of th e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "client",
          "must",
          "know",
          "hostname",
          "address"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "using (a port number is just a way of identifying a particular com munica-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "using",
          "port",
          "number",
          "identifying",
          "particular",
          "munica"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Once a client knows which server it should talk to for a particula r re-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "knows",
          "server",
          "talk",
          "particula"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "sion above how reliable communication layers work: with acknowledg -",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sion",
          "reliable",
          "communication",
          "layers",
          "work",
          "acknowledg"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "to the server , the server responds with an acknowledgment so th at the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "server",
          "server",
          "responds",
          "acknowledgment"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "caller knows the request was received. Similarly , when the ser ver sends",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "caller",
          "knows",
          "request",
          "received",
          "similarly",
          "sends"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "ing timeout/retry and acknowledgments much like we described above.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "timeout",
          "retry",
          "acknowledgments",
          "much",
          "like",
          "described"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_9",
        "text": "for some care here. One solution is to use an explicit acknowledgme nt",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "care",
          "solution",
          "explicit",
          "acknowledgme"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DI S T R I B U T E D SY S T E M S 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DI S T R I B U T E D SY S T E M S 13\nAside: T H E EN D -TO -E N D AR G U M E N T\nThe end-to-end argument makes the case that the highest level in a sys-\ntem, i.e., usually the application at \u201cthe end\u201d, is ultimatel y the only lo-\ncale within a layered system where certain functionality can truly be im-\nplemented. In their landmark paper [SRC84], Saltzer et al. arg ue this\nthrough an excellent example: reliable \ufb01le transfer between two ma-\nchines. If you want to transfer a \ufb01le from machine A to machine B, and\nmake sure that the bytes that end up on B are exactly the same as those\nthat began on A, you must have an \u201cend-to-end\u201d check of this; lower-\nlevel reliable machinery , e.g., in the network or disk, provide s no such\nguarantee.\nThe contrast is an approach which tries to solve the reliable-\ufb01l e-transfer\nproblem by adding reliability to lower layers of the system. For e xample,\nsay we build a reliable communication protocol and use it to build ou r\nreliable \ufb01le transfer . The communication protocol guarantees th at every\nbyte sent by a sender will be received in order by the receiver , say us-\ning timeout/retry , acknowledgments, and sequence numbers. U nfortu-\nnately , using such a protocol does not a reliable \ufb01le transfer make ; imag-\nine the bytes getting corrupted in sender memory before the commu ni-\ncation even takes place, or something bad happening when the rec eiver\nwrites the data to disk. In those cases, even though the bytes we re deliv-\nered reliably across the network, our \ufb01le transfer was ultimate ly not reli-\nable. T o build a reliable \ufb01le transfer , one must include end-t o-end checks\nof reliability , e.g., after the entire transfer is complete, r ead back the \ufb01le\non the receiver disk, compute a checksum, and compare that check sum\nto that of the \ufb01le on the sender .\nThe corollary to this maxim is that sometimes having lower layers pro-\nvide extra functionality can indeed improve system performanc e or oth-\nerwise optimize a system. Thus, you should not rule out having such\nmachinery at a lower-level in a system; rather , you should caref ully con-\nsider the utility of such machinery , given its eventual usage in an overall\nsystem or application.\n(from the receiver to sender) when the reply isn\u2019t immediately generated;\nthis lets the client know the server received the request. The n, after some\ntime has passed, the client can periodically ask whether the s erver is still\nworking on the request; if the server keeps saying \u201cyes\u201d, the cl ient should\nbe happy and continue to wait (after all, sometimes a procedure c all can\ntake a long time to \ufb01nish executing).\nThe run-time must also handle procedure calls with large argu ments,\nlarger than what can \ufb01t into a single packet. Some lower-level ne twork\nprotocols provide such sender-side fragmentation (of larger packets into\na set of smaller ones) and receiver-side reassembly (of smaller parts into\none larger logical whole); if not, the RPC run-time may have to imp lement\nsuch functionality itself. See Birrell and Nelson\u2019s paper for det ails [BN84].\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The contrast is an approach which tries to solve the reliable-\ufb01l e-transfer",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "contrast",
          "approach",
          "tries",
          "solve",
          "reliable",
          "transfer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ing timeout/retry , acknowledgments, and sequence numbers. U nfortu-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "timeout",
          "retry",
          "acknowledgments",
          "sequence",
          "numbers",
          "nfortu"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "on the receiver disk, compute a checksum, and compare that check sum",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "receiver",
          "disk",
          "compute",
          "checksum",
          "compare",
          "check"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "this lets the client know the server received the request. The n, after some",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "lets",
          "client",
          "know",
          "server",
          "received",
          "request"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "48",
    "title": "6 Summary",
    "document_source": "book.pdf",
    "start_line": 29,
    "type": "chapter",
    "content": "48.6 Summary\nW e have seen the introduction of a new topic, distributed systems , and\nits major issue: how to handle failure which is now a commonplace ev ent.\nAs they say inside of Google, when you have just your desktop machine ,\nfailure is rare; when you\u2019re in a data center with thousands of mac hines,\nfailure is happening all the time. The key to any distributed system is\nhow you deal with that failure.\nW e have also seen that communication forms the heart of any dis-\ntributed system. A common abstraction of that communication is foun d\nin remote procedure call (RPC), which enables clients to make r emote\ncalls on servers; the RPC package handles all of the gory details , includ-\ning timeout/retry and acknowledgment, in order to deliver a ser vice that\nclosely mirrors a local procedure call.\nThe best way to really understand an RPC package is of course to u se\none yourself. Sun\u2019s RPC system, using the stub compiler rpcgen, is an\nolder one; Google\u2019s gRPC and Apache Thrift are modern takes on the\nsame. T ry one out, and see what all the fuss is about.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ing timeout/retry and acknowledgment, in order to deliver a ser vice that",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "timeout",
          "retry",
          "acknowledgment",
          "order",
          "deliver",
          "vice"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The best way to really understand an RPC package is of course to u se",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "best",
          "really",
          "understand",
          "package",
          "course"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand and\nits major issue: how to handle failure which is now a commonplace ev ent.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and\nits major issue",
          "handle",
          "failure",
          "commonplace"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DI S T R I B U T E D SY S T E M S 15",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DI S T R I B U T E D SY S T E M S 15\nReferences\n[A70] \u201cThe ALOHA System \u2014 Another Alternative for Computer Communicati ons\u201d by Nor-\nman Abramson. The 1970 Fall Joint Computer Conference. The ALOHA network pioneered some\nbasic concepts in networking, including exponential back-off and retransmit, which formed the basis for\ncommunication in shared-bus Ethernet networks for years.\n[BN84] \u201cImplementing Remote Procedure Calls\u201d by Andrew D. Birrell , Bruce Jay Nelson.\nACM TOCS, V olume 2:1, February 1984. The foundational RPC system upon which all others build.\nY es, another pioneering effort from our friends at Xerox P ARC.\n[MK09] \u201cThe Effectiveness of Checksums for Embedded Control Networks\u201d b y Theresa C.\nMaxino and Philip J. Koopman. IEEE T ransactions on Dependable and Secure Co mputing,\n6:1, January \u201909. A nice overview of basic checksum machinery and some performance and robu stness\ncomparisons between them.\n[LH89] \u201cMemory Coherence in Shared Virtual Memory Systems\u201d by Kai Li and Paul Hudak.\nACM TOCS, 7:4, November 1989. The introduction of software-based shared memory via virtual\nmemory. An intriguing idea for sure, but not a lasting or good one in the end .\n[SK09] \u201cPrinciples of Computer System Design\u201d by Jerome H. Saltzer and M. Frans Kaashoek.\nMorgan-Kaufmann, 2009. An excellent book on systems, and a must for every bookshelf. One of the\nfew terri\ufb01c discussions on naming we\u2019ve seen.\n[SRC84] \u201cEnd-T o-End Arguments in System Design\u201d by Jerome H. Saltzer , David P . Reed,\nDavid D. Clark. ACM TOCS, 2:4, November 1984. A beautiful discussion of layering, abstraction,\nand where functionality must ultimately reside in computer systems.\n[VJ88] \u201cCongestion A voidance and Control\u201d by V an Jacobson. SIGCOMM \u201988 . A pioneering\npaper on how clients should adjust to perceived network congestion; de\ufb01ni tely one of the key pieces of\ntechnology underlying the Internet, and a must read for anyone serious about s ystems, and for V an\nJacobson\u2019s relatives because well relatives should read all of your papers.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "basic concepts in networking, including exponential back-off and retransmit, which formed the basis for",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "concepts",
          "networking",
          "including",
          "exponential",
          "back",
          "retransmit",
          "formed"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "[BN84] \u201cImplementing Remote Procedure Calls\u201d by Andrew D. Birrell , Bruce Jay Nelson.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementing",
          "remote",
          "procedure",
          "calls",
          "andrew",
          "birrell",
          "bruce",
          "nelson"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[SK09] \u201cPrinciples of Computer System Design\u201d by Jerome H. Saltzer and M. Frans Kaashoek.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "principles",
          "computer",
          "system",
          "design",
          "jerome",
          "saltzer",
          "frans",
          "kaashoek"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "[SRC84] \u201cEnd-T o-End Arguments in System Design\u201d by Jerome H. Saltzer , David P . Reed,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "arguments",
          "system",
          "design",
          "jerome",
          "saltzer",
          "david",
          "reed"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand V olume 2: 1, February 1984. The foundational RPC system upon which all others build.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "v olume 2",
          "february",
          "foundational",
          "system",
          "upon",
          "others",
          "build"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand 6: 1, January \u201909. A nice overview of basic checksum machinery and some performance and robu stness",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "january",
          "nice",
          "overview",
          "basic",
          "checksum",
          "machinery",
          "performance",
          "robu"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand 7: 4, November 1989. The introduction of software-based shared memory via virtual",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "november",
          "introduction",
          "software",
          "based",
          "shared",
          "memory",
          "virtual"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 2: 4, November 1984. A beautiful discussion of layering, abstraction,",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "november",
          "beautiful",
          "discussion",
          "layering",
          "abstraction"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Using the code provided in the chapter , build a simple UDP-ba sed",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "1. Using the code provided in the chapter , build a simple UDP-ba sed\nserver and client. The server should receive messages from the\nclient, and reply with an acknowledgment. In this \ufb01rst attemp t,\ndo not add any retransmission or robustness (assume that commu-\nnication works perfectly). Run this on a single machine for testi ng;\nlater , run it on two different machines.\n2. T urn your code into a communication library . Speci\ufb01cally , make\nyour own API, with send and receive calls, as well as other API\ncalls as needed. Rewrite your client and server to use your libr ary\ninstead of raw socket calls.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "client, and reply with an acknowledgment. In this \ufb01rst attemp t,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "reply",
          "acknowledgment",
          "attemp"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "3",
    "title": "Add reliable communication to your burgeoning communication li -",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "3. Add reliable communication to your burgeoning communication li -\nbrary , in the form of timeout/retry. Speci\ufb01cally , your library should\nmake a copy of any message that it is going to send. When sending\nit, it should start a timer , so it can track how long it has been sin ce\nthe message was sent. On the receiver , the library should acknowl-\nedge received messages. The client send should block when send-\ning, i.e., it should wait until the message has been acknowledg ed\nbefore returning. It should also be willing to retry sending in def-\ninitely . The maximum message size should be that of the largest\nsingle message you can send with UDP . Finally , be sure to perfor m\ntimeout/retry ef\ufb01ciently by putting the caller to sleep unti l either\nan ack arrives or the transmission times out; do not spin and waste\nthe CPU!\n4. Make your library more ef\ufb01cient and feature-\ufb01lled. First, a dd very-\nlarge message transfer . Speci\ufb01cally , although the network lim it max-\nimum message size, your library should take a message of arbitra r-\nily large size and transfer it from client to server . The clien t should\ntransmit these large messages in pieces to the server; the se rver-side\nlibrary code should assemble received fragments into the conti gu-\nous whole, and pass the single large buffer to the waiting serve r\ncode.\n5. Do the above again, but with high performance. Instead of send ing\neach fragment one at a time, you should rapidly send many pieces,\nthus allowing the network to be much more highly utilized. T o do\nso, carefully mark each piece of the transfer so that the re-ass embly\non the receiver side does not scramble the message.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the message was sent. On the receiver , the library should acknowl-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "message",
          "sent",
          "receiver",
          "library",
          "acknowl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ing, i.e., it should wait until the message has been acknowledg ed",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "wait",
          "message",
          "acknowledg"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "6",
    "title": "A \ufb01nal implementation challenge: asynchronous message send with",
    "document_source": "book.pdf",
    "start_line": 41,
    "type": "chapter",
    "content": "6. A \ufb01nal implementation challenge: asynchronous message send with\nin-order delivery . That is, the client should be able to repeat edly call\nsend to send one message after the other; the receiver should cal l re-\nceive and get each message in order , reliably; many messages f rom\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "A \ufb01nal implementation challenge: asynchronous message send with",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementation",
          "challenge",
          "asynchronous",
          "message",
          "send"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in-order delivery . That is, the client should be able to repeat edly call",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "order",
          "delivery",
          "client",
          "able",
          "repeat",
          "edly",
          "call"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "DI S T R I B U T E D SY S T E M S 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "DI S T R I B U T E D SY S T E M S 17\nthe sender should be able to be in \ufb02ight concurrently . Also add a\nsender-side call that enables a client to wait for all outstand ing mes-\nsages to be acknowledged.\n7. Now , one more pain point: measurement. Measure the bandwidth\nof each of your approaches; how much data can you transfer be-\ntween two different machines, at what rate? Also measure lat ency:\nfor single packet send and acknowledgment, how quickly does it\n\ufb01nish? Finally , do your numbers look reasonable? What did you\nexpect? How can you better set your expectations so as to know if\nthere is a problem, or that your code is working well?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "the sender should be able to be in \ufb02ight concurrently . Also add a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sender",
          "able",
          "concurrently",
          "also"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "sages to be acknowledged.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "sages",
          "acknowledged"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "of each of your approaches; how much data can you transfer be-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approaches",
          "much",
          "data",
          "transfer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "for single packet send and acknowledgment, how quickly does it",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "single",
          "packet",
          "send",
          "acknowledgment",
          "quickly"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "expect? How can you better set your expectations so as to know if",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "expect",
          "better",
          "expectations",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand one more pain point: measurement. Measure the bandwidth",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "one more pain point",
          "measurement",
          "measure",
          "bandwidth"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Also measure lat ency: for single packet send and acknowledgment, how quickly does it",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "also measure lat ency",
          "single",
          "packet",
          "send",
          "acknowledgment",
          "quickly"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "49\nSun\u2019s Network File System (NFS)\nOne of the \ufb01rst uses of distributed client/server computing was in the\nrealm of distributed \ufb01le systems. In such an environment, ther e are a\nnumber of client machines and one server (or a few); the server st ores the\ndata on its disks, and clients request data through well-formed protocol\nmessages. Figure 49.1 depicts the basic setup.\nClient 0\nClient 1\nClient 2\nClient 3\nServer\nRAID\nNetwork\nFigure 49.1: A Generic Client/Server System\nAs you can see from the picture, the server has the disks, and cli ents\nsend messages across a network to access their directories and \ufb01 les on\nthose disks. Why do we bother with this arrangement? (i.e., why don\u2019t\nwe just let clients use their local disks?) W ell, primarily th is setup allows\nfor easy sharing of data across clients. Thus, if you access a \ufb01le on one\nmachine (Client 0) and then later use another (Client 2), you wi ll have the\nsame view of the \ufb01le system. Y our data is naturally shared across these\ndifferent machines. A secondary bene\ufb01t is centralized administration ;\nfor example, backing up \ufb01les can be done from the few server machi nes\ninstead of from the multitude of clients. Another advantage could be\nsecurity; having all servers in a locked machine room prevents certain\ntypes of problems from arising.\n1",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 1: A Generic Client/Server System",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "generic",
          "client",
          "server",
          "system"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "1 A Basic Distributed File System",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "49.1 A Basic Distributed File System\nW e now will study the architecture of a simpli\ufb01ed distributed \ufb01 le sys-\ntem. A simple client/server distributed \ufb01le system has more c omponents\nthan the \ufb01le systems we have studied so far . On the client side , there are\nclient applications which access \ufb01les and directories through the client-\nside \ufb01le system . A client application issues system calls to the client-side\n\ufb01le system (such as open(), read(), write(), close(), mkdir(),\netc.) in order to access \ufb01les which are stored on the server . Thus , to client\napplications, the \ufb01le system does not appear to be any different than a lo-\ncal (disk-based) \ufb01le system, except perhaps for performance; in this way ,\ndistributed \ufb01le systems provide transparent access to \ufb01les, an obvious\ngoal; after all, who would want to use a \ufb01le system that required a differ-\nent set of APIs or otherwise was a pain to use?\nThe role of the client-side \ufb01le system is to execute the actions n eeded\nto service those system calls. For example, if the client issue s a read()\nrequest, the client-side \ufb01le system may send a message to the server-side\n\ufb01le system (or , as it is commonly called, the \ufb01le server ) to read a partic-\nular block; the \ufb01le server will then read the block from disk (or it s own\nin-memory cache), and send a message back to the client with th e re-\nquested data. The client-side \ufb01le system will then copy the da ta into the\nuser buffer supplied to the read() system call and thus the request will\ncomplete. Note that a subsequent read() of the same block on the client\nmay be cached in client memory or on the client\u2019s disk even; in the best\nsuch case, no network traf\ufb01c need be generated.\nClient Application\nClient-side File System\nNetworking Layer\nFile Server\nNetworking Layer\nDisks\nFigure 49.2: Distributed File System Architecture\nFrom this simple overview , you should get a sense that there are tw o\nimportant pieces of software in a client/server distributed \ufb01l e system: the\nclient-side \ufb01le system and the \ufb01le server . T ogether their beh avior deter-\nmines the behavior of the distributed \ufb01le system. Now it\u2019s time to study\none particular system: Sun\u2019s Network File System (NFS).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "goal; after all, who would want to use a \ufb01le system that required a differ-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goal",
          "would",
          "want",
          "system",
          "required",
          "differ"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "important pieces of software in a client/server distributed \ufb01l e system: the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "pieces",
          "software",
          "client",
          "server",
          "distributed",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 2: Distributed File System Architecture",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "distributed",
          "file",
          "system",
          "architecture"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand a basic distributed file system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "basic",
          "distributed",
          "file",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "2 On T o NFS",
    "document_source": "book.pdf",
    "start_line": 16,
    "type": "chapter",
    "content": "49.2 On T o NFS\nOne of the earliest and quite successful distributed systems was devel-\noped by Sun Microsystems, and is known as the Sun Network File Sys-\ntem (or NFS) [S86]. In de\ufb01ning NFS, Sun took an unusual approach: in-\nstead of building a proprietary and closed system, Sun instead de veloped\nan open protocol which simply speci\ufb01ed the exact message formats that\nclients and servers would use to communicate. Different groups could\ndevelop their own NFS servers and thus compete in an NFS marketpl ace\nwhile preserving interoperability . It worked: today there are many com-\npanies that sell NFS servers (including Oracle/Sun, NetApp [ HLM94],\nEMC, IBM, and others), and the widespread success of NFS is like ly at-\ntributed to this \u201copen market\u201d approach.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "oped by Sun Microsystems, and is known as the Sun Network File Sys-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "oped",
          "microsystems",
          "known",
          "network",
          "file"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "tem (or NFS) [S86]. In de\ufb01ning NFS, Sun took an unusual approach: in-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "took",
          "unusual",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "develop their own NFS servers and thus compete in an NFS marketpl ace",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "develop",
          "servers",
          "thus",
          "compete",
          "marketpl"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "tributed to this \u201copen market\u201d approach.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "tributed",
          "open",
          "market",
          "approach"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand It worked: today there are many com-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "it worked",
          "today",
          "many"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand on t o nfs",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "49",
    "title": "3 Focus: Simple And Fast Server Crash Recovery",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "49.3 Focus: Simple And Fast Server Crash Recovery\nIn this chapter , we will discuss the classic NFS protocol (versi on 2,\na.k.a. NFSv2), which was the standard for many years; small cha nges\nwere made in moving to NFSv3, and larger-scale protocol changes we re\nmade in moving to NFSv4. However , NFSv2 is both wonderful and frus-\ntrating and thus serves as our focus.\nIn NFSv2, the main goal in the design of the protocol was simple and\nfast server crash recovery . In a multiple-client, single-server environment,\nthis goal makes a great deal of sense; any minute that the server is down\n(or unavailable) makes all the client machines (and their users) unhappy\nand unproductive. Thus, as the server goes, so goes the entire sy stem.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "In NFSv2, the main goal in the design of the protocol was simple and",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "main",
          "goal",
          "design",
          "protocol",
          "simple"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "this goal makes a great deal of sense; any minute that the server is down",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "goal",
          "makes",
          "great",
          "deal",
          "sense",
          "minute",
          "server"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 3 Focus: Simple And Fast Server Crash Recovery",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3 focus",
          "simple",
          "fast",
          "server",
          "crash",
          "recovery"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "4 Key T o Fast Crash Recovery: Statelessness",
    "document_source": "book.pdf",
    "start_line": 1,
    "type": "chapter",
    "content": "49.4 Key T o Fast Crash Recovery: Statelessness\nThis simple goal is realized in NFSv2 by designing what we refer to\nas a stateless protocol. The server , by design, does not keep track of any-\nthing about what is happening at each client. For example, the s erver\ndoes not know which clients are caching which blocks, or which \ufb01les are\ncurrently open at each client, or the current \ufb01le pointer position for a \ufb01le,\netc. Simply put, the server does not track anything about what cli ents are\ndoing; rather , the protocol is designed to deliver in each protocol r equest\nall the information that is needed in order to complete the request. If it\ndoesn\u2019t now , this stateless approach will make more sense as we dis cuss\nthe protocol in more detail below .\nFor an example of a stateful (not stateless) protocol, consider the open()\nsystem call. Given a pathname, open() returns a \ufb01le descriptor (an inte-\nger). This descriptor is used on subsequent read() or write() requests\nto access various \ufb01le blocks, as in this application code (note tha t proper\nerror checking of the system calls is omitted for space reasons):\nchar buffer[MAX];\nint fd = open(\"foo\", O_RDONLY); // get descriptor \"fd\"\nread(fd, buffer, MAX); // read MAX from foo via \"fd\"\nread(fd, buffer, MAX); // read MAX again\n...\nread(fd, buffer, MAX); // read MAX again\nclose(fd); // close file\nFigure 49.3: Client Code: Reading From A File\nNow imagine that the client-side \ufb01le system opens the \ufb01le by sen ding\na protocol message to the server saying \u201copen the \ufb01le \u2019foo\u2019 and give me\nback a descriptor \u201d. The \ufb01le server then opens the \ufb01le locally on it s side\nand sends the descriptor back to the client. On subsequent rea ds, the\nclient application uses that descriptor to call the read() system call; the\nclient-side \ufb01le system then passes the descriptor in a messag e to the \ufb01le\nserver , saying \u201cread some bytes from the \ufb01le that is referred to by the\ndescriptor I am passing you here\u201d.\nIn this example, the \ufb01le descriptor is a piece of shared state between\nthe client and the server (Ousterhout calls this distributed state [O91]).\nShared state, as we hinted above, complicates crash recovery . Im agine\nthe server crashes after the \ufb01rst read completes, but before th e client\nhas issued the second one. After the server is up and running aga in,\nthe client then issues the second read. Unfortunately , the ser ver has no\nidea to which \ufb01le fd is referring; that information was ephemeral (i.e.,\nin memory) and thus lost when the server crashed. T o handle this situa-\ntion, the client and server would have to engage in some kind of recovery\nprotocol, where the client would make sure to keep enough information\naround in its memory to be able to tell the server what it needs to know\n(in this case, that \ufb01le descriptor fd refers to \ufb01le foo).\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "This simple goal is realized in NFSv2 by designing what we refer to",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "simple",
          "goal",
          "realized",
          "designing",
          "refer"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "as a stateless protocol. The server , by design, does not keep track of any-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "stateless",
          "protocol",
          "server",
          "design",
          "keep",
          "track"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "does not know which clients are caching which blocks, or which \ufb01les are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "know",
          "clients",
          "caching",
          "blocks"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "doing; rather , the protocol is designed to deliver in each protocol r equest",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "rather",
          "protocol",
          "designed",
          "deliver",
          "protocol",
          "equest"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "doesn\u2019t now , this stateless approach will make more sense as we dis cuss",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "stateless",
          "approach",
          "make",
          "sense",
          "cuss"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "around in its memory to be able to tell the server what it needs to know",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "around",
          "memory",
          "able",
          "tell",
          "server",
          "needs",
          "know"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand 3: Client Code: Reading From A File",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "client",
          "code",
          "reading",
          "file"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand key t o fast crash recovery: statelessness",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "fast",
          "crash",
          "recovery",
          "statelessness"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "5 The NFSv2 Protocol",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "49.5 The NFSv2 Protocol\nW e thus arrive at the NFSv2 protocol de\ufb01nition. Our problem state-\nment is simple:\nTH E CR U X : H O W TO DE FI N E A S TAT E L E S S FI L E PR O TO C O L\nHow can we de\ufb01ne the network protocol to enable stateless operation?\nClearly , stateful calls like open() can\u2019t be a part of the discussion (as it\nwould require the server to track open \ufb01les); however , the clien t appli-\ncation will want to call open(), read(), write(), close() and other\nstandard API calls to access \ufb01les and directories. Thus, as a r e\ufb01ned ques-\ntion, how do we de\ufb01ne the protocol to both be stateless and support the\nPOSIX \ufb01le system API?\nOne key to understanding the design of the NFS protocol is under-\nstanding the \ufb01le handle . File handles are used to uniquely describe the\n\ufb01le or directory a particular operation is going to operate upon; thu s,\nmany of the protocol requests include a \ufb01le handle.\nY ou can think of a \ufb01le handle as having three important components: a\nvolume identi\ufb01er , an inode number , and a generation number ; together , these\nthree items comprise a unique identi\ufb01er for a \ufb01le or directory tha t a client\nwishes to access. The volume identi\ufb01er informs the server whic h \ufb01le sys-\ntem the request refers to (an NFS server can export more than one \ufb01 le\nsystem); the inode number tells the server which \ufb01le within th at partition\nthe request is accessing. Finally , the generation number is n eeded when\nreusing an inode number; by incrementing it whenever an inode n um-\nber is reused, the server ensures that a client with an old \ufb01le h andle can\u2019t\naccidentally access the newly-allocated \ufb01le.\nHere is a summary of some of the important pieces of the protocol; the\nfull protocol is available elsewhere (see Callaghan\u2019s book for an ex cellent\nand detailed overview of NFS [C00]).\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "One key to understanding the design of the NFS protocol is under-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "understanding",
          "design",
          "protocol"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "standing the \ufb01le handle . File handles are used to uniquely describe the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "standing",
          "handle",
          "file",
          "handles",
          "used",
          "uniquely",
          "describe"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Y ou can think of a \ufb01le handle as having three important components: a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "think",
          "handle",
          "three",
          "important",
          "components"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "Here is a summary of some of the important pieces of the protocol; the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "summary",
          "important",
          "pieces",
          "protocol"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand tem the request: (an NFS server can export more than one \ufb01 le",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "tem the request",
          "server",
          "export"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand ment is simple: TH E CR U X : H O W TO DE FI N E A S TAT E L E S S FI L E PR O TO C O L",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "ment is simple"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand the nfsv2 protocol",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "protocol"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "6 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "6 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nNFSPROC GETATTR \ufb01le handle\nreturns: attributes\nNFSPROC\nSETATTR \ufb01le handle, attributes\nreturns: \u2013\nNFSPROC\nLOOKUP directory \ufb01le handle, name of \ufb01le/dir to look up\nreturns: \ufb01le handle\nNFSPROC\nREAD \ufb01le handle, offset, count\ndata, attributes\nNFSPROC\nWRITE \ufb01le handle, offset, count, data\nattributes\nNFSPROC\nCREATE directory \ufb01le handle, name of \ufb01le, attributes\n\u2013\nNFSPROC\nREMOVE directory \ufb01le handle, name of \ufb01le to be removed\n\u2013\nNFSPROC\nMKDIR directory \ufb01le handle, name of directory , attributes\n\ufb01le handle\nNFSPROC\nRMDIR directory \ufb01le handle, name of directory to be removed\n\u2013\nNFSPROC\nREADDIR directory handle, count of bytes to read, cookie\nreturns: directory entries, cookie (to get more entries)\nFigure 49.4: The NFS Protocol: Examples\nW e brie\ufb02y highlight the important components of the protocol. First ,\nthe LOOKUP protocol message is used to obtain a \ufb01le handle, which i s\nthen subsequently used to access \ufb01le data. The client passes a directory\n\ufb01le handle and name of a \ufb01le to look up, and the handle to that \ufb01le (or\ndirectory) plus its attributes are passed back to the client f rom the server .\nFor example, assume the client already has a directory \ufb01le hand le for\nthe root directory of a \ufb01le system ( /) (indeed, this would be obtained\nthrough the NFS mount protocol , which is how clients and servers \ufb01rst\nare connected together; we do not discuss the mount protocol here for\nsake of brevity). If an application running on the client opens th e \ufb01le\n/foo.txt, the client-side \ufb01le system sends a lookup request to the serve r ,\npassing it the root \ufb01le handle and the name foo.txt; if successful, the\n\ufb01le handle (and attributes) for foo.txt will be returned.\nIn case you are wondering, attributes are just the metadata tha t the \ufb01le\nsystem tracks about each \ufb01le, including \ufb01elds such as \ufb01le crea tion time,\nlast modi\ufb01cation time, size, ownership and permissions informat ion, and\nso forth, i.e., the same type of information that you would get back i f you\ncalled stat() on a \ufb01le.\nOnce a \ufb01le handle is available, the client can issue READ and W RITE\nprotocol messages on a \ufb01le to read or write the \ufb01le, respectively . T he\nREAD protocol message requires the protocol to pass along the \ufb01le han dle\nof the \ufb01le along with the offset within the \ufb01le and number of bytes t o read.\nThe server then will be able to issue the read (after all, the h andle tells the\nserver which volume and which inode to read from, and the offset an d\ncount tells it which bytes of the \ufb01le to read) and return the data to the\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "CREATE directory \ufb01le handle, name of \ufb01le, attributes",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "create",
          "directory",
          "handle",
          "name",
          "attributes"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "W e brie\ufb02y highlight the important components of the protocol. First ,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "highlight",
          "important",
          "components",
          "protocol",
          "first"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "The server then will be able to issue the read (after all, the h andle tells the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "server",
          "able",
          "issue",
          "read",
          "andle",
          "tells"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_4",
        "text": "understand cookie\nreturns: directory entries, cookie (to get more entries)",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "cookie\nreturns",
          "directory",
          "entries",
          "cookie",
          "entries"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand 4: The NFS Protocol: Examples",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "protocol",
          "examples"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "6 From Protocol T o Distributed File System",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "49.6 From Protocol T o Distributed File System\nHopefully you are now getting some sense of how this protocol is\nturned into a \ufb01le system across the client-side \ufb01le system and the \ufb01le\nserver . The client-side \ufb01le system tracks open \ufb01les, and gene rally trans-\nlates application requests into the relevant set of protocol mess ages. The\nserver simply responds to protocol messages, each of which contain s all\ninformation needed to complete request.\nFor example, let us consider a simple application which reads a \ufb01 le.\nIn the diagram (Figure 49.5), we show what system calls the app lication\nmakes, and what the client-side \ufb01le system and \ufb01le server do i n respond-\ning to such calls.\nA few comments about the \ufb01gure. First, notice how the client track s all\nrelevant state for the \ufb01le access, including the mapping of the integer \ufb01le\ndescriptor to an NFS \ufb01le handle as well as the current \ufb01le pointe r . This\nenables the client to turn each read request (which you may hav e noticed\ndo not specify the offset to read from explicitly) into a properly-form atted\nread protocol message which tells the server exactly which byte s from\nthe \ufb01le to read. Upon a successful read, the client updates the current\n\ufb01le position; subsequent reads are issued with the same \ufb01le han dle but a\ndifferent offset.\nSecond, you may notice where server interactions occur . When the \ufb01l e\nis opened for the \ufb01rst time, the client-side \ufb01le system sends a L OOKUP\nrequest message. Indeed, if a long pathname must be traversed (e.g.,\n/home/remzi/foo.txt), the client would send three LOOKUPs: one\nto look up home in the directory /, one to look up remzi in home, and\n\ufb01nally one to look up foo.txt in remzi.\nThird, you may notice how each server request has all the informat ion\nneeded to complete the request in its entirety . This design poi nt is critical\nto be able to gracefully recover from server failure, as we will now discuss\nin more detail; it ensures that the server does not need state to b e able to\nrespond to the request.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "needed to complete the request in its entirety . This design poi nt is critical",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "needed",
          "complete",
          "request",
          "entirety",
          "design",
          "critical"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "to be able to gracefully recover from server failure, as we will now discuss",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "gracefully",
          "recover",
          "server",
          "failure",
          "discuss"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "in more detail; it ensures that the server does not need state to b e able to",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "detail",
          "ensures",
          "server",
          "need",
          "state",
          "able"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand from protocol t o distributed file system",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "protocol",
          "distributed",
          "file",
          "system"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "8 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "8 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nClient Server\nfd = open(\u201d/foo\u201d, ...);\nSend LOOKUP (rootdir FH, \u201dfoo\u201d)\nReceive LOOKUP request\nlook for \u201dfoo\u201d in root dir\nreturn foo\u2019s FH + attributes\nReceive LOOKUP reply\nallocate \ufb01le desc in open \ufb01le table\nstore foo\u2019s FH in table\nstore current \ufb01le position (0)\nreturn \ufb01le descriptor to application\nread(fd, buffer, MAX);\nIndex into open \ufb01le table with fd\nget NFS \ufb01le handle (FH)\nuse current \ufb01le position as offset\nSend READ (FH, offset=0, count=MAX)\nReceive READ request\nuse FH to get volume/inode num\nread inode from disk (or cache)\ncompute block location (using offset)\nread data from disk (or cache)\nreturn data to client\nReceive READ reply\nupdate \ufb01le position (+bytes read)\nset current \ufb01le position = MAX\nreturn data/error code to app\nread(fd, buffer, MAX);\nSame except offset=MAX and set current \ufb01le position = 2*MAX\nread(fd, buffer, MAX);\nSame except offset=2*MAX and set current \ufb01le position = 3*MAX\nclose(fd);\nJust need to clean up local structures\nFree descriptor \u201dfd\u201d in open \ufb01le table\n(No need to talk to server)\nFigure 49.5: Reading A File: Client-side And File Server Actions\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 5: Reading A File: Client-side And File Server Actions",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "5",
          "reading",
          "file",
          "client",
          "side",
          "file",
          "server",
          "actions"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "7 Handling Server Failure With Idempotent Operations",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "49.7 Handling Server Failure With Idempotent Operations\nWhen a client sends a message to the server , it sometimes does not re-\nceive a reply . There are many possible reasons for this failure t o respond.\nIn some cases, the message may be dropped by the network; networks do\nlose messages, and thus either the request or the reply could be l ost and\nthus the client would never receive a response.\nIt is also possible that the server has crashed, and thus is not c urrently\nresponding to messages. After a bit, the server will be rebooted and start\nrunning again, but in the meanwhile all requests have been los t. In all of\nthese cases, clients are left with a question: what should they do when\nthe server does not reply in a timely manner?\nIn NFSv2, a client handles all of these failures in a single, uni form, and\nelegant way: it simply retries the request. Speci\ufb01cally , after sending the\nrequest, the client sets a timer to go off after a speci\ufb01ed time period. If a\nreply is received before the timer goes off, the timer is cancele d and all is\nwell. If, however , the timer goes off before any reply is received, the client\nassumes the request has not been processed and resends it. If th e server\nreplies, all is well and the client has neatly handled the prob lem.\nThe ability of the client to simply retry the request (regardl ess of what\ncaused the failure) is due to an important property of most NFS req uests:\nthey are idempotent. An operation is called idempotent when the effect\nof performing the operation multiple times is equivalent to the e ffect of\nperforming the operation a single time. For example, if you store a v alue\nto a memory location three times, it is the same as doing so once; thu s\n\u201cstore value to memory\u201d is an idempotent operation. If, however , you in-\ncrement a counter three times, it results in a different amount than doing\nso just once; thus, \u201cincrement counter \u201d is not idempotent. More ge ner-\nally , any operation that just reads data is obviously idempotent; an oper-\nation that updates data must be more carefully considered to det ermine\nif it has this property .\nThe heart of the design of crash recovery in NFS is the idempotency\nof most common operations. LOOKUP and READ requests are trivially\nidempotent, as they only read information from the \ufb01le server and d o not\nupdate it. More interestingly , WRITE requests are also idemp otent. If,\nfor example, a WRITE fails, the client can simply retry it. The WRITE\nmessage contains the data, the count, and (importantly) the exa ct offset\nto write the data to. Thus, it can be repeated with the knowledge that the\noutcome of multiple writes is the same as the outcome of a single one.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "caused the failure) is due to an important property of most NFS req uests:",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "caused",
          "failure",
          "important",
          "property",
          "uests"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "The heart of the design of crash recovery in NFS is the idempotency",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "heart",
          "design",
          "crash",
          "recovery",
          "idempotency"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "message contains the data, the count, and (importantly) the exa ct offset",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "message",
          "contains",
          "data",
          "count",
          "importantly",
          "offset"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "to write the data to. Thus, it can be repeated with the knowledge that the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "write",
          "data",
          "thus",
          "repeated",
          "knowledge"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "outcome of multiple writes is the same as the outcome of a single one.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "outcome",
          "multiple",
          "writes",
          "outcome",
          "single"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand and\nelegant way: it simply retries the request. Speci\ufb01cally , after sending the",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "and\nelegant way",
          "simply",
          "retries",
          "request",
          "sending"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand handling server failure with idempotent operations",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "handling",
          "server",
          "failure",
          "idempotent",
          "operations"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nCase 1: Request Lost\nClient\n[send request]\nServer\n(no mesg)\nCase 2: Server Down\nClient\n[send request]\nServer\n(down)\nCase 3: Reply lost on way back from Server\nClient\n[send request]\nServer\n[recv request]\n[handle request]\n[send reply]\nFigure 49.6: The Three T ypes Of Loss\nIn this way , the client can handle all timeouts in a uni\ufb01ed way . If a\nWRITE request was simply lost (Case 1 above), the client will re try it, the\nserver will perform the write, and all will be well. The same wi ll happen\nif the server happened to be down while the request was sent, bu t back\nup and running when the second request is sent, and again all wor ks\nas desired (Case 2). Finally , the server may in fact receive t he WRITE\nrequest, issue the write to its disk, and send a reply . This re ply may get\nlost (Case 3), again causing the client to re-send the request . When the\nserver receives the request again, it will simply do the exac t same thing:\nwrite the data to disk and reply that it has done so. If the client this time\nreceives the reply , all is again well, and thus the client has handled both\nmessage loss and server failure in a uniform manner . Neat!\nA small aside: some operations are hard to make idempotent. For\nexample, when you try to make a directory that already exists, y ou are\ninformed that the mkdir request has failed. Thus, in NFS, if the \ufb01le server\nreceives a MKDIR protocol message and executes it successfully but the\nreply is lost, the client may repeat it and encounter that failu re when in\nfact the operation at \ufb01rst succeeded and then only failed on the re try .\nThus, life is not perfect.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "key_term_3",
        "text": "understand Case 3: Reply lost on way back from Server",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "case 3",
          "reply",
          "lost",
          "back",
          "server"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand 6: The Three T ypes Of Loss",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "6",
          "three",
          "ypes",
          "loss"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand A small aside: some operations are hard to make idempotent. For",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a small aside",
          "operations",
          "hard",
          "make",
          "idempotent"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "8 Improving Performance: Client-side Caching",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "49.8 Improving Performance: Client-side Caching\nDistributed \ufb01le systems are good for a number of reasons, but sendi ng\nall read and write requests across the network can lead to a big p erfor-\nmance problem: the network generally isn\u2019t that fast, especial ly as com-\npared to local memory or disk. Thus, another problem: how can we im-\nprove the performance of a distributed \ufb01le system?\nThe answer , as you might guess from reading the big bold words in\nthe sub-heading above, is client-side caching. The NFS client-side \ufb01le\nsystem caches \ufb01le data (and metadata) that it has read from the server in\nclient memory . Thus, while the \ufb01rst access is expensive (i.e. , it requires\nnetwork communication), subsequent accesses are serviced qui te quickly\nout of client memory .\nThe cache also serves as a temporary buffer for writes. When a cl ient\napplication \ufb01rst writes to a \ufb01le, the client buffers the data i n client mem-\nory (in the same cache as the data it read from the \ufb01le server) bef ore writ-\ning the data out to the server . Such write buffering is useful because it de-\ncouples application write() latency from actual write performance, i.e.,\nthe application\u2019s call to write() succeeds immediately (and just puts\nthe data in the client-side \ufb01le system\u2019s cache); only later does the data get\nwritten out to the \ufb01le server .\nThus, NFS clients cache data and performance is usually great and\nwe are done, right? Unfortunately , not quite. Adding caching in to any\nsort of system with multiple client caches introduces a big and i nteresting\nchallenge which we will refer to as the cache consistency problem .",
    "learning_concepts": [
      {
        "id": "key_term_2",
        "text": "understand mance problem: the network generally isn\u2019t that fast, especial ly as com-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "mance problem",
          "network",
          "generally",
          "fast",
          "especial"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand improving performance: client-side caching",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "improving",
          "performance",
          "client",
          "side",
          "caching"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "49",
    "title": "9 The Cache Consistency Problem",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "49.9 The Cache Consistency Problem\nThe cache consistency problem is best illustrated with two cli ents and\na single server . Imagine client C1 reads a \ufb01le F , and keeps a cop y of the\n\ufb01le in its local cache. Now imagine a different client, C2, overw rites the\n\ufb01le F , thus changing its contents; let\u2019s call the new version of th e \ufb01le F\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand the cache consistency problem",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "cache",
          "consistency",
          "problem"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "12 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "12 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nC1\ncache: F[v1]\nC2\ncache: F[v2]\nC3\ncache: empty\nServer S\ndisk: F[v1] at first\n      F[v2] eventually\nFigure 49.7: The Cache Consistency Problem\n(version 2), or F[v2] and the old version F[v1] so we can keep the tw o\ndistinct (but of course the \ufb01le has the same name, just differen t contents).\nFinally , there is a third client, C3, which has not yet accesse d the \ufb01le F .\nY ou can probably see the problem that is upcoming (Figure 49.7). I n\nfact, there are two subproblems. The \ufb01rst subproblem is that th e client C2\nmay buffer its writes in its cache for a time before propagating t hem to the\nserver; in this case, while F[v2] sits in C2\u2019s memory , any acces s of F from\nanother client (say C3) will fetch the old version of the \ufb01le (F[v1 ]). Thus,\nby buffering writes at the client, other clients may get stale versions of the\n\ufb01le, which may be undesirable; indeed, imagine the case wher e you log\ninto machine C2, update F , and then log into C3 and try to read th e \ufb01le,\nonly to get the old copy! Certainly this could be frustrating. Thu s, let us\ncall this aspect of the cache consistency problem update visibility ; when\ndo updates from one client become visible at other clients?\nThe second subproblem of cache consistency is a stale cache ; in this\ncase, C2 has \ufb01nally \ufb02ushed its writes to the \ufb01le server , and th us the server\nhas the latest version (F[v2]). However , C1 still has F[v1] in i ts cache; if a\nprogram running on C1 reads \ufb01le F , it will get a stale version (F[v 1]) and\nnot the most recent copy (F[v2]), which is (often) undesirable.\nNFSv2 implementations solve these cache consistency problems in two\nways. First, to address update visibility , clients impleme nt what is some-\ntimes called \ufb02ush-on-close (a.k.a., close-to-open) consistency semantics;\nspeci\ufb01cally , when a \ufb01le is written to and subsequently closed by a client\napplication, the client \ufb02ushes all updates (i.e., dirty page s in the cache)\nto the server . With \ufb02ush-on-close consistency , NFS ensures tha t a subse-\nquent open from another node will see the latest \ufb01le version.\nSecond, to address the stale-cache problem, NFSv2 clients \ufb01rst c heck\nto see whether a \ufb01le has changed before using its cached content s. Specif-\nically , before using a cached block, the client-side \ufb01le syste m will issue a\nGET A TTR request to the server to fetch the \ufb01le\u2019s attributes. T he attributes,\nimportantly , include information as to when the \ufb01le was last modi \ufb01ed on\nthe server; if the time-of-modi\ufb01cation is more recent than the ti me that the\n\ufb01le was fetched into the client cache, the client invalidates the \ufb01le, thus\nremoving it from the client cache and ensuring that subsequent reads will\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "NFSv2 implementations solve these cache consistency problems in two",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementations",
          "solve",
          "cache",
          "consistency",
          "problems"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "importantly , include information as to when the \ufb01le was last modi \ufb01ed on",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "importantly",
          "include",
          "information",
          "last",
          "modi"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_5",
        "text": "understand 7: The Cache Consistency Problem",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "7",
          "cache",
          "consistency",
          "problem"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "10 Assessing NFS Cache Consistency",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "49.10 Assessing NFS Cache Consistency\nA few \ufb01nal words about NFS cache consistency . The \ufb02ush-on-close be -\nhavior was added to \u201cmake sense\u201d, but introduced a certain perf ormance\nproblem. Speci\ufb01cally , if a temporary or short-lived \ufb01le was creat ed on a\nclient and then soon deleted, it would still be forced to the serve r . A more\nideal implementation might keep such short-lived \ufb01les in memor y until\nthey are deleted and thus remove the server interaction entire ly , perhaps\nincreasing performance.\nMore importantly , the addition of an attribute cache into NFS mad e\nit very hard to understand or reason about exactly what version of a \ufb01le\none was getting. Sometimes you would get the latest version; sometim es\nyou would get an old version simply because your attribute cache ha dn\u2019t\nyet timed out and thus the client was happy to give you what was in\nclient memory . Although this was \ufb01ne most of the time, it would (and\nstill does!) occasionally lead to odd behavior .\nAnd thus we have described the oddity that is NFS client cachin g.\nIt serves as an interesting example where details of an implem entation\nserve to de\ufb01ne user-observable semantics, instead of the other way around.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ideal implementation might keep such short-lived \ufb01les in memor y until",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ideal",
          "implementation",
          "might",
          "keep",
          "short",
          "lived",
          "memor"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "More importantly , the addition of an attribute cache into NFS mad e",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "importantly",
          "addition",
          "attribute",
          "cache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "it very hard to understand or reason about exactly what version of a \ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "hard",
          "understand",
          "reason",
          "exactly",
          "version"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "And thus we have described the oddity that is NFS client cachin g.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "thus",
          "described",
          "oddity",
          "client",
          "cachin"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand assessing nfs cache consistency",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "assessing",
          "cache",
          "consistency"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "49",
    "title": "11 Implications On Server-Side W rite Buffering",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "49.11 Implications On Server-Side W rite Buffering\nOur focus so far has been on client caching, and that is where most\nof the interesting issues arise. However , NFS servers tend to b e well-\nequipped machines with a lot of memory too, and thus they have cachi ng\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand implications on server-side w rite buffering",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "implications",
          "server",
          "side",
          "rite",
          "buffering"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "14 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "14 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nconcerns as well. When data (and metadata) is read from disk, NF S\nservers will keep it in memory , and subsequent reads of said dat a (and\nmetadata) will not go to disk, a potential (small) boost in perform ance.\nMore intriguing is the case of write buffering. NFS servers abs olutely\nmay not return success on a WRITE protocol request until the write has\nbeen forced to stable storage (e.g., to disk or some other persiste nt device).\nWhile they can place a copy of the data in server memory , returnin g suc-\ncess to the client on a WRITE protocol request could result in incorr ect\nbehavior; can you \ufb01gure out why?\nThe answer lies in our assumptions about how clients handle serve r\nfailure. Imagine the following sequence of writes as issued by a client:\nwrite(fd, a_buffer, size); // fill 1st block with a\u2019s\nwrite(fd, b_buffer, size); // fill 2nd block with b\u2019s\nwrite(fd, c_buffer, size); // fill 3rd block with c\u2019s\nThese writes overwrite the three blocks of a \ufb01le with a block of a\u2019s,\nthen b\u2019s, and then c\u2019s. Thus, if the \ufb01le initially looked like this :\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\nzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\nW e might expect the \ufb01nal result after these writes to be like t his, with the\nx\u2019s, y\u2019s, and z\u2019s, would be overwritten with a\u2019s, b\u2019s, and c\u2019s, respect ively .\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\ncccccccccccccccccccccccccccccccccccccccccccc\nNow let\u2019s assume for the sake of the example that these three clien t\nwrites were issued to the server as three distinct WRITE protoc ol mes-\nsages. Assume the \ufb01rst WRITE message is received by the serve r and\nissued to the disk, and the client informed of its success. Now as sume\nthe second write is just buffered in memory , and the server also reports\nit success to the client before forcing it to disk; unfortunately , the server\ncrashes before writing it to disk. The server quickly restart s and receives\nthe third write request, which also succeeds.\nThus, to the client, all the requests succeeded, but we are su rprised\nthat the \ufb01le contents look like this:\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy <--- oops\ncccccccccccccccccccccccccccccccccccccccccccc\nYikes! Because the server told the client that the second write was\nsuccessful before committing it to disk, an old chunk is left in t he \ufb01le,\nwhich, depending on the application, might be catastrophic.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "49",
    "title": "12 Summary",
    "document_source": "book.pdf",
    "start_line": 38,
    "type": "chapter",
    "content": "49.12 Summary\nW e have seen the introduction of the NFS distributed \ufb01le system. NFS\nis centered around the idea of simple and fast recovery in the fac e of\nserver failure, and achieves this end through careful protocol d esign. Idem-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "16 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "16 S U N\u2019 S NE T W O R K FI L E SY S T E M (NFS)\nAS I D E : K E Y NFS T E R M S\n\u2022 The key to realizing the main goal of fast and simple crash recove ry\nin NFS is in the design of a stateless protocol. After a crash, the\nserver can quickly restart and begin serving requests again ; clients\njust retry requests until they succeed.\n\u2022 Making requests idempotent is a central aspect of the NFS protocol.\nAn operation is idempotent when the effect of performing it multi-\nple times is equivalent to performing it once. In NFS, idempotenc y\nenables client retry without worry , and uni\ufb01es client lost-mes sage\nretransmission and how the client handles server crashes.\n\u2022 Performance concerns dictate the need for client-side caching and\nwrite buffering , but introduces a cache consistency problem .\n\u2022 NFS implementations provide an engineering solution to cache\nconsistency through multiple means: a \ufb02ush-on-close (close-to-\nopen) approach ensures that when a \ufb01le is closed, its contents are\nforced to the server , enabling other clients to observe the upda tes\nto it. An attribute cache reduces the frequency of checking wi th the\nserver whether a \ufb01le has changed (via GET A TTR requests).\n\u2022 NFS servers must commit writes to persistent media before retu rn-\ning success; otherwise, data loss can arise.\n\u2022 T o support NFS integration into the operating system, Sun intro-\nduced the VFS/Vnode interface, enabling multiple \ufb01le system im-\nplementations to coexist in the same operating system.\npotency of operations is essential; because a client can safely r eplay a\nfailed operation, it is OK to do so whether or not the server has exe cuted\nthe request.\nW e also have seen how the introduction of caching into a multiple-\nclient, single-server system can complicate things. In part icular , the sys-\ntem must resolve the cache consistency problem in order to behave rea-\nsonably; however , NFS does so in a slightly ad hoc fashion which can\noccasionally result in observably weird behavior . Finally , we s aw how\nserver caching can be tricky: writes to the server must be forc ed to stable\nstorage before returning success (otherwise data can be lost).\nW e haven\u2019t talked about other issues which are certainly releva nt, no-\ntably security . Security in early NFS implementations was rem arkably\nlax; it was rather easy for any user on a client to masquerade as ot her\nusers and thus gain access to virtually any \ufb01le. Subsequent in tegration\nwith more serious authentication services (e.g., Kerberos [NT9 4]) have\naddressed these obvious de\ufb01ciencies.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "The key to realizing the main goal of fast and simple crash recove ry",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "realizing",
          "main",
          "goal",
          "fast",
          "simple",
          "crash",
          "recove"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "in NFS is in the design of a stateless protocol. After a crash, the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "stateless",
          "protocol",
          "crash"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "NFS implementations provide an engineering solution to cache",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implementations",
          "provide",
          "engineering",
          "solution",
          "cache"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "approach ensures that when a \ufb01le is closed, its contents are",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "approach",
          "ensures",
          "closed",
          "contents"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "potency of operations is essential; because a client can safely r eplay a",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "potency",
          "operations",
          "essential",
          "client",
          "safely",
          "eplay"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "tem must resolve the cache consistency problem in order to behave rea-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "must",
          "resolve",
          "cache",
          "consistency",
          "problem",
          "order",
          "behave"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "tably security . Security in early NFS implementations was rem arkably",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "tably",
          "security",
          "security",
          "early",
          "implementations",
          "arkably"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_2",
        "text": "understand making requests idempotent is a central aspect of the nfs protocol.",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "making",
          "requests",
          "idempotent",
          "central",
          "aspect",
          "protocol"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand performance concerns dictate the need for client-side caching and",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "performance",
          "concerns",
          "dictate",
          "need",
          "client",
          "side",
          "caching"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_5",
        "text": "understand nfs servers must commit writes to persistent media before retu rn-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "servers",
          "must",
          "commit",
          "writes",
          "persistent",
          "media",
          "retu"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_6",
        "text": "understand t o support nfs integration into the operating system, sun intro-",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "support",
          "integration",
          "operating",
          "system",
          "intro"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "SU N\u2019 S NE T W O R K FI L E SY S T E M (NFS) 17",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "SU N\u2019 S NE T W O R K FI L E SY S T E M (NFS) 17\nReferences\n[AKW88] \u201cThe A WK Programming Language\u201d by Alfred V . Aho, Brian W . Kerni ghan, Peter\nJ. W einberger . Pearson, 1988 (1st edition). A concise, wonderful book about awk. We once had the\npleasure of meeting Peter Weinberger; when he introduced himself, he said \u201cI\u2019m Peter Weinberger , you\nknow, the \u2019W\u2019 in awk?\u201d As huge awk fans, this was a moment to savor . One of us (Remzi ) then said,\n\u201cI love awk! I particularly love the book, which makes everything so wonderful ly clear .\u201d Weinberger\nreplied (crestfallen), \u201cOh, Kernighan wrote the book.\u201d\n[C00] \u201cNFS Illustrated\u201d by Brent Callaghan. Addison-W esley Profess ional Computing Series,\n2000. A great NFS reference; incredibly thorough and detailed per the protocol i tself.\n[ES03] \u201cNew NFS T racing T ools and T echniques for System Analysis\u201d by Da niel Ellard and\nMargo Seltzer . LISA \u201903, San Diego, California. An intricate, careful analysis of NFS done via\npassive tracing. By simply monitoring network traf\ufb01c, the authors show how to de rive a vast amount\nof \ufb01le system understanding.\n[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,\nMichael Malcolm. USENIX Winter 1994. San Francisco, California, 1994. Hitz et al. were greatly\nin\ufb02uenced by previous work on log-structured \ufb01le systems.\n[K86] \u201cVnodes: An Architecture for Multiple File System T ypes in Sun UN I X\u201d by Steve R.\nKleiman. USENIX Summer \u201986, Atlanta, Georgia. This paper shows how to build a \ufb02exible \ufb01le\nsystem architecture into an operating system, enabling multiple differe nt \ufb01le system implementations\nto coexist. Now used in virtually every modern operating system in some form .\n[NT94] \u201cKerberos: An Authentication Service for Computer Networks \u201d by B. Clifford Neu-\nman, Theodore T s\u2019o. IEEE Communications, 32(9):33-38, September 199 4. Kerberos is an early\nand hugely in\ufb02uential authentication service. We probably should write a b ook chapter about it some-\ntime...\n[O91] \u201cThe Role of Distributed State\u201d by John K. Ousterhout. 1991. A va ilable at this site:\nftp://ftp.cs.berkeley.edu/ucb/sprite/papers/state.ps. A rarely referenced dis-\ncussion of distributed state; a broader perspective on the problems and chall enges.\n[P+94] \u201cNFS V ersion 3: Design and Implementation\u201d by Brian Pawlows ki, Chet Juszczak, Peter\nStaubach, Carl Smith, Diane Lebel, Dave Hitz. USENIX Summer 1994 , pages 137-152. The small\nmodi\ufb01cations that underlie NFS version 3.\n[P+00] \u201cThe NFS version 4 protocol\u201d by Brian Pawlowski, David Noveck , David Robinson,\nRobert Thurlow . 2nd International System Administration and Networ king Conference (SANE\n2000). Undoubtedly the most literary paper on NFS ever written.\n[RO91] \u201cThe Design and Implementation of the Log-structured File Syst em\u201d by Mendel Rosen-\nblum, John Ousterhout. Symposium on Operating Systems Principles (SOSP), 1991. LFS again.\nNo, you can never get enough LFS.\n[S86] \u201cThe Sun Network File System: Design, Implementation and Exp erience\u201d by Russel\nSandberg. USENIX Summer 1986. The original NFS paper; though a bit of a challenging read,\nit is worthwhile to see the source of these wonderful ideas.\n[Sun89] \u201cNFS: Network File System Protocol Speci\ufb01cation\u201d by Sun Micro systems, Inc. Request\nfor Comments: 1094, March 1989. A vailable: http://www.ietf.org/rfc/rfc1094.txt.\nThe dreaded speci\ufb01cation; read it if you must, i.e., you are getting paid to r ead it. Hopefully, paid a lot.\nCash money!\n[V72] \u201cLa Begueule\u201d by Francois-Marie Arouet a.k.a. V oltaire. Pub lished in 1772. V oltaire said\na number of clever things, this being but one example. For example, V ol taire also said \u201cIf you have two\nreligions in your land, the two will cut each others throats; but if you have thi rty religions, they will\ndwell in peace.\u201d What do you say to that, Democrats and Republicans?\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "know, the \u2019W\u2019 in awk?\u201d As huge awk fans, this was a moment to savor . One of us (Remzi ) then said,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "know",
          "huge",
          "fans",
          "moment",
          "savor",
          "remzi",
          "said"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "of \ufb01le system understanding.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "system",
          "understanding"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[HLM94] \u201cFile System Design for an NFS File Server Appliance\u201d by Da ve Hitz, James Lau,",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "file",
          "system",
          "design",
          "file",
          "server",
          "appliance",
          "hitz",
          "james"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "system architecture into an operating system, enabling multiple differe nt \ufb01le system implementations",
        "type": "explicit_objective",
        "difficulty": "advanced",
        "keywords": [
          "system",
          "architecture",
          "operating",
          "system",
          "enabling",
          "multiple",
          "differe",
          "system"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "[P+94] \u201cNFS V ersion 3: Design and Implementation\u201d by Brian Pawlows ki, Chet Juszczak, Peter",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ersion",
          "design",
          "implementation",
          "brian",
          "pawlows",
          "chet",
          "juszczak",
          "peter"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_6",
        "text": "[RO91] \u201cThe Design and Implementation of the Log-structured File Syst em\u201d by Mendel Rosen-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "design",
          "implementation",
          "structured",
          "file",
          "syst",
          "mendel",
          "rosen"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_7",
        "text": "blum, John Ousterhout. Symposium on Operating Systems Principles (SOSP), 1991. LFS again.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "blum",
          "john",
          "ousterhout",
          "symposium",
          "operating",
          "systems",
          "principles",
          "sosp"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_8",
        "text": "[S86] \u201cThe Sun Network File System: Design, Implementation and Exp erience\u201d by Russel",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "network",
          "file",
          "system",
          "design",
          "implementation",
          "erience",
          "russel"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand Vnodes: An Architecture for Multiple File System T ypes in Sun UN I X\u201d by Steve R.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "vnodes",
          "architecture",
          "multiple",
          "file",
          "system",
          "ypes",
          "steve"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand Kerberos: An Authentication Service for Computer Networks \u201d by B. Clifford Neu-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "kerberos",
          "authentication",
          "service",
          "computer",
          "networks",
          "clifford"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_6",
        "text": "understand NFS: Network File System Protocol Speci\ufb01cation\u201d by Sun Micro systems, Inc. Request",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "nfs",
          "network",
          "file",
          "system",
          "protocol",
          "micro",
          "systems",
          "request"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand for Comments: 1094, March 1989. A vailable: http://www.ietf.org/rfc/rfc1094.txt.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "for comments",
          "march",
          "vailable",
          "http",
          "ietf"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "A \ufb01rst question for your trace analysis: using the timestamps found",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "1. A \ufb01rst question for your trace analysis: using the timestamps found\nin the \ufb01rst column, determine the period of time the traces were\ntaken from. How long is the period? What day/week/month/year\nwas it? (does this match the hint given in the \ufb01le name?) Hint: U se\nthe tools head -1 and tail -1 to extract the \ufb01rst and last lines of\nthe \ufb01le, and do the calculation.\n2. Now , let\u2019s do some operation counts. How many of each type of op-\neration occur in the trace? Sort these by frequency; which operati on\nis most frequent? Does NFS live up to its reputation?\n3. Now let\u2019s look at some particular operations in more detail. For\nexample, the GET A TTR request returns a lot of information about\n\ufb01les, including which user ID the request is being performed f or ,\nthe size of the \ufb01le, and so forth. Make a distribution of \ufb01le sizes\naccessed within the trace; what is the average \ufb01le size? Also, how\nmany different users access \ufb01les in the trace? Do a few users d om-\ninate traf\ufb01c, or is it more spread out? What other interesting inf or-\nmation is found within GET A TTR replies?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the average \ufb01le size",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "average",
          "size"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "4",
    "title": "Y ou can also look at requests to a given \ufb01le and determine how",
    "document_source": "book.pdf",
    "start_line": 24,
    "type": "chapter",
    "content": "4. Y ou can also look at requests to a given \ufb01le and determine how\n\ufb01les are being accessed. For example, is a given \ufb01le being read or\nwritten sequentially? Or randomly? Look at the details of READ\nand WRITE requests/replies to compute the answer .",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "5",
    "title": "T raf\ufb01c comes from many machines and goes to one server (in this",
    "document_source": "book.pdf",
    "start_line": 28,
    "type": "chapter",
    "content": "5. T raf\ufb01c comes from many machines and goes to one server (in this\ntrace). Compute a traf\ufb01c matrix, which shows how many different\nclients there are in the trace, and how many requests/replies go to\neach. Do a few machines dominate, or is it more evenly balanced?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "The timing information, and the per-request/reply unique I D, should",
    "document_source": "book.pdf",
    "start_line": 32,
    "type": "chapter",
    "content": "6. The timing information, and the per-request/reply unique I D, should\nallow you to compute the latency for a given request. Compute the\nlatencies of all request/reply pairs, and plot them as a distri bution.\nWhat is the average? Maximum? Minimum?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the average",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "average"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "7",
    "title": "Sometimes requests are retried, as the request or its reply cou ld be",
    "document_source": "book.pdf",
    "start_line": 36,
    "type": "chapter",
    "content": "7. Sometimes requests are retried, as the request or its reply cou ld be\nlost or dropped. Can you \ufb01nd any evidence of such retrying in the\ntrace sample?",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "8",
    "title": "There are many other questions you could answer through more",
    "document_source": "book.pdf",
    "start_line": 39,
    "type": "chapter",
    "content": "8. There are many other questions you could answer through more\nanalysis. What questions do you think are important? Suggest\nthem to us, and perhaps we\u2019ll add them here!\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "analysis. What questions do you think are important? Suggest",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "analysis",
          "questions",
          "think",
          "important",
          "suggest"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "1 AFS V ersion 1",
    "document_source": "book.pdf",
    "start_line": 21,
    "type": "chapter",
    "content": "50.1 AFS V ersion 1\nW e will discuss two versions of AFS [H+88, S+85]. The \ufb01rst version\n(which we will call AFSv1, but actually the original system was called\nthe ITC distributed \ufb01le system [S+85]) had some of the basic desi gn in\nplace, but didn\u2019t scale as desired, which led to a re-design an d the \ufb01nal\nprotocol (which we will call AFSv2, or just AFS) [H+88]. W e now discus s\nthe \ufb01rst version.\n1 Though originally referred to as \u201cCarnegie-Mellon University\u201d, CMU l ater dropped\nthe hyphen, and thus was born the modern form, \u201cCarnegie Mellon Universit y .\u201d As AFS\nderived from work in the early 80\u2019s, we refer to CMU in its original fu lly-hyphenated form. See\nhttps://www.quora.com/When-did-Carnegie-Mellon-University-remove-the-\nhyphen-in-the-university-name for more details, if you are into really boring minutiae.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "place, but didn\u2019t scale as desired, which led to a re-design an d the \ufb01nal",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "place",
          "scale",
          "desired",
          "design"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand See\nhttps: //www.quora.com/When-did-Carnegie-Mellon-University-remove-the-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "see\nhttps",
          "quora",
          "carnegie",
          "mellon",
          "university",
          "remove"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand afs v ersion 1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ersion"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 T H E AN D R E W FI L E SY S T E M (AFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 T H E AN D R E W FI L E SY S T E M (AFS)\nTestAuth Test whether a file has changed\n(used to validate cached entries)\nGetFileStat Get the stat info for a file\nFetch Fetch the contents of file\nStore Store this file on the server\nSetFileStat Set the stat info for a file\nListDir List the contents of a directory\nFigure 50.1: AFSv1 Protocol Highlights\nOne of the basic tenets of all versions of AFS is whole-\ufb01le caching on\nthe local disk of the client machine that is accessing a \ufb01le. When you\nopen() a \ufb01le, the entire \ufb01le (if it exists) is fetched from the server a nd\nstored in a \ufb01le on your local disk. Subsequent application read() and\nwrite() operations are redirected to the local \ufb01le system where the \ufb01le i s\nstored; thus, these operations require no network communication a nd are\nfast. Finally , upon close(), the \ufb01le (if it has been modi\ufb01ed) is \ufb02ushed\nback to the server . Note the obvious contrasts with NFS, which cach es\nblocks (not whole \ufb01les, although NFS could of course cache every block of\nan entire \ufb01le) and does so in client memory (not local disk).\nLet\u2019s get into the details a bit more. When a client application \ufb01 rst calls\nopen(), the AFS client-side code (which the AFS designers call V enus)\nwould send a Fetch protocol message to the server . The Fetch protocol\nmessage would pass the entire pathname of the desired \ufb01le (for ex am-\nple, /home/remzi/notes.txt) to the \ufb01le server (the group of which\nthey called Vice), which would then traverse the pathname, \ufb01nd the de-\nsired \ufb01le, and ship the entire \ufb01le back to the client. The clie nt-side code\nwould then cache the \ufb01le on the local disk of the client (by writing it to\nlocal disk). As we said above, subsequent read() and write() system\ncalls are strictly local in AFS (no communication with the server occurs);\nthey are just redirected to the local copy of the \ufb01le. Because the read()\nand write() calls act just like calls to a local \ufb01le system, once a block\nis accessed, it also may be cached in client memory . Thus, AFS a lso uses\nclient memory to cache copies of blocks that it has in its local disk . Fi-\nnally , when \ufb01nished, the AFS client checks if the \ufb01le has been modi\ufb01ed\n(i.e., that it has been opened for writing); if so, it \ufb02ushes the n ew version\nback to the server with a Store protocol message, sending the entir e \ufb01le\nand pathname to the server for permanent storage.\nThe next time the \ufb01le is accessed, AFSv1 does so much more ef\ufb01-\nciently . Speci\ufb01cally , the client-side code \ufb01rst contacts the s erver (using\nthe T estAuth protocol message) in order to determine whether the \ufb01le\nhas changed. If not, the client would use the locally-cached copy , thus\nimproving performance by avoiding a network transfer . The \ufb01gure above\nshows some of the protocol messages in AFSv1. Note that this early ver-\nsion of the protocol only cached \ufb01le contents; directories, for exampl e,\nwere only kept at the server .\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "back to the server . Note the obvious contrasts with NFS, which cach es",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "back",
          "server",
          "note",
          "obvious",
          "contrasts",
          "cach"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "open(), the AFS client-side code (which the AFS designers call V enus)",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "open",
          "client",
          "side",
          "code",
          "designers",
          "call",
          "enus"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 1: AFSv1 Protocol Highlights",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "1",
          "protocol",
          "highlights"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "2 Problems with V ersion 1",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "50.2 Problems with V ersion 1\nA few key problems with this \ufb01rst version of AFS motivated the de-\nsigners to rethink their \ufb01le system. T o study the problems in d etail, the\ndesigners of AFS spent a great deal of time measuring their exis ting pro-\ntotype to \ufb01nd what was wrong. Such experimentation is a good thing,\nbecause measurement is the key to understanding how systems work\nand how to improve them; obtaining concrete, good data is thus a nece s-\nsary part of systems construction. In their study , the authors fou nd two\nmain problems with AFSv1:\n\u2022 Path-traversal costs are too high : When performing a Fetch or Store\nprotocol request, the client passes the entire pathname (e.g., /home/\nremzi/notes.txt) to the server . The server , in order to access the\n\ufb01le, must perform a full pathname traversal, \ufb01rst looking in the root\ndirectory to \ufb01nd home, then in home to \ufb01nd remzi, and so forth,\nall the way down the path until \ufb01nally the desired \ufb01le is located .\nWith many clients accessing the server at once, the designers of AFS\nfound that the server was spending much of its CPU time simply\nwalking down directory paths.\n\u2022 The client issues too many T estAuth protocol messages : Much\nlike NFS and its overabundance of GET A TTR protocol messages,\nAFSv1 generated a large amount of traf\ufb01c to check whether a lo-\ncal \ufb01le (or its stat information) was valid with the T estAuth prot o-\ncol message. Thus, servers spent much of their time telling cli ents\nwhether it was OK to used their cached copies of a \ufb01le. Most of the\ntime, the answer was that the \ufb01le had not changed.\nThere were actually two other problems with AFSv1: load was not\nbalanced across servers, and the server used a single distinc t process per\nclient thus inducing context switching and other overheads. Th e load\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "designers of AFS spent a great deal of time measuring their exis ting pro-",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "designers",
          "spent",
          "great",
          "deal",
          "time",
          "measuring",
          "exis",
          "ting"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "because measurement is the key to understanding how systems work",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "measurement",
          "understanding",
          "systems",
          "work"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "With many clients accessing the server at once, the designers of AFS",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "many",
          "clients",
          "accessing",
          "server",
          "designers"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand problems with v ersion 1",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "problems",
          "ersion"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_2",
        "text": "understand path-traversal costs are too high : when performing a fetch or store",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "path",
          "traversal",
          "costs",
          "high",
          "performing",
          "fetch",
          "store"
        ],
        "confidence": 0.7
      },
      {
        "id": "section_concept_3",
        "text": "understand the client issues too many t estauth protocol messages : much",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "issues",
          "many",
          "estauth",
          "protocol",
          "messages",
          "much"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "3 Improving the Protocol",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "50.3 Improving the Protocol\nThe two problems above limited the scalability of AFS; the server CPU\nbecame the bottleneck of the system, and each server could only se r-\nvice 20 clients without becoming overloaded. Servers were receiv ing too\nmany T estAuth messages, and when they received Fetch or Store me s-\nsages, were spending too much time traversing the directory hi erarchy .\nThus, the AFS designers were faced with a problem:\nTH E CR U X : H O W TO DE S I G N A S C A L A B L E FI L E PR O TO C O L\nHow should one redesign the protocol to minimize the number of\nserver interactions, i.e., how could they reduce the number of T e stAuth\nmessages? Further , how could they design the protocol to make thes e\nserver interactions ef\ufb01cient? By attacking both of these issue s, a new pro-\ntocol would result in a much more scalable version AFS.",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Thus, the AFS designers were faced with a problem:",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "thus",
          "designers",
          "faced",
          "problem"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "How should one redesign the protocol to minimize the number of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "redesign",
          "protocol",
          "minimize",
          "number"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "messages? Further , how could they design the protocol to make thes e",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "messages",
          "could",
          "design",
          "protocol",
          "make",
          "thes"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand improving the protocol",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "improving",
          "protocol"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "50",
    "title": "4 AFS V ersion 2",
    "document_source": "book.pdf",
    "start_line": 19,
    "type": "chapter",
    "content": "50.4 AFS V ersion 2\nAFSv2 introduced the notion of a callback to reduce the number of\nclient/server interactions. A callback is simply a promise fr om the server\nto the client that the server will inform the client when a \ufb01le t hat the\nclient is caching has been modi\ufb01ed. By adding this state to the system,\nthe client no longer needs to contact the server to \ufb01nd out if a cac hed \ufb01le\nis still valid. Rather , it assumes that the \ufb01le is valid until the server tells it\notherwise; notice the analogy to polling versus interrupts.\nAFSv2 also introduced the notion of a \ufb01le identi\ufb01er (FID) (similar to\nthe NFS \ufb01le handle ) instead of pathnames to specify which \ufb01le a client\nwas interested in. An FID in AFS consists of a volume identi\ufb01er , a \ufb01le\nidenti\ufb01er , and a \u201cuniqui\ufb01er \u201d (to enable reuse of the volume and \ufb01le IDs\nwhen a \ufb01le is deleted). Thus, instead of sending whole pathname s to\nthe server and letting the server walk the pathname to \ufb01nd the desired\n\ufb01le, the client would walk the pathname, one piece at a time, cac hing the\nresults and thus hopefully reducing the load on the server .\nFor example, if a client accessed the \ufb01le /home/remzi/notes.txt,\nand home was the AFS directory mounted onto / (i.e., / was the local root\ndirectory , but home and its children were in AFS), the client would \ufb01rst\nFetch the directory contents of home, put them in the local-disk cache,\nand set up a callback on home. Then, the client would Fetch the directory\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "section_concept_1",
        "text": "understand afs v ersion 2",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "ersion"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "TH E AN D R E W FI L E SY S T E M (AFS) 5",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "TH E AN D R E W FI L E SY S T E M (AFS) 5\nClient (C 1) Server\nfd = open(\u201c/home/remzi/notes.txt\u201d, ...);\nSend Fetch (home FID, \u201cremzi\u201d)\nReceive Fetch request\nlook for remzi in home dir\nestablish callback(C 1) on remzi\nreturn remzi\u2019s content and FID\nReceive Fetch reply\nwrite remzi to local disk cache\nrecord callback status of remzi\nSend Fetch (remzi FID, \u201cnotes.txt\u201d)\nReceive Fetch request\nlook for notes.txt in remzi dir\nestablish callback(C 1) on notes.txt\nreturn notes.txt\u2019s content and FID\nReceive Fetch reply\nwrite notes.txt to local disk cache\nrecord callback status of notes.txt\nlocal open() of cached notes.txt\nreturn \ufb01le descriptor to application\nread(fd, buffer, MAX);\nperform local read() on cached copy\nclose(fd);\ndo local close() on cached copy\nif \ufb01le has changed, \ufb02ush to server\nfd = open(\u201c/home/remzi/notes.txt\u201d, ...);\nForeach dir (home, remzi)\nif (callback(dir) == V ALID)\nuse local copy for lookup(dir)\nelse\nFetch (as above)\nif (callback(notes.txt) == V ALID)\nopen local cached copy\nreturn \ufb01le descriptor to it\nelse\nFetch (as above) then open and return fd\nFigure 50.2: Reading A File: Client-side And File Server Actions\nremzi, put it in the local-disk cache, and set up a callback on remzi.\nFinally , the client would Fetch notes.txt, cache this regular \ufb01le in the\nlocal disk, set up a callback, and \ufb01nally return a \ufb01le descript or to the\ncalling application. See Figure 50.2 for a summary .\nThe key difference, however , from NFS, is that with each fetch of a\ndirectory or \ufb01le, the AFS client would establish a callback with the server ,\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 2: Reading A File: Client-side And File Server Actions",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "2",
          "reading",
          "file",
          "client",
          "side",
          "file",
          "server",
          "actions"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "5 Cache Consistency",
    "document_source": "book.pdf",
    "start_line": 25,
    "type": "chapter",
    "content": "50.5 Cache Consistency\nWhen we discussed NFS, there were two aspects of cache consisten cy\nwe considered: update visibility and cache staleness . With update visi-\nbility , the question is: when will the server be updated with a new version\nof a \ufb01le? With cache staleness, the question is: once the server h as a new\nversion, how long before clients see the new version instead of an old er\ncached copy?\nBecause of callbacks and whole-\ufb01le caching, the cache consiste ncy pro-\nvided by AFS is easy to describe and understand. There are two im-\nportant cases to consider: consistency between processes on different ma-\nchines, and consistency between processes on the same machine.\nBetween different machines, AFS makes updates visible at th e server\nand invalidates cached copies at the exact same time, which is when the\nupdated \ufb01le is closed. A client opens a \ufb01le, and then writes to it (perhaps\nrepeatedly). When it is \ufb01nally closed, the new \ufb01le is \ufb02ushed to the server\n(and thus visible). At this point, the server then \u201cbreaks\u201d ca llbacks for\nany clients with cached copies; the break is accomplished by con tacting\neach client and informing it that the callback it has on the \ufb01le i s no longer\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "vided by AFS is easy to describe and understand. There are two im-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "vided",
          "easy",
          "describe",
          "understand"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand the question is: when will the server be updated with a new version",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the question is",
          "server",
          "updated",
          "version"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand the question is: once the server h as a new",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "the question is",
          "server"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_4",
        "text": "understand portant cases to consider: consistency between processes on different ma-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "portant cases to consider",
          "consistency",
          "processes",
          "different"
        ],
        "confidence": 0.8
      },
      {
        "id": "section_concept_1",
        "text": "understand cache consistency",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "cache",
          "consistency"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "TH E AN D R E W FI L E SY S T E M (AFS) 7",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "TH E AN D R E W FI L E SY S T E M (AFS) 7\nClient1 Client2 Server Comments\nP1 P2 Cache P 3 Cache Disk\nopen(F) - - - File created\nwrite(A) A - -\nclose() A - A\nopen(F) A - A\nread() \u2192 A A - A\nclose() A - A\nopen(F) A - A\nwrite(B) B - A\nopen(F) B - A Local processes\nread() \u2192 B B - A see writes immediately\nclose() B - A\nB open(F) A A Remote processes\nB read() \u2192 A A A do not see writes...\nB close() A A\nclose() B \u271aA B ... until close()\nB open(F) B B has taken place\nB read() \u2192 B B B\nB close() B B\nB open(F) B B\nopen(F) B B B\nwrite(D) D B B\nD write(C) C B\nD close() C C\nclose() D \u2701C D\nD open(F) D D Unfortunately for P 3\nD read() \u2192 D D D the last writer wins\nD close() D D\nFigure 50.3: Cache Consistency Timeline\nvalid. This step ensures that clients will no longer read stal e copies of\nthe \ufb01le; subsequent opens on those clients will require a re-fet ch of the\nnew version of the \ufb01le from the server (and will also serve to rees tablish\na callback on the new version of the \ufb01le).\nAFS makes an exception to this simple model between processes on\nthe same machine. In this case, writes to a \ufb01le are immediatel y visible to\nother local processes (i.e., a process does not have to wait until a \ufb01 le is\nclosed to see its latest updates). This makes using a single ma chine be-\nhave exactly as you would expect, as this behavior is based upon ty pical\nUN I X semantics. Only when switching to a different machine would y ou\nbe able to detect the more general AFS consistency mechanism.\nThere is one interesting cross-machine case that is worthy of fur ther\ndiscussion. Speci\ufb01cally , in the rare case that processes on diff erent ma-\nchines are modifying a \ufb01le at the same time, AFS naturally empl oys what\nis known as a last writer wins approach (which perhaps should be called\nlast closer wins ). Speci\ufb01cally , whichever client calls close() last will\nupdate the entire \ufb01le on the server last and thus will be the \u201cwi nning\u201d\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "open(F) - - - File created",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "open",
          "file",
          "created"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "be able to detect the more general AFS consistency mechanism.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "able",
          "detect",
          "general",
          "consistency",
          "mechanism"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "is known as a last writer wins approach (which perhaps should be called",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "known",
          "last",
          "writer",
          "wins",
          "approach",
          "perhaps",
          "called"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand 3: Cache Consistency Timeline",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "3",
          "cache",
          "consistency",
          "timeline"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "6 Crash Recovery",
    "document_source": "book.pdf",
    "start_line": 18,
    "type": "chapter",
    "content": "50.6 Crash Recovery\nFrom the description above, you might sense that crash recovery is\nmore involved than with NFS. Y ou would be right. For example, imagin e\nthere is a short period of time where a server (S) is not able to contac t\na client (C1), for example, while the client C1 is rebooting. Whi le C1\nis not available, S may have tried to send it one or more callback re call\nmessages; for example, imagine C1 had \ufb01le F cached on its local di sk, and\nthen C2 (another client) updated F , thus causing S to send mess ages to all\nclients caching the \ufb01le to remove it from their local caches. Bec ause C1\nmay miss those critical messages when it is rebooting, upon rejoin ing the\nsystem, C1 should treat all of its cache contents as suspect. Thu s, upon\nthe next access to \ufb01le F , C1 should \ufb01rst ask the server (with a T e stAuth\nprotocol message) whether its cached copy of \ufb01le F is still valid; i f so, C1\ncan use it; if not, C1 should fetch the newer version from the serve r .\nServer recovery after a crash is also more complicated. The proble m\nthat arises is that callbacks are kept in memory; thus, when a s erver re-\nboots, it has no idea which client machine has which \ufb01les. Thus, upon\nserver restart, each client of the server must realize that th e server has\ncrashed and treat all of their cache contents as suspect, and (a s above)\nreestablish the validity of a \ufb01le before using it. Thus, a serve r crash is a\nbig event, as one must ensure that each client is aware of the cra sh in a\ntimely manner , or risk a client accessing a stale \ufb01le. There ar e many ways\nto implement such recovery; for example, by having the server s end a\nmessage (saying \u201cdon\u2019t trust your cache contents!\u201d) to each clien t when\nit is up and running again, or by having clients check that the s erver is\nalive periodically (with a heartbeat message, as it is called). As you can\nsee, there is a cost to building a more scalable and sensible cac hing model;\nwith NFS, clients hardly noticed a server crash.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "there is a short period of time where a server (S) is not able to contac t",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "short",
          "period",
          "time",
          "server",
          "able",
          "contac"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "may miss those critical messages when it is rebooting, upon rejoin ing the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "miss",
          "critical",
          "messages",
          "rebooting",
          "upon",
          "rejoin"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "to implement such recovery; for example, by having the server s end a",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "implement",
          "recovery",
          "example",
          "server"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand crash recovery",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "crash",
          "recovery"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Small \ufb01le, sequential read Ns \u00b7 Lnet Ns \u00b7 Lnet 1",
    "document_source": "book.pdf",
    "start_line": 3,
    "type": "chapter",
    "content": "1. Small \ufb01le, sequential read Ns \u00b7 Lnet Ns \u00b7 Lnet 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Small \ufb01le, sequential re-read Ns \u00b7 Lmem Ns \u00b7 Lmem 1",
    "document_source": "book.pdf",
    "start_line": 4,
    "type": "chapter",
    "content": "2. Small \ufb01le, sequential re-read Ns \u00b7 Lmem Ns \u00b7 Lmem 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Medium \ufb01le, sequential read Nm \u00b7 Lnet Nm \u00b7 Lnet 1",
    "document_source": "book.pdf",
    "start_line": 5,
    "type": "chapter",
    "content": "3. Medium \ufb01le, sequential read Nm \u00b7 Lnet Nm \u00b7 Lnet 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "4",
    "title": "Medium \ufb01le, sequential re-read Nm \u00b7 Lmem Nm \u00b7 Lmem 1",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "4. Medium \ufb01le, sequential re-read Nm \u00b7 Lmem Nm \u00b7 Lmem 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_5",
    "number": "5",
    "title": "Large \ufb01le, sequential read NL \u00b7 Lnet NL \u00b7 Lnet 1",
    "document_source": "book.pdf",
    "start_line": 7,
    "type": "chapter",
    "content": "5. Large \ufb01le, sequential read NL \u00b7 Lnet NL \u00b7 Lnet 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_6",
    "number": "6",
    "title": "Large \ufb01le, sequential re-read NL \u00b7 Lnet NL \u00b7 Ldisk",
    "document_source": "book.pdf",
    "start_line": 8,
    "type": "chapter",
    "content": "6. Large \ufb01le, sequential re-read NL \u00b7 Lnet NL \u00b7 Ldisk\nLdisk\nLnet",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_7",
    "number": "7",
    "title": "Large \ufb01le, single read Lnet NL \u00b7 Lnet NL",
    "document_source": "book.pdf",
    "start_line": 11,
    "type": "chapter",
    "content": "7. Large \ufb01le, single read Lnet NL \u00b7 Lnet NL",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_8",
    "number": "8",
    "title": "Small \ufb01le, sequential write Ns \u00b7 Lnet Ns \u00b7 Lnet 1",
    "document_source": "book.pdf",
    "start_line": 12,
    "type": "chapter",
    "content": "8. Small \ufb01le, sequential write Ns \u00b7 Lnet Ns \u00b7 Lnet 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_9",
    "number": "9",
    "title": "Large \ufb01le, sequential write NL \u00b7 Lnet NL \u00b7 Lnet 1",
    "document_source": "book.pdf",
    "start_line": 13,
    "type": "chapter",
    "content": "9. Large \ufb01le, sequential write NL \u00b7 Lnet NL \u00b7 Lnet 1",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_10",
    "number": "10",
    "title": "Large \ufb01le, sequential overwrite NL \u00b7 Lnet 2 \u00b7 NL \u00b7 Lnet 2",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "10. Large \ufb01le, sequential overwrite NL \u00b7 Lnet 2 \u00b7 NL \u00b7 Lnet 2",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_11",
    "number": "11",
    "title": "Large \ufb01le, single write Lnet 2 \u00b7 NL \u00b7 Lnet 2 \u00b7 NL",
    "document_source": "book.pdf",
    "start_line": 15,
    "type": "chapter",
    "content": "11. Large \ufb01le, single write Lnet 2 \u00b7 NL \u00b7 Lnet 2 \u00b7 NL\nFigure 50.4: Comparison: AFS vs. NFS",
    "learning_concepts": [
      {
        "id": "key_term_1",
        "text": "understand 4: Comparison: AFS vs. NFS",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "4",
          "comparison"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_12",
    "number": "50",
    "title": "7 Scale And Performance Of AFSv2",
    "document_source": "book.pdf",
    "start_line": 17,
    "type": "chapter",
    "content": "50.7 Scale And Performance Of AFSv2\nWith the new protocol in place, AFSv2 was measured and found to be\nmuch more scalable that the original version. Indeed, each serv er could\nsupport about 50 clients (instead of just 20). A further bene\ufb01t w as that\nclient-side performance often came quite close to local performa nce, be-\ncause in the common case, all \ufb01le accesses were local; \ufb01le reads u sually\nwent to the local disk cache (and potentially , local memory). Onl y when a\nclient created a new \ufb01le or wrote to an existing one was there need to send\na Store message to the server and thus update the \ufb01le with new cont ents.\nLet us also gain some perspective on AFS performance by compar-\ning common \ufb01le-system access scenarios with NFS. Figure 50.4 (pa ge 9)\nshows the results of our qualitative comparison.\nIn the \ufb01gure, we examine typical read and write patterns anal ytically ,\nfor \ufb01les of different sizes. Small \ufb01les have Ns blocks in them; medium\n\ufb01les have Nm blocks; large \ufb01les have NL blocks. W e assume that small\nand medium \ufb01les \ufb01t into the memory of a client; large \ufb01les \ufb01t on a loc al\ndisk but not in client memory .\nW e also assume, for the sake of analysis, that an access across th e net-\nwork to the remote server for a \ufb01le block takes Lnet time units. Access\nto local memory takes Lmem, and access to local disk takes Ldisk. The\ngeneral assumption is that Lnet > Ldisk > Lmem.\nFinally , we assume that the \ufb01rst access to a \ufb01le does not hit in an y\ncaches. Subsequent \ufb01le accesses (i.e., \u201cre-reads\u201d) we assum e will hit in\ncaches, if the relevant cache has enough capacity to hold the \ufb01l e.\nThe columns of the \ufb01gure show the time a particular operation (e.g. , a\nsmall \ufb01le sequential read) roughly takes on either NFS or AFS. The right-\nmost column displays the ratio of AFS to NFS.\nW e make the following observations. First, in many cases, the per -\nformance of each system is roughly equivalent. For example, when \ufb01rst\nreading a \ufb01le (e.g., W orkloads 1, 3, 5), the time to fetch the \ufb01le from the re-\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "client created a new \ufb01le or wrote to an existing one was there need to send",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "created",
          "wrote",
          "existing",
          "need",
          "send"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand scale and performance of afsv2",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "scale",
          "performance"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "10 T H E AN D R E W FI L E SY S T E M (AFS)",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "10 T H E AN D R E W FI L E SY S T E M (AFS)\nmote server dominates, and is similar on both systems. Y ou might th ink\nAFS would be slower in this case, as it has to write the \ufb01le to local disk;\nhowever , those writes are buffered by the local (client-side) \ufb01 le system\ncache and thus said costs are likely hidden. Similarly , you migh t think\nthat AFS reads from the local cached copy would be slower , again be-\ncause AFS stores the cached copy on disk. However , AFS again bene\ufb01 ts\nhere from local \ufb01le system caching; reads on AFS would likely hit i n the\nclient-side memory cache, and performance would be similar to N FS.\nSecond, an interesting difference arises during a large-\ufb01le s equential\nre-read (W orkload 6). Because AFS has a large local disk cache, i t will\naccess the \ufb01le from there when the \ufb01le is accessed again. NFS, in contrast,\nonly can cache blocks in client memory; as a result, if a large \ufb01le (i.e., a \ufb01le\nbigger than local memory) is re-read, the NFS client will have t o re-fetch\nthe entire \ufb01le from the remote server . Thus, AFS is faster than N FS in this\ncase by a factor of Lnet\nLdisk\n, assuming that remote access is indeed slower\nthan local disk. W e also note that NFS in this case increases ser ver load,\nwhich has an impact on scale as well.\nThird, we note that sequential writes (of new \ufb01les) should perfor m\nsimilarly on both systems (W orkloads 8, 9). AFS, in this case, will write\nthe \ufb01le to the local cached copy; when the \ufb01le is closed, the AFS cl ient\nwill force the writes to the server , as per the protocol. NFS will b uffer\nwrites in client memory , perhaps forcing some blocks to the serve r due\nto client-side memory pressure, but de\ufb01nitely writing them t o the server\nwhen the \ufb01le is closed, to preserve NFS \ufb02ush-on-close consistenc y . Y ou\nmight think AFS would be slower here, because it writes all data to local\ndisk. However , realize that it is writing to a local \ufb01le system; those writes\nare \ufb01rst committed to the page cache, and only later (in the back ground)\nto disk, and thus AFS reaps the bene\ufb01ts of the client-side OS me mory\ncaching infrastructure to improve performance.\nFourth, we note that AFS performs worse on a sequential \ufb01le over-\nwrite (W orkload 10). Thus far , we have assumed that the workloads that\nwrite are also creating a new \ufb01le; in this case, the \ufb01le exists , and is then\nover-written. Overwrite can be a particularly bad case for AFS, because\nthe client \ufb01rst fetches the old \ufb01le in its entirety , only to subs equently over-\nwrite it. NFS, in contrast, will simply overwrite blocks and thus avoid the\ninitial (useless) read 2 .\nFinally , workloads that access a small subset of data within lar ge \ufb01les\nperform much better on NFS than AFS (W orkloads 7, 11). In these cas es,\nthe AFS protocol fetches the entire \ufb01le when the \ufb01le is opened; unf ortu-\nnately , only a small read or write is performed. Even worse, if the \ufb01le is\nmodi\ufb01ed, the entire \ufb01le is written back to the server , doubling the per-\n2 W e assume here that NFS writes are block-sized and block-aligned; if t hey were not, the\nNFS client would also have to read the block \ufb01rst. W e also assume the \ufb01 le was not opened\nwith the O TRUNC \ufb02ag; if it had been, the initial open in AFS would not fetch the soon to be\ntruncated \ufb01le\u2019s contents.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "access the \ufb01le from there when the \ufb01le is accessed again. NFS, in contrast,",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "access",
          "accessed",
          "contrast"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "write it. NFS, in contrast, will simply overwrite blocks and thus avoid the",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "write",
          "contrast",
          "simply",
          "overwrite",
          "blocks",
          "thus",
          "avoid"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "8 AFS: Other Improvements",
    "document_source": "book.pdf",
    "start_line": 26,
    "type": "chapter",
    "content": "50.8 AFS: Other Improvements\nLike we saw with the introduction of Berkeley FFS (which added sy m-\nbolic links and a number of other features), the designers of AFS t ook the\nopportunity when building their system to add a number of featur es that\nmade the system easier to use and manage. For example, AFS provi des a\ntrue global namespace to clients, thus ensuring that all \ufb01les were named\nthe same way on all client machines. NFS, in contrast, allows each client\nto mount NFS servers in any way that they please, and thus only by con-\nvention (and great administrative effort) would \ufb01les be named s imilarly\nacross clients.\nAFS also takes security seriously , and incorporates mechanism s to au-\nthenticate users and ensure that a set of \ufb01les could be kept priv ate if a\nuser so desired. NFS, in contrast, had quite primitive support f or security\nfor many years.\nAFS also includes facilities for \ufb02exible user-managed acces s control.\nThus, when using AFS, a user has a great deal of control over who exac tly\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "bolic links and a number of other features), the designers of AFS t ook the",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "bolic",
          "links",
          "number",
          "features",
          "designers"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "the same way on all client machines. NFS, in contrast, allows each client",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "client",
          "machines",
          "contrast",
          "allows",
          "client"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "user so desired. NFS, in contrast, had quite primitive support f or security",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "user",
          "desired",
          "contrast",
          "quite",
          "primitive",
          "support",
          "security"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand afs: other improvements",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "improvements"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "50",
    "title": "9 Summary",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "50.9 Summary\nAFS shows us how distributed \ufb01le systems can be built quite diff er-\nently than what we saw with NFS. The protocol design of AFS is partic -\nularly important; by minimizing server interactions (through whole-\ufb01le\ncaching and callbacks), each server can support many clients and thus\nreduce the number of servers needed to manage a particular sit e. Many\nother features, including the single namespace, security , a nd access-control\nlists, make AFS quite nice to use. The consistency model provide d by AFS\nis simple to understand and reason about, and does not lead to the oc ca-\nsional weird behavior as one sometimes observes in NFS.\nPerhaps unfortunately , AFS is likely on the decline. Because N FS be-\ncame an open standard, many different vendors supported it, and , along\nwith CIFS (the Windows-based distributed \ufb01le system protocol), NFS\ndominates the marketplace. Although one still sees AFS install ations\nfrom time to time (such as in various educational institutions, i ncluding\nWisconsin), the only lasting in\ufb02uence will likely be from the id eas of AFS\nrather than the actual system itself. Indeed, NFSv4 now adds se rver state\n(e.g., an \u201copen\u201d protocol message), and thus bears an increasing similar-\nity to the basic AFS protocol.\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "ently than what we saw with NFS. The protocol design of AFS is partic -",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ently",
          "protocol",
          "design",
          "partic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "ularly important; by minimizing server interactions (through whole-\ufb01le",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "ularly",
          "important",
          "minimizing",
          "server",
          "interactions",
          "whole"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "is simple to understand and reason about, and does not lead to the oc ca-",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "simple",
          "understand",
          "reason",
          "lead"
        ],
        "confidence": 0.9
      },
      {
        "id": "section_concept_1",
        "text": "understand summary",
        "type": "section_concept",
        "difficulty": "beginner",
        "keywords": [
          "summary"
        ],
        "confidence": 0.7
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "TH E AN D R E W FI L E SY S T E M (AFS) 13",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "TH E AN D R E W FI L E SY S T E M (AFS) 13\nReferences\n[B+91] \u201cMeasurements of a Distributed File System\u201d by Mary Baker , John Hartman, Martin\nKupfer , Ken Shirriff, John Ousterhout. SOSP \u201991, Paci\ufb01c Grove, Californi a, October 1991. An\nearly paper measuring how people use distributed \ufb01le systems. Matches m uch of the intuition found in\nAFS.\n[H+11] \u201cA File is Not a File: Understanding the I/O Behavior of Apple Desktop Applications\u201d\nby T yler Harter , Chris Dragga, Michael V aughn, Andrea C. Arpaci-Dusse au, Remzi H. Arpaci-\nDusseau. SOSP \u201911, New Y ork, New Y ork, October 2011. Our own paper studying the behavior of\nApple Desktop workloads; turns out they are a bit different than many of the serv er-based workloads the\nsystems research community usually focuses upon. Also a good recent re ference which points to a lot of\nrelated work.\n[H+88] \u201cScale and Performance in a Distributed File System\u201d by John H. H oward, Michael\nL. Kazar , Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Rober t N. Sidebotham,\nMichael J. W est. ACM T ransactions on Computing Systems (ACM TOCS), V olum e 6:1, Febru-\nary 1988. The long journal version of the famous AFS system, still in use in a number of places\nthroughout the world, and also probably the earliest clear thinking on how to bui ld distributed \ufb01le\nsystems. A wonderful combination of the science of measurement and princ ipled engineering.\n[R+00] \u201cA Comparison of File System W orkloads\u201d by Drew Rosell i, Jacob R. Lorch, Thomas E.\nAnderson. USENIX \u201900, San Diego, California, June 2000. A more recent set of traces as compared\nto the Baker paper [B+91], with some interesting twists.\n[S+85] \u201cThe ITC Distributed File System: Principles and Design\u201d by M. Sa tyanarayanan, J.H.\nHoward, D.A. Nichols, R.N. Sidebotham, A. Spector , M.J. W est. SOSP \u2019 85, Orcas Island, W ash-\nington, December 1985. The older paper about a distributed \ufb01le system. Much of the basic design of\nAFS is in place in this older system, but not the improvements for scale. T he name change to \u201cAndrew\u201d\nis an homage to two people both named Andrew, Andrew Carnegie and Andrew Me llon. These two\nrich dudes started the Carnegie Institute of T echnology and the Mellon Institute of Industrial Research,\nrespectively, which eventually merged to become what is now known as Carn egie Mellon University.\n[V99] \u201cFile system usage in Windows NT 4.0\u201d by W erner V ogels. SOSP \u201999, Kiawah Island\nResort, South Carolina, December 1999. A cool study of Windows workloads, which are inherently\ndifferent than many of the UN I X-based studies that had previously been done.\nc\u20dd 2008\u201319, A R PA C I-D U S S E A U TH R E E\nEA S Y\nPI E C E S",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "[H+11] \u201cA File is Not a File: Understanding the I/O Behavior of Apple Desktop Applications\u201d",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "file",
          "file",
          "understanding",
          "behavior",
          "apple",
          "desktop",
          "applications"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Anderson. USENIX \u201900, San Diego, California, June 2000. A more recent set of traces as compared",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "anderson",
          "usenix",
          "diego",
          "california",
          "june",
          "recent",
          "traces",
          "compared"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "[S+85] \u201cThe ITC Distributed File System: Principles and Design\u201d by M. Sa tyanarayanan, J.H.",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "distributed",
          "file",
          "system",
          "principles",
          "design",
          "tyanarayanan"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_4",
        "text": "ington, December 1985. The older paper about a distributed \ufb01le system. Much of the basic design of",
        "type": "explicit_objective",
        "difficulty": "intermediate",
        "keywords": [
          "ington",
          "december",
          "older",
          "paper",
          "distributed",
          "system",
          "much",
          "basic"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_5",
        "text": "respectively, which eventually merged to become what is now known as Carn egie Mellon University.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "respectively",
          "eventually",
          "merged",
          "become",
          "known",
          "carn",
          "egie",
          "mellon"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Run a few simple cases to make sure you can predict what value s",
    "document_source": "book.pdf",
    "start_line": 6,
    "type": "chapter",
    "content": "1. Run a few simple cases to make sure you can predict what value s\nwill be read by clients. V ary the random seed \ufb02ag ( -s) and see\nif you can trace through and predict both intermediate values as\nwell as the \ufb01nal values stored in the \ufb01les. Also vary the number of\n\ufb01les ( -f), the number of clients ( -C), and the read ratio ( -r, from\nbetween 0 to 1) to make it a bit more challenging. Y ou might also\nwant to generate slightly longer traces to make for more interes ting\ninteractions, e.g., ( -n 2 or higher).",
    "learning_concepts": []
  },
  {
    "id": "book.pdf_chapter_2",
    "number": "2",
    "title": "Now do the same thing and see if you can predict each callback t hat",
    "document_source": "book.pdf",
    "start_line": 14,
    "type": "chapter",
    "content": "2. Now do the same thing and see if you can predict each callback t hat\nthe AFS server initiates. T ry different random seeds, and mak e sure\nto use a high level of detailed feedback (e.g., -d 3) to see when call-\nbacks occur when you have the program compute the answers for\nyou (with -c). Can you guess exactly when each callback occurs?\nWhat is the precise condition for one to take place?",
    "learning_concepts": [
      {
        "id": "question_concept_1",
        "text": "understand the precise condition for one to take place",
        "type": "question_concept",
        "difficulty": "beginner",
        "keywords": [
          "precise",
          "condition",
          "take",
          "place"
        ],
        "confidence": 0.5
      }
    ]
  },
  {
    "id": "book.pdf_chapter_3",
    "number": "3",
    "title": "Similar to above, run with some different random seeds and see i f",
    "document_source": "book.pdf",
    "start_line": 20,
    "type": "chapter",
    "content": "3. Similar to above, run with some different random seeds and see i f\nyou can predict the exact cache state at each step. Cache state can\nbe observed by running with -c and -d 7.\n4. Now let\u2019s construct some speci\ufb01c workloads. Run the simulation\nwith -A oa1:w1:c1,oa1:r1:c1 \ufb02ag. What are different possi-\nble values observed by client 1 when it reads the \ufb01le a, when run-\nning with the random scheduler? (try different random seeds to\nsee different outcomes)? Of all the possible schedule interlea vings\nof the two clients\u2019 operations, how many of them lead to client 1\nreading the value 1, and how many reading the value 0?\n5. Now let\u2019s construct some speci\ufb01c schedules. When running with\nthe -A oa1:w1:c1,oa1:r1:c1 \ufb02ag, also run with the following\nschedules: -S 01, -S 100011, -S 011100, and others of which\nyou can think. What value will client 1 read?",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "see different outcomes)? Of all the possible schedule interlea vings",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "different",
          "outcomes",
          "possible",
          "schedule",
          "interlea",
          "vings"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_1",
        "text": "understand A oa1: w1:c1,oa1:r1:c1 \ufb02ag. What are different possi-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a oa1",
          "different",
          "possi"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_2",
        "text": "understand A oa1: w1:c1,oa1:r1:c1 \ufb02ag, also run with the following",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "a oa1",
          "also",
          "following"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_3",
        "text": "understand schedules: -S 01, -S 100011, -S 011100, and others of which",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "schedules",
          "others"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_4",
    "number": "6",
    "title": "Now run with this workload: -A oa1:w1:c1,oa1:w1:c1, and",
    "document_source": "book.pdf",
    "start_line": 34,
    "type": "chapter",
    "content": "6. Now run with this workload: -A oa1:w1:c1,oa1:w1:c1, and\nvary the schedules as above. What happens when you run with -S\n011100? What about when you run with -S 010011? What is\nimportant in determining the \ufb01nal value of the \ufb01le?\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N 1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "important in determining the \ufb01nal value of the \ufb01le?",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "important",
          "determining",
          "value"
        ],
        "confidence": 0.9
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "Section 1",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "51\nSummary Dialogue on Distribution\nStudent: Well, that was quick. T oo quick, in my opinion!\nProfessor: Y es, distributed systems are complicated and cool and well worth\nyour study; just not in this book (or course).\nStudent: That\u2019s too bad; I wanted to learn more! But I did learn a few things.\nProfessor: Like what?\nStudent: Well, everything can fail.\nProfessor: Good start.\nStudent: But by having lots of these things (whether disks, machines, or wha t-\never), you can hide much of the failure that arises.\nProfessor: Keep going!\nStudent: Some basic techniques like retrying are really useful.\nProfessor: That\u2019s true.\nStudent: And you have to think carefully about protocols: the exact bits that\nare exchanged between machines. Protocols can affect everything , including how\nsystems respond to failure and how scalable they are.\nProfessor: Y ou really are getting better at this learning stuff.\nStudent: Thanks! And you\u2019re not a bad teacher yourself!\nProfessor: Well thank you very much too.\nStudent: So is this the end of the book?\nProfessor: I\u2019m not sure. They don\u2019t tell me anything.\nStudent: Me neither . Let\u2019s get out of here.\nProfessor: OK.\nStudent: Go ahead.\nProfessor: No, after you.\nStudent: Please, professors \ufb01rst.\n1",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: That\u2019s too bad; I wanted to learn more! But I did learn a few things.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "wanted",
          "learn",
          "learn",
          "things"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Student: Some basic techniques like retrying are really useful.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "basic",
          "techniques",
          "like",
          "retrying",
          "really",
          "useful"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_3",
        "text": "Professor: Y ou really are getting better at this learning stuff.",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "really",
          "getting",
          "better",
          "learning",
          "stuff"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_2",
        "text": "understand Professor: Y es, distributed systems are complicated and cool and well worth",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "distributed",
          "systems",
          "complicated",
          "cool",
          "well",
          "worth"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_5",
        "text": "understand Student: Well, everything can fail.",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "well",
          "everything",
          "fail"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_7",
        "text": "understand Student: But by having lots of these things (whether disks, machines, or wha t-",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "lots",
          "things",
          "whether",
          "disks",
          "machines"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_11",
        "text": "understand Student: And you have to think carefully about protocols: the exact bits that",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "think",
          "carefully",
          "protocols",
          "exact",
          "bits"
        ],
        "confidence": 0.8
      },
      {
        "id": "key_term_13",
        "text": "understand Student: Thanks! And you\u2019re not a bad teacher yourself!",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "thanks",
          "teacher"
        ],
        "confidence": 0.8
      }
    ]
  },
  {
    "id": "book.pdf_chapter_1",
    "number": "1",
    "title": "2 S U M M A RYDI A L O G U E O NDI S T R I B U T I...",
    "document_source": "book.pdf",
    "start_line": 0,
    "type": "chapter",
    "content": "2 S U M M A RYDI A L O G U E O NDI S T R I B U T I O N\nProfessor: No, please, after you.\nStudent: (exasperated) Fine!\nProfessor: (waiting) ... so why haven\u2019t you left?\nStudent: I don\u2019t know how. T urns out, the only thing I can do is participate in\nthese dialogues.\nProfessor: Me too. And now you\u2019ve learned our \ufb01nal lesson...\nOP E R AT I N G\nSY S T E M S\n[V E R S I O N1.01]\nW W W.O S T E P.O R G",
    "learning_concepts": [
      {
        "id": "explicit_obj_1",
        "text": "Student: I don\u2019t know how. T urns out, the only thing I can do is participate in",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "student",
          "know",
          "urns",
          "thing",
          "participate"
        ],
        "confidence": 0.9
      },
      {
        "id": "explicit_obj_2",
        "text": "Professor: Me too. And now you\u2019ve learned our \ufb01nal lesson...",
        "type": "explicit_objective",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "learned",
          "lesson"
        ],
        "confidence": 0.9
      },
      {
        "id": "key_term_3",
        "text": "understand Professor: (waiting) ... so why haven\u2019t you left?",
        "type": "key_term",
        "difficulty": "beginner",
        "keywords": [
          "professor",
          "waiting",
          "left"
        ],
        "confidence": 0.8
      }
    ]
  }
]